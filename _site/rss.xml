<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">
<channel>
        <title>turboFei's blog</title>
        <description>turboFei's blog - turboFei</description>
        <link>http://www.turbofei.wang</link>
        <link>http://www.turbofei.wang</link>
        <lastBuildDate>2024-11-28T19:02:57-08:00</lastBuildDate>
        <pubDate>2024-11-28T19:02:57-08:00</pubDate>
        <ttl>1800</ttl>


        <item>
                <title>Automating Celeborn with RESTful API</title>
                <description>
&lt;p&gt;Table of contents&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#introduction&quot; id=&quot;markdown-toc-introduction&quot;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#celeborn-master-management&quot; id=&quot;markdown-toc-celeborn-master-management&quot;&gt;Celeborn Master Management&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#pre-restart-workflow-for-master-pod&quot; id=&quot;markdown-toc-pre-restart-workflow-for-master-pod&quot;&gt;Pre-Restart Workflow for Master Pod&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#1-check-the-status-of-the-celeborn-master-cluster&quot; id=&quot;markdown-toc-1-check-the-status-of-the-celeborn-master-cluster&quot;&gt;1. Check the Status of the Celeborn Master Cluster&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#2-create-celeborn-master-ratis-snapshot&quot; id=&quot;markdown-toc-2-create-celeborn-master-ratis-snapshot&quot;&gt;2. Create Celeborn Master Ratis Snapshot&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#3-perform-celeborn-master-failover-and-check-as-needed&quot; id=&quot;markdown-toc-3-perform-celeborn-master-failover-and-check-as-needed&quot;&gt;3. Perform Celeborn Master Failover and Check as Needed&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#post-restart-workflow-for-master-pod&quot; id=&quot;markdown-toc-post-restart-workflow-for-master-pod&quot;&gt;Post-Restart Workflow for Master Pod&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#celeborn-worker-management&quot; id=&quot;markdown-toc-celeborn-worker-management&quot;&gt;Celeborn Worker Management&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#worker-decommission&quot; id=&quot;markdown-toc-worker-decommission&quot;&gt;Worker Decommission&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#1-exclude-worker&quot; id=&quot;markdown-toc-1-exclude-worker&quot;&gt;1. Exclude Worker&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#2-send-decommissionthenidle-event-and-wait-for-worker-to-enter-idle-state&quot; id=&quot;markdown-toc-2-send-decommissionthenidle-event-and-wait-for-worker-to-enter-idle-state&quot;&gt;2. Send &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DecommissionThenIdle&lt;/code&gt; Event and Wait for Worker to Enter IDLE State&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#3-graceful-shutdown&quot; id=&quot;markdown-toc-3-graceful-shutdown&quot;&gt;3. Graceful Shutdown&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#worker-recommission&quot; id=&quot;markdown-toc-worker-recommission&quot;&gt;Worker Recommission&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#summary&quot; id=&quot;markdown-toc-summary&quot;&gt;Summary&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;introduction&quot;&gt;Introduction&lt;/h3&gt;

&lt;p&gt;Apache Celeborn is a unified big data intermediate service dedicated to improving the efficiency and elasticity of different map-reduce engines. It provides an elastic, high-efficient management service for intermediate data, including shuffle data, spilled data, result data, etc. Currently, Celeborn is focusing on shuffle data.&lt;/p&gt;

&lt;p&gt;In order to improve the elasticity of Spark on Kubernetes and solve the flexibility and stability issues of External Shuffle Service, eBay introduced Celeborn as a Remote Shuffle Service.&lt;/p&gt;

&lt;p&gt;The Celeborn cluster itself consists of two components: Celeborn Master and Celeborn Worker. The Worker is responsible for data read and write and reports various information to the Master through heartbeat. The Master ensures the consistency of cluster data through the raft protocol.&lt;/p&gt;

&lt;p&gt;For Celeborn Master, we deploy it in a Cloud Native manner. Celeborn Worker is co-located with the NodeManager of existing compute nodes and managed by systemctl. Currently, the largest cluster has nearly 6000 Celeborn Workers.&lt;/p&gt;

&lt;p&gt;Due to the large scale of the cluster and the need to patch the OS of the cluster’s Pods every month, meaning the Worker Pods will restart once a month, we need to manage the Celeborn cluster through automation tools to better ensure the stability of the cluster.&lt;/p&gt;

&lt;p&gt;Therefore, we have optimized Celeborn’s &lt;a href=&quot;https://celeborn.apache.org/docs/latest/restapi/&quot;&gt;RESTful API&lt;/a&gt; for better integration with automation tools. These improvements will be available in version 0.6.0, along with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;celeborn-openapi-client&lt;/code&gt; SDK to assist users in interacting with the new RESTful APIs.
Additionally, since Celeborn 0.5.0, you can view the Swagger UI at &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;http://host:port/swagger&lt;/code&gt; to better understand the usage of the API.&lt;/p&gt;

&lt;p&gt;This article will introduce how we integrate automation tools to manage the Celeborn cluster based on the latest RESTful API, without detailing other aspects.&lt;/p&gt;

&lt;h3 id=&quot;celeborn-master-management&quot;&gt;Celeborn Master Management&lt;/h3&gt;

&lt;p&gt;For Celeborn Master, we deploy it on Kubernetes. There is an agent container in the Master pod that communicates with automation tools before and after the restart, triggering the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;podPreStart&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;podPostStart&lt;/code&gt; workflows to determine whether the restart can proceed and whether the service is functioning normally after the restart.&lt;/p&gt;

&lt;h4 id=&quot;pre-restart-workflow-for-master-pod&quot;&gt;Pre-Restart Workflow for Master Pod&lt;/h4&gt;

&lt;p&gt;Below is the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;podPreStart&lt;/code&gt; workflow diagram. First, we determine whether it is within the SLA window. If it is, we wait.
&lt;img src=&quot;/imgs/celeborn/podPreStart.png&quot; width=&quot;500&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;1-check-the-status-of-the-celeborn-master-cluster&quot;&gt;1. Check the Status of the Celeborn Master Cluster&lt;/h5&gt;
&lt;ol&gt;
  &lt;li&gt;Since the Master ensures data consistency based on the RAFT protocol, the number of Masters before the restart must be greater than half of the total number plus one. We determine the number of Masters through Prometheus metrics.&lt;/li&gt;
  &lt;li&gt;Check that the current cluster has a Master leader by calling the Master API &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GET /api/v1/masters&lt;/code&gt; and checking the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;leader&lt;/code&gt; field in the response.
&lt;img src=&quot;/imgs/celeborn/masters.png&quot; width=&quot;800&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;Confirm that the group size of the current Master cluster is as expected by checking the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;masterCommitInfo&lt;/code&gt; field’s size in the response.&lt;/li&gt;
  &lt;li&gt;Check that the commit index of the current active Masters is consistent by checking the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;commitIndex&lt;/code&gt; field in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;masterCommitInfo&lt;/code&gt; of the response. If the gap in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;commitIndex&lt;/code&gt; is greater than a certain threshold, wait.&lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&quot;2-create-celeborn-master-ratis-snapshot&quot;&gt;2. Create Celeborn Master Ratis Snapshot&lt;/h5&gt;

&lt;p&gt;Ratis is a Java implementation of the Raft protocol. Celeborn uses Ratis to ensure data consistency in the Master cluster. To quickly recover data after a restart, we create a Ratis snapshot before the restart.&lt;/p&gt;

&lt;p&gt;Previously, the Celeborn community provided Ratis-shell to manage the Ratis cluster. To better integrate with automation tools, we implemented all Ratis-shell commands as RESTful APIs, facilitating Master failover and Ratis snapshot creation.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/celeborn/ratis-rest.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Create a snapshot by calling &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;POST /api/v1/ratis/snapshot/create&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/celeborn/ratis-snapshot.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;3-perform-celeborn-master-failover-and-check-as-needed&quot;&gt;3. Perform Celeborn Master Failover and Check as Needed&lt;/h5&gt;

&lt;p&gt;If the current Master pod is the leader, perform a failover.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Pause the current pod’s leader election by calling &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;POST /api/v1/ratis/election/pause&lt;/code&gt;.
&lt;img src=&quot;/imgs/celeborn/ratis-election-pause.png&quot; width=&quot;800&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;Step down the current pod’s leader by calling &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;POST /api/v1/ratis/election/step_down&lt;/code&gt;.
&lt;img src=&quot;/imgs/celeborn/ratis-election-stepdown.png&quot; width=&quot;800&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;After waiting for a while, resume the current pod’s leader election by calling &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;POST /api/v1/ratis/election/resume&lt;/code&gt;.
&lt;img src=&quot;/imgs/celeborn/ratis-election-resume.png&quot; width=&quot;800&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;Recheck the status of the current Master cluster and ensure the leader has changed, meaning the current pod is no longer the leader.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;You can also trigger a Master failover separately by calling &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;POST /api/v1/ratis/election/transfer&lt;/code&gt; to transfer the leader to a specified Master.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/celeborn/ratis-election-transfer.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;post-restart-workflow-for-master-pod&quot;&gt;Post-Restart Workflow for Master Pod&lt;/h4&gt;

&lt;p&gt;Below is the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;podPostStart&lt;/code&gt; workflow diagram:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Check if the pod is ready, such as whether the hostname and VIP are normal.&lt;/li&gt;
  &lt;li&gt;Perform some initialization operations, such as loading the configuration.&lt;/li&gt;
  &lt;li&gt;Check the status of the current Master cluster, which is similar to the pre-restart check. The only difference is that after the restart, it is only necessary to ensure that the number of active Masters is greater than half of the total number.
&lt;img src=&quot;/imgs/celeborn/podPostStart.png&quot; width=&quot;400&quot; /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;celeborn-worker-management&quot;&gt;Celeborn Worker Management&lt;/h3&gt;

&lt;p&gt;Automation tools periodically call the Master’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GET /api/v1/workers&lt;/code&gt; to get the status of all registered Workers, including &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lostWorkers&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;excludedWorkers&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;manualExcludedWorkers&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;shutdownWorkers&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;decommissionWorkers&lt;/code&gt;. We also set &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;celeborn.master.workerUnavailableInfo.expireTimeout=-1&lt;/code&gt; so that even if a Worker is offline for a long time, its information will not be cleared (you can call &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/api/v1/workers/remove_unavailable&lt;/code&gt; to clean up as needed).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/celeborn/workers.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;worker-decommission&quot;&gt;Worker Decommission&lt;/h4&gt;

&lt;h5 id=&quot;1-exclude-worker&quot;&gt;1. Exclude Worker&lt;/h5&gt;

&lt;p&gt;First, call the Master’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;POST /api/v1/workers/exclude&lt;/code&gt; to add the Worker information to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;add&lt;/code&gt; field, adding the Worker to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;manualExcludedWorkers&lt;/code&gt; list so that the Master will no longer assign slots to this Worker.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/celeborn/exclude-worker.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;2-send-decommissionthenidle-event-and-wait-for-worker-to-enter-idle-state&quot;&gt;2. Send &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DecommissionThenIdle&lt;/code&gt; Event and Wait for Worker to Enter IDLE State&lt;/h5&gt;

&lt;p&gt;Currently, Celeborn Master supports event types such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;None&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Immediately&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Decommission&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DecommissionThenIdle&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Graceful&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Recommission&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;For decommissioning, the event types are &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Decommission&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DecommissionThenIdle&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The following diagram shows some Worker states and the transitions between events. The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Decommission&lt;/code&gt; event will exit the Worker process after completion, while the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DecommissionThenIdle&lt;/code&gt; event will make the Worker enter the IDLE state after completion.&lt;/p&gt;

&lt;p&gt;Since the Worker process will be automatically restarted by systemctl after exiting, we choose to use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DecommissionThenIdle&lt;/code&gt; event for decommissioning to better control the Worker’s state.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/celeborn/worker-states.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Call the Master’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;POST /api/v1/workers/events&lt;/code&gt; with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;eventType&lt;/code&gt; set to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DecommissionThenIdle&lt;/code&gt; to send the decommission event and wait for the Worker to enter the IDLE state.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/celeborn/worker-decom.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;3-graceful-shutdown&quot;&gt;3. Graceful Shutdown&lt;/h5&gt;

&lt;p&gt;After the Worker enters the IDLE state, check the Worker’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;resourceConsumptions&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;resourceConsumptions&lt;/code&gt; is a map where the key is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;userIdentifier&lt;/code&gt; and the value is the user’s resource usage, including &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;diskBytesWritten&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;diskFileCount&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hdfsBytesWritten&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hdfsFileCount&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;subResourceConsumptions&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;subResourceConsumptions&lt;/code&gt; is also a map where the key is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;applicationId&lt;/code&gt; and the value is the application’s resource usage.&lt;/p&gt;

&lt;p&gt;We determine whether the Worker has released all shuffle files by checking that there are no non-empty &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;resourceConsumption&lt;/code&gt; entries in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;subResourceConsumptions&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;If the Worker has released all shuffle files, it can be gracefully shut down. Otherwise, continue to wait until the waiting time reaches a specified threshold.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/celeborn/worker-resource-consumptions.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;worker-recommission&quot;&gt;Worker Recommission&lt;/h4&gt;

&lt;p&gt;To re-add a Worker to the cluster, simply call the Master’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;POST /api/v1/workers/exclude&lt;/code&gt; and put the Worker information in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;remove&lt;/code&gt; field to remove the Worker from the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;manualExcludedWorkers&lt;/code&gt; list, allowing it to assign slots again.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/celeborn/exclude-worker.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;

&lt;p&gt;This article introduces some practices for automating the management of Celeborn clusters based on the latest RESTful API, with all API calls accessing the Master’s API.&lt;/p&gt;
</description>
                <link>http://www.turbofei.wang/celeborn/2024/11/28/automating-celeborn-with-restful-api</link>
                <guid>http://www.turbofei.wang/celeborn/2024/11/28/automating-celeborn-with-restful-api</guid>
                <pubDate>2024-11-28T00:00:00-08:00</pubDate>
        </item>

        <item>
                <title>基于Celeborn RESTful API进行自动化工具集成</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#前言&quot; id=&quot;markdown-toc-前言&quot;&gt;前言&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#celeborn-master-管理&quot; id=&quot;markdown-toc-celeborn-master-管理&quot;&gt;Celeborn Master 管理&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#master-pod重启前流程&quot; id=&quot;markdown-toc-master-pod重启前流程&quot;&gt;Master Pod重启前流程&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#1-检查-celeborn-master-集群的状态&quot; id=&quot;markdown-toc-1-检查-celeborn-master-集群的状态&quot;&gt;1. 检查 Celeborn Master 集群的状态&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#2-创建-celeborn-master-ratis-快照&quot; id=&quot;markdown-toc-2-创建-celeborn-master-ratis-快照&quot;&gt;2. 创建 Celeborn Master Ratis 快照&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#3-按需进行celeborn-mastere-failover以及检查&quot; id=&quot;markdown-toc-3-按需进行celeborn-mastere-failover以及检查&quot;&gt;3. 按需进行Celeborn Mastere Failover以及检查&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#master-pod重启后流程&quot; id=&quot;markdown-toc-master-pod重启后流程&quot;&gt;Master Pod重启后流程&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#celeborn-worker-管理&quot; id=&quot;markdown-toc-celeborn-worker-管理&quot;&gt;Celeborn Worker 管理&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#worker-decommission&quot; id=&quot;markdown-toc-worker-decommission&quot;&gt;Worker decommission&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#1-exclude-worker&quot; id=&quot;markdown-toc-1-exclude-worker&quot;&gt;1. Exclude Worker&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#2-发送-decommissionthenidle-event-并等待worker进入idle-状态&quot; id=&quot;markdown-toc-2-发送-decommissionthenidle-event-并等待worker进入idle-状态&quot;&gt;2. 发送 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DecommissionThenIdle&lt;/code&gt; event 并等待Worker进入IDLE 状态&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#3-graceful-shutdown&quot; id=&quot;markdown-toc-3-graceful-shutdown&quot;&gt;3. Graceful Shutdown&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#worker-recommission&quot; id=&quot;markdown-toc-worker-recommission&quot;&gt;Worker recommission&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#总结&quot; id=&quot;markdown-toc-总结&quot;&gt;总结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;前言&quot;&gt;前言&lt;/h3&gt;

&lt;p&gt;Apache Celeborn 是一个统一的大数据中间服务，致力于提高不同MapReduce引擎的效率和弹性，并为中间数据（包括shuffle数据、溢出数据、结果数据等）提供弹性、高效的管理服务。目前，Celeborn专注于shuffle数据。&lt;/p&gt;

&lt;p&gt;为了Spark on Kubernetes的弹性以及解决External Shuffle Service的灵活性和稳定性不足，eBay引入 Celeborn 作为Remote Shuffle Service。&lt;/p&gt;

&lt;p&gt;Celeborn 集群本身分为两个组件，Celeborn Master 和 Celeborn Worker, Worker负责处理数据的读写，并通过心跳将各种信息汇报给 Master, 然后Master通过raft 协议保证集群数据的一致性。&lt;/p&gt;

&lt;p&gt;对于Celeborn Master，我们进行Cloud Native部署， Celeborn Worker与现有的计算节点的NodeManager进行混布，使用systemctl管理Worker服务进程, 目前最大的集群大概有接近6000台 Celeborn Worker。&lt;/p&gt;

&lt;p&gt;由于集群规模较大，而且每个月都需要对集群的Pod进行OS patching，也就是说每个月Worker Pod都会重启一次，所以我们需要通过自动化工具来管理Celeborn集群，以便更好地保证集群的稳定性。&lt;/p&gt;

&lt;p&gt;因此，我们对 Celeborn 的&lt;a href=&quot;https://celeborn.apache.org/docs/latest/restapi/&quot;&gt;RESTful API&lt;/a&gt; 进行了优化，以便更好地与自动化工具进行集成。这些改进将在 0.6.0 版本中发布，并且 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;celeborn-openapi-client&lt;/code&gt; SDK 也将可用，以帮助用户与新的 RESTful API 进行交互。
另外在 Celeborn 0.5.0 之后就支持通过 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;http://host:port/swagger&lt;/code&gt; 来查看swagger UI, 可以更好地了解API的使用。&lt;/p&gt;

&lt;p&gt;本文将介绍我们如何基于最新的RESTful API集成自动化工具来管理Celeborn集群，其他方面不再详细说明。&lt;/p&gt;

&lt;h3 id=&quot;celeborn-master-管理&quot;&gt;Celeborn Master 管理&lt;/h3&gt;

&lt;p&gt;对于Celeborn Master我们是部署在Kubernetes，在Master pod 里有一个 agent 的container，会在重启前和重启后和自动化工具进行通信，触发 podPreStart 和 podPostStart workflow，来判断是否能够重启以及重启后服务是否正常。&lt;/p&gt;

&lt;h4 id=&quot;master-pod重启前流程&quot;&gt;Master Pod重启前流程&lt;/h4&gt;

&lt;p&gt;下面是 podPreStart workflow 的流程图，首先我们会判断当前是否处于 SLA window，如果是则等待。
&lt;img src=&quot;/imgs/celeborn/podPreStart.png&quot; width=&quot;500&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;1-检查-celeborn-master-集群的状态&quot;&gt;1. 检查 Celeborn Master 集群的状态&lt;/h5&gt;
&lt;ol&gt;
  &lt;li&gt;因为Master基于RAFT协议保证数据的一致性，所以重启前Master 的数量要大于总数量的一半 + 1，Master 数量目前我们是通过Prometheus的Metrics来判断。&lt;/li&gt;
  &lt;li&gt;检查当前集群Master集群拥有Leader，通过call Master API &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GET /api/v1/masters&lt;/code&gt;, 然后检查返回结果&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;leader&lt;/code&gt;字段.
&lt;img src=&quot;/imgs/celeborn/masters.png&quot; width=&quot;800&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;确认当前Master 集群的group size是预期的，检查返回结果的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;masterCommitInfo&lt;/code&gt; 字段的size.&lt;/li&gt;
  &lt;li&gt;检查当前活着的Master的 commit index 是否一致，检查返回结果的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;masterCommitInfo&lt;/code&gt;的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;commitIndex&lt;/code&gt; 字段, 如果 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;commitIndex&lt;/code&gt;的gap大于一定的阈值，则需要等待。&lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&quot;2-创建-celeborn-master-ratis-快照&quot;&gt;2. 创建 Celeborn Master Ratis 快照&lt;/h5&gt;

&lt;p&gt;Ratis是一个Raft 协议的Java实现，Celeborn 使用Ratis来保证Master集群的数据一致性，为了在重启后快速恢复数据，我们会在重启前创建Ratis的快照。&lt;/p&gt;

&lt;p&gt;Celeborn社区之前提供了Ratis-shell来管理ratis 集群，为了更好地和自动化工具进行集成，我们把所有ratis-shell命令都进行了RESTful实现, 方便进行Master的Failover以及创建Ratis快照。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/celeborn/ratis-rest.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;通过调用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;POST /api/v1/ratis/snapshot/create&lt;/code&gt; 来创建快照。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/celeborn/ratis-snapshot.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;3-按需进行celeborn-mastere-failover以及检查&quot;&gt;3. 按需进行Celeborn Mastere Failover以及检查&lt;/h5&gt;

&lt;p&gt;如果当前Master Pod是Leader, 则需要进行Failover。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;暂停当前Pod的Leader选举，调用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;POST /api/v1/ratis/election/pause&lt;/code&gt;。
&lt;img src=&quot;/imgs/celeborn/ratis-election-pause.png&quot; width=&quot;800&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;让出当前Pod的Leader, 调用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;POST /api/v1/ratis/election/step_down&lt;/code&gt;。
  &lt;img src=&quot;/imgs/celeborn/ratis-election-stepdown.png&quot; width=&quot;800&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;等待一段时间之后，恢复当前Pod的Leader选举，调用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;POST /api/v1/ratis/election/resume&lt;/code&gt;。
  &lt;img src=&quot;/imgs/celeborn/ratis-election-resume.png&quot; width=&quot;800&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;重新检查当前Master集群的状态，并确保Leader已经变更，即当前Pod不再是Leader。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;另外也可以单独触发 Master Failover, 调用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;POST /api/v1/ratis/election/transfer&lt;/code&gt; 将leader转移到指定的Master上。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/celeborn/ratis-election-transfer.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;master-pod重启后流程&quot;&gt;Master Pod重启后流程&lt;/h4&gt;

&lt;p&gt;下面是 podPostStart workflow 的流程图:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;检查pod 是否ready，比如 hostname 和 VIP 是否正常。&lt;/li&gt;
  &lt;li&gt;进行一些初始化操作，比如load conf。&lt;/li&gt;
  &lt;li&gt;检查当前Master集群的状态，跟Pod重启前的检查基本一样，唯一不同的是，重启后只需确保活着的Master数量大于总数量的一半即可。
&lt;img src=&quot;/imgs/celeborn/podPostStart.png&quot; width=&quot;400&quot; /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;celeborn-worker-管理&quot;&gt;Celeborn Worker 管理&lt;/h3&gt;

&lt;p&gt;自动化工具会周期性调用 Master的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GET /api/v1/workers&lt;/code&gt; 来获取所有的注册的Worker的状态，包括 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lostWorkers&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;excludedWorkers&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;manualExcludedWorkers&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;shutdownWorkers&lt;/code&gt; 和 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;decommissionWorkers&lt;/code&gt;。
同时我们设置了 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;celeborn.master.workerUnavailableInfo.expireTimeout=-1&lt;/code&gt;, 以便即使Worker长时间下线，其信息也不会被清除掉(可调用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/api/v1/workers/remove_unavailable&lt;/code&gt; 按需清理)。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/celeborn/workers.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;worker-decommission&quot;&gt;Worker decommission&lt;/h4&gt;

&lt;h5 id=&quot;1-exclude-worker&quot;&gt;1. Exclude Worker&lt;/h5&gt;

&lt;p&gt;首先，调用 Master &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;POST /api/v1/workers/exclude&lt;/code&gt; 把worker信息放入 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;add&lt;/code&gt; 字段把worker加入到 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;manualExcludedWorkers&lt;/code&gt; 列表中，这样Master就不会再往这个worker上分配slots。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/celeborn/exclude-worker.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;2-发送-decommissionthenidle-event-并等待worker进入idle-状态&quot;&gt;2. 发送 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DecommissionThenIdle&lt;/code&gt; event 并等待Worker进入IDLE 状态&lt;/h5&gt;

&lt;p&gt;目前Celeborn Master支持的events类型有 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;None&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Immediately&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Decommission&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DecommissionThenIdle&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Graceful&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Recommission&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;用于 Decommission 的event类型有 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Decommission&lt;/code&gt; 和 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DecommissionThenIdle&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;下图是一些Worker State和event之间的转换图，其中 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Decommission&lt;/code&gt; event会在完成之后，退出Worker 进程，而 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DecommissionThenIdle&lt;/code&gt; event 是在完成之后，让Worker进入IDLE状态。&lt;/p&gt;

&lt;p&gt;由于Worker进程在退出之后会被systemctl 自动拉起，所以我们选择使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DecommissionThenIdle&lt;/code&gt; event来进行Decommission操作，以便更好地控制Worker的状态。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/celeborn/worker-states.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;调用 Master &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;POST /api/v1/workers/events&lt;/code&gt;, eventType 为 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DecommissionThenIdle&lt;/code&gt; 来发送Decommission事件, 并等待Worker进入IDLE状态。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/celeborn/worker-decom.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;3-graceful-shutdown&quot;&gt;3. Graceful Shutdown&lt;/h5&gt;

&lt;p&gt;在 Worker 进入IDLE 状态之后，检查Worker的 resourceConsumptions.&lt;/p&gt;

&lt;p&gt;resourceConsumptions 是 一个map，key 为 userIdentifier, value用户的资源占用情况，包括 diskBytesWritten, diskFileCount, hdfsBytesWritten, hdfsFileCount 和 subResourceConsumptions。&lt;/p&gt;

&lt;p&gt;subResourceConsumptions 也是一个map，key 为 applicationId, value是 application的资源占用情况。&lt;/p&gt;

&lt;p&gt;我们通过判断当前Worker 上面不存在 subResourceConsumptions 非空的 resourceConsumption 来判断当前worker是否已经释放所有shuffle文件。&lt;/p&gt;

&lt;p&gt;如果Worker已经释放所有shuffle文件，那么就可以graceful的shutdown当前Worker，否则需要继续等待，直到等待时间到达一个指定的阈值。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/celeborn/worker-resource-consumptions.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;worker-recommission&quot;&gt;Worker recommission&lt;/h4&gt;

&lt;p&gt;当要把一台worker 重新加入到集群中时，只需调用 Master &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;POST /api/v1/workers/exclude&lt;/code&gt; 把 worker信息放入 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;remove&lt;/code&gt; 字段即可将worker 从 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;manualExcludedWorkers&lt;/code&gt; 中移除, 重新接受分配slots。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/celeborn/exclude-worker.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;总结&quot;&gt;总结&lt;/h3&gt;

&lt;p&gt;本文介绍了eBay基于最新RESTful API 进行自动化管理Celeborn集群的一些实践，所有API调用都是访问Master的API。&lt;/p&gt;
</description>
                <link>http://www.turbofei.wang/celeborn/2024/11/01/celeborn-automation</link>
                <guid>http://www.turbofei.wang/celeborn/2024/11/01/celeborn-automation</guid>
                <pubDate>2024-11-01T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>Ebay Kyuubi Spark Engine Big Result Sets Solution</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#前言&quot; id=&quot;markdown-toc-前言&quot;&gt;前言&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#问题分析&quot; id=&quot;markdown-toc-问题分析&quot;&gt;问题分析&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#sql-分类&quot; id=&quot;markdown-toc-sql-分类&quot;&gt;SQL 分类&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#spark读取文件过程&quot; id=&quot;markdown-toc-spark读取文件过程&quot;&gt;Spark读取文件过程&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#针对不需排序的sql结果落地&quot; id=&quot;markdown-toc-针对不需排序的sql结果落地&quot;&gt;针对不需排序的SQL结果落地&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#针对需要排序的sql计算结果落地&quot; id=&quot;markdown-toc-针对需要排序的sql计算结果落地&quot;&gt;针对需要排序的SQL计算结果落地&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#uploaddatadownloaddata-api&quot; id=&quot;markdown-toc-uploaddatadownloaddata-api&quot;&gt;UploadData/DownloadData API&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#uploaddata&quot; id=&quot;markdown-toc-uploaddata&quot;&gt;UploadData&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#downloaddata&quot; id=&quot;markdown-toc-downloaddata&quot;&gt;DownloadData&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#总结&quot; id=&quot;markdown-toc-总结&quot;&gt;总结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本文讲下ebay对于Kyuubi Spark 引擎big result sets场景做的一些优化，如果错误，欢迎指正。&lt;/p&gt;

&lt;h3 id=&quot;前言&quot;&gt;前言&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://www.bilibili.com/video/BV1oa411R7BC/&quot;&gt;eBay基于kyuubi构建spark服务的gateway&lt;/a&gt;，最常见的场景是Spark SQL, 主要分为以下两种:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;用户在BI 工具上面执行sql语句，计算结果会被截断，返回&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kyuubi.operation.result.max.rows&lt;/code&gt;条结果。&lt;/li&gt;
  &lt;li&gt;用户使用JDBC拉取全部计算结果，可能会有几千万条。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;对于第二种场景，如果sql的执行结果集特别大，如果Spark driver将所有计算结果保存在内存中，那么Spark driver会成为瓶颈，非常容易产生OOM。&lt;/p&gt;

&lt;p&gt;因此Kyuubi社区提供了一个&lt;a href=&quot;https://kyuubi.apache.org/docs/latest/deployment/spark/incremental_collection.html?highlight=big%20result&quot;&gt;针对大计算结果集的一个方案&lt;/a&gt;, 可以将&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kyuubi.operation.incremental.collect&lt;/code&gt; 设为true来将原本调用dataFrame的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;collect&lt;/code&gt;方法改为调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;toLocalIterator&lt;/code&gt; 方法。&lt;/p&gt;

&lt;p&gt;dataFrame是分partition的，每个partition对应一个task去执行。&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;collect&lt;/code&gt;方法是将所有task并行执行，然后收集结果。而&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;toLocalIterator&lt;/code&gt;是一个lazy 操作，它是一次计算一个partition的结果，只有在client端需要读取下一部分结果时候，才会计算下一个partition的结果，也就是将所有task串行执行。&lt;/p&gt;

&lt;p&gt;当第一个task完成之后，Kyuubi Spark 引擎就会把这个operation的状态设置为&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FINISHED&lt;/code&gt;, 允许client端&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fetchResults&lt;/code&gt;。比如client端默认每次拉取1000条数据，会发送一条&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TFetchResultsReq&lt;/code&gt;的rpc, 然后Spark端返回当前collect的计算结果，如果不到1000条，就会触发下一个task的计算，直到能够返回client端需要的条数或者所有的task计算完成，然后作为&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TFetchResultsResp&lt;/code&gt;返回，这算一次rpc.&lt;/p&gt;

&lt;p&gt;虽然它保护了Spark driver, 不容易OOM，但是不保证性能，特别是用户的sql比较复杂时候，大大的拉长了计算时间。&lt;/p&gt;

&lt;p&gt;比如说用户的sql对一张大表进行查询，加入了很多过滤条件:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;这个查询创建了大量的partition(task)&lt;/li&gt;
  &lt;li&gt;但是有些partition经过过滤之后，并没有复合条件的结果返回，或者只有几条对应的结果。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这就造成了以下问题:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;串行执行这些大量的partition(task)性能很差&lt;/li&gt;
  &lt;li&gt;有些partition没有符合条件的结果返回，这些无效的计算，延迟到了拉取结果时候&lt;/li&gt;
  &lt;li&gt;可能需要串行计算很多partition(task)，才能返回client需要的条数，造成client端timeout。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;本文讲下，我们针对big result sets场景下做的一些优化。&lt;/p&gt;

&lt;h3 id=&quot;问题分析&quot;&gt;问题分析&lt;/h3&gt;

&lt;p&gt;Kyuubi Spark 大计算结果集场景下，主要有以下问题&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;不能将所有结果都保存在内存中，防止OOM，而且不能入侵Spark内核，去做一些计算结果spill的优化&lt;/li&gt;
  &lt;li&gt;如果使用incremental collect, 延迟计算导致运行时间大大拉长&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对于第一个问题，不能全部放在内存，我们可以将计算结果落地。&lt;/p&gt;

&lt;p&gt;对于第二个问题，延迟计算导致性能问题，我们可以进行预计算，不延迟无效计算，将结果规整的落入文件(每个文件大小相当)，然后在incremental 拉取结果时，让每次拉取，可以读取到期望size的计算结果，避免client端&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TFetchResultsReq&lt;/code&gt; rpc timeout。&lt;/p&gt;

&lt;p&gt;所以，我们做了一些优化，将sql的计算结果，进行预计算，按照预期的size落入hdfs文件，然后在后续的拉取时，依然采用incremental 拉取，按照预期的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;partitionBytes&lt;/code&gt;去split计算结果划分partition(task)，快速拉取。&lt;/p&gt;

&lt;h3 id=&quot;sql-分类&quot;&gt;SQL 分类&lt;/h3&gt;

&lt;p&gt;用户的sql分为以下两种：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;不需排序的SQL&lt;/li&gt;
  &lt;li&gt;需要排序的SQL&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;对于不需要排序的SQL，可以直接将计算结果落盘。&lt;/p&gt;

&lt;p&gt;但是对于需要排序的SQL，不能直接落盘，因为直接落盘之后，再重新读取，顺序是不能保证的。&lt;/p&gt;

&lt;h3 id=&quot;spark读取文件过程&quot;&gt;Spark读取文件过程&lt;/h3&gt;

&lt;p&gt;下面是 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;org.apache.spark.sql.execution.DataSourceScanExec::createNonBucketedReadRDD&lt;/code&gt;的代码，用于在非bucket读取时候创建RDD.&lt;/p&gt;

&lt;p&gt;这里面有两个参数，一个是 maxSplitBytes, 代表一个partition(task)最大处理的bytes 大小，另一个是openCostInBytes,代表打开一个文件所需要的开销。&lt;/p&gt;

&lt;p&gt;可以看到这个方法会把selectedPartitions里面的每个文件，按照maxSplitBytes进行split(如果支持split), 然后flatMap展开，之后按照split之后的length，从大到小排序。&lt;/p&gt;

&lt;p&gt;然后将排序好的splitFiles，构建partitions，构建过程就是把排好序的splitFiles进行合并，如果&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;currentSize + file.length &amp;gt; maxSplitBytes&lt;/code&gt;，那么就把current选择的splitFile(s)作为一个partition，然后两个splitFile 合并之间有一个openCostInBytes的开销。&lt;/p&gt;

&lt;p&gt;所以，即使将计算结果有序的写入多个数据文件中，再次读取的时候，这些结果的顺序也会被打乱。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;cm&quot;&gt;/**
   * Create an RDD for non-bucketed reads.
   * The bucketed variant of this function is [[createBucketedReadRDD]].
   *
   * @param readFile a function to read each (part of a) file.
   * @param selectedPartitions Hive-style partition that are part of the read.
   * @param fsRelation [[HadoopFsRelation]] associated with the read.
   */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;createNonBucketedReadRDD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;readFile&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;PartitionedFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;InternalRow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;],&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;selectedPartitions&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;PartitionDirectory&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;],&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;fsRelation&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;HadoopFsRelation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;RDD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;InternalRow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;openCostInBytes&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;fsRelation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;sparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;sessionState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;filesOpenCostInBytes&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;maxSplitBytes&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;
      &lt;span class=&quot;nv&quot;&gt;FilePartition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;maxSplitBytes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;fsRelation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;sparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;selectedPartitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;logInfo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Planning scan with bin packing, max size: $maxSplitBytes bytes, &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;open cost is considered as scanning $openCostInBytes bytes.&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;splitFiles&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;selectedPartitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;flatMap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partition&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nv&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;files&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;flatMap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;// getPath() is very expensive so we only want to call it once in this block:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;filePath&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;getPath&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;isSplitable&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;relation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;fileFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;isSplitable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
          &lt;span class=&quot;nv&quot;&gt;relation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;sparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;relation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filePath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nv&quot;&gt;PartitionedFileUtil&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;splitFiles&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;sparkSession&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;relation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;sparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;filePath&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filePath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;isSplitable&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;isSplitable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;maxSplitBytes&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maxSplitBytes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;partitionValues&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;values&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;sortBy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;implicitly&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Ordering&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]].&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;reverse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;partitions&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;
      &lt;span class=&quot;nv&quot;&gt;FilePartition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;getFilePartitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;relation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;sparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;splitFiles&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maxSplitBytes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;FileScanRDD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;fsRelation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;sparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;readFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;针对不需排序的sql结果落地&quot;&gt;针对不需排序的SQL结果落地&lt;/h3&gt;

&lt;p&gt;对于不需要排序的sql，我们可以直接将计算结果进行落地，但是为了规整的写入，规整的读出，我们加入了一些参数。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;minFileSize, 这个参数代表可以接受的落盘文件平均大小&lt;/li&gt;
  &lt;li&gt;fileCoalesceNumThreshold， 这个参数代表对文件进行合并的文件数量阈值，如果写出的文件平均size小于minFileSize, 且文件个数大于这个阈值，将会对写出文件进行合并，期待合并的文件大小是下面第三个参数&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;partitonBytes&lt;/code&gt;的值，算出合并之后文件个数之后，将前面写出文件读出再写入到&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Coalesce&lt;/code&gt;路径。&lt;/li&gt;
  &lt;li&gt;partitonBytes， 这个参数代表，在读取落地的计算结果时候，每个partition(task)处理的文件bytes。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;写入过程大概如下:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;根据sql query的schema, 创建一张external parquet分区表(分区键是一个unique的string, 表路径在sessionScrathPath之下)&lt;/li&gt;
  &lt;li&gt;将sql的结果写入到这张表中&lt;/li&gt;
  &lt;li&gt;拿到表路径的content summary, 得到写出文件数量和size，如果复合上面提到的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Coalesce&lt;/code&gt;条件，则对这些文件进行合并&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这里之所以创建分区表，是为了在job 完成commit files时候，可以只用rename 一个partition path而不是去rename所有文件，来减少对hdfs namenode的rpc。&lt;/p&gt;

&lt;p&gt;关于读取过程，先看下Spark代码 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;org.apache.spark.sql.execution.datasources.FilePartition::maxSplitBytes&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;第一个参数 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;defaultMaxSplitBytes&lt;/code&gt; 是从&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.files.maxPartitionBytes&lt;/code&gt;中获得，默认128M。&lt;/p&gt;

&lt;p&gt;第二个参数&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;openCostInBytes&lt;/code&gt; 是从&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.files.openCostInBytes&lt;/code&gt;中获得，默认4M。&lt;/p&gt;

&lt;p&gt;第三个参数 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;minPartitionNum&lt;/code&gt;, 是首先从&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.files.minPartitionNum&lt;/code&gt;中获得，如果未设置，则取&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.default.parallelism&lt;/code&gt;的值，默认是当前&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cores* 2&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;然后&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;totalBytes&lt;/code&gt;是要读取文件的size之和， &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bytesPerCore&lt;/code&gt; 是 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;totalBytes/minPartitionNum&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;最后&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;maxSplitBytes&lt;/code&gt;的结果，会取 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;defaultMaxSplitBytes&lt;/code&gt; 和 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Math.max(openCostInBytes, bytesPerCore)&lt;/code&gt; 之中的最小值。&lt;/p&gt;

&lt;p&gt;也就是说当计算资源很丰富，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cores&lt;/code&gt;很大时候，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bytesPerCore&lt;/code&gt; 会很小，导致得到的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;maxSplitBytes&lt;/code&gt; 会很小。&lt;/p&gt;

&lt;p&gt;比如说，当incremental读取写出去的400M计算结果，而当前cores数量是40， 那么 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bytesPerCore&lt;/code&gt;是5M，默认参数情况下，得到的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;maxSplitBytes&lt;/code&gt; split size也就是5M，那么Spark会至少分配80个task 去串行的读取这个计算结果。&lt;/p&gt;

&lt;p&gt;Spark这样做的目的是为了最大化利用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cores&lt;/code&gt;来快速并行执行，而我们在incremental collect时候，task都是串行。默认情况下&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.files.minPartitionNum&lt;/code&gt;未设置,  当计算资源充足时候，会划分过多的partition, 造成太多的碎片, 拉长读取计算的结果的时间。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;maxSplitBytes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;sparkSession&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;selectedPartitions&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;PartitionDirectory&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;defaultMaxSplitBytes&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;sparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;sessionState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;filesMaxPartitionBytes&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;openCostInBytes&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;sparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;sessionState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;filesOpenCostInBytes&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;minPartitionNum&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;sparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;sessionState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;filesMinPartitionNum&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;getOrElse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;sparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;sparkContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;defaultParallelism&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;totalBytes&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;selectedPartitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;flatMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;files&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;getLen&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;openCostInBytes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;sum&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;bytesPerCore&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;totalBytes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minPartitionNum&lt;/span&gt;

    &lt;span class=&quot;nv&quot;&gt;Math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;defaultMaxSplitBytes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;Math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;openCostInBytes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bytesPerCore&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;所以针对计算结果读取过程，我们做的优化如下:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;根据计算结果的totalSize和上面说的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;partitonBytes&lt;/code&gt; ，将 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;totalSize/partitonBytes&lt;/code&gt; 的结果用来临时去set &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.files.minPartitionNum&lt;/code&gt;（会在operation 结束之后还原), 这样按照&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;partitionBytes&lt;/code&gt;去控制incremental读取计算结果的partition(task)数量，减少碎片，可以快速的返回client结果，避免rpc timeout.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;针对需要排序的sql计算结果落地&quot;&gt;针对需要排序的SQL计算结果落地&lt;/h3&gt;

&lt;p&gt;前面说过，将计算结果落地之后再读取，不能保证有序。&lt;/p&gt;

&lt;p&gt;除非将排序的SQL结果写入一个文件，并且写入的结果要有序。&lt;/p&gt;

&lt;p&gt;所以，针对需要排序的SQL计算结果落地，需要把计算结果写入一个文件，而这必然要求设置一个阈值，将之命名为 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sortLimitThreshold&lt;/code&gt;, 默认为100万条。只有当需要排序SQL的计算结果小于这个阈值时，才会将计算结果落地。同时也加了一个参数为&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sortLimitEnabled&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;此处面临两个问题&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;如何将结果只写入一个文件&lt;/li&gt;
  &lt;li&gt;且保证文件内容有序&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;对于问题1， 只需在原有sql基础上，加上一个 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;limit $count&lt;/code&gt; 即可让其结果只输出到一个文件。&lt;/p&gt;

&lt;p&gt;对于问题2，需要借助Spark 里面的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TakeOrderedAndProjectExec&lt;/code&gt;来保证输出文件内容有序。&lt;/p&gt;

&lt;p&gt;关于&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TakeOrderedAndProjectExec&lt;/code&gt;,  从代码中可以看出只有当 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;limit &amp;lt; spark.sql.execution.topKSortFallbackThreshold&lt;/code&gt;的值时候，才会用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TakeOrderedAndProjectExec&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;cm&quot;&gt;/**
   * Plans special cases of limit operators.
   */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SpecialLimits&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Strategy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plan&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;LogicalPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;SparkPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plan&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ReturnAnswer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rootPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rootPlan&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Limit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;IntegerLiteral&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;limit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Sort&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;order&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;child&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;topKSortFallbackThreshold&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nc&quot;&gt;TakeOrderedAndProjectExec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;limit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;order&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;child&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;planLater&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;child&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Nil&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Limit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;IntegerLiteral&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;limit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Project&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;projectList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Sort&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;order&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;child&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;topKSortFallbackThreshold&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nc&quot;&gt;TakeOrderedAndProjectExec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;limit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;order&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;projectList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;planLater&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;child&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Nil&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Limit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;IntegerLiteral&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;limit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;child&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nc&quot;&gt;CollectLimitExec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;limit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;planLater&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;child&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Nil&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Tail&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;IntegerLiteral&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;limit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;child&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nc&quot;&gt;CollectTailExec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;limit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;planLater&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;child&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Nil&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;other&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;planLater&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;other&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Nil&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Limit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;IntegerLiteral&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;limit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Sort&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;order&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;child&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;topKSortFallbackThreshold&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;TakeOrderedAndProjectExec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;limit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;order&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;child&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;planLater&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;child&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Nil&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Limit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;IntegerLiteral&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;limit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Project&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;projectList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Sort&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;order&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;child&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;topKSortFallbackThreshold&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;TakeOrderedAndProjectExec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;limit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;order&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;projectList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;planLater&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;child&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Nil&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Nil&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;TOP_K_SORT_FALLBACK_THRESHOLD&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;buildConf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;spark.sql.execution.topKSortFallbackThreshold&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;internal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;doc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;In SQL queries with a SORT followed by a LIMIT like &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
          &lt;span class=&quot;s&quot;&gt;&quot;&apos;SELECT x FROM t ORDER BY y LIMIT m&apos;, if m is under this threshold, do a top-K sort&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
          &lt;span class=&quot;s&quot;&gt;&quot; in memory, otherwise do a global sort which spills to disk if necessary.&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;2.4.0&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;intConf&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;createWithDefault&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ByteArrayMethods&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;MAX_ROUNDED_ARRAY_LENGTH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;写入过程如下:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;如果&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sortLimitEnabled&lt;/code&gt;是true，那么去拿到&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql(statement).count&lt;/code&gt;的结果&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rowCount&lt;/code&gt;, 如果其小于&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sortLimitThreshold&lt;/code&gt;, 那么在原有&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;statement&lt;/code&gt; 基础之上加上&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;limit $rowCount&lt;/code&gt;, 以确保其结果输出到单个文件&lt;/li&gt;
  &lt;li&gt;临时 set &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.execution.topKSortFallbackThreshold&lt;/code&gt; 为rowCount, 以确保其使用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TakeOrderedAndProjectExec&lt;/code&gt;，确保其输出文件内容有序&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;uploaddatadownloaddata-api&quot;&gt;UploadData/DownloadData API&lt;/h3&gt;

&lt;p&gt;此外我们在内部扩展了hive-service-rpc, 引入了UploadData/DownloadData API, 且这个特性，我司同事已经贡献给Hive 社区，https://github.com/apache/hive/pull/2878， 已经在hive-service-rpc &lt;a href=&quot;https://mvnrepository.com/artifact/org.apache.hive/hive-service-rpc/4.0.0-alpha-1&quot;&gt;4.0.0-alpha-1&lt;/a&gt; 发布。&lt;/p&gt;

&lt;p&gt;UploadData可以让用户上传本地数据到集群的表中，然后在集群操作。&lt;/p&gt;

&lt;p&gt;DownloadData可以让用户下载大的计算结果到本地文件，然后在本地处理。&lt;/p&gt;

&lt;p&gt;这里对内部实现进行简单描述:&lt;/p&gt;

&lt;h4 id=&quot;uploaddata&quot;&gt;UploadData&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;用户指定本地文件路径，然后通过&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TUploadDataReq&lt;/code&gt;发送文件内容的binary, Spark端接收后，存入到working 目录下的hdfs文件&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;扩展 SparkSessionExtensions，支持UploadDataCommand 和 MoveDataCommand&lt;/p&gt;

    &lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;statement&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;UPLOAD&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DATA&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;INPATH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;STRING&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OVERWRITE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;multipartIdentifier&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partitionSpec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optionSpec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?&lt;/span&gt;              &lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uploadData&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;MOVE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DATA&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;INPATH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;STRING&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OVERWRITE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;destDir&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;STRING&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;destFileName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;STRING&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?&lt;/span&gt;                       &lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;moveData&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;UploadDataCommand用于将上传的文件，upload到表中&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;MoveDataCommand用于将上传到working目录下的hdfs文件，move到指定的hdfs路径&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;downloaddata&quot;&gt;DownloadData&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;用户可以下载指定的hdfs路径下的数据，或者指定一个sql query, 将其结果下载到本地&lt;/li&gt;
  &lt;li&gt;用户可以指定下载数据的format，比如csv或者parquet&lt;/li&gt;
  &lt;li&gt;可以指定文件的minSize和fileNumber等参数&lt;/li&gt;
  &lt;li&gt;spark端会先将结果存入到working 目录下的路径下&lt;/li&gt;
  &lt;li&gt;类似于上面的数据落盘，如果用户的sql没有排序操作，则对小文件进行Coalesce&lt;/li&gt;
  &lt;li&gt;client端拉取时候会获得, fileName, data binary, schema和size，然后依靠这些信息，新建或者存入已有文件中。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;总结&quot;&gt;总结&lt;/h3&gt;

&lt;p&gt;对于big result sets场景中，为了让服务更加稳定，对其结果进行预计算，将计算结果规整的落入文件，然后在读取时候，规整的读出，减少split的partition 数量和碎片，可以极大的提高用户query的稳定性和性能。此外，简单介绍UploadData/DownloadData API.&lt;/p&gt;
</description>
                <link>http://www.turbofei.wang/spark/2022/11/18/ebay-kyuubi-spark-engine-big-result-sets-solution</link>
                <guid>http://www.turbofei.wang/spark/2022/11/18/ebay-kyuubi-spark-engine-big-result-sets-solution</guid>
                <pubDate>2022-11-18T00:00:00-08:00</pubDate>
        </item>

        <item>
                <title>Ebay Spark Test Framework Woody</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#前言&quot; id=&quot;markdown-toc-前言&quot;&gt;前言&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#背景&quot; id=&quot;markdown-toc-背景&quot;&gt;背景&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#woody的架构&quot; id=&quot;markdown-toc-woody的架构&quot;&gt;Woody的架构&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#spark-sql-job&quot; id=&quot;markdown-toc-spark-sql-job&quot;&gt;Spark-sql Job&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#logical-plan&quot; id=&quot;markdown-toc-logical-plan&quot;&gt;Logical Plan&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#parserrulecontext&quot; id=&quot;markdown-toc-parserrulecontext&quot;&gt;ParserRuleContext&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#语句转换&quot; id=&quot;markdown-toc-语句转换&quot;&gt;语句转换&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#隔离&quot; id=&quot;markdown-toc-隔离&quot;&gt;隔离&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#context&quot; id=&quot;markdown-toc-context&quot;&gt;Context&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#提取&quot; id=&quot;markdown-toc-提取&quot;&gt;提取&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#转换&quot; id=&quot;markdown-toc-转换&quot;&gt;转换&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#准备&quot; id=&quot;markdown-toc-准备&quot;&gt;准备&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#数据质量校验&quot; id=&quot;markdown-toc-数据质量校验&quot;&gt;数据质量校验&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#校验什么&quot; id=&quot;markdown-toc-校验什么&quot;&gt;校验什么&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#关于select&quot; id=&quot;markdown-toc-关于select&quot;&gt;关于select&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#如何校验&quot; id=&quot;markdown-toc-如何校验&quot;&gt;如何校验&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#使用场景&quot; id=&quot;markdown-toc-使用场景&quot;&gt;使用场景&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#1-spark版本升级测试&quot; id=&quot;markdown-toc-1-spark版本升级测试&quot;&gt;1. Spark版本升级测试&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#2-spark-sql-job调优&quot; id=&quot;markdown-toc-2-spark-sql-job调优&quot;&gt;2. Spark-sql job调优&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#3-端到端测试&quot; id=&quot;markdown-toc-3-端到端测试&quot;&gt;3. 端到端测试&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#1串联job&quot; id=&quot;markdown-toc-1串联job&quot;&gt;1）串联job&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#2转换详情&quot; id=&quot;markdown-toc-2转换详情&quot;&gt;2）转换详情&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#总结&quot; id=&quot;markdown-toc-总结&quot;&gt;总结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;前言&quot;&gt;前言&lt;/h3&gt;

&lt;p&gt;本文讲eBay Spark测试框架-Woody, 其已被发表在公众号eBay技术荟&lt;a href=&quot;https://mp.weixin.qq.com/s/PZoGtkPd6RHTEtfwOx2H0w&quot;&gt;Hadoop 平台进阶之路|eBay Spark测试框架–Woody&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;新版本的Spark拥有更好的性能和稳定性，对于用户来说，如果长期停留在低版本的Spark，不仅会浪费集群资源，还会进一步加大平台管理团队的工作量。如果进行Spark大版本升级，考虑到版本间可能由于计算行为不一致而导致的数据质量问题，用户就要投入大量的精力去对比重要的job在不同版本下的数据质量，加大了版本升级的困难度。&lt;/p&gt;

&lt;p&gt;ADI Hadoop team负责管理eBay的Hadoop集群、 Spark的版本升级和bug修复等事务。&lt;strong&gt;为了提升Spark版本升级的效率，本团队开发了Spark测试框架——Woody。&lt;/strong&gt;该测试框架会将线上spark-sql job语句转换为和线上job隔离的测试语句，然后调用不同的Spark版本执行测试语句，最终对比版本间数据质量。Woody不仅可以用于Spark版本升级，也可用于job调优以及job pipeline的端到端测试。本文将分享Spark测试框架Woody的架构，实现以及使用场景，希望能对读者有所帮助。&lt;/p&gt;

&lt;h3 id=&quot;背景&quot;&gt;背景&lt;/h3&gt;

&lt;p&gt;Hadoop team目前管理两个大Spark分支，Spark-2.1和Spark-2.3，目前的版本开发均基于Spark-2.3，而对于Spark-2.1分支已经不再进行维护，未来会升级到Spark-3.0。&lt;/p&gt;

&lt;p&gt;Hadoop team从两年前就着手进行从Spark-2.1 到Spark-2.3的迁移工作，用了将近两年时间完成了迁移。&lt;/p&gt;

&lt;p&gt;为什么会用这么长时间呢？&lt;/p&gt;

&lt;p&gt;因为大版本之间可能会存在不兼容问题，计算行为可能发生改变，也就是说两个版本间的计算结果可能不一致。&lt;/p&gt;

&lt;p&gt;数据质量是至关重要的，特别是对于金融数据，业务团队需要在升级之前进行两个版本间的计算结果对比。&lt;/p&gt;

&lt;p&gt;而这需要用户去手动修改线上代码，然后利用两个Spark版本进行双跑，最后再去手动对比两个版本的计算结果。eBay内部的spark-sql任务数不胜数，大版本升级会消耗大量的资源和人力。&lt;/p&gt;

&lt;p&gt;Spark-2.1到Spark-2.3 已经耗费了这么长时间，那么将来升级到Spark-3.0想必也是一个浩大的工程。&lt;/p&gt;

&lt;p&gt;为了解决这个问题，Hadoop team开发了一个Spark测试框架，命名为Woody。Woody的名字取自一个卡通啄木鸟，希望可以帮助找出不同Spark版本之间或者Spark job中的bug(虫子)。&lt;/p&gt;

&lt;p&gt;Woody可以将线上的SQL语句进行转换，然后分别启动两个Spark版本运行转换后的SQL，从而对比两个版本的计算结果，判断两个版本计算结果是否一致，也可以用于比较两个版本的性能。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/woody/p1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;woody的架构&quot;&gt;Woody的架构&lt;/h3&gt;

&lt;p&gt;Woody的架构如图2所示，提供restful api，使用mysql存储数据，支持多个集群。用户可以一次提交一批用于测试的job，Woody用一个workflow封装这批job,由workflow调度器进行调度，每个workflow调度时生成一个对应的jobSetManager,进入job调度器，job调度器会限制同时运行job的数量。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/woody/p2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;一个job的生命周期为：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;将job语句转换为测试语句&lt;/li&gt;
  &lt;li&gt;测试运行前准备工作&lt;/li&gt;
  &lt;li&gt;调用Spark版本1运行测试语句&lt;/li&gt;
  &lt;li&gt;计算Spark版本1结果的校验信息&lt;/li&gt;
  &lt;li&gt;调用Spark版本2运行测试语句&lt;/li&gt;
  &lt;li&gt;计算Spark版本2结果的校验信息&lt;/li&gt;
  &lt;li&gt;给出数据质量报告&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;关于job语句的转换，Woody为各个集群启动多个长运行的conversion executor，这些conversion executor会向Woody Server进行注册并定期汇报自己的心跳，由Conversion Service Manager来管理。&lt;/p&gt;

&lt;p&gt;在job需要运行测试语句阶段，Spark App Submit Service会向相应的集群提交Spark任务, Woody会记录其ApplicationId存入mysql。&lt;/p&gt;

&lt;p&gt;Woody使用mysql共享状态数据，支持HA, 是cloud-native的服务。在一台Woody服务关闭时会将其正在运行的workflow标记为游离状态，这些游离状态的workflow会被其他正在运行的Woody服务接管，或者由当前Woody服务重启后重新接管。&lt;/p&gt;

&lt;h3 id=&quot;spark-sql-job&quot;&gt;Spark-sql Job&lt;/h3&gt;

&lt;p&gt;首先，介绍一下本文中对source表，working表和target表的定义：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;source表是作为输入的表，是被select from的表；&lt;/li&gt;
  &lt;li&gt;working表是在job运行中被创建的表，包括(temporary)view；&lt;/li&gt;
  &lt;li&gt;target表是被写入数据的表，比如被load数据，或者被insert数据等等。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;前面提到了用户在测试版本间数据质量的时候，需要手动对两个Spark版本间的计算进行对比，这一操作有以下三个要点:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;更改SQL语句，至少需要更改insert数据的表名，避免影响线上job；&lt;/li&gt;
  &lt;li&gt;保持source表的数据一致；&lt;/li&gt;
  &lt;li&gt;手动检查两个Spark版本的计算结果。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Woody需要自动化完成以上三方面的工作。&lt;/p&gt;

&lt;p&gt;首先，对于如何去自动地更改线上job语句，请参考以下这组简单的Spark-sql语句：&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;replace&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;temporary&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;view&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;working_table&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;…&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;insert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;overwrite&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_table&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;working_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;working_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在这组语句里面，由src_table 作为job的输入，而working_table是在job运行时候生成的，target_table则作为job的输出。&lt;/p&gt;

&lt;p&gt;如果要更改线上job语句，不被改变的src_table是不用更改的，作为输出的target_table是必须修改的，临时（temporary）的working表(temporary view)是不用更改的，非临时的working表则必须更改。&lt;/p&gt;

&lt;p&gt;那么如何才能找出这些src, working和target表呢？&lt;/p&gt;

&lt;h3 id=&quot;logical-plan&quot;&gt;Logical Plan&lt;/h3&gt;

&lt;p&gt;Catalyst是Spark-sql可扩展的SQL优化器。它会将一条SQL语句或者dataframe操作转换为logical plan，然后进行优化，最后转换成可执行的物理计划运行，因篇幅限制，此处不做过多展开。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/woody/p3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如上图所示，Woody会使用其中的unresolved logical plan 来进行分析，来找出其中的source表，working表，target表和一些location等信息。&lt;/p&gt;

&lt;p&gt;比如，下面的这句SQL会转换为一个logical plan，可以从叶子节点拿到该语句的source表信息；而对于create table语句，它对应一个CreateTable类型的logical plan，可以从该plan拿到working表信息；相应的insert语句对应于一个InsertIntoTable类型的logical plan，可以从中获得target表等等。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/woody/p4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;前文提到可以从一个LogicalPlan的叶子节点拿到其中的source表信息。每个logical plan对应一个抽象语法树，而这颗抽象语法树上面的每个节点也是一个logical plan，所以一条语句的logical plan对应的其实是一个森林，Woody要找到的就是这个森林里面的所有叶子节点。&lt;/p&gt;

&lt;p&gt;比如说下面的语句：&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;udf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;current_timestamp&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;其中subQuery的Project列表里面的第二列，包含source表信息，Woody需要将这个logical plan对应的森林各个分支都进行遍历，找到所有叶子节点，从中提取出表信息。&lt;/p&gt;

&lt;p&gt;当然在一个sql job中是有很多条sql语句的，上一条语句的target表可能是下条语句的source表，前面创建的working表，可能是后面用到的source表，以及语句中会有AlterTableSetLocation等等语句，Woody会把解析过程中的context保存起来，用于串联前后表之间的依赖关系，从而进行语句转换。&lt;/p&gt;

&lt;p&gt;不只是表信息，对于location的信息，Woody也要进行提取，用于后面转为测试环境中的location等等。&lt;/p&gt;

&lt;h3 id=&quot;parserrulecontext&quot;&gt;ParserRuleContext&lt;/h3&gt;

&lt;p&gt;即使找到了语句中的表信息和location信息，那又要如何利用这些信息对原有的sql语句进行转换呢？单纯的利用logical plan是无法做到的，即使编辑了这个logical plan也无法将其映射为sql文本。&lt;/p&gt;

&lt;p&gt;Spark使用antlr4 进行语法分析，每个sql文本初次转换之后会获得一个ParserRuleContext，然后catalyst会基于它生成相应的logical plan。&lt;/p&gt;

&lt;p&gt;而ParserRuleContext包含一个inputStream对应原始的SQL文本，而且ParserRuleContext也是一颗树,其各个节点也都有自己的类型，每个节点有字段代表其在该inputStream上面的偏移量。&lt;/p&gt;

&lt;p&gt;比如说表名对应TableIdentifierContext，location 对应LocationSpecContext。如果要替换一些表名或者location，只需要找到这些表名所在的ParserRuleContext节点，然后将其对应的文本进行替换，再和前后的文本进行拼接，即可对语句进行转换。&lt;/p&gt;

&lt;p&gt;举个例子：&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ta&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tb&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;对于这个语句，如果我们要转换它的source表ta和tb,就要先拿到对应的ParserRuleContext，找到表名节点，得到其在ParserRuleContext inputStream之上的偏移量；假设ta对应的TableIdentifierContext偏移量是50-52,而tb对应的偏移量是70-72。&lt;/p&gt;

&lt;p&gt;那么替换的结果就是:&lt;/p&gt;

&lt;p&gt;originText(0, 49) + replace(ta) + originText(52, 69) + replace(tb) + originText(72, length).&lt;/p&gt;

&lt;p&gt;接下来讲Woody的转换规则。&lt;/p&gt;

&lt;h3 id=&quot;语句转换&quot;&gt;语句转换&lt;/h3&gt;

&lt;h4 id=&quot;隔离&quot;&gt;隔离&lt;/h4&gt;

&lt;p&gt;首先，转换后的语句必定要与线上环境隔离开来，不能影响线上job和数据。Woody的策略是创建一个数据库专门用于对这个job的测试，然后将该job中要输出的数据全部保存在该数据库下面。&lt;/p&gt;

&lt;p&gt;假设这个数据库命名为 WOODY_DB_${UNIQUE_ID}。&lt;/p&gt;

&lt;p&gt;对于job中只读的source表，Woody不会去转换这些表的名字。对于job中的输出表，其原有的名字是dbName.tblName, Woody会将其表名转换为WOODY_DB_${UNIQUE_ID}.dbName__tblName，也就是说把数据输出到前面提及到的数据库中,原有的数据库名和表名用两条下划线拼接作为新的表名。&lt;/p&gt;

&lt;p&gt;举个例子:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;insert&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;into&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gdw_tables&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tgt_tbl&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gdw_tables&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src_tbl&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;；&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;会被转换为&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;insert&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;into&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;WOODY_DB_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;UNIQUE_ID&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gdw_tables__tgt_tbl&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gdw_tables&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src_tbl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;context&quot;&gt;Context&lt;/h4&gt;

&lt;p&gt;Woody保存转换过程中提取到的信息以及当前的上下文，包含有：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;source表以及这些表是否是global的表；&lt;/li&gt;
  &lt;li&gt;后续当做target表的source表；&lt;/li&gt;
  &lt;li&gt;语句中创建的working表；&lt;/li&gt;
  &lt;li&gt;被后续当做source表的working表；&lt;/li&gt;
  &lt;li&gt;被后续当做target表的working表；&lt;/li&gt;
  &lt;li&gt;target表以及其被写入的partition信息；&lt;/li&gt;
  &lt;li&gt;在job中被写入数据的dir信息；&lt;/li&gt;
  &lt;li&gt;当前的数据库是什么，use database语句可更改当前数据库；&lt;/li&gt;
  &lt;li&gt;当前被alter(包括被写入数据，alter location等等)的表的信息等。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;接下来介绍Woody如何提取信息，并将这些信息存入该context，串联整个job。&lt;/p&gt;

&lt;h4 id=&quot;提取&quot;&gt;提取&lt;/h4&gt;

&lt;p&gt;Woody会按照job语句顺序，提取当前语句中的信息，存入context中，然后转换当前语句，如此循环。&lt;/p&gt;

&lt;p&gt;对于一条语句，首先得到对应的unresolved logical plan。&lt;/p&gt;

&lt;p&gt;此处解释下为什么一定是unresolved logical plan, 不能是resolved logical plan或者optimized logical plan。&lt;/p&gt;

&lt;p&gt;因为这是发生在Woody提取信息过程中，并没有真正地运行sql，前置的sql都没有运行，而当前语句可能依赖前置sql的结果，比如依赖前面创建的temporary view，自然无法resolve logical plan 和后续的optimized logical plan（而且optimized logical plan经过catalyst优化，可能会丢失一些需要用于转换原语句的信息）。&lt;/p&gt;

&lt;p&gt;拿到unresolved logical plan之后，Woody会去匹配该plan的类型，看其是DDL,DML还是DQL,首先保存不属于source表的信息(working表，target表, 需转换的location信息)。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;CreateViewCommand/CreateViewUsing/CreateTable等创建表语句，将被创建的working表信息存入context，同时记录指定的location信息；&lt;/li&gt;
  &lt;li&gt;LoadDataCommand和insert语句，将被insert数据的表以及partition信息存入context；&lt;/li&gt;
  &lt;li&gt;AlterTable语句，将alter信息加入context…&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;之后，Woody会遍历该logical plan的每一个分支(logical plan的children方法不能覆盖所有分支，Woody参考了catalyst中的LogicalPlanVistor类)，找到所有叶子节点，包括：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Project的project list的每一个元素，&lt;/li&gt;
  &lt;li&gt;Join条件的left表达式，right表达式，以及condition表达式，&lt;/li&gt;
  &lt;li&gt;Aggregate的grouping 表达式，aggregate表达式，&lt;/li&gt;
  &lt;li&gt;Sort的order表达式……&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;从这些叶子节点过滤得到 UnresolvedRelation类型的节点，这些节点对应的都是source表。&lt;/p&gt;

&lt;p&gt;而接下来需要替换的target表，working表，source表或者location信息，均已从当前语句中提取出来，结合当前的context即可进行转换。&lt;/p&gt;

&lt;h4 id=&quot;转换&quot;&gt;转换&lt;/h4&gt;

&lt;p&gt;接下来需要依据提取到的信息结合当前context进行转换。前面提到ParserRuleContext用于替换，只需要找到需要转换的节点。&lt;/p&gt;

&lt;p&gt;那么，哪些节点是可能被替换的呢？&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;表名信息；&lt;/li&gt;
  &lt;li&gt;包含base和field信息的节点，例如语句‘select ta.id from ta’的‘ta.id’, 可能需要替换其中的表名ta部分；&lt;/li&gt;
  &lt;li&gt;表property节点，比如spark data source表property 里面的path就是表的路径，Woody可能需要转换这个路径；&lt;/li&gt;
  &lt;li&gt;Location节点。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;第三条和第四条，都是为了转换location信息，只需要做一个路径映射即可。&lt;/p&gt;

&lt;p&gt;关于第一条：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果该表是source表且没有被alter过，则继续用原表；&lt;/li&gt;
  &lt;li&gt;如果该表是source表，但是被alter过，则使用转换后的表名(参考第一小节：隔离)。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;关于第二条包含base 和field信息的节点:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;这个base表可能是别名不需要转换；&lt;/li&gt;
  &lt;li&gt;这个base表可能是With语句中的temp view，不用转换；&lt;/li&gt;
  &lt;li&gt;参考第一条的转换规则。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;除此之外，还有一些场景，无法在一次替换中解决, 比如，一个表可能既是source表又是target表。&lt;/p&gt;

&lt;p&gt;insert into ta select ta.* from ta join tb on …&lt;/p&gt;

&lt;p&gt;Woody会在完成第一次替换之后才将表ta标记为target表，然后再次替换被insert表的表名为测试表。&lt;/p&gt;

&lt;p&gt;而对于以下语句，Woody可以直接跳过该转换部分。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;use database, Woody会在context中改变当前database;&lt;/li&gt;
  &lt;li&gt;set/reset/clear cache语句，保留原语句。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;此外，Woody在完成job中所有语句转换之后，会去校验context中的所有source表是否含有global view。&lt;/p&gt;

&lt;p&gt;由于view只是将一个查询进行封装，底层仍然可能含有source表信息，Woody为了将所有表信息更好地串联起来，会去查询该view的创建语句，然后转换该view的创建语句，直到所有的source表不存在global view为止。&lt;/p&gt;

&lt;h4 id=&quot;准备&quot;&gt;准备&lt;/h4&gt;

&lt;p&gt;经过前面的语句转换，Woody会直接读取线上表的数据，然后将计算结果输出到测试表中。&lt;/p&gt;

&lt;p&gt;Woody会查询metastore, 获取这些测试表对应的线上表的建表语句，然后转换为测试表的建表语句，用于后续的测试前准备阶段。&lt;/p&gt;

&lt;h3 id=&quot;数据质量校验&quot;&gt;数据质量校验&lt;/h3&gt;

&lt;p&gt;进行完测试前准备之后，Woody按照要对比的两个Spark版本，顺序启动两个Spark 应用来运行转换后的语句。在每个版本的Spark运行结束之后去拿到job输出的信息(table count和checksum以及sample)，然后对这些输出数据清空复原。在两个版本的Spark应用均运行结束之后，对比其结果，如果结果一致，则代表两个Spark版本的数据是一致的，是兼容的。&lt;/p&gt;

&lt;h4 id=&quot;校验什么&quot;&gt;校验什么&lt;/h4&gt;

&lt;p&gt;首先，Woody校验数据有以下几种：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;insert 语句写入的表&lt;/li&gt;
  &lt;li&gt;job中创建但是后续没有被使用到的working表&lt;/li&gt;
  &lt;li&gt;select语句的结果&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;前两种场景很好理解，Woody会在语法分析的时候记录这些表，然后在Spark计算任务完成之后，去校验这些表。&lt;/p&gt;

&lt;h4 id=&quot;关于select&quot;&gt;关于select&lt;/h4&gt;

&lt;p&gt;经典的tpc-ds和tpc-h基准测试，都是使用select语句进行，Woody也支持对select语句进行结果校验。&lt;/p&gt;

&lt;p&gt;Spark中在缓存（cache）某个RDD的时候，不会立即缓存这个RDD，而是先进行缓存标记，当RDD链触发到这个RDD时才会真正触发缓存操作，Woody对select语句的转换校验也是如此。&lt;/p&gt;

&lt;p&gt;首先，Woody在进行语句转换时会识别出哪些语句是select语句，然后用一个计数器计数，先给这个select语句要存入的表分配一个表名，比如WOODY_SELECT_RESULT_{INDEX}。&lt;/p&gt;

&lt;p&gt;Woody这样做是因为这个select语句会调用job中其他语句的结果，在转换分析时由于没有真正运行无法拿到该select语句 AnalyzedLogicalPlan, 而无法创建保存这个select结果的表。&lt;/p&gt;

&lt;p&gt;在Spark执行这些select语句的时候，Woody会再次识别出这些select语句；然后拿到该select语句的AnalyzedLogicalPlan，从而拿到select结果的schema信息；再根据schema信息，创建用于保存select结果的表；之后再把select语句的结果保存到这个表中，用于后续的结果校验。&lt;/p&gt;

&lt;h4 id=&quot;如何校验&quot;&gt;如何校验&lt;/h4&gt;

&lt;p&gt;crc32是一种简单快速的校验算法，通常用于数据传输，它也被用于Hadoop中。Spark中提供了内置函数crc32。该函数的值是Long类型，最大值不会超过10^19。&lt;/p&gt;

&lt;p&gt;Decimal是数据库中的一种数据类型，不属于浮点数类型，可以在定义时划定整数部分以及小数部分的位数。对于一个Decimal类型，scale表示其小数部分的位数，precision表示整数部分位数和小数部分位数之和。&lt;/p&gt;

&lt;p&gt;一个Decimal类型可以表示为Decimal(precision, scale)，在Spark中，precision和scale的上限都是38。因此可以将crc32的值转换为Decimal(19, 0)。&lt;/p&gt;

&lt;p&gt;Woody将表中每行的各列数据concat起来，然后计算其crc32，将该crc32转换为Decimal(19, 0)。由于表的count也是Long类型，不会超过10^19，所以每行的crc32值之和不会超过10^19*10^19=10^38，也就是说不会超过Decimal(38, 0)可表示的范围。&lt;/p&gt;

&lt;p&gt;在concat表中一行数据的每列数据时，使用‘\u0000’来代表值为空的列，并且每列之间用‘\u0001’隔开。&lt;/p&gt;

&lt;p&gt;这样count和checksum就可以有效地表示一个表的检验信息，在获得这个校验信息之后，就可以把当前测试产生的数据清空。&lt;/p&gt;

&lt;p&gt;值得注意的是，有些表中含有一些用于审计的列，比如使用current_timestamp来表示更新时间或者current_user来表示是由哪些用户来维护，这些列值会动态变化而且与数据质量无关，业务方提供了这些用于审计的列名，Woody在做checksum的时候会把这些列过滤掉。&lt;/p&gt;

&lt;h3 id=&quot;使用场景&quot;&gt;使用场景&lt;/h3&gt;

&lt;h4 id=&quot;1-spark版本升级测试&quot;&gt;1. Spark版本升级测试&lt;/h4&gt;

&lt;p&gt;开发Woody的初衷就是为了让Spark版本升级更加流畅，以减少任务迁移过程中的工作量。Woody支持输入集群名称和成功过的Spark ApplicationId，从而自动拉取job的语句和配置，然后选择需要对比的版本即可进行数据质量对比。&lt;/p&gt;

&lt;p&gt;后续会支持账号级别的升级测试，只需要选择用户的账号，Woody即可对该账号需要升级的所有job进行升级测试，测试通过即可将该账号迁移至新版本Spark。&lt;/p&gt;

&lt;h4 id=&quot;2-spark-sql-job调优&quot;&gt;2. Spark-sql job调优&lt;/h4&gt;

&lt;p&gt;Spark-sql job调优通常分为:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;参数调优；&lt;/li&gt;
  &lt;li&gt;Sql语句调优。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Woody支持在选择Spark版本运行测试时，指定conf或者修改job语句来进行对比测试，用户可以利用Woody来进行job 调优。&lt;/p&gt;

&lt;h4 id=&quot;3-端到端测试&quot;&gt;3. 端到端测试&lt;/h4&gt;

&lt;p&gt;前面章节提到的测试都是针对单个job进行的测试。然而线上的Spark-sql job通常是一个job pipeline，包含多个有前后依赖的job。在上线新的job pipleline时，需要进行充足的测试。不仅仅需要benchmark测试，也需要进行仿真测试，用线上的数据来进行测试是一个很好的选择。&lt;/p&gt;

&lt;p&gt;但是这需要开发者手动修改job的语句，避免影响线上环境。而人工操作的引入又难免造成误操作，从而导致破坏线上数据，环境等。&lt;/p&gt;

&lt;p&gt;针对以上问题，Woody的自动转换线上语句功能就有了用武之地。Hadoop team基于此继续开发，使Woody支持端到端的测试，帮助用户安全的使用线上数据进行测试，而不需要进行任何手动修改工作。&lt;/p&gt;

&lt;h5 id=&quot;1串联job&quot;&gt;1）串联job&lt;/h5&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/woody/p5.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;对于单个job来说，转换的context只针对当前job，而针对job pipeline, Woody要将这个转换context扩展为整个 job plan, 要让这个job plan 里面的job联系起来，后面的job要拿前面job的输出作为输入，而不是每次都读取线上的数据作为输入。&lt;/p&gt;

&lt;p&gt;eBay内部使用的job pipeline调度框架，对于每个触发的job plan,会分配一个planId传给里面的每个Job, Woody会基于planId 将job pipeline里面的job串联起来。&lt;/p&gt;

&lt;p&gt;对于端到端的测试，Woody基于用户的账号来创建一个数据库用于存放job的输出结果，数据库命名规则为pre_prod_{preprod_account}_db；其location为/preprod/{preprod_account}/analysis.db。&lt;/p&gt;

&lt;p&gt;将job pipeline进行串联，也就是将前面job的输出作为后面job的输入。&lt;/p&gt;

&lt;p&gt;一个job的输出表达有两种:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;数据写到了哪些表&lt;/li&gt;
  &lt;li&gt;数据写到了哪些路径&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;关于数据写到了哪些表:&lt;/p&gt;

&lt;p&gt;假设表gdw_tables.tba_merge的location 是‘/sys/edw/gdw_tables/tba_merge’，使用b_woody_sub进行测试。如下两条语句:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;insert&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;into&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gdw_tables&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tba_merge&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20201019&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;…&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;alter&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gdw_tables&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tba&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;location&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gdw_tables&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tba_merge&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20201019&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;将会被转换为:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;insert&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;into&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;preprod_b_woody_sub_db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gdw_tables__tba_merge&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20201019&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;…&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;alter&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;preprod_b_woody_sub_db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gdw_tables__tba&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;location&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;‘&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;preprod&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b_woody_sub&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;analysis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gdw_tables&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tba_merge&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20201019&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;’&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Woody在转换第一条insert 语句时候，会将要写入的表名转换为&lt;/p&gt;

&lt;p&gt;&lt;em&gt;preprod_b_woody_sub_db.gdw_tables__tba_merge&lt;/em&gt;, 而这个转换后的表的location也会被转换为&lt;/p&gt;

&lt;p&gt;&lt;em&gt;‘/preprod/b_woody_sub/analysis.db/sys/edw/gdw_tables/tba_merge’&lt;/em&gt;，从而Woody得知该insert语句实际写入的location在测试环境里面是&lt;em&gt;‘/preprod/b_woody_sub/analysis.db/sys/edw/gdw_tables/tba_merge/dt=20201019’&lt;/em&gt;，&lt;/p&gt;

&lt;p&gt;Woody会将这个写入数据的路径记录下来。&lt;/p&gt;

&lt;p&gt;在转换第二条AlterTableSetLocation语句时，由于这个被set的location是前面写入过数据的路径，因此，Woody也会知道测试表 preprod_b_woody_sub_db.gdw_tables__tba 被set到了一个被写入过数据的路径，也是一个被写入数据的表。&lt;/p&gt;

&lt;p&gt;另外一种情况，如果第一条insert 语句和第二条AlterTableSetLocation语句分别属于两个job，但是有前后关系。&lt;/p&gt;

&lt;p&gt;在第一条Insert 语句运行完之后, &lt;em&gt;‘/preprod/b_woody_sub/analysis.db/sys/edw/gdw_tables/tba_merge/dt=20201019’&lt;/em&gt;会被创建出来；&lt;/p&gt;

&lt;p&gt;对于第二条AlterTableSetLocation语句，Woody判断得到：&lt;/p&gt;

&lt;p&gt;&lt;em&gt;‘/sys/edw/gdw_tables/tba_merge/dt=20201019’&lt;/em&gt; 对应的测试location &lt;em&gt;‘/preprod/b_woody_sub/analysis.db/sys/edw/gdw_tables/tba_merge/dt=20201019’&lt;/em&gt; 已经存在，也会将 preprod_b_woody_sub_db.gdw_tables__tba 标记为被写入数据的表。&lt;/p&gt;

&lt;p&gt;最终Woody会将这个job中所有被写入数据的表跟这个jobPlan 的planId关联起来，存储到mysql数据库中，作为这个jobPlan的context。&lt;/p&gt;

&lt;p&gt;在这个jobPlan中的其他job运行时，就可以优先读取这些上游产生的测试数据，而不是去读取线上数据，这样，一条pipeline就可以串联起来。&lt;/p&gt;

&lt;h5 id=&quot;2转换详情&quot;&gt;2）转换详情&lt;/h5&gt;

&lt;p&gt;为Woody开发了conversion history server以及runtime的conversions页面。图6是一个runtime的转换详情页面。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/woody/p6.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;总结&quot;&gt;总结&lt;/h3&gt;

&lt;p&gt;eBay Hadoop team开发的Spark测试框架Woody能够利用LogicalPlan提取job语句中的有效信息，并利用ParserRuleContext进行转换，以线上数据作为输入，将结果输出到测试目录；支持使用不同的Spark版本，conf，甚至修改job sql语句来运行，在运行之后得到数据质量结果和性能比较。总的来说，测试框架Woody的功能主要有以下两个方面：一是用于Spark版本升级及Spark sql job调优，二是用于端到端测试，帮助用户在job pipeline上线之前安全的利用真实的线上数据进行端到端的测试，验证新feature和bug修复，而无需修改任何代码。未来，Hadoop team将进一步优化Woody，以期更好的使用体验。&lt;/p&gt;

</description>
                <link>http://www.turbofei.wang/spark/2020/10/29/eBay-Spark-Test-Framework-Woody</link>
                <guid>http://www.turbofei.wang/spark/2020/10/29/eBay-Spark-Test-Framework-Woody</guid>
                <pubDate>2020-10-29T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>记一次与spark bucket table相关的小文件问题</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#前言&quot; id=&quot;markdown-toc-前言&quot;&gt;前言&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#关于bucket-table&quot; id=&quot;markdown-toc-关于bucket-table&quot;&gt;关于Bucket Table&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#创建bucket-表&quot; id=&quot;markdown-toc-创建bucket-表&quot;&gt;创建bucket 表&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#bucket表参数&quot; id=&quot;markdown-toc-bucket表参数&quot;&gt;Bucket表参数&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#insert-into-bucket-table&quot; id=&quot;markdown-toc-insert-into-bucket-table&quot;&gt;Insert into bucket table&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#问题分析&quot; id=&quot;markdown-toc-问题分析&quot;&gt;问题分析&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#关于double-和decimal&quot; id=&quot;markdown-toc-关于double-和decimal&quot;&gt;关于double 和Decimal&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#解决方案&quot; id=&quot;markdown-toc-解决方案&quot;&gt;解决方案&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#绕过数字类型解决小文件问题&quot; id=&quot;markdown-toc-绕过数字类型解决小文件问题&quot;&gt;绕过数字类型，解决小文件问题&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#通过重建表从根本解决问题&quot; id=&quot;markdown-toc-通过重建表从根本解决问题&quot;&gt;通过重建表从根本解决问题&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#平台侧可以做什么&quot; id=&quot;markdown-toc-平台侧可以做什么&quot;&gt;平台侧可以做什么&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#后记&quot; id=&quot;markdown-toc-后记&quot;&gt;后记&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#附录&quot; id=&quot;markdown-toc-附录&quot;&gt;附录&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#验证double-和decimal-类型的bucket-id-是否不同&quot; id=&quot;markdown-toc-验证double-和decimal-类型的bucket-id-是否不同&quot;&gt;验证double 和Decimal 类型的bucket Id 是否不同&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;记一次与bucket table相关的小文件问题，百万级小文件。&lt;/p&gt;

&lt;h3 id=&quot;前言&quot;&gt;前言&lt;/h3&gt;

&lt;p&gt;最近遇到了一次跟Spark bucket table相关的小文件问题。&lt;/p&gt;

&lt;p&gt;场景如下:&lt;/p&gt;

&lt;p&gt;存在一张bucket table, bucket column 是 c1, bucket数量是1000，用户在对这张bucket 表进行insert overwrite的时候，已经将spark.sql.shuffle.partitions 设置成了1000，而且对bucket column那列进行了distribute by 操作，理想情况下，这次overwrite操作将生成1000个文件，但是出人意料的是，这次操作生成了 1000*1000=100万个小文件!!!&lt;/p&gt;

&lt;p&gt;这么多小文件必定需要很多次create 请求和rename请求，因此必然的触发了Hadoop集群报警机制。&lt;/p&gt;

&lt;h3 id=&quot;关于bucket-table&quot;&gt;关于Bucket Table&lt;/h3&gt;

&lt;p&gt;Spark和Hive中都有bucket table，但是其格式不尽相同。本文不对此进行赘述，关于内容是关于Spark的bucket表。&lt;/p&gt;

&lt;p&gt;Bucket表的作用相当于一种数据预处理，如果两个bucket 表的bucket数量相同，且对两个表的bucket key进行join，那个可以避免shuffle 操作，需要数据管理者进行一定的设计。&lt;/p&gt;

&lt;h4 id=&quot;创建bucket-表&quot;&gt;创建bucket 表&lt;/h4&gt;

&lt;p&gt;语句格式:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IF&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;EXISTS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;db_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.]&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;table_name&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col_name1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col_type1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COMMENT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col_comment1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...)]&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;USING&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_source&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;OPTIONS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;val1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;val2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...)]&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PARTITIONED&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col_name1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col_name2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...)]&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CLUSTERED&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col_name3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col_name4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SORTED&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col_name1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ASC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col_name2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_buckets&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BUCKETS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;LOCATION&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COMMENT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table_comment&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TBLPROPERTIES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;val1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;val2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...)]&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;select_statement&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;PS: 创建bucket表时候用到的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;clustered by (key)&lt;/code&gt; 和 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sorted by (key)&lt;/code&gt;，和在select 数据时候用的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cluster by key&lt;/code&gt; 和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sort by key&lt;/code&gt; 很相似，但是用法是不同的。&lt;/p&gt;

&lt;p&gt;另外在select 时候有&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;distribute by&lt;/code&gt; 和 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cluster by&lt;/code&gt;两种语法，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cluster by key&lt;/code&gt; = &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;distribute by key sort by key&lt;/code&gt;. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;distribute by key&lt;/code&gt; = &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hash shuffle by key&lt;/code&gt;.&lt;/p&gt;

&lt;h4 id=&quot;bucket表参数&quot;&gt;Bucket表参数&lt;/h4&gt;

&lt;p&gt;Spark中有两个bucket表相关参数：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spark.sql.sources.bucketing.enabled  是否将bucekt表看成是bucekt表
spark.sql.sources.bucketing.maxBuckets 允许的最大bucekt 数量，默认是100000
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;关于第一个参数，作用是否将bucket表看成是bucekt表。&lt;/p&gt;

&lt;p&gt;Spark针对bucket表读取的时候，会对每一个bucket分配一个task来读取，因为如果进行bucket join就不能再对这个bucket的数据进行拆分。但是有些时候，我们不是读取这个bucket表进行join，比如是简单的ETL，而此时map阶段会针对每个bucket分配一个mapTask，而如果这个bucket数据量很大，就会很缓慢。而如果此时，我们把spark.sql.sources.bucketing.enabled 设为false，那么就相当于一个普通表，map端可能会针对这个bucket的数据进行split，从而多分配一些task，加快速度。&lt;/p&gt;

&lt;h4 id=&quot;insert-into-bucket-table&quot;&gt;Insert into bucket table&lt;/h4&gt;

&lt;p&gt;Insert into bucket table的时候，会加一个针对bucket column的hashPartitioning 函数。因此如果一个task中的数据在insert into这个bucket table的时候，没有提前针对这个bucket column 进行过基于bucket number  的hash(可以将spark.sql.shuffle.partitions 设置为bucket number，然后进行distribute/cluster by),那么每个task 将会生成 bucket number个文件。&lt;/p&gt;

&lt;h3 id=&quot;问题分析&quot;&gt;问题分析&lt;/h3&gt;

&lt;p&gt;出现问题的sql语句的执行计划核心部分如下图所示。&lt;/p&gt;

&lt;p&gt;可以看到这是对两个子查询进行union，然后我们做了基于bucket column和number的hash(distribute and sort by), 之后insert overwrite 一个bucekt表。&lt;/p&gt;

&lt;p&gt;用户期望的结果是会最终产生1000个文件，但是出乎意料的生成了100万个小文件。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/spark-bucket-small-files/plan.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;通过对语句进行精简，我拿到一个可复现问题的简单测试。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nf&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;create table ta (c1 decimal(38, 18), c2 int, p1 int) using parquet partitioned&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot; by (p1) clustered by (c1) sorted by (c1) into 10 buckets&quot;&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;）&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;set spark.sql.shuffle.partitions=10&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;    

&lt;span class=&quot;nv&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;sparkContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;parallelize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Decimal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;toDF&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;c1&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;c2&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;overwrite&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;saveAsTable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;tb&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nv&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;sparkContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;parallelize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;toDouble&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;toDF&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;c1&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;c2&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;overwrite&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;saveAsTable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;tc&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;insert overwrite table ta partition(p1=1) select c1, c2 from tb union all &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;select c1, c2 from tc distribute by c1&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在这个测试中有三张表，ta是一张bucket表，有三列, c1, c2, p1, 而p1是分区列，c1是bucket列， bucket 数目是10. 我们已经将spark.sql.shuffle.partitions 设置为10.&lt;/p&gt;

&lt;p&gt;然后tb 和tc都有两列 c1, c2, 我们将select 两张表的数据，进行union，之后对c1 进行distribute by，之后overwrite 到 ta 中p1=1的分区。&lt;/p&gt;

&lt;p&gt;执行之后，查看ta下面p1=1目录，发现有200个小文件(已经很多了)。&lt;/p&gt;

&lt;p&gt;查看insert overwrite语句物理执行计划。&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; Physical Plan &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;
Execute InsertIntoHadoopFsRelationCommand file:/private/var/folders/lw/8qtm67pn1gdb86hj4jcrk_ww39cyt7/T/spark-40631839-0276-414f-aa2f-0721eaab3e26, Map&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;p1 -&amp;gt; 1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;, &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;, &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;p1#255], 10 buckets, bucket columns: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;c1], &lt;span class=&quot;nb&quot;&gt;sort &lt;/span&gt;columns: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;c1], Parquet, Map&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;path -&amp;gt; file:/private/var/folders/lw/8qtm67pn1gdb86hj4jcrk_ww39cyt7/T/spark-40631839-0276-414f-aa2f-0721eaab3e26&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;, Overwrite, CatalogTable&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
Database: default
Table: ta
Created Time: Sat Mar 28 10:19:48 PDT 2020
Last Access: UNKNOWN
Created By: Spark 3.1.0-SNAPSHOT
Type: EXTERNAL
Provider: parquet
Num Buckets: 10
Bucket Columns: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;c1&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
Sort Columns: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;c1&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
Location: file:///private/var/folders/lw/8qtm67pn1gdb86hj4jcrk_ww39cyt7/T/spark-40631839-0276-414f-aa2f-0721eaab3e26
Partition Provider: Catalog
Partition Columns: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;p1&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
Schema: root
 |-- c1: decimal&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;38,18&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;nullable &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
 |-- c2: integer &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;nullable &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
 |-- p1: integer &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;nullable &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;, org.apache.spark.sql.execution.datasources.CatalogFileIndex@3faae831, &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;c1, c2, p1]
+- &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;3&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; Project &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;ansi_cast&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;c1#250 as decimal&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;38,18&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; AS c1#254, c2#247, 1 AS p1#255]
   +- Exchange hashpartitioning&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;c1#250, 10&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;, &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;, &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;c&quot;&gt;#155]&lt;/span&gt;
      +- Union
         :- &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; Project &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;cast&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;c1#246 as double&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; AS c1#250, c2#247]
         :  +- &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; ColumnarToRow
         :     +- FileScan parquet default.tb[c1#246,c2#247] Batched: &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;, DataFilters: &lt;span class=&quot;o&quot;&gt;[]&lt;/span&gt;, Format: Parquet, Location: InMemoryFileIndex[file:/Users/fwang12/todo/apache-spark/sql/core/spark-warehouse/org.apache.spark..., PartitionFilters: &lt;span class=&quot;o&quot;&gt;[]&lt;/span&gt;, PushedFilters: &lt;span class=&quot;o&quot;&gt;[]&lt;/span&gt;, ReadSchema: struct&amp;lt;c1:decimal&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;38,18&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;,c2:int&amp;gt;
         +- &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;2&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; ColumnarToRow
            +- FileScan parquet default.tc[c1#248,c2#249] Batched: &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;, DataFilters: &lt;span class=&quot;o&quot;&gt;[]&lt;/span&gt;, Format: Parquet, Location: InMemoryFileIndex[file:/Users/fwang12/todo/apache-spark/sql/core/spark-warehouse/org.apache.spark..., PartitionFilters: &lt;span class=&quot;o&quot;&gt;[]&lt;/span&gt;, PushedFilters: &lt;span class=&quot;o&quot;&gt;[]&lt;/span&gt;, ReadSchema: struct&amp;lt;c1:double,c2:int&amp;gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;原来虽然表tb 和tc中都有名为c1的列，但是一个是Decimal类型，一个是double类型。在做union的时候，取 double 和Decimal的公共类型double，因此对表tb中的c1 进行了cast(c1 as double)，但是在insert overwrite bucket table的时候，由于bucket column c1的类型是Decimal，所以我们可以看到在进行&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Exchange hashpartitioning&lt;/code&gt; 之后进行了&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Project [ansi_cast(c1#250 as decimal(38,18)) AS c1#254, c2#247, 1 AS p1#255]&lt;/code&gt;  操作，又把double转成了Decimal.&lt;/p&gt;

&lt;p&gt;因此，我们前面hash 后的数据是基于double类型的hash，而bucket column类型是Decimal类型。&lt;/p&gt;

&lt;p&gt;查看FileFormatWriter中的write方法，其逻辑为，如果currentPartitionValue或者currentBucketId与next 不同。&lt;/p&gt;

&lt;p&gt;那么会创建一个新的文件。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currentPartionValues&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nextPartitionValues&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;currentBucketId&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nextBucketId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;// See a new partition or bucket - write to a new partition dir (or a new bucket file).&lt;/span&gt;
      &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isPartitioned&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;currentPartionValues&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nextPartitionValues&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;currentPartionValues&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Some&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;nextPartitionValues&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt;
        &lt;span class=&quot;nv&quot;&gt;statsTrackers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;foreach&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;newPartition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;currentPartionValues&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isBucketed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;currentBucketId&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nextBucketId&lt;/span&gt;
        &lt;span class=&quot;nv&quot;&gt;statsTrackers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;foreach&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;newBucket&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;currentBucketId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

      &lt;span class=&quot;n&quot;&gt;fileCounter&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
      &lt;span class=&quot;nf&quot;&gt;newOutputWriter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currentPartionValues&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;currentBucketId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;而double类型和Decimal类型getBucketId的算法是不同的。&lt;/p&gt;

&lt;p&gt;具体的实现涉及到&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;org.apache.spark.sql.catalyst.expressions.InterpretedHashFunction&lt;/code&gt;类中的hash方法。可以看到double类型和decimal类型有不同的实现。&lt;/p&gt;

&lt;p&gt;所以对double类型值其计算得到值和转化为Decimal再计算时不同的，附录中也提供了实践的验证方法。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;cm&quot;&gt;/**
   * Computes hash of a given `value` of type `dataType`. The caller needs to check the validity
   * of input `value`.
   */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;hash&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Any&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataType&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;DataType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Boolean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;hashInt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Byte&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;hashInt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Short&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;hashInt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;hashInt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;hashLong&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Float&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;hashInt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;Float&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;floatToIntBits&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Double&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;hashLong&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;Double&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;doubleToLongBits&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Decimal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;precision&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;dataType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;asInstanceOf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;DecimalType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;precision&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;precision&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;Decimal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;MAX_LONG_DIGITS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;nf&quot;&gt;hashLong&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;toUnscaledLong&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;bytes&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;toJavaBigDecimal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;unscaledValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;toByteArray&lt;/span&gt;
          &lt;span class=&quot;nf&quot;&gt;hashUnsafeBytes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bytes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;Platform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;BYTE_ARRAY_OFFSET&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;bytes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;因此，hash后的double类型数据，在转为Decimal之后，虽然其partitionValue获取是一致的，但是bucketId获取方法存在差异，因此一个task依然生成了十个bucket文件，造成了小文件的爆炸。&lt;/p&gt;

&lt;h3 id=&quot;关于double-和decimal&quot;&gt;关于double 和Decimal&lt;/h3&gt;

&lt;p&gt;除此之外，此处在简单介绍下double 和Decimal。&lt;/p&gt;

&lt;p&gt;double是一种采用科学计数法进行表示的模糊类型，其增大了表示范围，但是却丢失了表示精度。详细可参考前面写的一篇文章&lt;a href=&quot;/essay/2020/01/10/重新了解数字类型&quot;&gt;重新了解数字类型&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;而且前面提到的用户union 两个子查询，子查询有同名的列，一列是double， 一列是Decimal，而且以这两列进行Join key 进行join。&lt;/p&gt;

&lt;p&gt;double是一个模糊类型， Decimal是一个精确类型，在Spark中比较double 和Decimal的时候会将Decimal转化为double(强制类型转化) 然后与double进行比较，而这种比较是不精确的，容易造成输出爆炸。&lt;/p&gt;

&lt;p&gt;因此慎用double类型作为join key。&lt;/p&gt;

&lt;p&gt;例如下面的两个double 是不同的数字，比较相等却是true。&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;scala&amp;gt; 112345678901234568d &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; 112345678901234560d
res0: Boolean &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;解决方案&quot;&gt;解决方案&lt;/h3&gt;

&lt;p&gt;解决问题，可以从三方面考虑。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;绕过这个数字类型，解决小文件问题&lt;/li&gt;
  &lt;li&gt;通过重建表从根本解决问题&lt;/li&gt;
  &lt;li&gt;平台侧可以做什么&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;绕过数字类型解决小文件问题&quot;&gt;绕过数字类型，解决小文件问题&lt;/h4&gt;

&lt;p&gt;有两种方案。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第一种是用一个中间过渡表&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;首先将两个子查询 union之后的数据，写入到中间表。然后再select 这个中间表，然后对bucket column 对应的列进行cluster by（spark.sql.shuffle.partitions需要与bucket numer相同).&lt;/p&gt;

&lt;p&gt;这种方法的缺点是引入了working表，优点是可以分别针对 写入中间表部分和写入bucket表部分设置合适的spark.sql.shuffle.partitions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第二种方法是修改sql语句&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;修改前:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;insert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;overwrite&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ta&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tb&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;union&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;all&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tc&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distribute&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;修改后:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;partitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bucket&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;number&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;insert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;overwrite&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ta&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;cast&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Decimal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;38&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tb&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;union&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;all&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distribute&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;我们修改了语句，手动的将union之后为double类型c1 转为Decimal类型，然后再针对Decimal 类型的bucket 列进行 distributed by操作。当然在此之前，我们要将spark.sql.shuffle.partitions设为与bucket number相同的值。&lt;/p&gt;

&lt;h4 id=&quot;通过重建表从根本解决问题&quot;&gt;通过重建表从根本解决问题&lt;/h4&gt;

&lt;p&gt;强烈推荐用户使用这种方案。&lt;/p&gt;

&lt;h4 id=&quot;平台侧可以做什么&quot;&gt;平台侧可以做什么&lt;/h4&gt;

&lt;p&gt;在上面我们提到了我们的distribute/cluster是针对 union子查询的数据进行的，而在此之后要插入bucket表，又进行了类型转换。&lt;/p&gt;

&lt;p&gt;所以，平台是否可以针对insert bucket table这种case，做类似于谓词下推的把CAST下推到 distribute/cluster by 之前？&lt;/p&gt;

&lt;h3 id=&quot;后记&quot;&gt;后记&lt;/h3&gt;

&lt;p&gt;如果是一万个bucket 的bucket表，那岂不是小文件要破亿了？&lt;/p&gt;

&lt;h3 id=&quot;附录&quot;&gt;附录&lt;/h3&gt;

&lt;h4 id=&quot;验证double-和decimal-类型的bucket-id-是否不同&quot;&gt;验证double 和Decimal 类型的bucket Id 是否不同&lt;/h4&gt;

&lt;p&gt;此处使用json格式是因为其可以直接查看数据。&lt;/p&gt;

&lt;p&gt;在跑完之后去查看表下面的文件，文件名格式:&lt;/p&gt;

&lt;p&gt;part-{partId}-{UUID}_{bucketId}.c000.json&lt;/p&gt;

&lt;p&gt;我们只需对比两张表同样bucketId 文件下面的内容不同即可得出结论。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nf&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;create table ta(c1 double, c2 int) using json clustered by(c1) into 10 buckets&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;create table tb(c1 decimal(38, 18), c2 int) using json clustered by (c1) into 10 buckets&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;create table tc(c1 double, c2 int) using json&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;create table td(c1 decimal(38, 18), c2 int) using json&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;insert into tc select * from values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9), (10, 10)&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;insert into td select * from values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9),(10,10)&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;insert overwrite table ta select * from tc&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;insert overwrite table tb select * from td&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
                <link>http://www.turbofei.wang/spark/2020/03/28/%E8%AE%B0%E4%B8%80%E6%AC%A1%E4%B8%8ESpark-bucket-table%E7%9B%B8%E5%85%B3%E7%9A%84%E5%B0%8F%E6%96%87%E4%BB%B6%E9%97%AE%E9%A2%98</link>
                <guid>http://www.turbofei.wang/spark/2020/03/28/记一次与Spark bucket table相关的小文件问题</guid>
                <pubDate>2020-03-28T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>Spark Timeout Parameters</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#前言&quot; id=&quot;markdown-toc-前言&quot;&gt;前言&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#已废弃参数&quot; id=&quot;markdown-toc-已废弃参数&quot;&gt;已废弃参数&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#misc&quot; id=&quot;markdown-toc-misc&quot;&gt;Misc&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#dynamic-allocation&quot; id=&quot;markdown-toc-dynamic-allocation&quot;&gt;Dynamic Allocation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#network&quot; id=&quot;markdown-toc-network&quot;&gt;Network&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#rpc&quot; id=&quot;markdown-toc-rpc&quot;&gt;RPC&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#shuffle&quot; id=&quot;markdown-toc-shuffle&quot;&gt;Shuffle&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#sql&quot; id=&quot;markdown-toc-sql&quot;&gt;SQL&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#storage&quot; id=&quot;markdown-toc-storage&quot;&gt;Storage&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#task&quot; id=&quot;markdown-toc-task&quot;&gt;Task&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#worker&quot; id=&quot;markdown-toc-worker&quot;&gt;Worker&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;记录Spark中的timeout参数&lt;/p&gt;

&lt;h3 id=&quot;前言&quot;&gt;前言&lt;/h3&gt;

&lt;p&gt;Spark中许多timeout参数，本文对core和sql模块的相关参数进行梳理，基于spark-2.3.&lt;/p&gt;

&lt;h3 id=&quot;已废弃参数&quot;&gt;已废弃参数&lt;/h3&gt;

&lt;p&gt;spark从1.4开始用rpc取代了akka，所以akka相关的参数被rpc参数取代。详情请看[RPC]部分.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Spark.akka.askTimeout -&amp;gt; spark.rpc.spark.rpc.askTimeout&lt;/li&gt;
  &lt;li&gt;spark.akka.lookupTimeout -&amp;gt; spark.rpc.lookupTimeout&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;misc&quot;&gt;Misc&lt;/h3&gt;

&lt;p&gt;spark.starvation.timeout&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;spark.blacklist.timeout&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;默认 1h&lt;/p&gt;

      &lt;p&gt;一个节点或者executor对整个应用而言被blacklist的时间&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;spark.files.fetchTimeout&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;默认60s&lt;/p&gt;

      &lt;p&gt;通过调用SparkContex.addFile方法添加文件时的timeout.&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;spark.launcher.childConectionTimeout&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;默认10s&lt;/p&gt;

      &lt;p&gt;当调用SparkLauncher start()方法时，等待子线程和launcher server通信的timeout.&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;spark.starvation.timeout&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;默认15s&lt;/p&gt;

      &lt;p&gt;用于在应用初始阶段，以其为时间间隔检查是否task已经启动， 如果没有启动则表示task处于饥饿状态，打出warning通知用户。如果已经task启动， 则退出检查。&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dynamic-allocation&quot;&gt;Dynamic Allocation&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;spark.dynamicAllocation.cachedExecutorIdleTimeout&lt;/p&gt;

    &lt;blockquote&gt;

    &lt;/blockquote&gt;

    &lt;p&gt;spark.dynamicAllocation.executorIdleTimeout
spark.dynamicAllocation.schedulerBacklogTimeout
spark.dynamicAllocation.shuffleTimeout
spark.dynamicAllocation.sustainedSchedulerBacklogTimeout&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;network&quot;&gt;Network&lt;/h3&gt;

&lt;p&gt;spark.network.auth.rpcTimeout
spark.network.timeout&lt;/p&gt;

&lt;h3 id=&quot;rpc&quot;&gt;RPC&lt;/h3&gt;

&lt;p&gt;spark.rpc.RpcTimeout
spark.rpc.askTimeout
spark.rpc.long.timeout
spark.rpc.lookupTimeout
spark.rpc.short.timeout&lt;/p&gt;

&lt;h3 id=&quot;shuffle&quot;&gt;Shuffle&lt;/h3&gt;

&lt;p&gt;spark.shuffle.io.connectionTimeout
spark.shuffle.registration.timeout
spark.shuffle.sasl.timeout&lt;/p&gt;

&lt;h3 id=&quot;sql&quot;&gt;SQL&lt;/h3&gt;

&lt;p&gt;spark.sql.broadcastTimeout
spark.sql.catalyst.plans.logical.EventTimeTimeout
spark.sql.catalyst.plans.logical.NoTimeout
spark.sql.catalyst.plans.logical.ProcessingTimeTimeout
spark.sql.streaming.GroupStateTimeout
spark.sql.streaming.stopTimeout&lt;/p&gt;

&lt;h3 id=&quot;storage&quot;&gt;Storage&lt;/h3&gt;

&lt;p&gt;spark.storage.blockManagerSlaveTimeoutMs
spark.storage.blockManagerTimeout&lt;/p&gt;

&lt;h3 id=&quot;task&quot;&gt;Task&lt;/h3&gt;

&lt;p&gt;spark.task.killTimeout
spark.task.reaper.killTimeout&lt;/p&gt;

&lt;h3 id=&quot;worker&quot;&gt;Worker&lt;/h3&gt;

&lt;p&gt;spark.worker.driverTerminateTimeout
spark.worker.timeout&lt;/p&gt;

</description>
                <link>http://www.turbofei.wang/spark/2020/03/10/spark-timeout-parameters</link>
                <guid>http://www.turbofei.wang/spark/2020/03/10/spark-timeout-parameters</guid>
                <pubDate>2020-03-10T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>重新了解数字类型</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#前言&quot; id=&quot;markdown-toc-前言&quot;&gt;前言&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#基本数字类型&quot; id=&quot;markdown-toc-基本数字类型&quot;&gt;基本数字类型&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#浮点数&quot; id=&quot;markdown-toc-浮点数&quot;&gt;浮点数&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#类型转换&quot; id=&quot;markdown-toc-类型转换&quot;&gt;类型转换&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#关于decimal&quot; id=&quot;markdown-toc-关于decimal&quot;&gt;关于Decimal&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#结尾&quot; id=&quot;markdown-toc-结尾&quot;&gt;结尾&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最近遇到了一些数字类型有关的问题，重新了解一下数字类型&lt;/p&gt;

&lt;h3 id=&quot;前言&quot;&gt;前言&lt;/h3&gt;

&lt;p&gt;计算机中由二进制表示数据，所以一切数字都是表示为:&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;p10 * 2^0 + p11* 2^1 + p12 * 2^2 + ... + p1n * 2^n + p01 * 2^(-1) + p02 * 2^(-2) + ... + p0n * 2^(-n)， 其中p0k p1k 都是0或者1 。&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;因此，对于1.5 来说，其可以拆分为: 1*2^0 + 1 * 2^(-1)是可以准确表示的。&lt;/p&gt;

&lt;p&gt;但是对于1.6来说，其实拆分为 1* 2^0 + 1*2^(-1) + 0 * 2 ^(-2) + 0 *2^(-3) + 1 * 2 ^(-4) + … 是不能精确表示的。&lt;/p&gt;

&lt;p&gt;因此，在计算机中，1.6 -1.5并不是0.1, 如下。这跟自然中我们的理解是不同的。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.6&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.5&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;res2&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Double&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.10000000000000009&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;基本数字类型&quot;&gt;基本数字类型&lt;/h3&gt;

&lt;p&gt;在Spark中，基本数字类型可以分为IntegerType 和Float/DoubleType 以及Decimal类型。&lt;/p&gt;

&lt;p&gt;其中IntegerType又分为Byte, Short, Int, Long.  而Float/DoubleType 是浮点类型。&lt;/p&gt;

&lt;p&gt;IntegerType是一种可以精准表示一个数字的类型。Byte是8位，Short 16位，Int 32位，Long 64位，其最大值是2^n -1, n为位数。其中Int的最大值小于10^11次方，而Long的最大值小于10^20次方。&lt;/p&gt;

&lt;p&gt;浮点与定点是指小数点的位置会不会发生浮动，显然整数中小数点位置是不会浮动的，Decimal也是一种定点数。&lt;/p&gt;

&lt;h4 id=&quot;浮点数&quot;&gt;浮点数&lt;/h4&gt;

&lt;p&gt;回到浮点数，浮点数利用指数使小数点的位置可以根据需要进行上下浮动，从而灵活表达更大范围的实数。&lt;/p&gt;

&lt;p&gt;摘自百度百科，&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;浮点数从逻辑上用三元组{S, E, M}表示一个数v &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;|S|       E   |   M      |&lt;/code&gt;&lt;/p&gt;

  &lt;ul&gt;
    &lt;li&gt;其中S表示符号位，是正数还是负数&lt;/li&gt;
    &lt;li&gt;E 表示指数位，其可以为正数或者负数&lt;/li&gt;
    &lt;li&gt;M位于尾部。&lt;/li&gt;
  &lt;/ul&gt;

  &lt;p&gt;表达式为:&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;v=(-1)^s  * 2 ^e *m&lt;/code&gt;&lt;/p&gt;

  &lt;p&gt;现在大部分平台的浮点数遵循IEEE 754标准，float通常是32位，double 通常是64位。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;浮点数采用科学计数法，32位的float的小数部分有效位是8位,精确表示应该是7位， 而64位的double的小数部分有效位是16位, 精确表示位数应该是15位。&lt;/p&gt;

&lt;p&gt;例如: 112345678901234567d 被表示为 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1.1234567890123456E17&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;所以，当两个大于10^15的double/大于10^7次方的float进行比较是一件很危险的事情。&lt;/p&gt;

&lt;p&gt;例如下面两个完全不同的数字比较出来的结果却是相等。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;112345678901234568d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;112345678901234560d&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;res13&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Boolean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;112345678f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;112345679f&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;res14&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Boolean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;112345678f&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;res15&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Float&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.1234568E8&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;类型转换&quot;&gt;类型转换&lt;/h4&gt;

&lt;p&gt;在编程中，如果两个不同类型的操作数做计算，就会将低级别的类型向高级别的类型进行类型转换。&lt;/p&gt;

&lt;p&gt;通常的规则是Byte向Short转换，Short向Int转，然后向Long，向Float，Float向Double转换。&lt;/p&gt;

&lt;p&gt;比较一个整型和一个浮点类型是有风险的.&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1234567890&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1234567880f&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;res1&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Boolean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;123456789012345675&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;123456789012345679d&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;res2&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Boolean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;比较两个浮点型也是有风险的:&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;123456789012345679d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;123456789012345679f&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;res1&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Boolean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;112345678901234568d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;112345678901234560d&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;res2&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Boolean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;将一个Int值先转为float，再转为double 和直接转为double是不一样的。&lt;/p&gt;

&lt;p&gt;举个例子，如下:&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;MaxValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;toFloat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;toDouble&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;res23&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Double&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2.147483648E9&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;MaxValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;toDouble&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;res24&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Double&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2.147483647E9&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;关于decimal&quot;&gt;关于Decimal&lt;/h4&gt;

&lt;p&gt;用于表示小数，在Spark中，除了使用double/float,还有一个选择就是使用Decimal。&lt;/p&gt;

&lt;p&gt;关于Decimal，我曾经写过一篇文章&lt;a href=&quot;https://mp.weixin.qq.com/s/yKFzO41l-2n617xICN2ObQ&quot;&gt;案例分析| 由Decimal操作计算引发的Spark数据丢失问题&lt;/a&gt;, 里面介绍到Decimal，如下:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Decimal是数据库中的一种数据类型，不属于浮点数类型，可以在定义时划定整数部分以及小数部分的位数。&lt;/strong&gt;对于一个Decimal类型，scale表示其小数部分的位数，precision表示整数部分位数和小数部分位数之和。&lt;/p&gt;

  &lt;p&gt;一个Decimal类型表示为Decimal(precision, scale)，在Spark中，precision和scale的上限都是&lt;strong&gt;38&lt;/strong&gt;。&lt;/p&gt;

  &lt;p&gt;一个double类型可以精确地表示小数点后&lt;strong&gt;15位&lt;/strong&gt;，有效位数为&lt;strong&gt;16位&lt;/strong&gt;。&lt;/p&gt;

  &lt;p&gt;可见，Decimal类型则可以更加精确地表示，保证数据计算的精度。&lt;/p&gt;

  &lt;p&gt;例如一个&lt;strong&gt;Decimal(38, 24)类型&lt;/strong&gt;可以精确表示小数点后23位，小数点后有效位数为24位。而其整数部分还剩下14位可以用来表示数据，所以整数部分可以表示的范围是-10^14+1~10^14-1。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;所以关于金钱有关的数据，在Spark中通常是使用Decimal进行存储。&lt;/p&gt;

&lt;h3 id=&quot;结尾&quot;&gt;结尾&lt;/h3&gt;

&lt;p&gt;浮点类型是模糊的表示一个小数，它可以表示更大的范围，但是也丢失了很多东西。在Spark中如果以两个浮点类型的列做join是件蛮危险的事情, 可能会得到意想不到的结果。&lt;/p&gt;

&lt;p&gt;但是在Spark中，为了减少在Decimal操作时容易溢出的问题，有时候会将Decimal转换为double类型。&lt;/p&gt;

</description>
                <link>http://www.turbofei.wang/essay/2020/01/10/%E9%87%8D%E6%96%B0%E4%BA%86%E8%A7%A3%E6%95%B0%E5%AD%97%E7%B1%BB%E5%9E%8B</link>
                <guid>http://www.turbofei.wang/essay/2020/01/10/重新了解数字类型</guid>
                <pubDate>2020-01-10T00:00:00-08:00</pubDate>
        </item>

        <item>
                <title>About Hdfs Lease</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#背景&quot; id=&quot;markdown-toc-背景&quot;&gt;背景&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#hdfs-lease机制&quot; id=&quot;markdown-toc-hdfs-lease机制&quot;&gt;Hdfs lease机制&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#soft-limit&quot; id=&quot;markdown-toc-soft-limit&quot;&gt;Soft limit&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#基于soft-limit的lock&quot; id=&quot;markdown-toc-基于soft-limit的lock&quot;&gt;基于Soft Limit的Lock？&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#附录-soft-limit-单元测试&quot; id=&quot;markdown-toc-附录-soft-limit-单元测试&quot;&gt;附录-Soft Limit 单元测试&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;关于Hdfs的租约机制&lt;/p&gt;

&lt;h3 id=&quot;背景&quot;&gt;背景&lt;/h3&gt;

&lt;p&gt;最近有需求，需要了解一下hdfs 的lease机制。&lt;/p&gt;

&lt;h3 id=&quot;hdfs-lease机制&quot;&gt;Hdfs lease机制&lt;/h3&gt;

&lt;p&gt;本章节代码基于hadoop-2.7.4分支。&lt;/p&gt;

&lt;p&gt;hdfs是一个分布式文件系统，分布式意味着高并发，经常会面临文件同时访问的问题，如果保证合理有序的访问这些文件呢？答案就是lease机制，lease顾名思义租约，就是服务端给客户端一个临时的ticket，无此ticket以及ticket过期将不会再允许对此文件进行某些操作。&lt;/p&gt;

&lt;p&gt;Hdfs管理租约的类叫LeaseManager，里面维护了三个有序集合(TreeMap/TreeSet)，相当于三个不同的索引，用于不同的操作进行查询。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;租约持有者与租约的有序映射&lt;/li&gt;
  &lt;li&gt;文件路径与租约的映射&lt;/li&gt;
  &lt;li&gt;按照时间排序的租约集合&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;此外里面有两个重要的字段:&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;softLimit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;HdfsConstants&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;LEASE_SOFTLIMIT_PERIOD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 60s&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hardLimit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;HdfsConstants&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;LEASE_HARDLIMIT_PERIOD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 1hour&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里的softLimit 和hardLimit与linux中 soft limit和hard limit不同，linux中limit代表的是打开文件的上限，而这里的limit其实是一个周期。&lt;/p&gt;

&lt;p&gt;LeaseManager中大多数方法都是 get/remove/set方法以及renew操作，这些方法都是用于与dfsClient进行交互，是一些被动的操作，LeaseManager中一个最重要的操作是释放过期的租约，因为往往会有异常情况发生，DfsClient没有优雅的发送释放自己租约的请求而就异常关闭了。这时候，如果租约得不到释放， 将会影响到其他dfsClient对其持有文件的访问。&lt;/p&gt;

&lt;p&gt;LeaseManager中的做法是创建一个守护监控线程，定时的来监控和释放租约，其Monitor实现类如下:&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Monitor&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;implements&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Runnable&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;getClass&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getSimpleName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;

    &lt;span class=&quot;cm&quot;&gt;/** Check leases periodically. */&lt;/span&gt;
    &lt;span class=&quot;nd&quot;&gt;@Override&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shouldRunMonitor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fsnamesystem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;isRunning&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;kt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;needSync&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;fsnamesystem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;writeLockInterruptibly&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;// 当前模式不是安全模式&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fsnamesystem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;isInSafeMode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
              &lt;span class=&quot;c1&quot;&gt;// 调用checkLease，并且返回sortedLeases 是否需要sync&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;needSync&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;checkLeases&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;finally&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;fsnamesystem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;writeUnlock&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;leaseManager&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;// lease reassignments should to be sync&apos;ed.&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;needSync&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
              &lt;span class=&quot;c1&quot;&gt;// 如果需要sync sortedLeases，则进行同步&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;fsnamesystem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getEditLog&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;logSync&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
          &lt;span class=&quot;c1&quot;&gt;// 周期为 2000 ms&lt;/span&gt;
          &lt;span class=&quot;nc&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;HdfsServerConstants&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;NAMENODE_LEASE_RECHECK_INTERVAL&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;InterruptedException&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ie&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;LOG&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;isDebugEnabled&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;no&quot;&gt;LOG&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;debug&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; is interrupted&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ie&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;代码中显示，其会根据NAMENODE_LEASE_RECHECK_INTERVAL(2000ms)定时的调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;checkLeases&lt;/code&gt;方法。&lt;/p&gt;

&lt;p&gt;代码可以分为三部分：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;由于sortedLease是按照时间对租约排序，第一部分就是取出最老的lease 用于检查&lt;/li&gt;
  &lt;li&gt;第二部分是一个while循环检查这个lease&lt;/li&gt;
  &lt;li&gt;第三部分是在检查完之后，检查sortedLeases是否需要进行sync，返回检查结果，这个结果用于后续在monitor线程中对这个sortedLease进行同步。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;代码很清晰，核心逻辑是第二部分，我们看下第二部分的while循环代码。&lt;/p&gt;

&lt;p&gt;可以看到一上来就是先看当前lease 是否超出了hardLimit的限制，如果没有，那么直接退出check操作。&lt;/p&gt;

&lt;p&gt;如果超出了hardLimit的限制：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;获取当前lease持有的文件路径&lt;/li&gt;
  &lt;li&gt;如果其持有文件路径，则这些文件路径从租约中删除&lt;/li&gt;
  &lt;li&gt;将此租约删除。&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;   &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;leaseToCheck&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;leaseToCheck&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;expiredHardLimit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

      &lt;span class=&quot;no&quot;&gt;LOG&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;leaseToCheck&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; has expired hard limit&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;

      &lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;removing&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ArrayList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;();&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;// need to create a copy of the oldest lease paths, because &lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;// internalReleaseLease() removes paths corresponding to empty files,&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;// i.e. it needs to modify the collection being iterated over&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;// causing ConcurrentModificationException&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;leasePaths&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;leaseToCheck&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getPaths&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()];&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;leaseToCheck&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getPaths&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;toArray&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;leasePaths&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;leasePaths&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;nc&quot;&gt;INodesInPath&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iip&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fsnamesystem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getFSDirectory&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getINodesInPath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
          &lt;span class=&quot;kt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;completed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fsnamesystem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;internalReleaseLease&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;leaseToCheck&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;iip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;HdfsServerConstants&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;NAMENODE_LEASE_HOLDER&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;LOG&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;isDebugEnabled&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;completed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
              &lt;span class=&quot;no&quot;&gt;LOG&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;debug&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Lease recovery for &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; is complete. File closed.&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
              &lt;span class=&quot;no&quot;&gt;LOG&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;debug&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Started block recovery &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; lease &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;leaseToCheck&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
          &lt;span class=&quot;c1&quot;&gt;// If a lease recovery happened, we need to sync later.&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;needSync&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;completed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;needSync&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;IOException&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;no&quot;&gt;LOG&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Cannot release the path &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; in the lease &quot;&lt;/span&gt;
              &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;leaseToCheck&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;removing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

      &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;removing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;removeLease&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;leaseToCheck&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;leaseToCheck&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sortedLeases&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;higher&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;leaseToCheck&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;soft-limit&quot;&gt;Soft limit&lt;/h4&gt;

&lt;p&gt;上面我们看到在checkLease方法中，使用到了hardLimit，如果租约超时hardLimit，那么就将该lease相关清除掉。&lt;/p&gt;

&lt;p&gt;那么softLimit的作用呢？&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;cm&quot;&gt;/** @return true if the Soft Limit Timer has expired */&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;expiredSoftLimit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;monotonicNow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lastUpdate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;softLimit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;通过查看代码，我们看到有一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;expiredSoftLimit&lt;/code&gt;方法， 其调用是发生在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FSNameSystem&lt;/code&gt;中，对应方法为&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;recoverLeaseInternal&lt;/code&gt;，调用部分如下，如果当前的持有者已经在上个softLimit周期没有刷新这个lease,&lt;/p&gt;

&lt;p&gt;那么调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;internalReleaseLease&lt;/code&gt;， 顾名思义，释放internalLease, 其注释为 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Move a file that is being written to be immutable.&lt;/code&gt;, 也就是说把一个正在被写的文件变为不可改变的状态.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;        &lt;span class=&quot;c1&quot;&gt;// If the original holder has not renewed in the last SOFTLIMIT &lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;// period, then start lease recovery.&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;//&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lease&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;expiredSoftLimit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;no&quot;&gt;LOG&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;startFile: recover &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lease&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;, src=&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; client &quot;&lt;/span&gt;
              &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clientName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;internalReleaseLease&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lease&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;RecoveryInProgressException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;op&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getExceptionMessage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;holder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clientMachine&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;s&quot;&gt;&quot;lease recovery is in progress. Try again later.&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;关于这方面的上下文如下:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;首先DFSClient是获取lease的主体，当其生成之后会被添加到对应的LeaseRenewer的dfsClient列表里面，周期性的进行刷新lease，周期是固定的softLimitPeriod/2,也就是30s&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;所以一般情况下这个lease不会超过softLimit，除非&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;LeaseRenewer发生严重的GC，无法renew //可能性极小&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;DFSClient异常退出，已经从LeaseRenewer中移出，但是租约还未超过HardLimit所以租约还未移除&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;将文件从正在被写变为不可变状态意味着另外一个dfsClient可以开始对其写入，例如进行append操作。&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;基于soft-limit的lock&quot;&gt;基于Soft Limit的Lock？&lt;/h5&gt;

&lt;p&gt;那么是否可以利用soft limit做一个简单的锁？&lt;/p&gt;

&lt;p&gt;例如在app1 中create 一个lock文件，在应用正常结束时会清理掉这个lock文件，当然如果其异常退出，是不会清理掉这个lock文件的。&lt;/p&gt;

&lt;p&gt;另外一个app2尝试去探测这个lock文件，探测方法为如果这个lock存在则尝试append这个lock文件，如果append成功，则代表可以获得这个lock。&lt;/p&gt;

&lt;p&gt;如果不能append成功，则有两种可能:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;这个lock正在被另一个app持有&lt;/li&gt;
  &lt;li&gt;另一个app异常退出，但是距其异常退出的间隔还未到达softLimitPeriod&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;所以这个锁，就相当于app正常退出会释放， 如果app异常退出，超过softLimitPeriod(60s)也会自动释放。&lt;/p&gt;

&lt;h3 id=&quot;附录-soft-limit-单元测试&quot;&gt;附录-Soft Limit 单元测试&lt;/h3&gt;

&lt;p&gt;在pom.xml文件中添加:&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;nt&quot;&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.apache.hadoop&lt;span class=&quot;nt&quot;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;hadoop-minicluster&lt;span class=&quot;nt&quot;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;version&amp;gt;&lt;/span&gt;${hadoop.version}&lt;span class=&quot;nt&quot;&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;scope&amp;gt;&lt;/span&gt;test&lt;span class=&quot;nt&quot;&gt;&amp;lt;/scope&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.util.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Failure&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Success&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Try&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.hadoop.fs.Path&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.hadoop.hdfs.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;DistributedFileSystem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;HdfsConfiguration&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MiniDFSCluster&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.hadoop.hdfs.protocol.HdfsConstants&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.scalatest.Assertions.intercept&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SoftLimitLockSuite&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;hdfsConf&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;HdfsConfiguration&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;hdfsConf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;fs.hdfs.impl.disable.cache&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;true&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;cluster&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;MiniDFSCluster&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;Builder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hdfsConf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;cluster&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;waitClusterUp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;fs&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;cluster&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;getFileSystem&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;lock&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;getHomeDirectory&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;LOCK&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;// app 正常结束&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;app1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AppLockThread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lock&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;abort&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;nv&quot;&gt;app1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
      &lt;span class=&quot;nv&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;nv&quot;&gt;app1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;interrupt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
      &lt;span class=&quot;nv&quot;&gt;app1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;// fs 可以append 这个lock文件成功&lt;/span&gt;
      &lt;span class=&quot;nv&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lock&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;

      &lt;span class=&quot;c1&quot;&gt;// app 异常退出&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;app2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AppLockThread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lock&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;abort&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;nv&quot;&gt;app2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
      &lt;span class=&quot;nv&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;nv&quot;&gt;app2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;interrupt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
      &lt;span class=&quot;nv&quot;&gt;app2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;intercept&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Exception&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lock&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;// 等待一个soft limit 周期&lt;/span&gt;
      &lt;span class=&quot;nv&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;HdfsConstants&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;LEASE_SOFTLIMIT_PERIOD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;// fs 可以append成功&lt;/span&gt;
      &lt;span class=&quot;nv&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lock&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;finally&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;nv&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
      &lt;span class=&quot;nv&quot;&gt;cluster&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;shutdown&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;cm&quot;&gt;/**
   * 模拟一个app 线程, abort 参数代表是否正常退出
   */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AppLockThread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lock&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;abort&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Boolean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Thread&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dfs&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;DistributedFileSystem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;None&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;dfs&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Some&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;cluster&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;getFileSystem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nv&quot;&gt;dfs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;create&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lock&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;nv&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;HdfsConstants&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;LEASE_SOFTLIMIT_PERIOD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;InterruptedException&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;// Here is an reflection implementation of DistributedFileSystem.close()&lt;/span&gt;
            &lt;span class=&quot;nv&quot;&gt;dfs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;foreach&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;getClient&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;closeOutputStreams&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;abort&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;nf&quot;&gt;invokeSuperMethod&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;dfs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;close&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;finally&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nv&quot;&gt;dfs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;foreach&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;getClient&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;cm&quot;&gt;/**
   * Invoke a super method of an object via reflection.
   */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;invokeSuperMethod&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Any&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Any&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;Try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;method&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nv&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;getClass&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;getSuperclass&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;getDeclaredMethod&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;NoSuchMethodException&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nv&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;getClass&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;getMethod&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;nv&quot;&gt;method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;setAccessible&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;nv&quot;&gt;method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;invoke&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Success&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Failure&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
                <link>http://www.turbofei.wang/hadoop/2019/12/28/About-Hdfs-Lease</link>
                <guid>http://www.turbofei.wang/hadoop/2019/12/28/About-Hdfs-Lease</guid>
                <pubDate>2019-12-28T00:00:00-08:00</pubDate>
        </item>

        <item>
                <title>Spark随笔</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#前言&quot; id=&quot;markdown-toc-前言&quot;&gt;前言&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#关于bucket-table&quot; id=&quot;markdown-toc-关于bucket-table&quot;&gt;关于bucket table&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#关于解析和更改spark-sql语句&quot; id=&quot;markdown-toc-关于解析和更改spark-sql语句&quot;&gt;关于解析和更改Spark sql语句&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;写点Spark相关的随笔&lt;/p&gt;

&lt;h3 id=&quot;前言&quot;&gt;前言&lt;/h3&gt;

&lt;p&gt;最近可能比较忙，没有更新博客，写一点Spark相关的随笔。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;关于bucket table&lt;/li&gt;
  &lt;li&gt;关于解析和更改Spark sql语句&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;关于bucket-table&quot;&gt;关于bucket table&lt;/h3&gt;

&lt;p&gt;bucket table是一种Spark常见的优化查询的建表方式。&lt;/p&gt;

&lt;p&gt;创建方式是使用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;clustered by &lt;/code&gt;语法进行创建，会根据&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.shuffle.partitions&lt;/code&gt;的值创建若干个bucket。&lt;/p&gt;

&lt;p&gt;Spark中对于两个大表的join，采用的方式是SortMergeJoin.&lt;/p&gt;

&lt;p&gt;而如果两个表都是bucket表，而且bucket数量相同(业界有公司针对这块的优化，如果两个bucket表bucket数量是倍数关系也可以进行bucket join)，那么可以跳过sort(或者加速) 和 shuffle，直接进行join, 会产生较好的性能，通常需要业务方会约定好bucket的数量。&lt;/p&gt;

&lt;p&gt;Spark针对bucket表读取的时候，会对每一个bucket分配一个task来读取，因为如果进行bucket join就不能再对这个bucket的数据进行拆分。&lt;/p&gt;

&lt;p&gt;但是问题来了，我们并不是每次读取bucket表都是为了进行bucket join，比如说有时候我们会对这个bucket进行etl操作。&lt;/p&gt;

&lt;p&gt;如果只是单纯的对这个bucket表进行一些处理操作，例如就是一个单纯的shuffle操作。而这个bucket表的每个bucket都特别大，例如大于1个G，而在shuffle write阶段要生成3G的数据。那么这时候对每个bucket分配一个task来处理就会非常吃力。&lt;/p&gt;

&lt;p&gt;其实spark sql中有一个参数 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.sources.bucketing.enabled&lt;/code&gt;,默认是true。如果我们将这个参数设置为false，那么spark就会将一个bucket table看做一个普通的table。&lt;/p&gt;

&lt;p&gt;这意味着什么呢？&lt;/p&gt;

&lt;p&gt;Spark对于普通表，如果他的单个文件大于一个hdfs  block大小(通常是128M)，而且这个文件又是可拆分的(例如text文本，snappy 压缩格式的parquet文件等等)，那么spark会按照这个文件拆分，分配多个task来处理。&lt;/p&gt;

&lt;p&gt;因此，针对我们上面的场景，设置这个参数为false，可以大大的加快map阶段的执行，起到优化的效果。&lt;/p&gt;

&lt;h3 id=&quot;关于解析和更改spark-sql语句&quot;&gt;关于解析和更改Spark sql语句&lt;/h3&gt;

&lt;p&gt;如果你有对一个Spark sql语句进行解析和更改部分语句的需求。&lt;/p&gt;

&lt;p&gt;例如我需求对一条sql中的表名进行映射修改，或者对其中的UDF(其实在spark sql中function 和table 是很类似的东西)和location信息进行修改。&lt;/p&gt;

&lt;p&gt;可能首先想到的就是使用正则进行字符串匹配，去寻找自己需要的字段，但是这种方法十分的不靠谱，因为sql的语法十分复杂，我们很难完全准确的抓取到自己需要的信息。&lt;/p&gt;

&lt;p&gt;所以我们能不能根据抽象语法树去拿到我们想要的字段呢？&lt;/p&gt;

&lt;p&gt;答案当然是Ok的，一条sql语句进行解析器之后都会成为一个抽象语法树，每个TreeNode都有自己的类型，我们可以根据这些类型拿到自己想要的信息，比如table name， function name, location等等信息(table 根据TableIdentifier类型节点获得，function根据FunctionIdentifier, location信息从LoadDataCommand或者CreateTableCommand中获取)。&lt;/p&gt;

&lt;p&gt;如下图所以，一条SQL语句&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INSERT INTO TRABLE tb SELECT ta.id FROM ta JOIN tb on ta.id=tb.id&lt;/code&gt;会被大概转化为下面一个AST.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/spark-sth/ast.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;但是，当我们拿到我们想要的信息，之后如何转换想要的SQL呢？&lt;/p&gt;

&lt;p&gt;我第一想法是说，直接修改这个AST，然后将这个AST转化为一条SQL语句。但是AST转SQL很麻烦的事情，需要你自己精通sql语法，然后写一套 Plan转String的规则。这听起来就很麻烦。&lt;/p&gt;

&lt;p&gt;好在经过一番探索:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Spark使用antlr v4进行sql解析&lt;/li&gt;
  &lt;li&gt;每个sql最开始解析为一个原始的AST(parsedPlan，未经过analyze/optimize)&lt;/li&gt;
  &lt;li&gt;这个sql也对应一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ParserRuleContext&lt;/code&gt;(package &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;org.antlr.v4.runtime&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ParserRuleContext其实也是一棵树，类似于AST，但是它的每个叶子节点会对应一段text,也就是说对应一部分原始的sql语句(table对应TableIdentifierContext，function对应QualifiedNameContext, location对应LocationSpecContext)。&lt;/p&gt;

&lt;p&gt;感兴趣的话可以去看这个类的源码: https://github.com/antlr/antlr4/blob/master/runtime/Java/src/org/antlr/v4/runtime/ParserRuleContext.java。&lt;/p&gt;

&lt;p&gt;前面我们提到的语句会被转化为下面的一棵树，我这里是将其转为String打印出来，在每个节点处进行了换行。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/spark-sth/parserRuleContext.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;有了这样的两棵树AST 和ParserRuleContext，我们就可以根据第一棵树，拿到我们想要的信息，然后再在第二棵树上面找到其对应的偏移量。&lt;/p&gt;

&lt;p&gt;然后对对应部分进行替换，之后再把第二棵树的碎片对应的文本拼接起来就好了。&lt;/p&gt;
</description>
                <link>http://www.turbofei.wang/spark/2019/12/04/Spark%E9%9A%8F%E7%AC%94</link>
                <guid>http://www.turbofei.wang/spark/2019/12/04/Spark随笔</guid>
                <pubDate>2019-12-04T00:00:00-08:00</pubDate>
        </item>

        <item>
                <title>A Broadcastjoin Issue In Spark</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#前言&quot; id=&quot;markdown-toc-前言&quot;&gt;前言&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#broadcastjoin&quot; id=&quot;markdown-toc-broadcastjoin&quot;&gt;BroadcastJoin&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#问题描述&quot; id=&quot;markdown-toc-问题描述&quot;&gt;问题描述&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#问题排查&quot; id=&quot;markdown-toc-问题排查&quot;&gt;问题排查&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#解决方案&quot; id=&quot;markdown-toc-解决方案&quot;&gt;解决方案&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#总结&quot; id=&quot;markdown-toc-总结&quot;&gt;总结&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#附录&quot; id=&quot;markdown-toc-附录&quot;&gt;附录&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Spark中有三种Join, BroadcastJoin, ShuffleHashJoin, SortMergeJoin。而BroadcastJoin通常认为是一种较为轻量的Join，因为其不走shuffle，本文描述一个与BroadcastJoin相关比较诡异的Issue。&lt;/p&gt;

&lt;h3 id=&quot;前言&quot;&gt;前言&lt;/h3&gt;

&lt;p&gt;在Spark中，根据Join的物理执行方式来划分种类，可以分为以下三种。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;BroadcastJoin: 适用于一个极小表和一个大表的Join，其会把极小表由driver给各个executor，而不会触发Shuffle，而shuffle往往是任务的瓶颈所在，因此通常Broadcast被认为是一种十分轻量的Join。&lt;/li&gt;
  &lt;li&gt;ShuffleHashJoin:适用于一个小表和一个大表进行Join，会触发shuffle。&lt;/li&gt;
  &lt;li&gt;SortMergeJoin：适用于两个大表进行Join，其首先会对两个表的数据进行划分partition排序，然后把相应的分区进行发送到task端进行merge执行，因此称之为SortMergeJoin。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;broadcastjoin&quot;&gt;BroadcastJoin&lt;/h3&gt;
&lt;p&gt;前面提到BroadcastJoin是在一个极小表和一个大表进行Join时候选择的join方式，由于BroadcastJoin不需要进行shuffle，所以大家比较喜欢这种Join方式。但是由于Broadcast是需要将数据拉取到driver然后分发到各个executor，因此driver内存是一个瓶颈。前面也提到是极小表，那么是多小的表才会使用这种Join呢？&lt;/p&gt;

&lt;p&gt;Spark中有一个参数称之为&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.autoBroadcastJoinThreshold&lt;/code&gt;, 其代表当这个表在磁盘上size小于这个值时，会使用BroadcastJoin，而如果我们将其设为-1，代表disable BroadcastJoin（官方文档的解释)。&lt;/p&gt;

&lt;p&gt;除了该threshold之外，Broadcast还有一个限制，就是广播的表的行数不能超过512 milions行，也就是5亿多行，这个值是hard code的, 因为BroadcastJoin是要基于小表构建hashMap, 行数就对应其构建hashMap的元素数量，因此必须对小表的行数有限制。也就是说即使表的磁盘物理size小于threshold，条数超过这个行数也不能进行BroadcastJoin。&lt;/p&gt;

&lt;h3 id=&quot;问题描述&quot;&gt;问题描述&lt;/h3&gt;

&lt;p&gt;有一天我们遇到的一个Issue。其异常信息如下:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Caused by: org.apache.spark.SparkException: Cannot broadcast the table with more than 512 millions rows: 620880056 rows
	at org.apache.spark.sql.execution.exchange.BroadcastExchangeExec&lt;span class=&quot;nv&quot;&gt;$$&lt;/span&gt;anonfun&lt;span class=&quot;nv&quot;&gt;$relationFuture$1$$&lt;/span&gt;anonfun&lt;span class=&quot;nv&quot;&gt;$apply$1&lt;/span&gt;.apply&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;BroadcastExchangeExec.scala:78&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	at org.apache.spark.sql.execution.exchange.BroadcastExchangeExec&lt;span class=&quot;nv&quot;&gt;$$&lt;/span&gt;anonfun&lt;span class=&quot;nv&quot;&gt;$relationFuture$1$$&lt;/span&gt;anonfun&lt;span class=&quot;nv&quot;&gt;$apply$1&lt;/span&gt;.apply&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;BroadcastExchangeExec.scala:73&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	at org.apache.spark.sql.execution.SQLExecution&lt;span class=&quot;nv&quot;&gt;$.&lt;/span&gt;withExecutionId&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;SQLExecution.scala:97&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	at org.apache.spark.sql.execution.exchange.BroadcastExchangeExec&lt;span class=&quot;nv&quot;&gt;$$&lt;/span&gt;anonfun&lt;span class=&quot;nv&quot;&gt;$relationFuture$1&lt;/span&gt;.apply&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;BroadcastExchangeExec.scala:72&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	at org.apache.spark.sql.execution.exchange.BroadcastExchangeExec&lt;span class=&quot;nv&quot;&gt;$$&lt;/span&gt;anonfun&lt;span class=&quot;nv&quot;&gt;$relationFuture$1&lt;/span&gt;.apply&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;BroadcastExchangeExec.scala:72&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;看到这个异常的第一反应就是去查询&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.autoBroadcastJoinThreshold&lt;/code&gt;的值，然后查到的结果100m。当时的想法是，为什么这个表在磁盘上不到100m大小，而其有6亿行数据，难道是列数十分少，并且压缩的特别的严重，不像是生产环境中的表。&lt;/p&gt;

&lt;p&gt;然后查询了一下表的信息，果然这个表只有一列，类型为Decimal类型，然后使用的压缩方式是snappy，而表的大小只有3.5m，想必是由于列是数值类型，所以压缩十分恐怖。&lt;/p&gt;

&lt;p&gt;当时没有产生其他怀疑，就建议用户将&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.autoBroadcastJoinThreshold&lt;/code&gt;设置为-1，禁用掉BroadcastJoin。&lt;/p&gt;

&lt;p&gt;过了段时间，用户回复说设置了之后仍然报上面的异常。&lt;/p&gt;

&lt;p&gt;用户的sql语句格式为:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;from&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;join&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;join&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;on&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;问题排查&quot;&gt;问题排查&lt;/h3&gt;

&lt;p&gt;首先，就是自己把用户的sql语句拿过来，使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;setspark.sql.autoBroadcastJoinThreshold=-1&lt;/code&gt; 命令设置参数，使用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;explain&lt;/code&gt;命令进行查询执行计划。&lt;/p&gt;

&lt;p&gt;发现执行计划中有一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BroadcastNestedLoopJoin&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;然后去查看源码。发现其只有在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;JoinSelection&lt;/code&gt;这个将执行计划转换为物理执行计划的规则&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;apply&lt;/code&gt;的时候才进行调用。&lt;/p&gt;

&lt;p&gt;这个规则就是选择使用Join的方式，优先BroadcastJoin，其次ShuffleHashJoin，最次SortMergeJoin。&lt;/p&gt;

&lt;p&gt;通过查看其apply方法.&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plan&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;LogicalPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;SparkPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plan&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ExtractEquiJoinKeys&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;joinType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;leftKeys&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rightKeys&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;c1&quot;&gt;//省略若干关于决策BroadCastJoin, ShuffleHashJoin以及SortMergeJoin的代码&lt;/span&gt;
  
  &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;logical&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;Join&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;joinType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;//此处省略若干决策最优buildSide或根据BroadcastJoin Hint以及不得不选择一个buildSide的代码&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;  
  &lt;span class=&quot;nv&quot;&gt;joins&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;BroadcastNestedLoopJoinExec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;planLater&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;planLater&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;buildSide&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;joinType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Nil&lt;/span&gt;

   &lt;span class=&quot;c1&quot;&gt;// 省略CrossJoin,即笛卡尔积的相关代码&lt;/span&gt;
	 &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Nil&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;发现这个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BroadcastNestedLoopJoinExec&lt;/code&gt;只有在不能提取出equal的join key 的left/right Join 时才会调用，而且是一定会调用。&lt;/p&gt;

&lt;p&gt;什么是equal Join key的Join。举个例子.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;join&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;那么非equal 的left/right Join， 举个例子。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;join&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;join&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;解决方案&quot;&gt;解决方案&lt;/h3&gt;

&lt;p&gt;因此，问题就是用户在使用进行 left/right join时，表a 和表b的join key是空的，所以一定会调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BroadcastNestedLoopJoinExec&lt;/code&gt;,即使我们将BroadcastJoinThreshold设为-1.&lt;/p&gt;

&lt;p&gt;所以解决方案就是更改用户的sql语句，其实用户之前的sql在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;a left join b&lt;/code&gt;的时候没有添加join 条件，所以就相当于一个cross join，所以如果我们将原来语句中a b之间的left  join 改成cross join 就可以绕过BroadcastJoin，而去使用Cross join。但是，Cross join 是一个很重的join，其会产生M*R个task(M为 mapTask数量,R为reduceTask数量)。&lt;/p&gt;

&lt;p&gt;PS: 此处看起来，如果你要进行一个大表和小表的cross join，而且小表的条数又不会超过Broadcast的条数上限，那么将cross join 替换为无join条件的left join，走Broadcast是一个不错的选择。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;from&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;cross&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;join&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;join&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;on&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;所以在找到解决方案之后，我还是跟用户去确认了下，到底是不是想要cross join的结果，可以拿一个小数据集进行测试，跟用户沟通了之后，才发现之前的sql产生的结果并不是他想要的，他想要的是下面的SQL。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;from&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;join&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;on&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;join&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;on&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;总结&quot;&gt;总结&lt;/h3&gt;

&lt;p&gt;首先，明确需求很重要，可以先拿小数据集测试下自己想要的结果是否和测试结果一致。&lt;/p&gt;

&lt;p&gt;Spark在进行一个 non-equal key  left/right join条件(可能join 条件为空，也可能非空但是不是key equal)，一定会有BroadcastJoin，即使是两个超大的表也会，这样可能会导致三种结果。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;大表被Broadcast十分缓慢。&lt;/li&gt;
  &lt;li&gt;由于BroadcastJoin要将数据拉取到driver，可能造成driver的OOM。&lt;/li&gt;
  &lt;li&gt;即使不会造成OOM，大表也可能造成hard code的Broadcast 条数限制，导致无法执行。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;所以，我们要在明确需求的前提下，正确的使用left/right join以及设置合适的join条件。&lt;/p&gt;

&lt;h3 id=&quot;附录&quot;&gt;附录&lt;/h3&gt;

&lt;p&gt;在附录中提供一个Unit test 以及对应的explain.&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;nf&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;test brodacast join&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;withSQLConf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;spark.sql.crossJoin.enabled&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;true&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;s&quot;&gt;&quot;spark.sql.autoBroadcastJoinThreshold&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;-1&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;nf&quot;&gt;withTable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ta&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;tb&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;tc&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;create table ta(aid int) using parquet&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;create table tb(bid int, bid2 int) using parquet&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;create table tc(cid int) using parquet&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;nf&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;select * from &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
          &lt;span class=&quot;s&quot;&gt;&quot;ta left join tb left join tc &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
          &lt;span class=&quot;s&quot;&gt;&quot;on ta.aid=tb.bid and tb.bid2 = tc.cid&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;explain&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;nf&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;select * from &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
          &lt;span class=&quot;s&quot;&gt;&quot;ta cross join tb left join tc &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
          &lt;span class=&quot;s&quot;&gt;&quot;on ta.aid=tb.bid and tb.bid2 = tc.cid &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;explain&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;nf&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;select * from &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
          &lt;span class=&quot;s&quot;&gt;&quot;ta left join tb &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
          &lt;span class=&quot;s&quot;&gt;&quot;on ta.aid = tb.bid &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
          &lt;span class=&quot;s&quot;&gt;&quot;left join tc &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
          &lt;span class=&quot;s&quot;&gt;&quot;on tb.bid2=tc.cid&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;explain&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;nf&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;select * from &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
          &lt;span class=&quot;s&quot;&gt;&quot;ta left join tb &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
          &lt;span class=&quot;s&quot;&gt;&quot;on ta.aid != tb.bid &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
          &lt;span class=&quot;s&quot;&gt;&quot;left join tc &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
          &lt;span class=&quot;s&quot;&gt;&quot;on tb.bid2=tc.cid&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;explain&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;第一条select语句的执行计划如下，由于其a 与b的 joinKey为空，所以其包含&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BroadcastNestedLoopJoinExec&lt;/code&gt;。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Physical&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Plan&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;SortMergeJoin&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bid2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;177&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;178&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LeftOuter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;175&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;176&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sort&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bid2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;177&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ASC&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NULLS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FIRST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;+-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Exchange&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hashpartitioning&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bid2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;177&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;     &lt;span class=&quot;o&quot;&gt;+-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BroadcastNestedLoopJoin&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BuildRight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LeftOuter&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;        &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FileScan&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parquet&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;175&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Batched&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;Location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;InMemoryFileIndex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Users&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fwang12&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ebay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;longwing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;launcher&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;warehouse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PartitionFilters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PushedFilters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ReadSchema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;struct&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;        &lt;span class=&quot;o&quot;&gt;+-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BroadcastExchange&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IdentityBroadcastMode&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;           &lt;span class=&quot;o&quot;&gt;+-&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FileScan&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parquet&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;176&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bid2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;177&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Batched&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;Location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;InMemoryFileIndex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Users&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fwang12&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ebay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;longwing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;launcher&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;warehouse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PartitionFilters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PushedFilters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ReadSchema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;struct&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bid2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;+-&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sort&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;178&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ASC&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NULLS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FIRST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;+-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Exchange&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hashpartitioning&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;178&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;+-&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FileScan&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parquet&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;178&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Batched&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;Location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;InMemoryFileIndex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Users&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fwang12&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ebay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;longwing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;launcher&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;warehouse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PartitionFilters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PushedFilters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ReadSchema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;struct&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;第二条select语句执行计划如下，由于a 和b是cross join，而且b c之间有equi join key，所以其不会有&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BroadcastNestedLoopJoinExec&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Physical&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Plan&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;SortMergeJoin&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bid2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;177&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;178&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LeftOuter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;175&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;176&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sort&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bid2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;177&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ASC&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NULLS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FIRST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;+-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Exchange&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hashpartitioning&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bid2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;177&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;     &lt;span class=&quot;o&quot;&gt;+-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CartesianProduct&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;        &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FileScan&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parquet&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;175&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Batched&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;Location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;InMemoryFileIndex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Users&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fwang12&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ebay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;longwing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;launcher&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;warehouse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PartitionFilters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PushedFilters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ReadSchema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;struct&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;        &lt;span class=&quot;o&quot;&gt;+-&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FileScan&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parquet&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;176&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bid2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;177&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Batched&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;Location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;InMemoryFileIndex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Users&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fwang12&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ebay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;longwing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;launcher&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;warehouse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PartitionFilters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PushedFilters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ReadSchema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;struct&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bid2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;+-&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sort&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;178&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ASC&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NULLS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FIRST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;+-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Exchange&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hashpartitioning&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;178&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;+-&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FileScan&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parquet&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;178&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Batched&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;Location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;InMemoryFileIndex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Users&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fwang12&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ebay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;longwing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;launcher&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;warehouse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PartitionFilters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PushedFilters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ReadSchema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;struct&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;第三条语句由于a b 和 b c之间都有equi join key，所以其不会触发&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BroadcastNestedLoopJoinExec&lt;/code&gt;。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Physical&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Plan&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;SortMergeJoin&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bid2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;177&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;178&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LeftOuter&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sort&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bid2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;177&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ASC&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NULLS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FIRST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;+-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Exchange&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hashpartitioning&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bid2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;177&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;     &lt;span class=&quot;o&quot;&gt;+-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SortMergeJoin&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;175&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;176&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LeftOuter&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;        &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sort&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;175&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ASC&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NULLS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FIRST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;        &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;+-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Exchange&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hashpartitioning&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;175&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;        &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;     &lt;span class=&quot;o&quot;&gt;+-&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FileScan&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parquet&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;175&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Batched&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;Location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;InMemoryFileIndex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Users&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fwang12&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ebay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;longwing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;launcher&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;warehouse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PartitionFilters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PushedFilters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ReadSchema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;struct&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;        &lt;span class=&quot;o&quot;&gt;+-&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sort&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;176&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ASC&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NULLS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FIRST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;           &lt;span class=&quot;o&quot;&gt;+-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Exchange&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hashpartitioning&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;176&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;              &lt;span class=&quot;o&quot;&gt;+-&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FileScan&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parquet&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;176&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bid2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;177&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Batched&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;Location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;InMemoryFileIndex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Users&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fwang12&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ebay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;longwing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;launcher&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;warehouse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PartitionFilters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PushedFilters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ReadSchema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;struct&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bid2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;+-&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sort&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;178&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ASC&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NULLS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FIRST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;+-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Exchange&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hashpartitioning&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;178&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;+-&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FileScan&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parquet&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;178&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Batched&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;Location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;InMemoryFileIndex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Users&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fwang12&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ebay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;longwing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;launcher&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;warehouse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PartitionFilters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PushedFilters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ReadSchema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;struct&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;第四条语句由于a b之间虽然有 join key， 但是是非 equi的join key &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ta.aid != tb.bid&lt;/code&gt;，所以其会触发&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BroadcastNestedLoopJoinExec&lt;/code&gt;。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Physical&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Plan&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;SortMergeJoin&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bid2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;177&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;178&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LeftOuter&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sort&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bid2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;177&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ASC&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NULLS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FIRST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;+-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Exchange&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hashpartitioning&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bid2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;177&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;     &lt;span class=&quot;o&quot;&gt;+-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BroadcastNestedLoopJoin&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BuildRight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LeftOuter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;175&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;176&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;        &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FileScan&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parquet&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;175&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Batched&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;Location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;InMemoryFileIndex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Users&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fwang12&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ebay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;longwing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;launcher&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;warehouse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PartitionFilters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PushedFilters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ReadSchema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;struct&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;        &lt;span class=&quot;o&quot;&gt;+-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BroadcastExchange&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IdentityBroadcastMode&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;           &lt;span class=&quot;o&quot;&gt;+-&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FileScan&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parquet&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;176&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bid2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;177&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Batched&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;Location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;InMemoryFileIndex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Users&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fwang12&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ebay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;longwing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;launcher&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;warehouse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PartitionFilters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PushedFilters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ReadSchema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;struct&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bid2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;+-&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sort&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;178&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ASC&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NULLS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FIRST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;+-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Exchange&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hashpartitioning&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;178&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;+-&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FileScan&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parquet&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;178&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Batched&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;Location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;InMemoryFileIndex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Users&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fwang12&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ebay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;longwing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;launcher&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;warehouse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PartitionFilters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PushedFilters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ReadSchema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;struct&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
                <link>http://www.turbofei.wang/spark/2019/10/29/A-BroadCastJoin-Issue-in-spark</link>
                <guid>http://www.turbofei.wang/spark/2019/10/29/A-BroadCastJoin-Issue-in-spark</guid>
                <pubDate>2019-10-29T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>关于spark数据计算结果异常的场景分析</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#前言&quot; id=&quot;markdown-toc-前言&quot;&gt;前言&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#数据读取&quot; id=&quot;markdown-toc-数据读取&quot;&gt;数据读取&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#表类型&quot; id=&quot;markdown-toc-表类型&quot;&gt;表类型&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#兼容性问题与规避方案&quot; id=&quot;markdown-toc-兼容性问题与规避方案&quot;&gt;兼容性问题与规避方案&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#数据计算&quot; id=&quot;markdown-toc-数据计算&quot;&gt;数据计算&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#关于decimal-和decimal计算精度参数&quot; id=&quot;markdown-toc-关于decimal-和decimal计算精度参数&quot;&gt;关于Decimal 和Decimal计算精度参数&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#场景分析&quot; id=&quot;markdown-toc-场景分析&quot;&gt;场景分析&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#解决方案&quot; id=&quot;markdown-toc-解决方案&quot;&gt;解决方案&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#数据写入&quot; id=&quot;markdown-toc-数据写入&quot;&gt;数据写入&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#场景a&quot; id=&quot;markdown-toc-场景a&quot;&gt;场景A&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#场景b&quot; id=&quot;markdown-toc-场景b&quot;&gt;场景B&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#fileoutputcommitter&quot; id=&quot;markdown-toc-fileoutputcommitter&quot;&gt;FileOutputCommitter&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#表写入&quot; id=&quot;markdown-toc-表写入&quot;&gt;表写入&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#应用被kill掉working数据未被清理&quot; id=&quot;markdown-toc-应用被kill掉working数据未被清理&quot;&gt;应用被kill掉，working数据未被清理&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#两个应用并发写入一个表&quot; id=&quot;markdown-toc-两个应用并发写入一个表&quot;&gt;两个应用并发写入一个表&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;关于Spark中读取，计算和写入造成结果异常的场景分析&lt;/p&gt;

&lt;h3 id=&quot;前言&quot;&gt;前言&lt;/h3&gt;

&lt;p&gt;Spark是目前主流的分布式计算框架之一，本文谈在使用Spark进行计算时与结果正确性相关的一些issue的场景以及分析。&lt;/p&gt;

&lt;p&gt;计算可以分为三个过程，数据读取，数据计算，数据写入，本文就从这三个部分来阐述可能遇到的问题以及规避方案(如有错误，请指正)。&lt;/p&gt;

&lt;h3 id=&quot;数据读取&quot;&gt;数据读取&lt;/h3&gt;

&lt;p&gt;首先，spark在生产中最常用的使用场景就是spark-sql。在spark-sql中，使用 hive 的metastore进行元数据存储，因此在使用中，往往是spark DataSource表和hive表共存。&lt;/p&gt;

&lt;h4 id=&quot;表类型&quot;&gt;表类型&lt;/h4&gt;

&lt;p&gt;表的类型，可以分为以下几种。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;hive(managed/external)表: 如果不指定location，是一个managed表，直接存储在数据库对应的目录下，如果进行drop 操作，会将对应的数据删掉。如果对表指定location，是一个External表，数据存在指定的路径下，如果进行drop操作，不会删除对应的数据，这样相对来说会更安全一些，减小一些误操作造成数据丢失的风险。&lt;/li&gt;
  &lt;li&gt;spark DataSource(managed/external)表: 使用spark DataSource创建的表&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;parquet是一种列式存储格式，在数据库场景中可以在查询时过滤掉不必要的数据，适用于读多写少的场景。&lt;/p&gt;

&lt;p&gt;Spark选择了parquet作为常用的存储格式，因此在生产中，最常见的表就是parquet表。&lt;/p&gt;

&lt;p&gt;parquet是一种存储格式，既然是存储，就会有写入和读取的过程，也就是序列化和反序列化。&lt;/p&gt;

&lt;p&gt;在Spark-sql场景中，有两种parquet 版本，一种是spark内置的parquet，一种是hive内置的parquet版本，往往hive中的parquet版本较老，而spark中的parquet较新，其序列化和反序列化性能更好，但是可能会出现一些不兼容的情况。&lt;/p&gt;

&lt;p&gt;下面谈一下创建spark DataSource表和hive表的方式。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Spark Datasource 表&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;使用Spark DataFrame API进行创建&lt;/li&gt;
  &lt;li&gt;使用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;using parquet&lt;/code&gt;的方式创建
    &lt;ul&gt;
      &lt;li&gt;例如: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;create table ta (id int, name string) using parquet&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Hive 表&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;使用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;stored as parquet&lt;/code&gt;进行创建
    &lt;ul&gt;
      &lt;li&gt;例如: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;create table ta(id int, name string) stored as parquet &lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;如果想判断一张已经建的表是hive表还是spark DataSource表可以使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;show create table&lt;/code&gt;命令查看信息。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;hive表 可以看到其INPUTFORMAT/OUTPUTFORMAT是 hive开头的。&lt;/p&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;CREATE TABLE `ta`(`id` int, `name` string)
ROW FORMAT SERDE &apos;org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe&apos;
WITH SERDEPROPERTIES (
  &apos;serialization.format&apos; = &apos;1&apos;
)
STORED AS
  INPUTFORMAT &apos;org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat&apos;
  OUTPUTFORMAT &apos;org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat&apos;
TBLPROPERTIES (
  &apos;transient_lastDdlTime&apos; = &apos;1569816513&apos;
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Spark DataSource表&lt;/p&gt;
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;CREATE TABLE `ta` (`id` INT, `name` STRING)
USING parquet
OPTIONS (
  `serialization.format` &apos;1&apos;
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;兼容性问题与规避方案&quot;&gt;兼容性问题与规避方案&lt;/h4&gt;

&lt;p&gt;前面通过&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;show create table&lt;/code&gt;命令也看到了，hive表就是使用hive 的parquet序列化方式。而spark由于自带的parquet性能更加卓越，所以在spark中有一个参数，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.hive.convertMetastoreParquet&lt;/code&gt;, 其默认是true，表示将使用spark内置的parquet的序列化和反序列化去读取使用hive语法创建的hive表，而非使用hive内置的parquet序列化和反序列化。&lt;/p&gt;

&lt;p&gt;所以，有时候就会出现使用spark读取hive表时数据全为null的情况(spark中遇到数据解释不了，或者overflow，默认就是返回null)。&lt;/p&gt;

&lt;p&gt;这时候，可以将&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.hive.convertMetastoreParquet&lt;/code&gt;设为false，来解决这个问题。&lt;/p&gt;

&lt;h3 id=&quot;数据计算&quot;&gt;数据计算&lt;/h3&gt;

&lt;p&gt;关于数据计算，分析一个关于Decimal 计算异常的问题。&lt;/p&gt;

&lt;h4 id=&quot;关于decimal-和decimal计算精度参数&quot;&gt;关于Decimal 和Decimal计算精度参数&lt;/h4&gt;

&lt;p&gt;介绍一下Decimal类型。&lt;/p&gt;

&lt;p&gt;Decimal是数据库中的一种数据类型，不属于浮点数类型，可以在定义时划定整数部分以及小数部分的位数。对于一个Decimal类型，scale表示其小数部分的位数，precision表示整数部分位数和小数部分位数之和。&lt;/p&gt;

&lt;p&gt;一个Decimal 类型表示为Decimal(precision, scale)，在Spark中，precision和scale的上限都是38。&lt;/p&gt;

&lt;p&gt;对于一个double类型，其可以精确的表示小数点后15位，有效位数位16位。而Decimal类型相对于double类型可以更加精确的表示保证数据计算，例如对于一个Decimal(38, 24)类型，其可以精确的表示小数点后23位。&lt;/p&gt;

&lt;p&gt;下面介绍&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.decimalOperations.allowPrecisionLoss&lt;/code&gt;参数。&lt;/p&gt;

&lt;p&gt;当该参数为true(默认)，表示允许丢失精度，会根据Hive行为和SQL ANSI 2011规范来决定result的类型，即如果无法精确的表示，则舍入结果的小数部分。&lt;/p&gt;

&lt;p&gt;当该参数为false时，代表不允许丢失精度，这样会将数据表示的更加精确。&lt;/p&gt;

&lt;h4 id=&quot;场景分析&quot;&gt;场景分析&lt;/h4&gt;

&lt;p&gt;介绍一下这个场景。下面的语句:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decimalOperations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;allowPrecisionLoss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;when&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;123456789012345678901234&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;结果为空&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decimalOperations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;allowPrecisionLoss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;when&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;123456789012345678901234&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;结果是&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12345678901234568&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;，丢失了部分精度，因为允许丢失精度。&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;我们将上面语句的执行计划打印出来。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;&quot;== Physical Plan ==
*(1) Project [null AS (CASE WHEN (1 = 2) THEN CAST(1 AS DECIMAL(34,24)) ELSE CAST(1.123456789012345678901234 AS DECIMAL(34,24)) END * CAST(1 AS DECIMAL(34,24)))#170]
+- Scan OneRowRelation[]&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;执行计划很简单，里面有一个二元操作(乘法)，左边的case when 是一个Decimal(34, 24)类型，右边是一个Literal(1)。&lt;/p&gt;

&lt;p&gt;程序员都知道，在编程中，如果两个不同类型的操作数做计算，会将低级别的类型向高级别的类型进行类型转换，Spark中也是如此。&lt;/p&gt;

&lt;p&gt;一条SQL语句进入Spark-sql引擎之后，要经历Analysis-&amp;gt;optimization-&amp;gt;生成可执行物理计划的过程，而这个过程就是不同的Rule作用在Plan上面不断作用，然后Plan随之转化的过程。&lt;/p&gt;

&lt;p&gt;在Spark sql中有一系列关于类型转换的Rule，这些Rule作用在Analysis阶段的Resolution子阶段。&lt;/p&gt;

&lt;p&gt;我们来看一下其中一条Rule,  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ImplicitTypeCasts&lt;/code&gt; 中和BinaryOperator相关的代码。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/TypeCoercion.scala&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BinaryOperator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;dataType&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;dataType&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; 
  &lt;span class=&quot;nf&quot;&gt;findTightestCommonType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;dataType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;dataType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;map&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;commonType&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;inputType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;acceptsType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;commonType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; 
      &lt;span class=&quot;c1&quot;&gt;// If the expression accepts the tightest common type, cast to that. &lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;newLeft&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;dataType&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;commonType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Cast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;commonType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; 
      &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;newRight&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;dataType&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;commonType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Cast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;commonType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; 
      &lt;span class=&quot;nv&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;withNewChildren&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;newLeft&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;newRight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; 
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; 
      &lt;span class=&quot;c1&quot;&gt;// Otherwise, don&apos;t do anything with the expression. &lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; 
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; 
 &lt;span class=&quot;o&quot;&gt;}.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;getOrElse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;// If there is no applicable conversion, leave expression unchanged. &lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;解释一下上面的代码，针对一个BinaryOperator(例如 + - * /), 如果左边的数据类型和右边不一致，那么会寻找一个左右操作数的common type, 然后将左右操作数都转换为common type。针对我们此处case中的 Decimal(34, 24) 和Literal(1), 它们的common type就是Decimal(34, 24),所以这里的Literal(1)将被转换为Decimal(34, 24)。&lt;/p&gt;

&lt;p&gt;这样该二元操作的两边就都是Decimal类型。接下来这个二元操作会被Rule &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DecimalPrecision&lt;/code&gt;中的decimalAndDecimal方法处理。由于该二元操作是乘法操作，我们看乘法操作部分的代码。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/DecimalPrecision.scala&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Multiply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;DecimalType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;Expression&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;DecimalType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;Expression&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;resultType&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;SQLConf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;decimalOperationsAllowPrecisionLoss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;DecimalType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;adjustPrecisionScale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;DecimalType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;bounded&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;widerType&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;widerDecimalType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;nc&quot;&gt;CheckOverflow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Multiply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;promotePrecision&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;widerType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;promotePrecision&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;widerType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;resultType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;此处我们的操作数已经都是Decimal(34, 24)类型，所以p1=p2=34, s1=s2=24.&lt;/p&gt;

&lt;p&gt;如果不允许精度丢失，那么resultType就是 DecimalType.bounded(p1+p2+1, s1+s2), bounded方法代表precision 和 scale都不能超过38，所以这里的ResultType就是Decimal(38, 38), 也就是小数部分为38位，那么整数部分就只剩下0位来表示，也就是说如果整数部分非0，那么这个结果就会overflow。在当前版本中，如果发生Decimal Operation 计算发生了overflow，那么就会返回一个Null的结果。&lt;/p&gt;

&lt;h4 id=&quot;解决方案&quot;&gt;解决方案&lt;/h4&gt;

&lt;p&gt;解决此问题，可以合入PR&lt;a href=&quot;https://github.com/apache/spark/pull/25701&quot;&gt;SPARK-29000&lt;/a&gt;来解决在非Decimal和Decimal之间操作数转化时，精度转换不当的问题，合入  &lt;a href=&quot;https://github.com/apache/spark/pull/20350&quot;&gt;SPARK-23179&lt;/a&gt; 来在Decimal计算overflow时抛出一个异常来提醒用户计算出现问题，让用户感知。&lt;/p&gt;

&lt;p&gt;有兴趣的话，可以查看具体的分析和解决方案描述&lt;a href=&quot;https://www.turbofei.wang/spark/2019/09/09/Spark-SQL-Decimal-Precision-Overflow-Analysis&quot;&gt;Spark Sql Decimal Precision Overflow Analysis&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&quot;数据写入&quot;&gt;数据写入&lt;/h3&gt;

&lt;p&gt;分析一下在数据写入时候会发生的异常。&lt;/p&gt;

&lt;h4 id=&quot;场景a&quot;&gt;场景A&lt;/h4&gt;

&lt;p&gt;前面提到了外部表，可以在进行drop操作的时候不删数据。但这可能也会造成一个问题。&lt;/p&gt;

&lt;p&gt;对于一个外部分区表。&lt;/p&gt;

&lt;p&gt;如果我们先drop掉这张表的一个分区，然后再overwrite这个分区，可能会造成数据重复。&lt;/p&gt;

&lt;p&gt;下面是一个可复现的场景。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;创建外部分区表&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;external&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partitioned&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stored&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parquet&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;location&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;file://path&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;overwrite&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;一个分区&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;也因此创建了这个分区&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;insert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;overwrite&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;n1&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;drop&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;掉&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n1&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;这个分区&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ALTER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DROP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;n1&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;overwrite&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n1&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;这个分区&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;insert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;overwrite&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;n1&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;通过测试，发现在spark-2.3版本，进行上述操作，最后select这张表，得到的结果如下:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Id&lt;/th&gt;
      &lt;th&gt;Name&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;n1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;n1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;这个结果是异常的，正确的结果应该只有一条&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt; 2, n1&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;P.S. 在master分支，对hive table做了一些优化，如果将&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.hive.convertMetastoreParquet&lt;/code&gt;设为true(此时会将InsertIntoHiveTable的操作转换为使用Spark DataSource的写入)是可以得到正确的结果，但是如果将&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.hive.convertMetastoreParquet&lt;/code&gt;设为false，依然会得到上述异常数据。&lt;/p&gt;

&lt;p&gt;其实这是Hive的一个bug，相关patch为 &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-17063.&quot;&gt;HIVE-17063&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;暂时规避方案，就是在对外部表做overwrite partition操作前，先不要进行drop partition操作(已提jira，希望可后续解决)。&lt;/p&gt;

&lt;h4 id=&quot;场景b&quot;&gt;场景B&lt;/h4&gt;

&lt;p&gt;此场景发生在使用Spark file source方式对表进行写入(InsertIntoHadoopFsRelation)操作时候。&lt;/p&gt;

&lt;h5 id=&quot;fileoutputcommitter&quot;&gt;FileOutputCommitter&lt;/h5&gt;

&lt;p&gt;Spark对HDFS的写入实现，依赖于Hadoop 的FileOutputCommitter。&lt;/p&gt;

&lt;p&gt;简单介绍一下FileOutputCommitter。首先其有一个outputPath和一个committer 算法版本，1或者2。&lt;/p&gt;

&lt;p&gt;其会有一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$tablePath/_temporary/number&lt;/code&gt;（对于Spark来说是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$tablePath/_temporary/0&lt;/code&gt;）作为一个working 目录(存放中间数据)，task在未完成之前的数据在这个working目录中进行。&lt;/p&gt;

&lt;p&gt;如果committer算法版本为1，task完成之后会首先commit到一个 task_attempt_output目录(在_temporary/0下面)，在所有task完成之后会将所有task_attempt_output 下面的数据commit到outputPath中，这是一个二阶段提交。&lt;/p&gt;

&lt;p&gt;而如果committer算法版本为2，那么task完成之后会直接commit到最终目录里，这是一个非二阶段提交，所以会产生应用失败，但是部分数据写入的问题，但是由于其是一次写入到最终目录，所以性能较版本1要好。&lt;/p&gt;

&lt;p&gt;目前Spark默认的commit算法版本是1.&lt;/p&gt;

&lt;h5 id=&quot;表写入&quot;&gt;表写入&lt;/h5&gt;

&lt;p&gt;表按照是否有分区来划分，可以分为分区表和非分区表。&lt;/p&gt;

&lt;p&gt;针对非分区表，spark在进行写入时候的working目录都是 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$tablePath/_temporary/0&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;针对分区表，spark在写入时候会判断这个写入操作是否是dynamicPartitionOverwrite。如果是，则其working目录是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$tablePath/.spark-staging-${UUID}&lt;/code&gt;,也就是不会重复的，每次都独一无二的。如果不是，则其working目录还是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$tablePath/_temporary/0&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;介绍一下dynamicPartitionOverwrite。对分区表分区进行overwrite分为static 和dynamic两种类型。&lt;/p&gt;

&lt;p&gt;在Spark中相关参数为&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.sources.partitionOverwriteMode&lt;/code&gt;(hive中也有对应的参数),默认为&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;static&lt;/code&gt;，代表不允许进行dynamicPartitionOverwrite，如果设为&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dynamic&lt;/code&gt;代表允许dynamicPartitionOverwrite。&lt;/p&gt;

&lt;p&gt;dynamic代表你不必指定所有partition key的值，由spark来根据结果，确定你要overwrite哪些partition，因此其在数据计算完成之前，不会去删表中的分区。&lt;/p&gt;

&lt;p&gt;而static代表，你必须指定你要overwrite哪些分区，所以需要被overwrite的分区是可确定的，因此会在操作开始的时候就把对应的分区删除掉。&lt;/p&gt;

&lt;p&gt;比如下面的这个查询:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;insert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;overwrite&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tablea&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;如果是static的overwrite，其会首先删掉 表下面的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;p1=v1/p2=v2&lt;/code&gt;分区(会删掉下面所有的p3子分区)，然后在数据计算完之后，将数据写入。&lt;/p&gt;

&lt;p&gt;如果是dynamic的overwrite，其不会首先删掉表下面的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;p1=v1/p2=v2&lt;/code&gt;分区，而是会根据计算的结果去判断，我应该删掉哪些子分区。&lt;/p&gt;

&lt;p&gt;比如说在进行overwrite之前, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;p1=v1/p2=v2&lt;/code&gt;下面有 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;p3=v31&lt;/code&gt; 和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;p3=v32&lt;/code&gt;两个子分区，而实际&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;select ...&lt;/code&gt;语句产生的结果只有&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;p3=v31&lt;/code&gt;的结果。&lt;/p&gt;

&lt;p&gt;如果是static overwrite，会先把&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;p3=v31&lt;/code&gt; 和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;p3=v32&lt;/code&gt;两个子分区都删掉，而dynamic overwrite，只会在最后根据计算结果只overwrite &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;p3=v31&lt;/code&gt;这个分区。&lt;/p&gt;

&lt;p&gt;关于表的写入背景知识介绍到这里，下面介绍具体场景。&lt;/p&gt;

&lt;h5 id=&quot;应用被kill掉working数据未被清理&quot;&gt;应用被kill掉，working数据未被清理&lt;/h5&gt;

&lt;p&gt;如果应用appA 是对tableA一个static partition overwrite，其由于某个task hang住，然后被kill掉，所以其working目录($tableA/_temporary/0)没有被清理掉.&lt;/p&gt;

&lt;p&gt;而我们在其被kill掉之后，又重新跑这个应用，新的应用继续使用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$tableA/_temporary/0&lt;/code&gt;作为working目录，之后新应用运行成功，但是提交时候将上次遗留的一些task的数据提交到最终目录，造成数据重复。&lt;/p&gt;

&lt;p&gt;针对这个场景，暂时解决方案，我们需要在应用被kill之后，手动清理&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_temporary/0&lt;/code&gt;.&lt;/p&gt;

&lt;h5 id=&quot;两个应用并发写入一个表&quot;&gt;两个应用并发写入一个表&lt;/h5&gt;

&lt;p&gt;如果在kill应用的时候，resourceManager发生了异常，造成了我们以为应用已经被kill掉，然后我们又重新提交了一样的应用去写数据。两个应用会共用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_temporary/0&lt;/code&gt;,互相干扰，可能造成结果异常。&lt;/p&gt;

&lt;p&gt;针对这个场景，我们可能不容易察觉。&lt;/p&gt;

&lt;p&gt;其实即使是dynamic partition overwrite 会用独一无二的working目录，其在多个操作并发写入同一张表时，仍然可能会发生干扰冲突。&lt;/p&gt;

&lt;p&gt;关于场景B中问题的长期解决方案，PR &lt;a href=&quot;https://github.com/apache/spark/pull/25863&quot;&gt;SPARK-29037&lt;/a&gt; 正在致力于解决这个问题，希望可以解决数据重复以及在多个操作并发写入一张表可能造成干扰的问题。&lt;/p&gt;
</description>
                <link>http://www.turbofei.wang/spark/2019/09/30/%E5%85%B3%E4%BA%8ESpark%E6%95%B0%E6%8D%AE%E8%AE%A1%E7%AE%97%E7%BB%93%E6%9E%9C%E5%BC%82%E5%B8%B8%E7%9A%84%E5%9C%BA%E6%99%AF%E5%88%86%E6%9E%90</link>
                <guid>http://www.turbofei.wang/spark/2019/09/30/关于Spark数据计算结果异常的场景分析</guid>
                <pubDate>2019-09-30T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>Spark Sql Decimal Precision Overflow Analysis</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#前言&quot; id=&quot;markdown-toc-前言&quot;&gt;前言&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#场景&quot; id=&quot;markdown-toc-场景&quot;&gt;场景：&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#排查&quot; id=&quot;markdown-toc-排查&quot;&gt;排查&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#解决方案&quot; id=&quot;markdown-toc-解决方案&quot;&gt;解决方案&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#用户可感知的overflow&quot; id=&quot;markdown-toc-用户可感知的overflow&quot;&gt;用户可感知的overflow&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;An analysis of Spark data quality issue and relative solution.&lt;/p&gt;

&lt;h4 id=&quot;前言&quot;&gt;前言&lt;/h4&gt;

&lt;p&gt;eBay的Hadoop集群上面每天运行着大量的Spark计算任务，对于数据计算任务，不仅看重计算性能，数据质量也非常重要，特别是对于金融数据，数据发生corruption将会产生很严重的后果。本文分享一次数据质量相关的issue以及我们排查问题的过程和解决方案。&lt;/p&gt;

&lt;p&gt;本文已经发表在eBay公众号上面，而且其版本经过修订去掉了代码部分，更加容易理解，&lt;a href=&quot;https://mp.weixin.qq.com/s/yKFzO41l-2n617xICN2ObQ&quot;&gt;案例分析|由Decimal操作计算引发的Spark数据丢失问题&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&quot;场景&quot;&gt;场景：&lt;/h4&gt;

&lt;p&gt;一天，金融分析团队的同事报告了一个issue，他们发现在两个环境中，为了区分，命名为环境A和环境B，都运行Spark计算引擎，大版本都为2.3，运行同样的Sql语句，对结果进行对比，发现有一列数据不一致，环境B中的数据有部分丢失。&lt;/p&gt;

&lt;p&gt;此处对数据进行脱敏，仅显示发生数据丢失那一列的数据，如下:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;环境A&lt;/th&gt;
      &lt;th&gt;环境B&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0.4493&lt;/td&gt;
      &lt;td&gt;0.449286&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;157.3459&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;-0.2091&lt;/td&gt;
      &lt;td&gt;-0.209138&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;139.1228&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;-0.485562&lt;/td&gt;
      &lt;td&gt;-0.485562&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;可以看出来这列的数据，在环境A中查询是有的，但是在环境B中Spark client中去查询，出现了部分缺失。&lt;/p&gt;

&lt;h4 id=&quot;排查&quot;&gt;排查&lt;/h4&gt;

&lt;p&gt;上述两个查询中用的spark大版本是一致的，team的同事通过对比两个环境中的配置，发现有一个参数在最近进行了变更。该参数为，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.decimalOperations.allowPrecisionLoss&lt;/code&gt;,默认为true。&lt;/p&gt;

&lt;p&gt;在环境A中未设置此参数，所以为true，而在环境B中Spark client的spark-defaults.conf中，配置了该参数为false。&lt;/p&gt;

&lt;p&gt;该参数为PR SPARK-22036 引入，是为了控制在两个Decimal类型做计算的时候，是否允许丢失精度。&lt;/p&gt;

&lt;p&gt;在详细介绍该参数之前，先介绍一下Decimal。&lt;/p&gt;

&lt;p&gt;Decimal是数据库中的一种数据类型，不属于浮点数类型，可以在定义时划定整数部分以及小数部分的位数。对于一个Decimal类型，scale表示其小数部分的位数，precision表示整数部分位数和小数部分位数之和。&lt;/p&gt;

&lt;p&gt;一个Decimal 类型表示为Decimal(precision, scale)，在Spark中，precision和scale的上限都是38。&lt;/p&gt;

&lt;p&gt;对于一个double类型，其可以精确的表示小数点后15位，有效位数位16位。而Decimal类型相对于double类型可以更加精确的表示保证数据计算，例如对于一个Decimal(38, 24)类型，其可以精确的表示小数点后23位。&lt;/p&gt;

&lt;p&gt;下面介绍&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.decimalOperations.allowPrecisionLoss&lt;/code&gt;参数。&lt;/p&gt;

&lt;p&gt;当该参数为true(默认)，表示允许丢失精度，会根据Hive行为和SQL ANSI 2011规范来决定result的类型，即如果无法精确的表示，则舍入结果的小数部分。&lt;/p&gt;

&lt;p&gt;当该参数为false时，代表不允许丢失精度，这样会将数据表示的更加精确。eBay的ETL部门在进行数据validation的时候，对数据精度有较高要求，因此我们引入了这个参数，并将其设置为false以满足ETL部门的生产需求。&lt;/p&gt;

&lt;p&gt;设置这个参数的初衷是美好的，但是为什么会引发这个data corruption问题呢?&lt;/p&gt;

&lt;p&gt;用户的SQL数据非常的长，通过查看相关SQL的执行计划，然后进行简化，得到一个可以复现的SQL语句，如下:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decimalOperations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;allowPrecisionLoss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;when&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;123456789012345678901234&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;上面的select语句将会返回一个NULL。&lt;/p&gt;

&lt;p&gt;我们将上面语句的执行计划打印出来。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;&quot;== Physical Plan ==
*(1) Project [null AS (CASE WHEN (1 = 2) THEN CAST(1 AS DECIMAL(34,24)) ELSE CAST(1.123456789012345678901234 AS DECIMAL(34,24)) END * CAST(1 AS DECIMAL(34,24)))#170]
+- Scan OneRowRelation[]&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;执行计划很简单，里面有一个二元操作(乘法)，左边的case when 是一个Decimal(34, 24)类型，右边是一个Literal(1)。&lt;/p&gt;

&lt;p&gt;程序员都知道，在编程中，如果两个不同类型的操作数做计算，会将低级别的类型向高级别的类型进行类型转换，Spark中也是如此。&lt;/p&gt;

&lt;p&gt;一条SQL语句进入Spark-sql引擎之后，要经历Analysis-&amp;gt;optimization-&amp;gt;生成可执行物理计划的过程，而这个过程就是不同的Rule作用在Plan上面不断作用，然后Plan随之转化的过程。&lt;/p&gt;

&lt;p&gt;在Spark sql中有一系列关于类型转换的Rule，这些Rule作用在Analysis阶段的Resolution子阶段。&lt;/p&gt;

&lt;p&gt;我们来看一下其中一条Rule,  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ImplicitTypeCasts&lt;/code&gt; 中和BinaryOperator相关的代码。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/TypeCoercion.scala&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BinaryOperator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;dataType&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;dataType&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; 
  &lt;span class=&quot;nf&quot;&gt;findTightestCommonType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;dataType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;dataType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;map&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;commonType&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;inputType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;acceptsType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;commonType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; 
      &lt;span class=&quot;c1&quot;&gt;// If the expression accepts the tightest common type, cast to that. &lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;newLeft&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;dataType&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;commonType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Cast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;commonType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; 
      &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;newRight&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;dataType&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;commonType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Cast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;commonType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; 
      &lt;span class=&quot;nv&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;withNewChildren&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;newLeft&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;newRight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; 
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; 
      &lt;span class=&quot;c1&quot;&gt;// Otherwise, don&apos;t do anything with the expression. &lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; 
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; 
 &lt;span class=&quot;o&quot;&gt;}.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;getOrElse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;// If there is no applicable conversion, leave expression unchanged. &lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;解释一下上面的代码，针对一个BinaryOperator(例如 + - * /), 如果左边的数据类型和右边不一致，那么会寻找一个左右操作数的common type, 然后将左右操作数都转换为common type。针对我们此处case中的 Decimal(34, 24) 和Literal(1), 它们的common type就是Decimal(34, 24),所以这里的Literal(1)将被转换为Decimal(34, 24)。&lt;/p&gt;

&lt;p&gt;这样该二元操作的两边就都是Decimal类型。接下来这个二元操作会被Rule &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DecimalPrecision&lt;/code&gt;中的decimalAndDecimal方法处理。由于该二元操作是乘法操作，我们看乘法操作部分的代码。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/DecimalPrecision.scala&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Multiply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;DecimalType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;Expression&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;DecimalType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;Expression&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;resultType&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;SQLConf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;decimalOperationsAllowPrecisionLoss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;DecimalType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;adjustPrecisionScale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;DecimalType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;bounded&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;widerType&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;widerDecimalType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;nc&quot;&gt;CheckOverflow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Multiply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;promotePrecision&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;widerType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;promotePrecision&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;widerType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;resultType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;此处我们的操作数已经都是Decimal(34, 24)类型，所以p1=p2=34, s1=s2=24.&lt;/p&gt;

&lt;p&gt;如果不允许精度丢失，那么resultType就是 DecimalType.bounded(p1+p2+1, s1+s2), bounded方法代表precision 和 scale都不能超过38，所以这里的ResultType就是Decimal(38, 38), 也就是小数部分为38位，那么整数部分就只剩下0位来表示，也就是说如果整数部分非0，那么这个结果就会overflow。在当前版本中，如果发生Decimal Operation 计算发生了overflow，那么就会返回一个Null的结果。&lt;/p&gt;

&lt;p&gt;这也解释了前面的场景中，为什么使用环境B中Spark客户端跑的结果，非Null的结果中整数部分都是0，而且小数部分精度更高(因为不允许精度丢失)。&lt;/p&gt;

&lt;p&gt;好了，问题定位到这里结束，下面讲解决方案。&lt;/p&gt;

&lt;h4 id=&quot;解决方案&quot;&gt;解决方案&lt;/h4&gt;

&lt;p&gt;通过观察Spark sql中Decimal 相关的Rule，发现了Rule &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DecimalPrecision&lt;/code&gt;中的nondecimalAndDecimal方法，这个方法是用来处理非Decimal类型和Decimal类型操作数的二元操作。&lt;/p&gt;

&lt;p&gt;此方法代码不多，如下。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/DecimalPrecision.scala &lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;nondecimalAndDecimal&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;PartialFunction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Expression&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;Expression&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BinaryOperator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;dataType&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;dataType&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
       &lt;span class=&quot;nf&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Literal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;dataType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;isInstanceOf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;DecimalType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
         &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;dataType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;isInstanceOf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;IntegralType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
         &lt;span class=&quot;nv&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;makeCopy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Cast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;DecimalType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;fromLiteral&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
       &lt;span class=&quot;nf&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Literal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;dataType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;isInstanceOf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;DecimalType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
         &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;dataType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;isInstanceOf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;IntegralType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
         &lt;span class=&quot;nv&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;makeCopy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Cast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;DecimalType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;fromLiteral&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))))&lt;/span&gt;
       &lt;span class=&quot;nf&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;IntegralType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;DecimalType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;Expression&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
         &lt;span class=&quot;nv&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;makeCopy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Cast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;DecimalType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;forType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;dataType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
       &lt;span class=&quot;nf&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;DecimalType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;Expression&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;IntegralType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
         &lt;span class=&quot;nv&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;makeCopy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Cast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;DecimalType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;forType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;dataType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))))&lt;/span&gt;
       &lt;span class=&quot;nf&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;DecimalType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;Expression&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;isFloat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;dataType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
         &lt;span class=&quot;nv&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;makeCopy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Cast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DoubleType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt;
       &lt;span class=&quot;nf&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;DecimalType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;Expression&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;isFloat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;dataType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
         &lt;span class=&quot;nv&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;makeCopy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Cast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DoubleType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
       &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
     &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;用文字描述一下此处代码的意思，此代码的目的也是为了将BinaryOperator的两个操作数转换为同一类型。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果其中非Decimal类型的操作数是Literal, 那么使用DecimalType.fromLiteral方法将该Literal转换为Decimal，例如，如果是Literal(1)，则转化为Decimal(1, 0)，如果是Literal(100),则转化为Decimal(3, 0)。&lt;/li&gt;
  &lt;li&gt;如果其中非Decimal类型操作数是Integer类型，那么使用DecimalType.forType将Integer转换为Decimal类型，由于Integer.MAX_VALUE 为2147483647，小于3*10^9，所以将Integer转换为Decimal(10, 0)。&lt;/li&gt;
  &lt;li&gt;如果其中非Decimal类型的操作是float/double类型，则将Decimal类型转换为double类型(此为DB通用做法)。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因此，这里的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DecimalPrecision&lt;/code&gt; Rule的nonDecimalAndDecimal方法处理一个Decimal类型和另一个非Decimal类型操作数的BinaryOperator的做法要比前面提到的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ImplicitTypeCasts&lt;/code&gt;规则处理更加合适(ImplicitTypeCasts 将Literal(1) 转换为Decimal(34, 24), DecimalPrecision将Literal(1)转换为Decimal(1, 0) )。&lt;/p&gt;

&lt;p&gt;经过&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DecimalPrecision&lt;/code&gt; Rule的nonDecimalAndDecimal处理之后的两个Decimal类型操作数会被&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DecimalPrecision&lt;/code&gt;中的decimalAndDecimal方法(上文提及过)继续处理。&lt;/p&gt;

&lt;p&gt;针对上述提到的case，是一个MuiltiPly 操作，p1=34, s1=24, p2 =1, s2=0。&lt;/p&gt;

&lt;p&gt;其ResultType为Decimal(36,24)，也就是说24位表示小数部分, 12位表示整数部分，不容易发生overflow。&lt;/p&gt;

&lt;p&gt;前面提到过Spark sql中关于类型转换的Rule是作用在Analysis阶段的Resolution子阶段。 而Resolution子阶段有一批的Rule，这批Rule会一直作用在一个Plan上，直到这个Plan到达一个Fixpoint(即不动点，继续作用Rule也不再改变Plan)。&lt;/p&gt;

&lt;p&gt;因此，我们可以在ImplicitTypeCasts规则中对操作数类型进行判断，如果在一个BinaryOperator中有Decimal类型的操作数，则此处跳过处理，这个BinaryOperator后续会被DecimalPrecision规则中的nonDecimalAndDecimal方法和decimalAndDecimal方法继续处理，最终到达FixPoint.&lt;/p&gt;

&lt;p&gt;我们向Spark社区提了一个PR &lt;a href=&quot;https://github.com/apache/spark/pull/25701&quot;&gt;SPARK-29000&lt;/a&gt;, 目前已经合入master分支。&lt;/p&gt;

&lt;h5 id=&quot;用户可感知的overflow&quot;&gt;用户可感知的overflow&lt;/h5&gt;

&lt;p&gt;除此之外，默认的DecimalOperation如果发生了overflow，那么其结果将返回为空，这样的计算结果异常不容易被用户感知到(此处非常感谢金融分析团队的同事帮我们检查到了这个问题)。&lt;/p&gt;

&lt;p&gt;SQL ANSI 2011提出了当算术操作发生overflow时候，应该抛出一个异常。这也是大多数数据库的做法(例如SQLService, DB2).&lt;/p&gt;

&lt;p&gt;PR &lt;a href=&quot;https://github.com/apache/spark/pull/20350&quot;&gt;SPARK-23179&lt;/a&gt; 引入了一个参数&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.decimalOperations.nullOnOverflow&lt;/code&gt; 用来控制在Decimal Operation 发生overflow时候的处理方式。&lt;/p&gt;

&lt;p&gt;默认是true，代表在Decimal Operation发生overflow时返回NULL的结果。&lt;/p&gt;

&lt;p&gt;如果设置为false，则会在Decimal Operation发生overflow时候抛出一个异常。&lt;/p&gt;

&lt;p&gt;因此，我们在上面的基础上合入该PR，引入&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.decimalOperations.nullOnOverflow&lt;/code&gt;参数，设置为false, 以保证线上计算任务的数据质量。&lt;/p&gt;
</description>
                <link>http://www.turbofei.wang/spark/2019/09/09/Spark-SQL-Decimal-Precision-Overflow-Analysis</link>
                <guid>http://www.turbofei.wang/spark/2019/09/09/Spark-SQL-Decimal-Precision-Overflow-Analysis</guid>
                <pubDate>2019-09-09T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>Spark Blacklist Mechanism Introduction</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#前言&quot; id=&quot;markdown-toc-前言&quot;&gt;前言&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#blacklist机制&quot; id=&quot;markdown-toc-blacklist机制&quot;&gt;BlackList机制&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#blacklist级别&quot; id=&quot;markdown-toc-blacklist级别&quot;&gt;BlackList级别&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#fetchfailure--blacklist&quot; id=&quot;markdown-toc-fetchfailure--blacklist&quot;&gt;FetchFailure &amp;amp; BlackList&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#yarn-node-launch-failure&quot; id=&quot;markdown-toc-yarn-node-launch-failure&quot;&gt;Yarn Node launch Failure&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#blacklist-参数&quot; id=&quot;markdown-toc-blacklist-参数&quot;&gt;BlackList 参数&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本文讲Spark的Blacklist机制&lt;/p&gt;

&lt;h3 id=&quot;前言&quot;&gt;前言&lt;/h3&gt;

&lt;p&gt;Spark是一个分布式计算框架，task会分发到各个节点去执行，难免会有一些bad node 会导致task的失败，task失败的次数多了会导致stage失败，如果stage连续失败达到阈值又会导致application级别的失败。而blacklist,即黑名单机制，就是为了减少这些由于bad node从而导致应用最终失败的情况。&lt;/p&gt;

&lt;p&gt;BlackList机制是由PR &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-8425&quot;&gt;SPARK-8425&lt;/a&gt;提出，里面有设计文档以及相关sub-task.&lt;/p&gt;

&lt;h3 id=&quot;blacklist机制&quot;&gt;BlackList机制&lt;/h3&gt;

&lt;p&gt;在spark的调度中，首先是触发job，然后划分stage进行提交，而在每个stage中都是一些互相独立的task。因此针对spark的调度机制，blacklist分为多种级别。&lt;/p&gt;

&lt;h4 id=&quot;blacklist级别&quot;&gt;BlackList级别&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;(Executor, task)级别
    &lt;ul&gt;
      &lt;li&gt;一个task可以在一个executor上的最大尝试次数，如果超出次数，该executor加入该task的blacklist&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;（node, task)级别
    &lt;ul&gt;
      &lt;li&gt;一个task可以在一个node上的最大尝试次数，如果超出这个次数，则该node加入该task的blacklist&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;(executor, stage)级别
    &lt;ul&gt;
      &lt;li&gt;在一个stage中，如果其中的tasks在一个executor里失败次数超出阈值，则加入该stage的blacklist&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;(node, stage)级别
    &lt;ul&gt;
      &lt;li&gt;在一个stage中，如果其中tasks在一个node上失败次数超出阈值，则加入该stage的blacklist&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;(Executor, application)级别
    &lt;ul&gt;
      &lt;li&gt;在一个应用中，如果其中tasks在一个executor上失败次数超出阈值，则加入application 对应的blacklist&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;(Node, application)级别
    &lt;ul&gt;
      &lt;li&gt;在一个应用中，如果其中tasks在一个node上失败次数超出阈值，则加入application对应的blacklist&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;需要提出的是，针对&lt;strong&gt;application&lt;/strong&gt;的blacklist不是无限期的，有一个参数控制，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.blacklist.timeout&lt;/code&gt;,默认是1h，超出这个时间之后会从blacklist中移出。&lt;/p&gt;

&lt;p&gt;可以配置是否kill掉&lt;strong&gt;Application BlackList&lt;/strong&gt;的executor，如果一个node被加入到application级别的BlackList，那么node上的所有executor都要kill掉。&lt;/p&gt;

&lt;h4 id=&quot;fetchfailure--blacklist&quot;&gt;FetchFailure &amp;amp; BlackList&lt;/h4&gt;

&lt;p&gt;还有一个就是在FetchFailed错误的时候进行的blacklist了。&lt;/p&gt;

&lt;p&gt;首先介绍一下fetch Failure。&lt;/p&gt;

&lt;p&gt;这里的fetch是指shuffle fetch。参与的角色有三个，拉取数据的executor，发送数据的executor或者ExternalShuffleService，以及网络。&lt;/p&gt;

&lt;p&gt;往往拉取数据的executor不会是过错方，除非是说其在fetch的时候使用，一批数据的大小超过了其最大可放置在内存的阈值，需要这些数据进行落盘，然后之后创建inputStream的时候发生了IOException(可能是因为磁盘坏了，或者是网络传输问题)，所以过错方是拉取数据的executor可能性比较小。&lt;/p&gt;

&lt;p&gt;所以，问题就丢给了双方之间的网络以及被拉取的executor或者ESS。&lt;/p&gt;

&lt;p&gt;在进行shuffle fetch的时候，如果没有开启ExternalShuffleService，那么我们是向remote 的 executor索要数据，所以这时候会将这个executor 加入blacklist。&lt;/p&gt;

&lt;p&gt;而如果是开启了ESS，那么就是说我们向那个节点的nodemanager里面的ESS服务索要数据失败，那么就会将这个ESS所在的整个Node加入到blackList。&lt;/p&gt;

&lt;h4 id=&quot;yarn-node-launch-failure&quot;&gt;Yarn Node launch Failure&lt;/h4&gt;

&lt;p&gt;前面提到的都是在任务执行过程中失败，那么如果是在yarn 启动container的时候就失败呢。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-16630&quot;&gt;SPARK-16630&lt;/a&gt; 提出了将这个不能成功启动container的Node加入blackList.&lt;/p&gt;

&lt;h3 id=&quot;blacklist-参数&quot;&gt;BlackList 参数&lt;/h3&gt;

&lt;p&gt;下面是BlackList的参数，都与前面的介绍对应，不再写中文介绍。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;参数名称&lt;/th&gt;
      &lt;th&gt;默认值&lt;/th&gt;
      &lt;th&gt;说明&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.blacklist.enabled&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;If set to “true”, prevent Spark from scheduling tasks on executors that have been blacklisted due to too many task failures. The blacklisting algorithm can be further controlled by the other “spark.blacklist” configuration options.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.blacklist.timeout&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;1h&lt;/td&gt;
      &lt;td&gt;(Experimental) How long a node or executor is blacklisted for the entire application, before it is unconditionally removed from the blacklist to attempt running new tasks.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.blacklist.task.maxTaskAttemptsPerExecutor&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;(Experimental) For a given task, how many times it can be retried on one executor before the executor is blacklisted for that task.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.blacklist.task.maxTaskAttemptsPerNode&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;(Experimental) For a given task, how many times it can be retried on one node, before the entire node is blacklisted for that task.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.blacklist.stage.maxFailedTasksPerExecutor&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;(Experimental) How many different tasks must fail on one executor, within one stage, before the executor is blacklisted for that stage.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.blacklist.stage.maxFailedExecutorsPerNode&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;(Experimental) How many different executors are marked as blacklisted for a given stage, before the entire node is marked as failed for the stage.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.blacklist.application.maxFailedTasksPerExecutor&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;(Experimental) How many different tasks must fail on one executor, in successful task sets, before the executor is blacklisted for the entire application. Blacklisted executors will be automatically added back to the pool of available resources after the timeout specified by&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.blacklist.timeout&lt;/code&gt;. Note that with dynamic allocation, though, the executors may get marked as idle and be reclaimed by the cluster manager.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.blacklist.application.maxFailedExecutorsPerNode&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;(Experimental) How many different executors must be blacklisted for the entire application, before the node is blacklisted for the entire application. Blacklisted nodes will be automatically added back to the pool of available resources after the timeout specified by&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.blacklist.timeout&lt;/code&gt;. Note that with dynamic allocation, though, the executors on the node may get marked as idle and be reclaimed by the cluster manager.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.blacklist.killBlacklistedExecutors&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;(Experimental) If set to “true”, allow Spark to automatically kill the executors when they are blacklisted on fetch failure or blacklisted for the entire application, as controlled by spark.blacklist.application.*. Note that, when an entire node is added to the blacklist, all of the executors on that node will be killed.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.blacklist.application.fetchFailure.enabled&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;(Experimental) If set to “true”, Spark will blacklist the executor immediately when a fetch failure happens. If external shuffle service is enabled, then the whole node will be blacklisted.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.yarn.blacklist.executor.launch.blacklisting.enabled&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;Flag to enable blacklisting of nodes having YARN resource allocation problems. The error limit for blacklisting can be configured by spark.blacklist.application.maxFailedExecutorsPerNode.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
</description>
                <link>http://www.turbofei.wang/spark/2019/08/30/Spark-Blacklist-Mechanism-Introduction</link>
                <guid>http://www.turbofei.wang/spark/2019/08/30/Spark-Blacklist-Mechanism-Introduction</guid>
                <pubDate>2019-08-30T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>Linux Ops Commands</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#前言&quot; id=&quot;markdown-toc-前言&quot;&gt;前言&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#telnet&quot; id=&quot;markdown-toc-telnet&quot;&gt;telnet&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#ss--somaxconn&quot; id=&quot;markdown-toc-ss--somaxconn&quot;&gt;ss &amp;amp; somaxconn&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#recv-q--send-q&quot; id=&quot;markdown-toc-recv-q--send-q&quot;&gt;Recv-Q &amp;amp; Send-Q&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#somaxconn&quot; id=&quot;markdown-toc-somaxconn&quot;&gt;somaxconn&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#netstat&quot; id=&quot;markdown-toc-netstat&quot;&gt;netstat&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#top&quot; id=&quot;markdown-toc-top&quot;&gt;top&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#sysctl--systemctl&quot; id=&quot;markdown-toc-sysctl--systemctl&quot;&gt;sysctl &amp;amp; systemctl&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#to-be-continued&quot; id=&quot;markdown-toc-to-be-continued&quot;&gt;To Be Continued&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#references&quot; id=&quot;markdown-toc-references&quot;&gt;References&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;作为一个大数据平台从业人员，会操作线上服务器是必备的技能，因此必须要会一些常见的Linux运维命令。 本文记录一下最近用到的一些线上操作命令。&lt;/p&gt;

&lt;h3 id=&quot;前言&quot;&gt;前言&lt;/h3&gt;

&lt;p&gt;由于之前对线上操作不多，而最近开始接触线上操作，因此也在这个过程中学习到了一些Linux命令。&lt;/p&gt;

&lt;p&gt;解决问题的思维也需要慢慢进行转变，之前在定位Spark问题的时候，总是会从PAAS层进行寻找问题，例如去看是否是Spark自身的问题，而往往不会去考虑是否是Linux系统的问题。这也是自己所欠缺的地方。&lt;/p&gt;

&lt;p&gt;例如本周遇到的问题，是说executor 向External Shuffle Service发出连接请求，而总是connect timeout,当时我的第一想法就是说看是否是ESS所在的nodemanager比较繁忙。&lt;/p&gt;

&lt;p&gt;我的思路是首先查看PID，然后查看其jstack信息，以及gcutil信息，查看之后就发现其GC并不严重。到此，我就不知道该如何去定位问题了。但是在组里经验更加丰富的同事进行排查跟踪后，发现是其系统配置的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;somaxconn&lt;/code&gt;参数过小，不能处理处于大量的请求，导致丢包。&lt;/p&gt;

&lt;p&gt;因此这就需要深入了解Linux系统，了解TCP连接建立的过程，以及使用对应的命令进行排查。&lt;/p&gt;

&lt;p&gt;下面讲线上操作常见的操作命令。&lt;/p&gt;

&lt;h3 id=&quot;telnet&quot;&gt;telnet&lt;/h3&gt;

&lt;p&gt;在linux系统中，通常需要判断一些网络问题。比如某个节点是否是联通的，可以使用Ping 命令。&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ping &lt;span class=&quot;nb&quot;&gt;hostname&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;而如果要判断一个host的port是否互通就需要使用telnet命令。&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;telnet host port
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;嗯，感觉这个就够了…&lt;/p&gt;

&lt;h3 id=&quot;ss--somaxconn&quot;&gt;ss &amp;amp; somaxconn&lt;/h3&gt;

&lt;p&gt;说实话这个命令之前都没听过。&lt;/p&gt;

&lt;p&gt;ss 是socket statistics的简称。用于查看socket相关的统计信息。&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Usage: ss &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; OPTIONS &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
       ss &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; OPTIONS &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; FILTER &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;-h&lt;/span&gt;, &lt;span class=&quot;nt&quot;&gt;--help&lt;/span&gt;           this message      &lt;span class=&quot;c&quot;&gt;#显示帮助菜单&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;-V&lt;/span&gt;, &lt;span class=&quot;nt&quot;&gt;--version&lt;/span&gt;        output version information      &lt;span class=&quot;c&quot;&gt;#输出版本信息&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt;, &lt;span class=&quot;nt&quot;&gt;--numeric&lt;/span&gt;        don&lt;span class=&quot;s1&quot;&gt;&apos;t resolve service names    #不解析服务名
   -r, --resolve       resolve host names   #解析主机名
   -a, --all            display all sockets     #显示所有的套接字
   -l, --listening      display listening sockets   #显示监听状态的socket
   -o, --options       show timer information   #显示计时器信息
   -e, --extended      show detailed socket information #展示详细的socket信息
   -m, --memory        show socket memory usage #展示socket的内存使用
   -p, --processes      show process using socket   #展示使用socket的进程
   -i, --info           show internal TCP information   #展示tcp内部信息
   -s, --summary        show socket usage summary   #展示socket使用汇总

   -4, --ipv4          display only IP version 4 sockets    #只显示ipv4的sockets
   -6, --ipv6          display only IP version 6 sockets    #只显示ipv6的sockets
   -0, --packet display PACKET sockets  #显示包经过的网络接口
   -t, --tcp            display only TCP sockets    #显示tcp套接字
   -u, --udp            display only UDP sockets    #显示udp套接字
   -d, --dccp           display only DCCP sockets   #显示dccp套接字
   -w, --raw            display only RAW sockets    #显示raw套接字
   -x, --unix           display only Unix domain sockets    #显示unix套接字
   -f, --family=FAMILY display sockets of type FAMILY   #显示指定类型的套接字

   -A, --query=QUERY, --socket=QUERY    #查看某种类型
       QUERY := {all|inet|tcp|udp|raw|unix|packet|netlink}[,QUERY]

   -D, --diag=FILE      Dump raw information about TCP sockets to FILE  #将关于TCP套接字的原始信息转储到文件中
   -F, --filter=FILE   read filter information from FILE #使用此参数指定的过滤规则文件，过滤某种状态的连接
       FILTER := [ state TCP-STATE ] [ EXPRESSION ]
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里讲一下 -n 参数，如果不加 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-n&lt;/code&gt;参数，那么会显示服务名，而如果使用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-n&lt;/code&gt;，那么则不解析服务名。示例如下。&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;fwang12@fwang-dev1-3474144 ~]&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;ss &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt;
State       Recv-Q Send-Q  Local Address:Port                   Peer Address:Port
ESTAB       0      168    10.194.228.167:ssh                   10.242.101.88:56151
ESTAB       0      0      10.194.228.167:38570                 10.232.128.78:ldaps
ESTAB       0      0      10.194.228.167:54564                10.169.164.189:4505
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;fwang12@fwang-dev1-3474144 ~]&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;ss &lt;span class=&quot;nt&quot;&gt;-tn&lt;/span&gt;
State       Recv-Q Send-Q    Local Address:Port                   Peer Address:Port
ESTAB       0      168      10.194.228.167:22                    10.242.101.88:56151
ESTAB       0      0        10.194.228.167:38570                 10.232.128.78:636
ESTAB       0      0        10.194.228.167:54564                10.169.164.189:4505
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这样我们就可以看到服务所使用的端口号，这样就可以通过一些端口号来查看其socket 信息。例如我们熟知的ExternalShuffleService就是默认以7337作为端口，那么就可以使用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ss -ln |grep 7337&lt;/code&gt;来查看其socket信息。&lt;/p&gt;

&lt;h4 id=&quot;recv-q--send-q&quot;&gt;Recv-Q &amp;amp; Send-Q&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;当 client 通过 connect 向 server 发出 SYN 包时，client 会维护一个 socket 等待队列，而 server 会维护一个 SYN 队列&lt;/li&gt;
  &lt;li&gt;此时进入半链接的状态，如果 socket 等待队列满了，server 则会丢弃，而 client 也会由此返回 connection time out；只要是 client 没有收到 SYN+ACK，3s 之后，client 会再次发送，如果依然没有收到，9s 之后会继续发送&lt;/li&gt;
  &lt;li&gt;半连接 syn 队列的长度为 max(64, /proc/sys/net/ipv4/tcp_max_syn_backlog)  决定&lt;/li&gt;
  &lt;li&gt;当 server 收到 client 的 SYN 包后，会返回 SYN, ACK 的包加以确认，client 的 TCP 协议栈会唤醒 socket 等待队列，发出 connect 调用&lt;/li&gt;
  &lt;li&gt;client 返回 ACK 的包后，server 会进入一个新的叫 accept 的队列，该队列的长度为 min(backlog, somaxconn)，默认情况下，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;somaxconn&lt;/code&gt; 的值为 128，表示最多有 129 的 ESTAB 的连接等待 accept()，而 backlog 的值则由 &lt;a href=&quot;http://http//linux.die.net/man/2/listen&quot;&gt;int listen(int sockfd, int backlog)&lt;/a&gt; 中的第二个参数指定，listen 里面的 backlog 的含义请看这里。需要注意的是，&lt;a href=&quot;http://serverfault.com/questions/518862/testifying-rasing-net-core-somaxconn-can-make-a-difference&quot;&gt;一些 Linux 的发型版本可能存在对 somaxcon 错误 truncating 方式&lt;/a&gt;。&lt;/li&gt;
  &lt;li&gt;当 accept 队列满了之后，即使 client 继续向 server 发送 ACK 的包，也会不被相应，此时，server 通过 /proc/sys/net/ipv4/tcp_abort_on_overflow 来决定如何返回，0 表示直接丢丢弃该 ACK，1 表示发送 RST 通知 client；相应的，client 则会分别返回 read timeout 或者 connection reset by peer。上面说的只是些理论，如果服务器不及时的调用 accept()，当 queue 满了之后，服务器并不会按照理论所述，不再对 SYN 进行应答，返回 ETIMEDOUT。根据&lt;a href=&quot;http://www.douban.com/note/178129553/&quot;&gt;这篇&lt;/a&gt;文档的描述，实际情况并非如此，服务器会随机的忽略收到的 SYN，建立起来的连接数可以无限的增加，只不过客户端会遇到延时以及超时的情况。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;可以看到，整个 TCP stack 有如下的两个 queue:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;一个是 half open(syn queue) queue(max(tcp_max_syn_backlog, 64))，用来保存 SYN_SENT 以及 SYN_RECV 的信息。&lt;/li&gt;
  &lt;li&gt;另外一个是 accept queue(min(somaxconn, backlog))，保存 ESTAB 的状态，但是调用 accept()。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;somaxconn&quot;&gt;somaxconn&lt;/h4&gt;

&lt;p&gt;前面提到，client返回ack之后，server进入一个新的叫accept的队列，队列长度为min(backlog, somaxconn)。&lt;/p&gt;

&lt;p&gt;somaxconn定义了系统中每一个端口最大的监听队列的长度,这是个全局的参数,默认值为128.限制了每个端口接收新tcp连接侦听队列的大小。针对线上一些服务，比如说Spark 的External Shuffle Service，默认的128太小，必须设置很大才能满足生产需求。&lt;/p&gt;

&lt;p&gt;而somaxconn 是在文件&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/sysctl.conf&lt;/code&gt;中。&lt;/p&gt;

&lt;p&gt;保存之后使用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sysctl -p&lt;/code&gt;立即生效。&lt;/p&gt;

&lt;h3 id=&quot;netstat&quot;&gt;netstat&lt;/h3&gt;

&lt;p&gt;netstat的作用其实与 ss 类似。&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;fwang12@fwang-dev1-3474144 ~]&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;netstat &lt;span class=&quot;nt&quot;&gt;-h&lt;/span&gt;
usage: netstat &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;-vWeenNcCF&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;Af&amp;gt;] &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt;         netstat &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;-V&lt;/span&gt;|--version|-h|--help&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
       netstat &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;-vWnNcaeol&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;Socket&amp;gt; ...]
       netstat &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;-vWeenNac&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-I&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&amp;lt;Iface&amp;gt;] | &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;-veenNac&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; | &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;-cnNe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-M&lt;/span&gt; | &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;-6tuw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;delay]

        &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt;, &lt;span class=&quot;nt&quot;&gt;--route&lt;/span&gt;              display routing table
        &lt;span class=&quot;nt&quot;&gt;-I&lt;/span&gt;, &lt;span class=&quot;nt&quot;&gt;--interfaces&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&amp;lt;Iface&amp;gt; display interface table &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &amp;lt;Iface&amp;gt;
        &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt;, &lt;span class=&quot;nt&quot;&gt;--interfaces&lt;/span&gt;         display interface table
        &lt;span class=&quot;nt&quot;&gt;-g&lt;/span&gt;, &lt;span class=&quot;nt&quot;&gt;--groups&lt;/span&gt;             display multicast group memberships
        &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt;, &lt;span class=&quot;nt&quot;&gt;--statistics&lt;/span&gt;         display networking statistics &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;like SNMP&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;-M&lt;/span&gt;, &lt;span class=&quot;nt&quot;&gt;--masquerade&lt;/span&gt;         display masqueraded connections

        &lt;span class=&quot;nt&quot;&gt;-v&lt;/span&gt;, &lt;span class=&quot;nt&quot;&gt;--verbose&lt;/span&gt;            be verbose
        &lt;span class=&quot;nt&quot;&gt;-W&lt;/span&gt;, &lt;span class=&quot;nt&quot;&gt;--wide&lt;/span&gt;               don&lt;span class=&quot;s1&quot;&gt;&apos;t truncate IP addresses
        -n, --numeric            don&apos;&lt;/span&gt;t resolve names
        &lt;span class=&quot;nt&quot;&gt;--numeric-hosts&lt;/span&gt;          don&lt;span class=&quot;s1&quot;&gt;&apos;t resolve host names
        --numeric-ports          don&apos;&lt;/span&gt;t resolve port names
        &lt;span class=&quot;nt&quot;&gt;--numeric-users&lt;/span&gt;          don&lt;span class=&quot;s1&quot;&gt;&apos;t resolve user names
        -N, --symbolic           resolve hardware names
        -e, --extend             display other/more information
        -p, --programs           display PID/Program name for sockets
        -o, --timers             display timers
        -c, --continuous         continuous listing

        -l, --listening          display listening server sockets
        -a, --all                display all sockets (default: connected)
        -F, --fib                display Forwarding Information Base (default)
        -C, --cache              display routing cache instead of FIB
        -Z, --context            display SELinux security context for sockets

  &amp;lt;Socket&amp;gt;={-t|--tcp} {-u|--udp} {-U|--udplite} {-S|--sctp} {-w|--raw}
           {-x|--unix} --ax25 --ipx --netrom
  &amp;lt;AF&amp;gt;=Use &apos;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;-6&lt;/span&gt;|-4&lt;span class=&quot;s1&quot;&gt;&apos; or &apos;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;-A&lt;/span&gt; &amp;lt;af&amp;gt;&lt;span class=&quot;s1&quot;&gt;&apos; or &apos;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;--&lt;/span&gt;&amp;lt;af&amp;gt;&lt;span class=&quot;s1&quot;&gt;&apos;; default: inet
  List of possible address families (which support routing):
    inet (DARPA Internet) inet6 (IPv6) ax25 (AMPR AX.25)
    netrom (AMPR NET/ROM) ipx (Novell IPX) ddp (Appletalk DDP)
    x25 (CCITT X.25)
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;例如可以使用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;netstat -antlp&lt;/code&gt;列出所有非解析服务名字的tcp监听状态的server sockets，并打出pid.&lt;/p&gt;

&lt;h3 id=&quot;top&quot;&gt;top&lt;/h3&gt;

&lt;p&gt;输入top打印如下。&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;top - 11:05:18 up 9 days, 15:59,  1 user,  load average: 0.00, 0.01, 0.05
Tasks: 184 total,   1 running, 183 sleeping,   0 stopped,   0 zombie
%Cpu&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;s&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;:  0.0 us,  0.0 sy,  0.0 ni,100.0 &lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem : 32778616 total, 31754528 free,   350816 used,   673272 buff/cache
KiB Swap:        0 total,        0 free,        0 used. 31972344 avail Mem

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
 9198 fwang12   20   0  172408   2424   1632 R   0.3  0.0   0:00.01 top
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;其中显示的列信息，可以在进入top之后，按F进入编辑列，使用空格决定是否显示列信息。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;* PID     = Process Id
* USER    = Effective User Name
* PR      = Priority
* NI      = Nice Value  //PR(new) = PR(old) + NI
* VIRT    = Virtual Image (KiB)
* RES     = Resident Size (KiB)
* SHR     = Shared Memory (KiB)
* S       = Process Status
* %CPU    = CPU Usage
* %MEM    = Memory Usage (RES)
* TIME+   = CPU Time, hundredths
* COMMAND = Command Name/Line
  PPID    = Parent Process pid
  UID     = Effective User Id
  RUID    = Real User Id
  RUSER   = Real User Name
  SUID    = Saved User Id
  SUSER   = Saved User Name
  GID     = Group Id
  GROUP   = Group Name
  PGRP    = Process Group Id
  TTY     = Controlling Tty
  TPGID   = Tty Process Grp Id
  SID     = Session Id
  nTH     = Number of Threads
  P       = Last Used Cpu (SMP)
  TIME    = CPU Time
  SWAP    = Swapped Size (KiB)
  CODE    = Code Size (KiB)
  DATA    = Data+Stack (KiB)
  nMaj    = Major Page Faults
  nMin    = Minor Page Faults
  nDRT    = Dirty Pages Count
  WCHAN   = Sleeping in Function
  Flags   = Task Flags &amp;lt;sched.h&amp;gt;
  CGROUPS = Control Groups
  SUPGIDS = Supp Groups IDs
  SUPGRPS = Supp Groups Names
  TGID    = Thread Group Id
  ENVIRON = Environment vars
  vMj     = Major Faults delta
  vMn     = Minor Faults delta
  USED    = Res+Swap Size (KiB)
  nsIPC   = IPC namespace Inode
  nsMNT   = MNT namespace Inode
  nsNET   = NET namespace Inode
  nsPID   = PID namespace Inode
  nsUSER  = USER namespace Inode
  nsUTS   = UTS namespace Inode
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;fwang12@fwang-dev1-3474144 ~]&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;top &lt;span class=&quot;nt&quot;&gt;-h&lt;/span&gt;
  procps-ng version 3.3.10
Usage:
  top &lt;span class=&quot;nt&quot;&gt;-hv&lt;/span&gt; | &lt;span class=&quot;nt&quot;&gt;-bcHiOSs&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; secs &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; max &lt;span class=&quot;nt&quot;&gt;-u&lt;/span&gt;|U user &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; pid&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;s&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; field &lt;span class=&quot;nt&quot;&gt;-w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;cols]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;可以指定用户，PID等信息.&lt;/p&gt;

&lt;p&gt;进入top之后输入&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;?&lt;/code&gt;可以查看帮助，查看可以使用什么命令。&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Help &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;Interactive Commands - procps-ng version 3.3.10
Window 1:Def: Cumulative mode Off.  System: Delay 3.0 secs&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; Secure mode Off.

  Z,B,E,e   Global: &lt;span class=&quot;s1&quot;&gt;&apos;Z&apos;&lt;/span&gt; colors&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;B&apos;&lt;/span&gt; bold&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;E&apos;&lt;/span&gt;/&lt;span class=&quot;s1&quot;&gt;&apos;e&apos;&lt;/span&gt; summary/task memory scale
  l,t,m     Toggle Summary: &lt;span class=&quot;s1&quot;&gt;&apos;l&apos;&lt;/span&gt; load avg&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;t&apos;&lt;/span&gt; task/cpu stats&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;m&apos;&lt;/span&gt; memory info
  0,1,2,3,I Toggle: &lt;span class=&quot;s1&quot;&gt;&apos;0&apos;&lt;/span&gt; zeros&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;1/2/3&apos;&lt;/span&gt; cpus or numa node views&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;I&apos;&lt;/span&gt; Irix mode
  f,F,X     Fields: &lt;span class=&quot;s1&quot;&gt;&apos;f&apos;&lt;/span&gt;/&lt;span class=&quot;s1&quot;&gt;&apos;F&apos;&lt;/span&gt; add/remove/order/sort&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;X&apos;&lt;/span&gt; increase fixed-width

  L,&amp;amp;,&amp;lt;,&amp;gt; &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt; Locate: &lt;span class=&quot;s1&quot;&gt;&apos;L&apos;&lt;/span&gt;/&lt;span class=&quot;s1&quot;&gt;&apos;&amp;amp;&apos;&lt;/span&gt; find/again&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; Move &lt;span class=&quot;nb&quot;&gt;sort &lt;/span&gt;column: &lt;span class=&quot;s1&quot;&gt;&apos;&amp;lt;&apos;&lt;/span&gt;/&lt;span class=&quot;s1&quot;&gt;&apos;&amp;gt;&apos;&lt;/span&gt; left/right
  R,H,V,J &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt; Toggle: &lt;span class=&quot;s1&quot;&gt;&apos;R&apos;&lt;/span&gt; Sort&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;H&apos;&lt;/span&gt; Threads&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;V&apos;&lt;/span&gt; Forest view&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;J&apos;&lt;/span&gt; Num justify
  c,i,S,j &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt; Toggle: &lt;span class=&quot;s1&quot;&gt;&apos;c&apos;&lt;/span&gt; Cmd name/line&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;i&apos;&lt;/span&gt; Idle&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;S&apos;&lt;/span&gt; Time&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;j&apos;&lt;/span&gt; Str justify
  x,y     &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt; Toggle highlights: &lt;span class=&quot;s1&quot;&gt;&apos;x&apos;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sort &lt;/span&gt;field&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;y&apos;&lt;/span&gt; running tasks
  z,b     &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt; Toggle: &lt;span class=&quot;s1&quot;&gt;&apos;z&apos;&lt;/span&gt; color/mono&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;b&apos;&lt;/span&gt; bold/reverse &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;only &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;x&apos;&lt;/span&gt; or &lt;span class=&quot;s1&quot;&gt;&apos;y&apos;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  u,U,o,O &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt; Filter by: &lt;span class=&quot;s1&quot;&gt;&apos;u&apos;&lt;/span&gt;/&lt;span class=&quot;s1&quot;&gt;&apos;U&apos;&lt;/span&gt; effective/any user&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;o&apos;&lt;/span&gt;/&lt;span class=&quot;s1&quot;&gt;&apos;O&apos;&lt;/span&gt; other criteria
  n,#,^O  &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt; Set: &lt;span class=&quot;s1&quot;&gt;&apos;n&apos;&lt;/span&gt;/&lt;span class=&quot;s1&quot;&gt;&apos;#&apos;&lt;/span&gt; max tasks displayed&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; Show: Ctrl+&lt;span class=&quot;s1&quot;&gt;&apos;O&apos;&lt;/span&gt; other filter&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;s&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  C,...   &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt; Toggle scroll coordinates msg &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;: up,down,left,right,home,end

  k,r       Manipulate tasks: &lt;span class=&quot;s1&quot;&gt;&apos;k&apos;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;kill&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;r&apos;&lt;/span&gt; renice
  d or s    Set update interval
  W,Y       Write configuration file &lt;span class=&quot;s1&quot;&gt;&apos;W&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; Inspect other output &lt;span class=&quot;s1&quot;&gt;&apos;Y&apos;&lt;/span&gt;
  q         Quit
          &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt; commands shown with &lt;span class=&quot;s1&quot;&gt;&apos;.&apos;&lt;/span&gt; require a visible task display window &lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
Press &lt;span class=&quot;s1&quot;&gt;&apos;h&apos;&lt;/span&gt; or &lt;span class=&quot;s1&quot;&gt;&apos;?&apos;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;help &lt;/span&gt;with Windows,
Type &lt;span class=&quot;s1&quot;&gt;&apos;q&apos;&lt;/span&gt; or &amp;lt;Esc&amp;gt; to &lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;常用可以使用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1&lt;/code&gt;查看CPU信息。&lt;/p&gt;

&lt;h3 id=&quot;sysctl--systemctl&quot;&gt;sysctl &amp;amp; systemctl&lt;/h3&gt;

&lt;p&gt;sysctl用于运行时配置内核参数，这些参数位于/proc/sys目录下。sysctl配置与显示在/proc/sys目录中的内核参数．可以用sysctl来设置或重新设置联网功能，如IP转发、IP碎片去除以及源路由检查等。用户只需要编辑/etc/sysctl.conf文件，即可手工或自动执行由sysctl控制的功能。&lt;/p&gt;

&lt;p&gt;systemctl用于管理系统服务，systemd(system dameon),是相对于service和chkconfig的新命令.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;daemon命令&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;systemctl命令&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;说明&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;service [服务] start&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;systemctl start [unit type]&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;启动服务&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;service [服务] stop&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;systemctl stop [unit type]&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;停止服务&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;service [服务] restart&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;systemctl restart [unit type]&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;重启服务&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;daemon命令&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;systemctl命令&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;说明&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;chkconfig [服务] on&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;systemctl enable [unit type]&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;设置服务开机启动&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;chkconfig [服务] off&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;systemctl disable [unit type]&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;设备服务禁止开机启动&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;fwang12@fwang-dev1-3474144 ~]&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;sysctl &lt;span class=&quot;nt&quot;&gt;-h&lt;/span&gt;

Usage:
 sysctl &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;options] &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;variable[&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;value] ...]

Options:
  &lt;span class=&quot;nt&quot;&gt;-a&lt;/span&gt;, &lt;span class=&quot;nt&quot;&gt;--all&lt;/span&gt;            display all variables
  &lt;span class=&quot;nt&quot;&gt;-A&lt;/span&gt;                   &lt;span class=&quot;nb&quot;&gt;alias &lt;/span&gt;of &lt;span class=&quot;nt&quot;&gt;-a&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;-X&lt;/span&gt;                   &lt;span class=&quot;nb&quot;&gt;alias &lt;/span&gt;of &lt;span class=&quot;nt&quot;&gt;-a&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;--deprecated&lt;/span&gt;     include deprecated parameters to listing
  &lt;span class=&quot;nt&quot;&gt;-b&lt;/span&gt;, &lt;span class=&quot;nt&quot;&gt;--binary&lt;/span&gt;         print value without new line
  &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt;, &lt;span class=&quot;nt&quot;&gt;--ignore&lt;/span&gt;         ignore unknown variables errors
  &lt;span class=&quot;nt&quot;&gt;-N&lt;/span&gt;, &lt;span class=&quot;nt&quot;&gt;--names&lt;/span&gt;          print variable names without values
  &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt;, &lt;span class=&quot;nt&quot;&gt;--values&lt;/span&gt;         print only values of a variables
  &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt;, &lt;span class=&quot;nt&quot;&gt;--load&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[=&lt;/span&gt;&amp;lt;file&amp;gt;]  &lt;span class=&quot;nb&quot;&gt;read &lt;/span&gt;values from file
  &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt;                   &lt;span class=&quot;nb&quot;&gt;alias &lt;/span&gt;of &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;--system&lt;/span&gt;         &lt;span class=&quot;nb&quot;&gt;read &lt;/span&gt;values from all system directories
  &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt;, &lt;span class=&quot;nt&quot;&gt;--pattern&lt;/span&gt; &amp;lt;expression&amp;gt;
                       &lt;span class=&quot;k&quot;&gt;select &lt;/span&gt;setting that match expression
  &lt;span class=&quot;nt&quot;&gt;-q&lt;/span&gt;, &lt;span class=&quot;nt&quot;&gt;--quiet&lt;/span&gt;          &lt;span class=&quot;k&quot;&gt;do &lt;/span&gt;not &lt;span class=&quot;nb&quot;&gt;echo &lt;/span&gt;variable &lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;-w&lt;/span&gt;, &lt;span class=&quot;nt&quot;&gt;--write&lt;/span&gt;          &lt;span class=&quot;nb&quot;&gt;enable &lt;/span&gt;writing a value to variable
  &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt;                   does nothing
  &lt;span class=&quot;nt&quot;&gt;-x&lt;/span&gt;                   does nothing
  &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt;                   &lt;span class=&quot;nb&quot;&gt;alias &lt;/span&gt;of &lt;span class=&quot;nt&quot;&gt;-h&lt;/span&gt;

 &lt;span class=&quot;nt&quot;&gt;-h&lt;/span&gt;, &lt;span class=&quot;nt&quot;&gt;--help&lt;/span&gt;     display this &lt;span class=&quot;nb&quot;&gt;help &lt;/span&gt;and &lt;span class=&quot;nb&quot;&gt;exit&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;-V&lt;/span&gt;, &lt;span class=&quot;nt&quot;&gt;--version&lt;/span&gt;  output version information and &lt;span class=&quot;nb&quot;&gt;exit&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;常用的几个， &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sysctl -w&lt;/code&gt;可以直接写入一个值到sys内核参数中。&lt;/p&gt;

&lt;p&gt;Sysctl -p 可以立即读取/etc/sysctl.conf中的参数并生效。&lt;/p&gt;

&lt;p&gt;sysctl -a可以列出所有的内核参数。&lt;/p&gt;

&lt;h3 id=&quot;to-be-continued&quot;&gt;To Be Continued&lt;/h3&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/leezhxing/p/5329786.html&quot;&gt;ss与 Recv-Q Send-Q&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/yjclsx/article/details/81508455&quot;&gt;linux Top Usage&lt;/a&gt;&lt;/p&gt;
</description>
                <link>http://www.turbofei.wang/bigdata/2019/08/16/Linux-Ops-Commands</link>
                <guid>http://www.turbofei.wang/bigdata/2019/08/16/Linux-Ops-Commands</guid>
                <pubDate>2019-08-16T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>Spark Catalyst 添加自己的规则</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#前言&quot; id=&quot;markdown-toc-前言&quot;&gt;前言&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#一条sql的处理过程&quot; id=&quot;markdown-toc-一条sql的处理过程&quot;&gt;一条sql的处理过程&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#rule&quot; id=&quot;markdown-toc-rule&quot;&gt;Rule&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#strategy&quot; id=&quot;markdown-toc-strategy&quot;&gt;Strategy&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#sparksessionextensions&quot; id=&quot;markdown-toc-sparksessionextensions&quot;&gt;SparkSessionExtensions&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#在analysis阶段的resolution子阶段添加rule&quot; id=&quot;markdown-toc-在analysis阶段的resolution子阶段添加rule&quot;&gt;在Analysis阶段的Resolution子阶段添加Rule&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#在analysis阶段的post-hoc-resolution子阶段添加rule&quot; id=&quot;markdown-toc-在analysis阶段的post-hoc-resolution子阶段添加rule&quot;&gt;在Analysis阶段的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Post-Hoc Resolution&lt;/code&gt;子阶段添加Rule&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#在analysis阶段之后对logicalplan进行check&quot; id=&quot;markdown-toc-在analysis阶段之后对logicalplan进行check&quot;&gt;在Analysis阶段之后对LogicalPlan进行check&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#注入自己的optimizer-rule&quot; id=&quot;markdown-toc-注入自己的optimizer-rule&quot;&gt;注入自己的Optimizer Rule&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#注入自己的strategy&quot; id=&quot;markdown-toc-注入自己的strategy&quot;&gt;注入自己的Strategy&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#注入自己的解析器&quot; id=&quot;markdown-toc-注入自己的解析器&quot;&gt;注入自己的解析器&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#如何使用&quot; id=&quot;markdown-toc-如何使用&quot;&gt;如何使用&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#in-action&quot; id=&quot;markdown-toc-in-action&quot;&gt;In Action&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本文讲如何在Spark sql Catalyst里面添加自己的Rule，来进行一些优化或者check操作。&lt;/p&gt;

&lt;h3 id=&quot;前言&quot;&gt;前言&lt;/h3&gt;

&lt;p&gt;前面写过文章介绍&lt;a href=&quot;/spark/2018/08/01/spark-sql-catalyst&quot;&gt;Spark Catalyst&lt;/a&gt;. 此处再简单介绍下。&lt;/p&gt;

&lt;p&gt;在大数据的一些具有SQL功能的框架中，比如Hive，Flink使用Apache Calcite 来做sql的query优化。而Catalyst是spark官方为spark sql设计的query优化框架， 基于函数式编程语言Scala实现。Catalyst有一个优化规则库，可以针对spark sql语句进行自动分析优化。而且Catalyst利用Scala的强大语言特性，例如模式匹配和运行时元程序设计(&lt;a href=&quot;https://docs.scala-lang.org/overviews/quasiquotes/intro.html&quot;&gt;基于scala quasiquotes&lt;/a&gt;)，使得开发者可以简单方便的定制优化规则。&lt;/p&gt;

&lt;h3 id=&quot;一条sql的处理过程&quot;&gt;一条sql的处理过程&lt;/h3&gt;

&lt;p&gt;一条sql语句在spark 中会经过以下过程。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/spark-catalyst/catalyst.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;首先会通过解析器，将其解析为一个抽象语法树(AST)，这叫做unresolvedRelation LogicalPlan。&lt;/li&gt;
  &lt;li&gt;之后进入analysis阶段，可以将其分为几个子阶段
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Hints&lt;/code&gt;  比如BroadcastJoinHints处理&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Simple Sanity Check&lt;/code&gt; 简单check，比如检查sql 中的Function是否存在&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Substitution&lt;/code&gt; 对sql中的一些进行替换，比如如果union 只有一个child，则取消union&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Resolution&lt;/code&gt; 对sql中的一些信息进行绑定，这样就是Resolved LogicalPlan&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Post-Hoc Resolution&lt;/code&gt; resolution之后的操作，默认是空，用户可以自己注入&lt;/li&gt;
      &lt;li&gt;之后还有其他阶段，所以analysis阶段，不止resolution.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;接下来进行optimization阶段，使用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Rule&lt;/code&gt;对LogicalPlan 进行优化，得到Optimized LogicalPlan&lt;/li&gt;
  &lt;li&gt;之后是通过使用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SparkStrategy&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Rule&lt;/code&gt;来将&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LogicalPlan&lt;/code&gt;转换为可执行的物理计划&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SparkPlan&lt;/code&gt;。&lt;/li&gt;
  &lt;li&gt;之后进行codeGen&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;LogicalPlan是逻辑计划，SparkPlan是物理计划。&lt;/p&gt;

&lt;h4 id=&quot;rule&quot;&gt;Rule&lt;/h4&gt;

&lt;p&gt;首先，每个阶段都有一个执行计划，可以看成是一个树，树的每个节点是一个LogicalPlan 或者 SparkPlan.&lt;/p&gt;

&lt;p&gt;而Rule 就是对树上的每个节点进行transform操作。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;abstract&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Rule&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;TreeType&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;&amp;lt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;TreeNode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Logging&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

  &lt;span class=&quot;cm&quot;&gt;/** Name for this rule, automatically inferred based on class name. */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;ruleName&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;className&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;getClass&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;getName&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;className&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endsWith&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;$&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;className&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;dropRight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;className&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plan&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;TreeType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;TreeType&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;而我们看Rule的apply方法，是将一个TreeType转换为TreeType。&lt;/p&gt;

&lt;p&gt;也就是说，它可以将一个LogicalPlan转化为另一个LogicalPlan，或者将一个SparkPlan转化为另外一个SparkPlan。&lt;/p&gt;

&lt;p&gt;也就是说Rule不会涉及到质变。&lt;/p&gt;

&lt;h4 id=&quot;strategy&quot;&gt;Strategy&lt;/h4&gt;

&lt;p&gt;Strategy和Rule类似，同样是对树上的节点进行转化操作，但是Strategy是质的改变，它会将一个LogicalPlan转化为一系列SparkPlan。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;abstract&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;GenericStrategy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;PhysicalPlan&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;&amp;lt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;TreeNode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;PhysicalPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Logging&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

  &lt;span class=&quot;cm&quot;&gt;/**
   * Returns a placeholder for a physical plan that executes `plan`. This placeholder will be
   * filled in automatically by the QueryPlanner using the other execution strategies that are
   * available.
   */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;planLater&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plan&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;LogicalPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;PhysicalPlan&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plan&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;LogicalPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;PhysicalPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;sparksessionextensions&quot;&gt;SparkSessionExtensions&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SparkSessionExtensions&lt;/code&gt;是用来让用户自己扩展Catalyst 中的Rule, Strategy，甚至自己定义解析规则等等。用户只需要实现自己的Extensions，例如&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;class MyExtensions extends (SparkSessionExtensions =&amp;gt; Unit)&lt;/code&gt;,然后配置&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.extensions=MyExtensions&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;首先介绍里面定义的几种type.&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;c1&quot;&gt;// 注入一个Rule&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;RuleBuilder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SparkSession&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Rule&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;LogicalPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
	&lt;span class=&quot;c1&quot;&gt;// 用于check而已，只是check LogicalPlan，如果不通过，会抛异常，通过则不做任何操作，所以返回类型为Unit&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;CheckRuleBuilder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SparkSession&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LogicalPlan&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Unit&lt;/span&gt;
	&lt;span class=&quot;c1&quot;&gt;// 注入一个Strategy&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;StrategyBuilder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SparkSession&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Strategy&lt;/span&gt;
	&lt;span class=&quot;c1&quot;&gt;// 注入一个Parser, 用于语法解析&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ParserBuilder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;SparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ParserInterface&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ParserInterface&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这几种类型，是几种方法类型，是用于后面所说的几种方法使用。&lt;/p&gt;

&lt;p&gt;我们讲一下里面的几个public方法。&lt;/p&gt;

&lt;h4 id=&quot;在analysis阶段的resolution子阶段添加rule&quot;&gt;在Analysis阶段的Resolution子阶段添加Rule&lt;/h4&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;injectResolutionRule&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;builder&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;RuleBuilder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这个方法是添加一个Rule用于resolve unResolvedLogicalPlan。 只需要自己实现一个Rule，然后使用这个方法进行Rule注入。&lt;/p&gt;

&lt;h4 id=&quot;在analysis阶段的post-hoc-resolution子阶段添加rule&quot;&gt;在Analysis阶段的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Post-Hoc Resolution&lt;/code&gt;子阶段添加Rule&lt;/h4&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;injectPostHocResolutionRule&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;builder&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;RuleBuilder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;只需要自己实现一个Rule，会在ResolvedLogicalPlan之后,OptimizedLogicalPlan之前执行.&lt;/p&gt;

&lt;h4 id=&quot;在analysis阶段之后对logicalplan进行check&quot;&gt;在Analysis阶段之后对LogicalPlan进行check&lt;/h4&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;injectCheckRule&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;builder&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;CheckRuleBuilder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在Analysis阶段之后对LogicalPlan进行check，如果有问题，则抛异常。没问题则检查通过。&lt;/p&gt;

&lt;p&gt;需要自己实现CheckRuleBuilder.&lt;/p&gt;

&lt;h4 id=&quot;注入自己的optimizer-rule&quot;&gt;注入自己的Optimizer Rule&lt;/h4&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;injectOptimizerRule&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;builder&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;RuleBuilder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;注入自己的strategy&quot;&gt;注入自己的Strategy&lt;/h4&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;injectPlannerStrategy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;builder&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;StrategyBuilder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;注入自己的解析器&quot;&gt;注入自己的解析器&lt;/h4&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;injectParser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;builder&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ParserBuilder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;如何使用&quot;&gt;如何使用&lt;/h4&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MyResolutionRule&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Rule&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;LogicalPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plan&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;LogicalPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;LogicalPlan&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plan&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MyPostHocResolutionRule&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Rule&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;LogicalPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plan&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;LogicalPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;LogicalPlan&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plan&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MyOptimizerRule&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Rule&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;LogicalPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plan&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;LogicalPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;LogicalPlan&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plan&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MyCheckRule&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;LogicalPlan&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Unit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plan&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;LogicalPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MySparkStrategy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SparkStrategy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plan&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;LogicalPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;SparkPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;empty&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MyParser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delegate&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ParserInterface&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ParserInterface&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;parsePlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqlText&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;LogicalPlan&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;delegate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;parsePlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqlText&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;parseExpression&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqlText&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Expression&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;delegate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;parseExpression&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqlText&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;parseTableIdentifier&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqlText&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;TableIdentifier&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;delegate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;parseTableIdentifier&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqlText&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;parseFunctionIdentifier&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqlText&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;FunctionIdentifier&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;delegate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;parseFunctionIdentifier&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqlText&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;parseTableSchema&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqlText&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;StructType&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;delegate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;parseTableSchema&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqlText&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;parseDataType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqlText&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;DataType&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;delegate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;parseDataType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqlText&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MyExtensions&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;SparkSessionExtensions&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Unit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SparkSessionExtensions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;injectResolutionRule&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MyResolutionRule&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;injectPostHocResolutionRule&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MyPostHocResolutionRule&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;injectCheckRule&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MyCheckRule&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;injectOptimizerRule&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MyOptimizerRule&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;injectPlannerStrategy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MySparkStrategy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;injectParser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MyParser&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;in-action&quot;&gt;In Action&lt;/h3&gt;

&lt;p&gt;首先介绍下&lt;a href=&quot;https://github.com/yaooqinn/spark-greenplum&quot;&gt;Spark-greenplum&lt;/a&gt;项目，这是一个针对于greenplum(一种数据库)的一个DataSource实现。&lt;/p&gt;

&lt;p&gt;其使用PostgreSql的COPY命令进行数据写入，相对于JDBC DataSource(通用的操作数据库的DataSource)的分批insert数据性能提升可观。&lt;/p&gt;

&lt;p&gt;而在spark-greenplum中，如果我们 使用先建立&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TEMPORARY TABLE&lt;/code&gt;然后&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Insert&lt;/code&gt;数据的方法操作gp.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TEMPORARY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;USING&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;greenplum&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;options&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; 
  &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;jdbc:postgresql://greenplum:5432/&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;delimiter&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;dbschema&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;gptest&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;dbtable&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;store_sales&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;user&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;gptest&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;password&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;test&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tpcds_100g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;store_sales&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ss_sold_date_sk&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2451537&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ss_sold_date_sk&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2451520&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;首先，我们需要建立一个gp 表，然后在spark sql中创建 TEMPORARY TABLE， 这个临时表的schema是和gp表中的schema一样的。&lt;/p&gt;

&lt;p&gt;之后，我们使用Insert语句将子查询中的列插入到这个临时表，也就是写入到对应的gp表中。&lt;/p&gt;

&lt;p&gt;这时候我们通常需要判断&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT SUB Query&lt;/code&gt;中拿到的列是否和临时表中的列对应一致。&lt;/p&gt;

&lt;p&gt;所以我们选择添加一条CheckRule来实现，也就是调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;injectCheckRule&lt;/code&gt;方法。&lt;/p&gt;

&lt;p&gt;实现如下:&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.internal.Logging&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.sql.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;AnalysisException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SparkSessionExtensions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.sql.catalyst.plans.logical.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;LogicalPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Project&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.sql.execution.datasources.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;InsertIntoDataSourceCommand&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LogicalRelation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.sql.execution.datasources.greenplum.GreenplumRelation&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;GreenPlumColumnChecker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;LogicalPlan&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Unit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Logging&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plan&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;LogicalPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plan&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;InsertIntoDataSourceCommand&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;LogicalRelation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;GreenplumRelation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;Project&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;// The real output of sub query, which is not be casted.&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;realOutput&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;output&lt;/span&gt;
      &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;realOutput&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;realOutput&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;exists&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ats&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;ats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;_1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;ats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;_2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AnalysisException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
             | The column names of GreenPlum table are not consistent with the
             | projects output names of subQuery.
           &quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;stripMargin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;InsertIntoDataSourceCommand&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;LogicalRelation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;GreenplumRelation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
      &lt;span class=&quot;nf&quot;&gt;logWarning&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;GreenPlumColumnChecker: The query of this GreenPlumRelation &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;is a ${query.getClass.getName}.&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;GreenPlumColumnCheckerExtension&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;SparkSessionExtensions&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Unit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SparkSessionExtensions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;injectCheckRule&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;GreenPlumColumnChecker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;PS:  Spark-2.3.2只能指定一个spark.sql.extensions，可以合入&lt;a href=&quot;https://github.com/apache/spark/pull/23398&quot;&gt;PR-26493&lt;/a&gt;来支持多个extensions.&lt;/p&gt;
</description>
                <link>http://www.turbofei.wang/spark/2019/07/06/spark-catalyst-%E6%B7%BB%E5%8A%A0%E8%87%AA%E5%B7%B1%E7%9A%84%E8%A7%84%E5%88%99</link>
                <guid>http://www.turbofei.wang/spark/2019/07/06/spark-catalyst-添加自己的规则</guid>
                <pubDate>2019-07-06T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>Jvm Tools Usage</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#前言&quot; id=&quot;markdown-toc-前言&quot;&gt;前言&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#jps&quot; id=&quot;markdown-toc-jps&quot;&gt;Jps&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#jstack&quot; id=&quot;markdown-toc-jstack&quot;&gt;Jstack&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#jstat&quot; id=&quot;markdown-toc-jstat&quot;&gt;Jstat&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#jmap&quot; id=&quot;markdown-toc-jmap&quot;&gt;Jmap&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#mat&quot; id=&quot;markdown-toc-mat&quot;&gt;mat&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#jinfojava-configuration-info&quot; id=&quot;markdown-toc-jinfojava-configuration-info&quot;&gt;Jinfo(Java Configuration Info)&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#references&quot; id=&quot;markdown-toc-references&quot;&gt;References&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;简单介绍jvm的相关工具，例如 jps, jstack, jstat, jmap, jinfo.&lt;/p&gt;

&lt;h3 id=&quot;前言&quot;&gt;前言&lt;/h3&gt;

&lt;p&gt;jvm提供了一些工具用来用来查看运行java程序的一些状态。&lt;/p&gt;

&lt;h4 id=&quot;jps&quot;&gt;Jps&lt;/h4&gt;

&lt;p&gt;首先就是jps，用来查看运行的java线程。&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;nd&quot;&gt;@spark6&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:~&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jps&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;131649&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KyuubiSubmit&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;39087&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KyuubiSubmit&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;144342&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Jps&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;136470&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KyuubiSubmit&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在知道java线程的信息之后，可以使用ps -ef查看一些详细的启动信息.&lt;/p&gt;

&lt;p&gt;其中 -e 代表所有线程同A, -f代表 full-format, 包括command-line.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;nd&quot;&gt;@spark6&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:~&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ef&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grep&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KyuubiSubmit&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;    &lt;span class=&quot;mi&quot;&gt;39087&lt;/span&gt;      &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;99&lt;/span&gt; &lt;span class=&quot;mo&quot;&gt;05&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;29&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt;        &lt;span class=&quot;mi&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;44&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;home&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;current&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;java&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;home&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kyuubi_hz_cluster_10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kyuubi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kyuubi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;server&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;jar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;home&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kyuubi_hz_cluster_10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ne&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/:/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;home&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kyuubi_hz_cluster_10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ne&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jars&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/*:/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;home&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;client4cluster10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Xmx164g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;PrintFlagsFinal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;UnlockDiagnosticVMOptions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ParGCCardsPerStrideChunk&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4096&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;UseParNewGC&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;UseConcMarkSweepGC&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;CMSConcurrentMTEnabled&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;CMSInitiatingOccupancyFraction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;UseCMSInitiatingOccupancyOnly&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;CMSClassUnloadingEnabled&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;CMSParallelRemarkEnabled&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;UseCondCardMark&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;PermSize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MaxPermSize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MaxDirectMemorySize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8192&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;HeapDumpOnOutOfMemoryError&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;HeapDumpPath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=./&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;OnOutOfMemoryError&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kill&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;verbose:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;PrintGCDetails&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;PrintGCDateStamps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;PrintTenuringDistribution&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;Xloggc:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;./&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kyuubi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;server&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;log&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;UseGCLogFileRotation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;NumberOfGCLogFiles&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;GCLogFileSize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;M&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;NewRatio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Dio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;netty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;noPreferDirect&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Dio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;netty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;recycler&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;maxCapacity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Dio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;netty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;noUnsafe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;deploy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;KyuubiSubmit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;yaooqinn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;kyuubi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;server&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;KyuubiServer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;home&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kyuubi_hz_cluster_10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kyuubi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kyuubi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;server&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;jar&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;如果我们使用 ps -aux 命令，可以看到更多的信息。&lt;/p&gt;

&lt;p&gt;USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND&lt;/p&gt;

&lt;p&gt;VSZ 进程使用的虚拟內存量(KB)；&lt;/p&gt;

&lt;p&gt;RSS 该进程占用的固定內存量(KB)(驻留中页的数量)；&lt;/p&gt;

&lt;p&gt;TTY 该进程在哪个终端上进行(登陆者的终端位置)，若与终端无关，則显示(?)。&lt;/p&gt;

&lt;p&gt;START 该进程被启动时间；&lt;/p&gt;

&lt;p&gt;TIME 该进程实际使用CPU运行时间；&lt;/p&gt;

&lt;p&gt;COMMAND 命令的名称和参数；&lt;/p&gt;

&lt;p&gt;其他信息参考&lt;a href=&quot;https://www.cnblogs.com/dion-90/articles/9048627.html&quot;&gt;PS -aux 命令详解&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;nd&quot;&gt;@spark6&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:~&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aux&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grep&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KyuubiSubmit&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;    &lt;span class=&quot;mi&quot;&gt;39087&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;179&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;3.2&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;197330936&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8695348&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt;   &lt;span class=&quot;nc&quot;&gt;Sl&lt;/span&gt;   &lt;span class=&quot;mo&quot;&gt;05&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;29&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;828&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;00&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;home&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;current&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;java&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;home&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kyuubi_hz_cluster_10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kyuubi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kyuubi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;server&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;jar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;home&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kyuubi_hz_cluster_10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ne&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/:/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;home&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kyuubi_hz_cluster_10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ne&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jars&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/*:/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;home&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;client4cluster10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Xmx164g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;PrintFlagsFinal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;UnlockDiagnosticVMOptions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ParGCCardsPerStrideChunk&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4096&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;UseParNewGC&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;UseConcMarkSweepGC&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;CMSConcurrentMTEnabled&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;CMSInitiatingOccupancyFraction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;UseCMSInitiatingOccupancyOnly&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;CMSClassUnloadingEnabled&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;CMSParallelRemarkEnabled&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;UseCondCardMark&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;PermSize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MaxPermSize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MaxDirectMemorySize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8192&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;HeapDumpOnOutOfMemoryError&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;HeapDumpPath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=./&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;OnOutOfMemoryError&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kill&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;verbose:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;PrintGCDetails&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;PrintGCDateStamps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;PrintTenuringDistribution&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;Xloggc:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;./&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kyuubi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;server&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;log&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;UseGCLogFileRotation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;NumberOfGCLogFiles&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;GCLogFileSize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;M&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;NewRatio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Dio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;netty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;noPreferDirect&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Dio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;netty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;recycler&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;maxCapacity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Dio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;netty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;noUnsafe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;deploy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;KyuubiSubmit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;yaooqinn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;kyuubi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;server&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;KyuubiServer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;home&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kyuubi_hz_cluster_10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kyuubi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kyuubi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;server&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;jar&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;jstack&quot;&gt;Jstack&lt;/h4&gt;

&lt;p&gt;Jstack命令可以用来打印当前java 线程的线程栈，比如如果java程序长时间无响应，可以使用Jstack命令查看当前线程是否卡在了哪里，看是否存在死锁等情况。&lt;/p&gt;

&lt;p&gt;jstack命令生成的thread dump信息包含了JVM中所有存活的线程.&lt;/p&gt;

&lt;p&gt;在dump中，线程一般存在如下几种状态：
1、RUNNABLE，线程处于执行中
2、BLOCKED，线程被阻塞
3、WAITING，线程正在等待&lt;/p&gt;

&lt;p&gt;下面是一个示例.&lt;/p&gt;

&lt;p&gt;可以看到一个java程序里面有很多线程。一部分是JVM内部的功能线程，另一部分是用户自己的线程，可以参考&lt;a href=&quot;http://ifeve.com/jvm-thread/&quot;&gt;JVM内部线程&lt;/a&gt;。&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jstack&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;29047&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;2019&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;06&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;29&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;51&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;
&lt;span class=&quot;nc&quot;&gt;Full&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thread&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dump&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Java&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;HotSpot&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;TM&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Bit&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Server&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;VM&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;25.111&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b14&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mixed&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;):&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;&quot;Attach Listener&quot;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;13&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;daemon&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os_prio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;31&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x00007fc168804800&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0xe13&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;waiting&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x0000000000000000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;State&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;RUNNABLE&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;&quot;NGSession 1: (idle)&quot;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os_prio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;31&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x00007fc168146000&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x4603&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Object&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;wait&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x000070000ec8b000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;State&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;WAITING&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;monitor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Object&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;wait&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Native&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;waiting&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x00000007aae55e68&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Object&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Object&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;wait&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Object&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;502&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;com&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;martiansoftware&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;nailgun&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;NGSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;nextSocket&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;NGSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;167&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;locked&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x00000007aae55e68&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Object&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;com&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;martiansoftware&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;nailgun&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;NGSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;NGSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;186&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;&quot;DestroyJavaVM&quot;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os_prio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;31&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x00007fc168112800&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x2803&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;waiting&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x0000000000000000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;State&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;RUNNABLE&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;&quot;NGServer(localhost/127.0.0.1, 65319,27633241-7c9d-4458-9831-527f37863f1d)&quot;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os_prio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;31&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x00007fc169095800&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x4703&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;runnable&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x000070000eb88000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;State&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;RUNNABLE&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;PlainSocketImpl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;socketAccept&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Native&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;AbstractPlainSocketImpl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;accept&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;AbstractPlainSocketImpl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;409&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ServerSocket&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;implAccept&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ServerSocket&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;545&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ServerSocket&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;accept&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ServerSocket&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;513&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;com&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;martiansoftware&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;nailgun&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;NGServer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;NGServer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;418&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;745&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;&quot;Service Thread&quot;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;daemon&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os_prio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;31&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x00007fc168002000&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x3a03&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;runnable&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x0000000000000000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;State&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;RUNNABLE&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;&quot;C1 CompilerThread2&quot;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;daemon&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os_prio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;31&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x00007fc16883f000&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x3803&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;waiting&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x0000000000000000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;State&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;RUNNABLE&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;&quot;C2 CompilerThread1&quot;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;daemon&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os_prio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;31&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x00007fc169816800&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x3603&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;waiting&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x0000000000000000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;State&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;RUNNABLE&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;&quot;C2 CompilerThread0&quot;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;daemon&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os_prio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;31&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x00007fc16900f000&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x3503&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;waiting&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x0000000000000000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;State&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;RUNNABLE&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;&quot;Signal Dispatcher&quot;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;daemon&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os_prio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;31&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x00007fc16803b800&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x3403&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;runnable&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x0000000000000000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;State&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;RUNNABLE&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;&quot;Finalizer&quot;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;daemon&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os_prio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;31&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x00007fc168026800&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x2f03&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Object&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;wait&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x000070000e473000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;State&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;WAITING&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;monitor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Object&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;wait&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Native&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;waiting&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x00000007aab08e98&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ReferenceQueue&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;$Lock&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ReferenceQueue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;remove&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReferenceQueue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;143&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;locked&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x00000007aab08e98&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ReferenceQueue&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;$Lock&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ReferenceQueue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;remove&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReferenceQueue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;164&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Finalizer&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;$FinalizerThread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Finalizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;209&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;&quot;Reference Handler&quot;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;daemon&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os_prio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;31&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x00007fc169020000&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x2e03&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Object&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;wait&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x000070000e370000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;State&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;WAITING&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;monitor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Object&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;wait&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Native&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;waiting&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x00000007aab06b40&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Reference&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;$Lock&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Object&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;wait&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Object&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;502&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Reference&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;tryHandlePending&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Reference&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;191&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;locked&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x00000007aab06b40&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Reference&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;$Lock&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Reference&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;$ReferenceHandler&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Reference&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;153&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;&quot;VM Thread&quot;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os_prio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;31&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x00007fc169001000&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x2c03&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;runnable&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;&quot;GC task thread#0 (ParallelGC)&quot;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os_prio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;31&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x00007fc168004800&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x1d07&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;runnable&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;&quot;GC task thread#1 (ParallelGC)&quot;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os_prio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;31&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x00007fc168005800&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x1e03&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;runnable&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;&quot;GC task thread#2 (ParallelGC)&quot;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os_prio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;31&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x00007fc169002000&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x5403&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;runnable&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;&quot;GC task thread#3 (ParallelGC)&quot;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os_prio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;31&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x00007fc169003000&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x5303&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;runnable&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;&quot;VM Periodic Task Thread&quot;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os_prio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;31&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x00007fc16804d000&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x3c03&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;waiting&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt;

&lt;span class=&quot;no&quot;&gt;JNI&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;global&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;references:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;47&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;jstat&quot;&gt;Jstat&lt;/h4&gt;

&lt;p&gt;jstat用法如下:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;jstat -&amp;lt;option&amp;gt; [-t] [-h&amp;lt;lines&amp;gt;] &amp;lt;vmid&amp;gt; [&amp;lt;interval&amp;gt; [&amp;lt;count&amp;gt;]]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;-option 是可选选项
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;-class&lt;/p&gt;

        &lt;p&gt;跟class 加载，占用消耗有关的状态.&lt;/p&gt;

        &lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;nd&quot;&gt;@spark6&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:~&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jstat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;131649&lt;/span&gt;
&lt;span class=&quot;nc&quot;&gt;Loaded&lt;/span&gt;  &lt;span class=&quot;nc&quot;&gt;Bytes&lt;/span&gt;  &lt;span class=&quot;nc&quot;&gt;Unloaded&lt;/span&gt;  &lt;span class=&quot;nc&quot;&gt;Bytes&lt;/span&gt;     &lt;span class=&quot;nc&quot;&gt;Time&lt;/span&gt;
 &lt;span class=&quot;mi&quot;&gt;21038&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;42844.6&lt;/span&gt;      &lt;span class=&quot;mi&quot;&gt;904&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;1394.4&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;28.32&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;-compiler&lt;/p&gt;

        &lt;p&gt;应该是 即时编译有关吧.&lt;/p&gt;

        &lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;nd&quot;&gt;@spark6&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:~&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jstat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compiler&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;131649&lt;/span&gt;
&lt;span class=&quot;nc&quot;&gt;Compiled&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Failed&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Invalid&lt;/span&gt;   &lt;span class=&quot;nc&quot;&gt;Time&lt;/span&gt;   &lt;span class=&quot;nc&quot;&gt;FailedType&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;FailedMethod&lt;/span&gt;
   &lt;span class=&quot;mi&quot;&gt;39298&lt;/span&gt;      &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;       &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;   &lt;span class=&quot;mf&quot;&gt;216.39&lt;/span&gt;          &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ContextCleaner&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;$anonfun$org$apache$spark$ContextCleaner&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;$keepCleaning&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;apply$mcV$sp&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;-gc 垃圾回收统计&lt;/p&gt;

        &lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;nd&quot;&gt;@spark6&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:~&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jstat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gc&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;131649&lt;/span&gt;
&lt;span class=&quot;nl&quot;&gt;Warning:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Unresolved&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;Symbol:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sun&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;gc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;generation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;space&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;capacity&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;substituted&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;NaN&lt;/span&gt;
&lt;span class=&quot;nl&quot;&gt;Warning:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Unresolved&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;Symbol:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sun&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;gc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;generation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;space&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;used&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;substituted&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;NaN&lt;/span&gt;
 &lt;span class=&quot;no&quot;&gt;S0C&lt;/span&gt;    &lt;span class=&quot;no&quot;&gt;S1C&lt;/span&gt;    &lt;span class=&quot;no&quot;&gt;S0U&lt;/span&gt;    &lt;span class=&quot;no&quot;&gt;S1U&lt;/span&gt;      &lt;span class=&quot;no&quot;&gt;EC&lt;/span&gt;       &lt;span class=&quot;no&quot;&gt;EU&lt;/span&gt;        &lt;span class=&quot;no&quot;&gt;OC&lt;/span&gt;         &lt;span class=&quot;no&quot;&gt;OU&lt;/span&gt;       &lt;span class=&quot;no&quot;&gt;PC&lt;/span&gt;     &lt;span class=&quot;no&quot;&gt;PU&lt;/span&gt;    &lt;span class=&quot;no&quot;&gt;YGC&lt;/span&gt;     &lt;span class=&quot;no&quot;&gt;YGCT&lt;/span&gt;    &lt;span class=&quot;no&quot;&gt;FGC&lt;/span&gt;    &lt;span class=&quot;no&quot;&gt;FGCT&lt;/span&gt;     &lt;span class=&quot;no&quot;&gt;GCT&lt;/span&gt;
&lt;span class=&quot;mf&quot;&gt;186240.0&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;186240.0&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;186240.0&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;   &lt;span class=&quot;mf&quot;&gt;1490240.0&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;326860.8&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;5587220.0&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;3700631.8&lt;/span&gt;    &lt;span class=&quot;err&quot;&gt;�&lt;/span&gt;      &lt;span class=&quot;err&quot;&gt;�&lt;/span&gt;     &lt;span class=&quot;mi&quot;&gt;32818&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2921.766&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11684&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;4006.977&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;6928.743&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;-gccapacity 堆内存统计&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;-gccause&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;-gcnew&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;-gcnewcapacity&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;-gcold&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;-gcoldcapacity&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;-gcpermcapacity&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;-gcutil 总结垃圾回收统计&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;-printcompilation&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;-t 是用于显示timeStamp，示例如下。&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;hadoop@spark6:~$ jstat -gc 131649
Warning: Unresolved Symbol: sun.gc.generation.2.space.0.capacity substituted NaN
Warning: Unresolved Symbol: sun.gc.generation.2.space.0.used substituted NaN
 S0C    S1C    S0U    S1U      EC       EU        OC         OU       PC     PU    YGC     YGCT    FGC    FGCT     GCT
186240.0 186240.0 186240.0  0.0   1490240.0 1341107.0 5587220.0  3388251.2    �      �     32748 2914.187 11656 3990.174 6904.362
hadoop@spark6:~$ jstat -gc -t 131649
Warning: Unresolved Symbol: sun.gc.generation.2.space.0.capacity substituted NaN
Warning: Unresolved Symbol: sun.gc.generation.2.space.0.used substituted NaN
Timestamp        S0C    S1C    S0U    S1U      EC       EU        OC         OU       PC     PU    YGC     YGCT    FGC    FGCT     GCT
       247190.2 186240.0 186240.0 186240.0  0.0   1490240.0 1341242.8 5587220.0  3102583.1    �      �     32748 2914.187 11657 3990.174 6904.362
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;-h 是每行之间的样本数，用于求平均值吧&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;vmid 是java进程Id&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;interval 采样间距，单位为毫秒&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;采样次数&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;jmap&quot;&gt;Jmap&lt;/h4&gt;

&lt;p&gt;用法如下:&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;nd&quot;&gt;@spark6&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:~&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jmap&lt;/span&gt;
&lt;span class=&quot;nl&quot;&gt;Usage:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;jmap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;running&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;process&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;jmap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;executable&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;core&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;core&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;jmap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;server_id&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;remote&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;IP&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hostname&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;remote&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;debug&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;server&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;one&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;of:&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;none&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;               &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;same&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;info&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Solaris&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pmap&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heap&lt;/span&gt;                &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;heap&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;histo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;live&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;histogram&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;heap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;live&quot;&lt;/span&gt;
                         &lt;span class=&quot;n&quot;&gt;suboption&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;specified&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;only&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;live&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;objects&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;permstat&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;permanent&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;generation&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;statistics&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;finalizerinfo&lt;/span&gt;       &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;information&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;objects&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;awaiting&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;finalization&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;dump:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dump&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dump&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;heap&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hprof&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;binary&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;
                         &lt;span class=&quot;n&quot;&gt;dump&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;options:&lt;/span&gt;
                           &lt;span class=&quot;n&quot;&gt;live&lt;/span&gt;         &lt;span class=&quot;n&quot;&gt;dump&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;only&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;live&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;objects&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;specified&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
                                        &lt;span class=&quot;n&quot;&gt;all&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;objects&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;heap&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;are&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dumped&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
                           &lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;     &lt;span class=&quot;n&quot;&gt;binary&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;
                           &lt;span class=&quot;n&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;dump&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;heap&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
                         &lt;span class=&quot;nl&quot;&gt;Example:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jmap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;dump:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;live&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;bin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;F&lt;/span&gt;                   &lt;span class=&quot;n&quot;&gt;force&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Use&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;dump:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dump&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;histo&lt;/span&gt;
                         &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;force&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;heap&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dump&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;histogram&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;when&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;does&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;not&lt;/span&gt;
                         &lt;span class=&quot;n&quot;&gt;respond&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;The&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;live&quot;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;suboption&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;supported&lt;/span&gt;
                         &lt;span class=&quot;n&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;           &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;J&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;             &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pass&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;directly&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;runtime&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;system&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;​	首先介绍一下core dump。当程序运行的过程中异常终止或崩溃，操作系统会将程序当时的内存状态记录下来，保存在一个文件中，这种行为就叫做Core Dump。我们可以认为 core dump 是“内存快照”，但实际上，除了内存信息之外，还有些关键的程序运行状态也会同时 dump 下来，例如寄存器信息（包括程序指针、栈指针等）、内存管理信息、其他处理器和操作系统状态和信息。core dump 对于编程人员诊断和调试程序是非常有帮助的，因为对于有些程序错误是很难重现的，例如指针异常，而 core dump 文件可以再现程序出错时的情景。在linux中可以使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ulimit -c&lt;/code&gt;查看目前是否打开core dump 功能，如果显示为0则代表未打开，可以使用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ulimit -c unlimited&lt;/code&gt;打开core dump功能，当core dump是打开时，才会在程序崩溃时保存内存快照。&lt;/p&gt;

&lt;h5 id=&quot;mat&quot;&gt;mat&lt;/h5&gt;

&lt;p&gt;在实际生产中，我们通常使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;jmap -dump:live,format=b,file=heap.bin &amp;lt;pid&amp;gt;&lt;/code&gt;命令来将core  dump到文件中，然后使用 mat(eclipse memory analyzer)来分析这个dump文件，会生成一些html文件，然后将这些文件下载下来，点击其index.html来查看分析结果。&lt;/p&gt;

&lt;p&gt;mat的下载地址为:https://www.eclipse.org/mat/downloads.php。&lt;/p&gt;

&lt;p&gt;解压之后是一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mat&lt;/code&gt;文件夹，进入这个文件夹.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;o&quot;&gt;./&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ParseHeapDump&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;sh&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;info&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;eclipse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;mat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;api&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;suspects&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;eclipse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;mat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;api&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;overview&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;eclipse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;mat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;api&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;top_components&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;结果会生产如下三个zip文件，很小可以直接拷贝到本机.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;jmap_Leak_Suspects.zip
jmap_System_Overview.zip
jmap_Top_Components.zip
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;之后就可以解压查看其对应的index.html.&lt;/p&gt;

&lt;h4 id=&quot;jinfojava-configuration-info&quot;&gt;Jinfo(Java Configuration Info)&lt;/h4&gt;

&lt;p&gt;使用方法如下:&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;nd&quot;&gt;@spark6&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:~&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jinfo&lt;/span&gt;
&lt;span class=&quot;nl&quot;&gt;Usage:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;jinfo&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;running&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;process&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;jinfo&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;executable&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;core&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;core&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;jinfo&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;server_id&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;remote&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;IP&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hostname&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;remote&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;debug&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;server&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;one&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;of:&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;         &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;named&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;VM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[+|-]&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enable&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;disable&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;named&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;VM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;=&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;named&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;VM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;given&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flags&lt;/span&gt;               &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;VM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flags&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sysprops&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Java&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;system&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;properties&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;no&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;          &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;both&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;above&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;           &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;看到上面可以更改一些参数，那么哪些参数是可以动态更改?&lt;/p&gt;

&lt;p&gt;JVM官方文档说明如下，也就是说，标记为manageable的参数或者通过&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;com.sun.management.HotSpotDiagnosticMXBean&lt;/code&gt;这个类的接口得到；&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Flags marked as manageable are dynamically writeable through the JDK management interface (com.sun.management.HotSpotDiagnosticMXBean API) and also through JConsole.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;通过manageable方法更加方便，命令如下:&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;nd&quot;&gt;@spark6&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:~&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;XX:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;PrintFlagsInitial&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grep&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;manageable&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;intx&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;CMSAbortablePrecleanWaitMillis&lt;/span&gt;            &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;             &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;manageable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;intx&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;CMSWaitDuration&lt;/span&gt;                           &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2000&lt;/span&gt;            &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;manageable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;HeapDumpAfterFullGC&lt;/span&gt;                       &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;           &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;manageable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;HeapDumpBeforeFullGC&lt;/span&gt;                      &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;           &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;manageable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;HeapDumpOnOutOfMemoryError&lt;/span&gt;                &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;           &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;manageable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ccstr&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;HeapDumpPath&lt;/span&gt;                              &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;                 &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;manageable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;uintx&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MaxHeapFreeRatio&lt;/span&gt;                          &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;              &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;manageable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;uintx&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MinHeapFreeRatio&lt;/span&gt;                          &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;              &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;manageable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;PrintClassHistogram&lt;/span&gt;                       &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;           &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;manageable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;PrintClassHistogramAfterFullGC&lt;/span&gt;            &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;           &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;manageable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;PrintClassHistogramBeforeFullGC&lt;/span&gt;           &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;           &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;manageable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;PrintConcurrentLocks&lt;/span&gt;                      &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;           &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;manageable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;PrintGC&lt;/span&gt;                                   &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;           &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;manageable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;PrintGCDateStamps&lt;/span&gt;                         &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;           &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;manageable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;PrintGCDetails&lt;/span&gt;                            &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;           &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;manageable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;PrintGCTimeStamps&lt;/span&gt;                         &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;           &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;manageable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;所以只有这几个参数是可以通过 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;jinfo -flag  [+|-]&amp;lt;name&amp;gt;  pid&lt;/code&gt;或者&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;jinfo -flag &amp;lt;name&amp;gt;=&amp;lt;value&amp;gt; pid&lt;/code&gt;动态更改的.&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://ifeve.com/jvm-thread/&quot;&gt;JVM内部运行线程介绍&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/dion-90/articles/9048627.html&quot;&gt;PS -aux 命令详解&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.jianshu.com/p/a4ad53179df3&quot;&gt;Jmap使用&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;[http://moheqionglin.com/site/blogs/84/detail.html](http://moheqionglin.com/site/blogs/84/detail.html)&quot;&gt;mat使用方法&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.jianshu.com/p/c321d0808a1b&quot;&gt;jinfo&lt;/a&gt;&lt;/p&gt;
</description>
                <link>http://www.turbofei.wang/coding/2019/06/29/jvm-tools-usage</link>
                <guid>http://www.turbofei.wang/coding/2019/06/29/jvm-tools-usage</guid>
                <pubDate>2019-06-29T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>Spark Sql 参数调优</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#前言&quot; id=&quot;markdown-toc-前言&quot;&gt;前言&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#异常调优&quot; id=&quot;markdown-toc-异常调优&quot;&gt;异常调优&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#sparksqlhiveconvertmetastoreparquet&quot; id=&quot;markdown-toc-sparksqlhiveconvertmetastoreparquet&quot;&gt;spark.sql.hive.convertMetastoreParquet&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#sparksqlfilesignoremissingfiles--sparksqlfilesignorecorruptfiles&quot; id=&quot;markdown-toc-sparksqlfilesignoremissingfiles--sparksqlfilesignorecorruptfiles&quot;&gt;spark.sql.files.ignoreMissingFiles &amp;amp;&amp;amp; spark.sql.files.ignoreCorruptFiles&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#sparksqlhiveverifypartitionpath&quot; id=&quot;markdown-toc-sparksqlhiveverifypartitionpath&quot;&gt;spark.sql.hive.verifyPartitionPath&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#sparkfilesignorecorruptfiles--sparkfilesignoremissingfiles&quot; id=&quot;markdown-toc-sparkfilesignorecorruptfiles--sparkfilesignoremissingfiles&quot;&gt;spark.files.ignoreCorruptFiles &amp;amp;&amp;amp; spark.files.ignoreMissingFiles&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#性能调优&quot; id=&quot;markdown-toc-性能调优&quot;&gt;性能调优&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#sparkhadooprddignoreemptysplits&quot; id=&quot;markdown-toc-sparkhadooprddignoreemptysplits&quot;&gt;spark.hadoopRDD.ignoreEmptySplits&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#sparkhadoopmapreduceinputfileinputformatsplitminsize&quot; id=&quot;markdown-toc-sparkhadoopmapreduceinputfileinputformatsplitminsize&quot;&gt;spark.hadoop.mapreduce.input.fileinputformat.split.minsize&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#sparksqlautobroadcastjointhreshold---sparksqlbroadcasttimeout&quot; id=&quot;markdown-toc-sparksqlautobroadcastjointhreshold---sparksqlbroadcasttimeout&quot;&gt;spark.sql.autoBroadcastJoinThreshold &amp;amp;&amp;amp;  spark.sql.broadcastTimeout&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#sparksqladaptiveenabled--sparksqladaptiveshuffletargetpostshuffleinputsize&quot; id=&quot;markdown-toc-sparksqladaptiveenabled--sparksqladaptiveshuffletargetpostshuffleinputsize&quot;&gt;spark.sql.adaptive.enabled &amp;amp;&amp;amp; spark.sql.adaptive.shuffle.targetPostShuffleInputSize&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#sparksqlparquetmergeschema&quot; id=&quot;markdown-toc-sparksqlparquetmergeschema&quot;&gt;spark.sql.parquet.mergeSchema&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#sparkhadoopmapreducefileoutputcommitteralgorithmversion&quot; id=&quot;markdown-toc-sparkhadoopmapreducefileoutputcommitteralgorithmversion&quot;&gt;spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#spark-sql-参数表spark-232&quot; id=&quot;markdown-toc-spark-sql-参数表spark-232&quot;&gt;Spark Sql 参数表(spark-2.3.2)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;关于spark sql的一些参数的用法和调优.&lt;/p&gt;

&lt;h3 id=&quot;前言&quot;&gt;前言&lt;/h3&gt;

&lt;p&gt;Spark Sql里面有很多的参数，而且这些参数在Spark官网中没有明确的解释，可能是太多了吧，可以通过在spark-sql中使用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;set -v&lt;/code&gt; 命令显示当前spark-sql版本支持的参数。&lt;/p&gt;

&lt;p&gt;本文讲解最近关于在参与hive往spark迁移过程中遇到的一些参数相关问题的调优。&lt;/p&gt;

&lt;p&gt;内容分为两部分，第一部分讲遇到异常，从而需要通过设置参数来解决的调优；第二部分讲用于提升性能而进行的调优。&lt;/p&gt;

&lt;h3 id=&quot;异常调优&quot;&gt;异常调优&lt;/h3&gt;

&lt;h4 id=&quot;sparksqlhiveconvertmetastoreparquet&quot;&gt;spark.sql.hive.convertMetastoreParquet&lt;/h4&gt;

&lt;p&gt;parquet是一种列式存储格式，可以用于spark-sql 和hive 的存储格式。在spark中，如果使用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;using parqeut&lt;/code&gt;的形式创建表，则创建的是spark 的DataSource表；而如果使用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;stored as parquet&lt;/code&gt;则创建的是hive表。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.hive.convertMetastoreParquet&lt;/code&gt;默认设置是true, 它代表使用spark-sql内置的parquet的reader和writer(即进行反序列化和序列化),它具有更好地性能，如果设置为false，则代表使用 Hive的序列化方式。&lt;/p&gt;

&lt;p&gt;但是有时候当其设置为true时，会出现使用hive查询表有数据，而使用spark查询为空的情况.&lt;/p&gt;

&lt;p&gt;但是，有些情况下在将&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.hive.convertMetastoreParquet&lt;/code&gt;设为false，可能发生以下异常(spark-2.3.2)。&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ClassCastException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;io&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;LongWritable&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cannot&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;be&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cast&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;io&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;IntWritable&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hive&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;serde2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;objectinspector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;primitive&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;WritableIntObjectInspector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;WritableIntObjectInspector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;36&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这是因为在其为false时候，是使用hive-metastore使用的元数据进行读取数据，而如果此表是使用spark sql DataSource创建的parquet表，其数据类型可能出现不一致的情况，例如通过metaStore读取到的是IntWritable类型，其创建了一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WritableIntObjectInspector&lt;/code&gt;用来解析数据，而实际上value是LongWritable类型，因此出现了类型转换异常。&lt;/p&gt;

&lt;p&gt;与该参数相关的一个参数是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.hive.convertMetastoreParquet.mergeSchema&lt;/code&gt;, 如果也是true，那么将会尝试合并各个parquet 文件的schema，以使得产生一个兼容所有parquet文件的schema.&lt;/p&gt;

&lt;h4 id=&quot;sparksqlfilesignoremissingfiles--sparksqlfilesignorecorruptfiles&quot;&gt;spark.sql.files.ignoreMissingFiles &amp;amp;&amp;amp; spark.sql.files.ignoreCorruptFiles&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;这两个参数是只有在进行spark DataSource 表查询的时候才有效，如果是对hive表进行操作是无效的。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在进行spark DataSource 表查询时候，可能会遇到非分区表中的文件缺失/corrupt 或者分区表分区路径下的文件缺失/corrupt 异常，这时候加这两个参数会忽略这两个异常，这两个参数默认都是false，建议在线上可以都设为true.&lt;/p&gt;

&lt;p&gt;其源码逻辑如下，简单描述就是如果遇到&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FileNotFoundException&lt;/code&gt;, 如果设置了&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ignoreMissingFiles=true&lt;/code&gt;则忽略异常，否则抛出异常;如果不是FileNotFoundException 而是IOException(FileNotFoundException的父类)或者RuntimeException,则认为文件损坏,如果设置了&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ignoreCorruptFiles=true&lt;/code&gt;则忽略异常。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;FileNotFoundException&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ignoreMissingFiles&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nf&quot;&gt;logWarning&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Skipped missing file: $currentFile&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;finished&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;
  &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// Throw FileNotFoundException even if `ignoreCorruptFiles` is true&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;FileNotFoundException&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;!ignoreMissingFiles&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;RuntimeException&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;IOException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ignoreCorruptFiles&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nf&quot;&gt;logWarning&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Skipped the rest of the content in the corrupted file: $currentFile&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;finished&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;
  &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;sparksqlhiveverifypartitionpath&quot;&gt;spark.sql.hive.verifyPartitionPath&lt;/h4&gt;

&lt;p&gt;上面的两个参数在分区表情况下是针对分区路径存在的情况下，分区路径下面的文件不存在或者损坏的处理。而有另一种情况就是这个分区路径都不存在了。这时候异常信息如下:&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;io&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;FileNotFoundException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;File&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;does&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;exist:&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;hdfs:&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;//hz-cluster10/user/da_haitao/da_hivesrc/haitao_dev_log/integ_browse_app_dt/day=2019-06-25/os=Android/000067_0&lt;/span&gt;
 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;而&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.hive.verifyPartitionPath&lt;/code&gt;参数默认是false，当设置为true的时候会在获得分区路径时对分区路径是否存在做一个校验，过滤掉不存在的分区路径，这样就会避免上面的错误。&lt;/p&gt;

&lt;h4 id=&quot;sparkfilesignorecorruptfiles--sparkfilesignoremissingfiles&quot;&gt;spark.files.ignoreCorruptFiles &amp;amp;&amp;amp; spark.files.ignoreMissingFiles&lt;/h4&gt;

&lt;p&gt;这两个参数和上面的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.files.ignoreCorruptFiles&lt;/code&gt;很像，但是区别是很大的。在spark进行DataSource表查询时候&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sq.files.*&lt;/code&gt;才会生效，而spark如果查询的是一张hive表，其会走HadoopRDD这条执行路线。&lt;/p&gt;

&lt;p&gt;所以就会出现，即使你设置了&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.files.ignoreMissingFiles&lt;/code&gt;的情况下，仍然报FileNotFoundException的情况，异常栈如下, 可以看到这里面走到了HadoopRDD，而且后面是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;org.apache.hadoop.hive.ql.io.parquet.read.ParquetRecordReaderWrappe&lt;/code&gt;可见是查询一张hive表。&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nc&quot;&gt;Caused&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;by:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;SparkException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Job&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aborted&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;due&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;failure:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Task&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;107052&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;914.0&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;failed&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;times&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;most&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recent&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;failure:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Lost&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;task&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;107052.3&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;914.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;TID&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;387381&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hadoop2698&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;jd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;163&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;executor&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;266&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;io&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;FileNotFoundException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;File&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;does&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;exist:&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;hdfs:&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;//hz-cluster10/user/da_haitao/da_hivesrc/haitao_dev_log/integ_browse_app_dt/day=2019-06-25/os=Android/000067_0&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hdfs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;DistributedFileSystem&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;22&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;doCall&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;DistributedFileSystem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1309&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hdfs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;DistributedFileSystem&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;22&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;doCall&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;DistributedFileSystem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1301&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;FileSystemLinkResolver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;resolve&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;FileSystemLinkResolver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;81&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hdfs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;DistributedFileSystem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getFileStatus&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;DistributedFileSystem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1317&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parquet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ParquetFileReader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;readFooter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ParquetFileReader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;385&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parquet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ParquetFileReader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;readFooter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ParquetFileReader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;371&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hive&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;io&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;parquet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ParquetRecordReaderWrapper&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getSplit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ParquetRecordReaderWrapper&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;252&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hive&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;io&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;parquet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ParquetRecordReaderWrapper&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ParquetRecordReaderWrapper&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;99&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hive&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;io&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;parquet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ParquetRecordReaderWrapper&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ParquetRecordReaderWrapper&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;85&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hive&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;io&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;parquet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;MapredParquetInputFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getRecordReader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MapredParquetInputFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;72&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;HadoopRDD&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;$anon&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;liftedTree1&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;HadoopRDD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;257&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;此时可以将&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.files.ignoreCorruptFiles &amp;amp;&amp;amp; spark.files.ignoreMissingFiles&lt;/code&gt;设为true，其代码逻辑和上面的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.file.*&lt;/code&gt;逻辑没明显区别，此处不再赘述.&lt;/p&gt;

&lt;h3 id=&quot;性能调优&quot;&gt;性能调优&lt;/h3&gt;

&lt;p&gt;除了遇到异常需要被动调整参数之外，我们还可以主动调整参数从而对性能进行调优。&lt;/p&gt;

&lt;h4 id=&quot;sparkhadooprddignoreemptysplits&quot;&gt;spark.hadoopRDD.ignoreEmptySplits&lt;/h4&gt;

&lt;p&gt;默认是false，如果是true，则会忽略那些空的splits，减小task的数量。&lt;/p&gt;

&lt;h4 id=&quot;sparkhadoopmapreduceinputfileinputformatsplitminsize&quot;&gt;spark.hadoop.mapreduce.input.fileinputformat.split.minsize&lt;/h4&gt;

&lt;p&gt;是用于聚合input的小文件，用于控制每个mapTask的输入文件，防止小文件过多时候，产生太多的task.&lt;/p&gt;

&lt;h4 id=&quot;sparksqlautobroadcastjointhreshold---sparksqlbroadcasttimeout&quot;&gt;spark.sql.autoBroadcastJoinThreshold &amp;amp;&amp;amp;  spark.sql.broadcastTimeout&lt;/h4&gt;

&lt;p&gt;用于控制在spark sql中使用BroadcastJoin时候表的大小阈值，适当增大可以让一些表走BroadcastJoin，提升性能，但是如果设置太大又会造成driver内存压力，而broadcastTimeout是用于控制Broadcast的Future的超时时间，默认是300s，可根据需求进行调整。&lt;/p&gt;

&lt;h4 id=&quot;sparksqladaptiveenabled--sparksqladaptiveshuffletargetpostshuffleinputsize&quot;&gt;spark.sql.adaptive.enabled &amp;amp;&amp;amp; spark.sql.adaptive.shuffle.targetPostShuffleInputSize&lt;/h4&gt;

&lt;p&gt;该参数是用于开启spark的自适应执行，这是spark比较老版本的自适应执行，后面的targetPostShuffleInputSize是用于控制之后的shuffle 阶段的平均输入数据大小，防止产生过多的task。&lt;/p&gt;

&lt;p&gt;intel大数据团队开发的adaptive-execution相较于目前spark的ae更加实用，该特性也已经加入到社区3.0之后的roadMap中，令人期待。&lt;/p&gt;

&lt;h4 id=&quot;sparksqlparquetmergeschema&quot;&gt;spark.sql.parquet.mergeSchema&lt;/h4&gt;

&lt;p&gt;默认false。当设为true，parquet会聚合所有parquet文件的schema，否则是直接读取parquet summary文件，或者在没有parquet summary文件时候随机选择一个文件的schema作为最终的schema。&lt;/p&gt;

&lt;h4 id=&quot;sparkhadoopmapreducefileoutputcommitteralgorithmversion&quot;&gt;spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version&lt;/h4&gt;

&lt;p&gt;1或者2，默认是1. &lt;a href=&quot;https://issues.apache.org/jira/browse/MAPREDUCE-4815&quot;&gt;MapReduce-4815&lt;/a&gt; 详细介绍了 fileoutputcommitter 的原理，实践中设置了 version=2 的比默认 version=1 的减少了70%以上的 commit 时间，但是1更健壮，能处理一些情况下的异常。&lt;/p&gt;

&lt;h3 id=&quot;spark-sql-参数表spark-232&quot;&gt;Spark Sql 参数表(spark-2.3.2)&lt;/h3&gt;

&lt;table border=&quot;1&quot; cellspacing=&quot;0&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;key&lt;/th&gt;
      &lt;th&gt;value&lt;/th&gt;
      &lt;th&gt;meaning&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.adaptive.enabled&lt;/td&gt;
      &lt;td&gt;TRUE&lt;/td&gt;
      &lt;td&gt;When true, enable adaptive query execution.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.adaptive.shuffle.targetPostShuffleInputSize&lt;/td&gt;
      &lt;td&gt;67108864b&lt;/td&gt;
      &lt;td&gt;The target post-shuffle input size in bytes of a task.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.autoBroadcastJoinThreshold&lt;/td&gt;
      &lt;td&gt;209715200&lt;/td&gt;
      &lt;td&gt;Configures the maximum size in bytes for a table that will be broadcast   to all worker nodes when performing a join.    By setting this value to -1 broadcasting can be disabled. Note that   currently statistics are only supported for Hive Metastore tables where the   command &lt;code&gt;ANALYZE TABLE &amp;lt;tableName&amp;gt; COMPUTE   STATISTICS noscan&lt;/code&gt; has been run, and file-based data source   tables where the statistics are computed directly on the files of data.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.broadcastTimeout&lt;/td&gt;
      &lt;td&gt;300000ms&lt;/td&gt;
      &lt;td&gt;Timeout in seconds for the broadcast wait time in broadcast joins.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.cbo.enabled&lt;/td&gt;
      &lt;td&gt;FALSE&lt;/td&gt;
      &lt;td&gt;Enables CBO for estimation of plan statistics when set true.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.cbo.joinReorder.dp.star.filter&lt;/td&gt;
      &lt;td&gt;FALSE&lt;/td&gt;
      &lt;td&gt;Applies star-join filter heuristics to cost based join enumeration.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.cbo.joinReorder.dp.threshold&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;The maximum number of joined nodes allowed in the dynamic programming   algorithm.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.cbo.joinReorder.enabled&lt;/td&gt;
      &lt;td&gt;FALSE&lt;/td&gt;
      &lt;td&gt;Enables join reorder in CBO.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.cbo.starSchemaDetection&lt;/td&gt;
      &lt;td&gt;FALSE&lt;/td&gt;
      &lt;td&gt;When true, it enables join reordering based on star schema   detection.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.columnNameOfCorruptRecord&lt;/td&gt;
      &lt;td&gt;_corrupt_record&lt;/td&gt;
      &lt;td&gt;The name of internal column for storing raw/un-parsed JSON and CSV   records that fail to parse.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.crossJoin.enabled&lt;/td&gt;
      &lt;td&gt;TRUE&lt;/td&gt;
      &lt;td&gt;When false, we will throw an error if a query contains a cartesian   product without explicit CROSS JOIN syntax.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.execution.arrow.enabled&lt;/td&gt;
      &lt;td&gt;FALSE&lt;/td&gt;
      &lt;td&gt;When true, make use of Apache Arrow for columnar data transfers.   Currently available for use with pyspark.sql.DataFrame.toPandas, and   pyspark.sql.SparkSession.createDataFrame when its input is a Pandas   DataFrame. The following data types are unsupported: BinaryType, MapType,   ArrayType of TimestampType, and nested StructType.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.execution.arrow.maxRecordsPerBatch&lt;/td&gt;
      &lt;td&gt;10000&lt;/td&gt;
      &lt;td&gt;When using Apache Arrow, limit the maximum number of records that can be   written to a single ArrowRecordBatch in memory. If set to zero or negative   there is no limit.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.extensions&lt;/td&gt;
      &lt;td&gt;&lt;undefined&gt;&lt;/undefined&gt;&lt;/td&gt;
      &lt;td&gt;Name of the class used to configure Spark Session extensions. The class   should implement Function1[SparkSessionExtension, Unit], and must have a   no-args constructor.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.files.ignoreCorruptFiles&lt;/td&gt;
      &lt;td&gt;FALSE&lt;/td&gt;
      &lt;td&gt;Whether to ignore corrupt files. If true, the Spark jobs will continue to   run when encountering corrupted files and the contents that have been read   will still be returned.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.files.ignoreMissingFiles&lt;/td&gt;
      &lt;td&gt;FALSE&lt;/td&gt;
      &lt;td&gt;Whether to ignore missing files. If true, the Spark jobs will continue to   run when encountering missing files and the contents that have been read will   still be returned.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.files.maxPartitionBytes&lt;/td&gt;
      &lt;td&gt;134217728&lt;/td&gt;
      &lt;td&gt;The maximum number of bytes to pack into a single partition when reading   files.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.files.maxRecordsPerFile&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;Maximum number of records to write out to a single file. If this value is   zero or negative, there is no limit.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.function.concatBinaryAsString&lt;/td&gt;
      &lt;td&gt;FALSE&lt;/td&gt;
      &lt;td&gt;When this option is set to false and all inputs are binary,   &lt;code class=&quot;highlighter-rouge&quot;&gt;functions.concat&lt;/code&gt; returns an output as binary. Otherwise, it returns as a   string.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.function.eltOutputAsString&lt;/td&gt;
      &lt;td&gt;FALSE&lt;/td&gt;
      &lt;td&gt;When this option is set to false and all inputs are binary, &lt;code class=&quot;highlighter-rouge&quot;&gt;elt&lt;/code&gt; returns   an output as binary. Otherwise, it returns as a string.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.groupByAliases&lt;/td&gt;
      &lt;td&gt;TRUE&lt;/td&gt;
      &lt;td&gt;When true, aliases in a select list can be used in group by clauses. When   false, an analysis exception is thrown in the case.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.groupByOrdinal&lt;/td&gt;
      &lt;td&gt;TRUE&lt;/td&gt;
      &lt;td&gt;When true, the ordinal numbers in group by clauses are treated as the   position in the select list. When false, the ordinal numbers are ignored.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.hive.caseSensitiveInferenceMode&lt;/td&gt;
      &lt;td&gt;INFER_AND_SAVE&lt;/td&gt;
      &lt;td&gt;Sets the action to take when a case-sensitive schema cannot be read from   a Hive table’s properties. Although Spark SQL itself is not case-sensitive,   Hive compatible file formats such as Parquet are. Spark SQL must use a   case-preserving schema when querying any table backed by files containing   case-sensitive field names or queries may not return accurate results. Valid   options include INFER_AND_SAVE (the default mode– infer the case-sensitive   schema from the underlying data files and write it back to the table   properties), INFER_ONLY (infer the schema but don’t attempt to write it to   the table properties) and NEVER_INFER (fallback to using the case-insensitive   metastore schema instead of inferring).&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.hive.convertMetastoreParquet&lt;/td&gt;
      &lt;td&gt;TRUE&lt;/td&gt;
      &lt;td&gt;When set to true, the built-in Parquet reader and writer are used to   process parquet tables created by using the HiveQL syntax, instead of Hive   serde.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.hive.convertMetastoreParquet.mergeSchema&lt;/td&gt;
      &lt;td&gt;FALSE&lt;/td&gt;
      &lt;td&gt;When true, also tries to merge possibly different but compatible Parquet   schemas in different Parquet data files. This configuration is only effective   when “spark.sql.hive.convertMetastoreParquet” is true.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.hive.filesourcePartitionFileCacheSize&lt;/td&gt;
      &lt;td&gt;262144000&lt;/td&gt;
      &lt;td&gt;When nonzero, enable caching of partition file metadata in memory. All   tables share a cache that can use up to specified num bytes for file   metadata. This conf only has an effect when hive filesource partition   management is enabled.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.hive.manageFilesourcePartitions&lt;/td&gt;
      &lt;td&gt;TRUE&lt;/td&gt;
      &lt;td&gt;When true, enable metastore partition management for file source tables   as well. This includes both datasource and converted Hive tables. When   partition management is enabled, datasource tables store partition in the   Hive metastore, and use the metastore to prune partitions during query   planning.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.hive.metastore.barrierPrefixes&lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
      &lt;td&gt;A comma separated list of class prefixes that should explicitly be   reloaded for each version of Hive that Spark SQL is communicating with. For   example, Hive UDFs that are declared in a prefix that typically would be   shared (i.e. &lt;code&gt;org.apache.spark.*&lt;/code&gt;).&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.hive.metastore.jars&lt;/td&gt;
      &lt;td&gt;builtin&lt;/td&gt;
      &lt;td&gt;Location of the jars that should be   used to instantiate the HiveMetastoreClient.     This property can be one of three   options: “     1.   “builtin”       Use Hive 1.2.1, which is bundled   with the Spark assembly when       &lt;code&gt;-Phive&lt;/code&gt; is   enabled. When this option is chosen,         &lt;code&gt;spark.sql.hive.metastore.version&lt;/code&gt; must be   either       &lt;code&gt;1.2.1&lt;/code&gt; or   not defined.     2. “maven”       Use Hive jars of specified version   downloaded from Maven repositories.     3. A classpath in the   standard format for both Hive and Hadoop.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.hive.metastore.sharedPrefixes&lt;/td&gt;
      &lt;td&gt;com.mysql.jdbc,&lt;br /&gt;org.postgresql,&lt;br /&gt;com.microsoft.sqlserver,&lt;br /&gt;oracle.jdbc&lt;/td&gt;
      &lt;td&gt;A comma separated list of class prefixes that should be loaded using the   classloader that is shared between Spark SQL and a specific version of Hive.   An example of classes that should be shared is JDBC drivers that are needed   to talk to the metastore. Other classes that need to be shared are those that   interact with classes that are already shared. For example, custom appenders   that are used by log4j.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.hive.metastore.version&lt;/td&gt;
      &lt;td&gt;1.2.1&lt;/td&gt;
      &lt;td&gt;Version of the Hive metastore. Available options are   &lt;code&gt;0.12.0&lt;/code&gt; through &lt;code&gt;2.1.1&lt;/code&gt;.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.hive.metastorePartitionPruning&lt;/td&gt;
      &lt;td&gt;TRUE&lt;/td&gt;
      &lt;td&gt;When true, some predicates will be pushed down into the Hive metastore so   that unmatching partitions can be eliminated earlier. This only affects Hive   tables not converted to filesource relations (see   HiveUtils.CONVERT_METASTORE_PARQUET and HiveUtils.CONVERT_METASTORE_ORC for   more information).&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.hive.thriftServer.async&lt;/td&gt;
      &lt;td&gt;TRUE&lt;/td&gt;
      &lt;td&gt;When set to true, Hive Thrift server executes SQL queries in an   asynchronous way.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.hive.thriftServer.singleSession&lt;/td&gt;
      &lt;td&gt;FALSE&lt;/td&gt;
      &lt;td&gt;When set to true, Hive Thrift server is running in a single session mode.   All the JDBC/ODBC connections share the temporary views, function registries,   SQL configuration and the current database.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.hive.verifyPartitionPath&lt;/td&gt;
      &lt;td&gt;FALSE&lt;/td&gt;
      &lt;td&gt;When true, check all the partition paths under the table’s root directory   when reading data stored in HDFS.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.hive.version&lt;/td&gt;
      &lt;td&gt;1.2.1&lt;/td&gt;
      &lt;td&gt;deprecated, please use spark.sql.hive.metastore.version to get the Hive   version in Spark.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.inMemoryColumnarStorage.batchSize&lt;/td&gt;
      &lt;td&gt;10000&lt;/td&gt;
      &lt;td&gt;Controls the size of batches for columnar caching.  Larger batch sizes can improve memory   utilization and compression, but risk OOMs when caching data.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.inMemoryColumnarStorage.compressed&lt;/td&gt;
      &lt;td&gt;TRUE&lt;/td&gt;
      &lt;td&gt;When set to true Spark SQL will automatically select a compression codec   for each column based on statistics of the data.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.inMemoryColumnarStorage.enableVectorizedReader&lt;/td&gt;
      &lt;td&gt;TRUE&lt;/td&gt;
      &lt;td&gt;Enables vectorized reader for columnar caching.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.optimizer.metadataOnly&lt;/td&gt;
      &lt;td&gt;TRUE&lt;/td&gt;
      &lt;td&gt;When true, enable the metadata-only query optimization that use the   table’s metadata to produce the partition columns instead of table scans. It   applies when all the columns scanned are partition columns and the query has   an aggregate operator that satisfies distinct semantics.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.orc.compression.codec&lt;/td&gt;
      &lt;td&gt;snappy&lt;/td&gt;
      &lt;td&gt;Sets the compression codec used when writing ORC files. If either   &lt;code class=&quot;highlighter-rouge&quot;&gt;compression&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;orc.compress&lt;/code&gt; is specified in the table-specific   options/properties, the precedence would be &lt;code class=&quot;highlighter-rouge&quot;&gt;compression&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;orc.compress&lt;/code&gt;,   &lt;code class=&quot;highlighter-rouge&quot;&gt;spark.sql.orc.compression.codec&lt;/code&gt;.Acceptable values include: none,   uncompressed, snappy, zlib, lzo.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.orc.enableVectorizedReader&lt;/td&gt;
      &lt;td&gt;TRUE&lt;/td&gt;
      &lt;td&gt;Enables vectorized orc decoding.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.orc.filterPushdown&lt;/td&gt;
      &lt;td&gt;FALSE&lt;/td&gt;
      &lt;td&gt;When true, enable filter pushdown for ORC files.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.orderByOrdinal&lt;/td&gt;
      &lt;td&gt;TRUE&lt;/td&gt;
      &lt;td&gt;When true, the ordinal numbers are treated as the position in the select   list. When false, the ordinal numbers in order/sort by clause are ignored.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.parquet.binaryAsString&lt;/td&gt;
      &lt;td&gt;FALSE&lt;/td&gt;
      &lt;td&gt;Some other Parquet-producing systems, in particular Impala and older   versions of Spark SQL, do not differentiate between binary data and strings   when writing out the Parquet schema. This flag tells Spark SQL to interpret   binary data as a string to provide compatibility with these systems.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.parquet.compression.codec&lt;/td&gt;
      &lt;td&gt;snappy&lt;/td&gt;
      &lt;td&gt;Sets the compression codec used when writing Parquet files. If either   &lt;code class=&quot;highlighter-rouge&quot;&gt;compression&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;parquet.compression&lt;/code&gt; is specified in the table-specific   options/properties, the precedence would be &lt;code class=&quot;highlighter-rouge&quot;&gt;compression&lt;/code&gt;,   &lt;code class=&quot;highlighter-rouge&quot;&gt;parquet.compression&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;spark.sql.parquet.compression.codec&lt;/code&gt;. Acceptable   values include: none, uncompressed, snappy, gzip, lzo.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.parquet.enableVectorizedReader&lt;/td&gt;
      &lt;td&gt;TRUE&lt;/td&gt;
      &lt;td&gt;Enables vectorized parquet decoding.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.parquet.filterPushdown&lt;/td&gt;
      &lt;td&gt;TRUE&lt;/td&gt;
      &lt;td&gt;Enables Parquet filter push-down optimization when set to true.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.parquet.int64AsTimestampMillis&lt;/td&gt;
      &lt;td&gt;FALSE&lt;/td&gt;
      &lt;td&gt;(Deprecated since Spark 2.3, please set   spark.sql.parquet.outputTimestampType.) When true, timestamp values will be   stored as INT64 with TIMESTAMP_MILLIS as the extended type. In this mode, the   microsecond portion of the timestamp value will betruncated.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.parquet.int96AsTimestamp&lt;/td&gt;
      &lt;td&gt;TRUE&lt;/td&gt;
      &lt;td&gt;Some Parquet-producing systems, in particular Impala, store Timestamp   into INT96. Spark would also store Timestamp as INT96 because we need to   avoid precision lost of the nanoseconds field. This flag tells Spark SQL to   interpret INT96 data as a timestamp to provide compatibility with these   systems.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.parquet.int96TimestampConversion&lt;/td&gt;
      &lt;td&gt;FALSE&lt;/td&gt;
      &lt;td&gt;This controls whether timestamp adjustments should be applied to INT96   data when converting to timestamps, for data written by Impala.  This is necessary because Impala stores   INT96 data with a different timezone offset than Hive &amp;amp; Spark.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.parquet.mergeSchema&lt;/td&gt;
      &lt;td&gt;FALSE&lt;/td&gt;
      &lt;td&gt;When true, the Parquet data source merges schemas collected from all data   files, otherwise the schema is picked from the summary file or a random data   file if no summary file is available.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.parquet.outputTimestampType&lt;/td&gt;
      &lt;td&gt;INT96&lt;/td&gt;
      &lt;td&gt;Sets which Parquet timestamp type to use when Spark writes data to   Parquet files. INT96 is a non-standard but commonly used timestamp type in   Parquet. TIMESTAMP_MICROS is a standard timestamp type in Parquet, which   stores number of microseconds from the Unix epoch. TIMESTAMP_MILLIS is also   standard, but with millisecond precision, which means Spark has to truncate   the microsecond portion of its timestamp value.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.parquet.recordLevelFilter.enabled&lt;/td&gt;
      &lt;td&gt;FALSE&lt;/td&gt;
      &lt;td&gt;If true, enables Parquet’s native record-level filtering using the pushed   down filters. This configuration only has an effect when   ‘spark.sql.parquet.filterPushdown’ is enabled.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.parquet.respectSummaryFiles&lt;/td&gt;
      &lt;td&gt;FALSE&lt;/td&gt;
      &lt;td&gt;When true, we make assumption that all part-files of Parquet are   consistent with summary files and we will ignore them when merging schema.   Otherwise, if this is false, which is the default, we will merge all   part-files. This should be considered as expert-only option, and shouldn’t be   enabled before knowing what it means exactly.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.parquet.writeLegacyFormat&lt;/td&gt;
      &lt;td&gt;FALSE&lt;/td&gt;
      &lt;td&gt;Whether to be compatible with the legacy Parquet format adopted by Spark   1.4 and prior versions, when converting Parquet schema to Spark SQL schema   and vice versa.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.parser.quotedRegexColumnNames&lt;/td&gt;
      &lt;td&gt;FALSE&lt;/td&gt;
      &lt;td&gt;When true, quoted Identifiers (using backticks) in SELECT statement are   interpreted as regular expressions.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.pivotMaxValues&lt;/td&gt;
      &lt;td&gt;10000&lt;/td&gt;
      &lt;td&gt;When doing a pivot without specifying values for the pivot column this is   the maximum number of (distinct) values that will be collected without error.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.queryExecutionListeners&lt;/td&gt;
      &lt;td&gt;&lt;undefined&gt;&lt;/undefined&gt;&lt;/td&gt;
      &lt;td&gt;List of class names implementing QueryExecutionListener that will be   automatically added to newly created sessions. The classes should have either   a no-arg constructor, or a constructor that expects a SparkConf argument.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.redaction.options.regex&lt;/td&gt;
      &lt;td&gt;(?i)url&lt;/td&gt;
      &lt;td&gt;Regex to decide which keys in a Spark SQL command’s options map contain   sensitive information. The values of options whose names that match this   regex will be redacted in the explain output. This redaction is applied on   top of the global redaction configuration defined by spark.redaction.regex.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.redaction.string.regex&lt;/td&gt;
      &lt;td&gt;&lt;value of=&quot;&quot; spark.redaction.string.regex=&quot;&quot;&gt;&lt;/value&gt;&lt;/td&gt;
      &lt;td&gt;Regex to decide which parts of strings produced by Spark contain   sensitive information. When this regex matches a string part, that string   part is replaced by a dummy value. This is currently used to redact the   output of SQL explain commands. When this conf is not set, the value from   &lt;code class=&quot;highlighter-rouge&quot;&gt;spark.redaction.string.regex&lt;/code&gt; is used.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.session.timeZone&lt;/td&gt;
      &lt;td&gt;Asia/Shanghai&lt;/td&gt;
      &lt;td&gt;The ID of session local timezone, e.g. “GMT”,   “America/Los_Angeles”, etc.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.shuffle.partitions&lt;/td&gt;
      &lt;td&gt;4096&lt;/td&gt;
      &lt;td&gt;The default number of partitions to use when shuffling data for joins or   aggregations.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.sources.bucketing.enabled&lt;/td&gt;
      &lt;td&gt;TRUE&lt;/td&gt;
      &lt;td&gt;When false, we will treat bucketed table as normal table&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.sources.default&lt;/td&gt;
      &lt;td&gt;parquet&lt;/td&gt;
      &lt;td&gt;The default data source to use in input/output.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.sources.parallelPartitionDiscovery.threshold&lt;/td&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;The maximum number of paths allowed for listing files at driver side. If   the number of detected paths exceeds this value during partition discovery,   it tries to list the files with another Spark distributed job. This applies   to Parquet, ORC, CSV, JSON and LibSVM data sources.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.sources.partitionColumnTypeInference.enabled&lt;/td&gt;
      &lt;td&gt;TRUE&lt;/td&gt;
      &lt;td&gt;When true, automatically infer the data types for partitioned columns.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.sources.partitionOverwriteMode&lt;/td&gt;
      &lt;td&gt;STATIC&lt;/td&gt;
      &lt;td&gt;When INSERT OVERWRITE a partitioned data source table, we currently   support 2 modes: static and dynamic. In static mode, Spark deletes all the   partitions that match the partition specification(e.g. PARTITION(a=1,b)) in   the INSERT statement, before overwriting. In dynamic mode, Spark doesn’t   delete partitions ahead, and only overwrite those partitions that have data   written into it at runtime. By default we use static mode to keep the same   behavior of Spark prior to 2.3. Note that this config doesn’t affect Hive   serde tables, as they are always overwritten with dynamic mode.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.statistics.fallBackToHdfs&lt;/td&gt;
      &lt;td&gt;TRUE&lt;/td&gt;
      &lt;td&gt;If the table statistics are not available from table metadata enable fall   back to hdfs. This is useful in determining if a table is small enough to use   auto broadcast joins.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.statistics.histogram.enabled&lt;/td&gt;
      &lt;td&gt;FALSE&lt;/td&gt;
      &lt;td&gt;Generates histograms when computing column statistics if enabled.   Histograms can provide better estimation accuracy. Currently, Spark only   supports equi-height histogram. Note that collecting histograms takes extra   cost. For example, collecting column statistics usually takes only one table   scan, but generating equi-height histogram will cause an extra table scan.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.statistics.size.autoUpdate.enabled&lt;/td&gt;
      &lt;td&gt;FALSE&lt;/td&gt;
      &lt;td&gt;Enables automatic update for table size once table’s data is changed.   Note that if the total number of files of the table is very large, this can   be expensive and slow down data change commands.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.streaming.checkpointLocation&lt;/td&gt;
      &lt;td&gt;&lt;undefined&gt;&lt;/undefined&gt;&lt;/td&gt;
      &lt;td&gt;The default location for storing checkpoint data for streaming queries.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.streaming.metricsEnabled&lt;/td&gt;
      &lt;td&gt;FALSE&lt;/td&gt;
      &lt;td&gt;Whether Dropwizard/Codahale metrics will be reported for active streaming   queries.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.streaming.numRecentProgressUpdates&lt;/td&gt;
      &lt;td&gt;100&lt;/td&gt;
      &lt;td&gt;The number of progress updates to retain for a streaming query&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.thriftserver.scheduler.pool&lt;/td&gt;
      &lt;td&gt;&lt;undefined&gt;&lt;/undefined&gt;&lt;/td&gt;
      &lt;td&gt;Set a Fair Scheduler pool for a JDBC client session.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.thriftserver.ui.retainedSessions&lt;/td&gt;
      &lt;td&gt;200&lt;/td&gt;
      &lt;td&gt;The number of SQL client sessions kept in the JDBC/ODBC web UI history.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.thriftserver.ui.retainedStatements&lt;/td&gt;
      &lt;td&gt;200&lt;/td&gt;
      &lt;td&gt;The number of SQL statements kept in the JDBC/ODBC web UI history.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.ui.retainedExecutions&lt;/td&gt;
      &lt;td&gt;1000&lt;/td&gt;
      &lt;td&gt;Number of executions to retain in the Spark UI.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.variable.substitute&lt;/td&gt;
      &lt;td&gt;TRUE&lt;/td&gt;
      &lt;td&gt;This enables substitution using syntax like ${var} ${system:var} and   ${env:var}.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spark.sql.warehouse.dir&lt;/td&gt;
      &lt;td&gt;/user/warehouse&lt;/td&gt;
      &lt;td&gt;The default location for managed databases and tables.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

</description>
                <link>http://www.turbofei.wang/spark/2019/06/26/spark-sql-%E5%8F%82%E6%95%B0%E8%B0%83%E4%BC%98</link>
                <guid>http://www.turbofei.wang/spark/2019/06/26/spark-sql-参数调优</guid>
                <pubDate>2019-06-26T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>About Threadlocal</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#什么是threadlocal&quot; id=&quot;markdown-toc-什么是threadlocal&quot;&gt;什么是ThreadLocal&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#case-1&quot; id=&quot;markdown-toc-case-1&quot;&gt;Case 1&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#case-2&quot; id=&quot;markdown-toc-case-2&quot;&gt;Case 2&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#case-3&quot; id=&quot;markdown-toc-case-3&quot;&gt;Case 3&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#如何正确使用threadlocal&quot; id=&quot;markdown-toc-如何正确使用threadlocal&quot;&gt;如何正确使用ThreadLocal&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#源码实现&quot; id=&quot;markdown-toc-源码实现&quot;&gt;源码实现&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#引用类型&quot; id=&quot;markdown-toc-引用类型&quot;&gt;引用类型&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#threadlocalmap&quot; id=&quot;markdown-toc-threadlocalmap&quot;&gt;ThreadLocalMap&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#threadlocalinitialvalue&quot; id=&quot;markdown-toc-threadlocalinitialvalue&quot;&gt;ThreadLocal.initialValue()&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#inheritthreadlocal&quot; id=&quot;markdown-toc-inheritthreadlocal&quot;&gt;InheritThreadLocal&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#内存角度&quot; id=&quot;markdown-toc-内存角度&quot;&gt;内存角度&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#jmm&quot; id=&quot;markdown-toc-jmm&quot;&gt;JMM&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#tlabthread-local-allocation-buffer&quot; id=&quot;markdown-toc-tlabthread-local-allocation-buffer&quot;&gt;TLAB(Thread Local Allocation Buffer)&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#reference&quot; id=&quot;markdown-toc-reference&quot;&gt;Reference&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本文讲ThreadLocal的使用场景，注意事项以及源码实现。&lt;/p&gt;

&lt;h3 id=&quot;什么是threadlocal&quot;&gt;什么是ThreadLocal&lt;/h3&gt;

&lt;p&gt;ThreadLocal，顾名思义，是线程本地的，也就是说非多线程共享，是为了解决线程并发时，变量共享的问题。但是在使用时需要注意内存泄露，脏数据等问题。&lt;/p&gt;

&lt;p&gt;那么什么时候需要用到ThreadLocal呢？此处举几个例子.&lt;/p&gt;

&lt;h4 id=&quot;case-1&quot;&gt;Case 1&lt;/h4&gt;

&lt;p&gt;例如我们定义了一个类，代表一个Student，然后场景是一个考场，每个学生用一个线程进行表示，而每个学生有一个做卷子的进度变量，这个变量必须是对应一个学生，也就是一个线程。这个时候，我们需要定义一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ThreadLocal&lt;/code&gt;类型的state变量来表示每个学生目前的状态，这样每个学生的状态不会互相干扰.&lt;/p&gt;

&lt;p&gt;例如下面的这段代码，在同一个线程里面的Student 的ThreadLocal值是一样的。&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;java.util.concurrent.atomic.AtomicInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TestThreadLocal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;Student&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Student&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Current Thread value:&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;// Current Thread value:1&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;Student&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Student&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Current Thread value:&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// Current Thread value:1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;removeState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;Student&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Student&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;New Thread value:&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// New Thread value:2&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;s3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;removeState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Student&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AtomicInteger&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;al&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AtomicInteger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ThreadLocal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;state&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ThreadLocal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;withInitial&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;al&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;incrementAndGet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;getState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;removeState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;remove&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;case-2&quot;&gt;Case 2&lt;/h4&gt;

&lt;p&gt;对于一些非线程安全的类，例如SimpleDateFormat，定义为static，会有数据同步风险。SimpleDateFormat内部有一个Calendar对象，在日期转字符串或者字符串转日期的过程中，多线程共享时有非常高的概率产生错误，推荐的方式是使用ThreadLocal，让每个线程单独拥有这个对象.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ThreadLocal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;DateFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;DATA_FORMAT_THREADLOCAL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 
          &lt;span class=&quot;nc&quot;&gt;ThreadLocal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;withInitial&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SimpleDateFormat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;yyyy-mm-dd&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;case-3&quot;&gt;Case 3&lt;/h4&gt;

&lt;p&gt;在父线程和子线程之间传递变量，可以使用ThreadLocal.&lt;/p&gt;

&lt;p&gt;ThreadLocal有一个子类是InheritThreadLocal. 使用方式如下:&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;java.util.Date&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Helper&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ThreadLocal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;InheritableThreadLocal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nd&quot;&gt;@Override&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;initialValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Date&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getTime&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;};&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TestInheritThreadLocal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ParentThreadTime:&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Helper&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// ParentThreadTime:1561222644968&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;CurrentThreadTime:&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Date&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getTime&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// CurrentThreadTime:1561222645061&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;InheritTime:&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Helper&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// InheritTime:1561222644968&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;如何正确使用threadlocal&quot;&gt;如何正确使用ThreadLocal&lt;/h3&gt;

&lt;p&gt;在使用ThreadLocal时候要注意避免产生脏数据和内存泄露。这两个问题通常是在线程池的线程中使用ThreadLocal引发的，因为线程池中有线程复用和内存常驻两个特点.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;脏数据&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;线程复用可能会产生脏数据，由于线程池会重用Thread对象，那么与Thread绑定的类的静态属性ThreadLocal变量也会被重用。如果在实现的线程&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;run()&lt;/code&gt;方法体重不显示的调用remove()清理与线程相关的ThreadLocal信息，那么倘若下一个线程不调用set()设置初始值，就可能get到重用的线程信息，包括ThreadLocal所关联的线程对象的Value值.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;内存泄露&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在源码注释中提示使用static关键字来修饰ThreadLocal。在此场景下，寄希望于ThreadLocal对象失去引用后，触发弱引用机制来回收不显示，因此在线程执行完毕之后，需要执行remove()方法，不然其对应ThreadLocal持有的值不会被释放。&lt;/p&gt;

&lt;h3 id=&quot;源码实现&quot;&gt;源码实现&lt;/h3&gt;

&lt;h4 id=&quot;引用类型&quot;&gt;引用类型&lt;/h4&gt;

&lt;p&gt;首先介绍一下Java中的四种引用类型.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;强引用。 例如:&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Object obj = new Object()&lt;/code&gt;。只要对象具有可达性，就不能被回收。&lt;/li&gt;
  &lt;li&gt;软引用。在即将OOM之前，即使有可达性，也可回收。&lt;/li&gt;
  &lt;li&gt;弱引用。在下一次YGC时会被回收。&lt;/li&gt;
  &lt;li&gt;虚引用。一种极弱的引用关系，定义完成后，就无法通过该引用获取指向的对象。为一个对象设置虚引用的唯一目的是希望能在这个对象回收时收到一个系统通知。虚引用必须与引用队列联合使用，当垃圾会收拾，如果发现存在虚引用，就会在回收对象内存前，把这个虚引用加入与之关联的引用队列中。&lt;strong&gt;极少使用。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;此处给出软引用和弱引用的使用示例.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;java.lang.ref.SoftReference&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;java.lang.ref.WeakReference&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TestReference&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;soft&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10086&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;SoftReference&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;soft&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SoftReference&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 对象设为空，解除强引用劫持.&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  
  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;weak&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10086&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;WeakReference&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;soft&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;WeakReference&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 对象设为空，解除强引用劫持.&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;ThreadLocal的设计中使用了WeakReference， JDK中设计的愿意是在ThreadLocal对象消失后，线程对象再持有这个ThreadLocal对象是没有任何意义的，应该进行回收，从而避免内存泄露，这种设计的出发点很好，但弱引用的设计增加了对ThreadLocal 和Thread体系的理解难度。&lt;/p&gt;

&lt;h4 id=&quot;threadlocalmap&quot;&gt;ThreadLocalMap&lt;/h4&gt;

&lt;p&gt;ThreadLocal有个静态内部类叫做&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ThreadLocalMap&lt;/code&gt;, 它还有一个静态内部类叫&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Entry&lt;/code&gt;, 而Entry是弱引用类型.&lt;/p&gt;

&lt;p&gt;ThreadLocal与ThreadLocalMap有三组对应的方法，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;get()&lt;/code&gt;,&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;set()&lt;/code&gt;,&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;remove()&lt;/code&gt;。在ThreadLocal中只是做校验和判断，最终的实现会落在ThreadLocalMap中。&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;        &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Entry&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;WeakReference&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ThreadLocal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;?&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;cm&quot;&gt;/** The value associated with this ThreadLocal. */&lt;/span&gt;
            &lt;span class=&quot;nc&quot;&gt;Object&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;

            &lt;span class=&quot;nc&quot;&gt;Entry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ThreadLocal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;?&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Object&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;kd&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Entry继承了WeakReference, 只有一个value成员变量，其Key是ThreadLocal对象。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;每一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Thread&lt;/code&gt; 中有一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ThreadLocalMap&lt;/code&gt;&lt;/strong&gt;(因为一个Thread中可能有多个ThreadLocal，所以需要一个Map保存所有的ThreadLocal变量，而key就是ThreadLocal变量，value是对应的值).&lt;/p&gt;

&lt;h4 id=&quot;threadlocalinitialvalue&quot;&gt;ThreadLocal.initialValue()&lt;/h4&gt;

&lt;p&gt;虽然说每个Thread有一个ThreadLocalMap，那么这个localMap是如何创建的呢？&lt;/p&gt;

&lt;p&gt;首先，ThreadLocal有三个方法，其中get方法就是为了去获取其对应的值，如果没有调用get，那么这个ThreadLocal毫无价值。&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;Thread&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;currentThread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;ThreadLocalMap&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;getMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nc&quot;&gt;ThreadLocalMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Entry&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getEntry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;nd&quot;&gt;@SuppressWarnings&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;unchecked&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;no&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;setInitialValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;首先，它会去获得这个Thread对应的localMap，如果这个localMap非空，而且可以在这个localMap中找到，那么直接返回找到的值。&lt;/p&gt;

&lt;p&gt;如果这个localMap为空，或者说这个localMap没有对应的值。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果localMap为空。那么会创建createMap方法，创建对应的ThreadLocalMap,并且初始化的kv是(当前线程，initialValue创建的值).&lt;/li&gt;
  &lt;li&gt;如果localMap非空，那么就像这个localMap中添加值.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;inheritthreadlocal&quot;&gt;InheritThreadLocal&lt;/h4&gt;

&lt;p&gt;这是ThreadLocal的一个子类，上面我们也提到了其用法。其override了ThreadLocal的几个方法，去掉注释如下.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-Java&quot;&gt;public class InheritableThreadLocal&amp;lt;T&amp;gt; extends ThreadLocal&amp;lt;T&amp;gt; {
    protected T childValue(T parentValue) {
        return parentValue;
    }
    ThreadLocalMap getMap(Thread t) {
       return t.inheritableThreadLocals;
    }
    void createMap(Thread t, T firstValue) {
        t.inheritableThreadLocals = new ThreadLocalMap(this, firstValue);
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;只override了三个方法，其中 childValue 是ThreadLocal不支持的，其调用是只在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;createInheritedMap&lt;/code&gt;时进行调用。而其他两个getMap 和 createMap是在从Thread中获取localMap时的改写，以及在创建localMap的改写。&lt;/p&gt;

&lt;p&gt;那么对应的 线程本地变量是如何传递进来的呢？&lt;/p&gt;

&lt;p&gt;看下面的方法调用.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Thread-&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nextThreadNum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ThreadGroup&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Runnable&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
                      &lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stackSize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stackSize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
		&lt;span class=&quot;c1&quot;&gt;// 此处 inheritThreadLocals = true&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ThreadGroup&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Runnable&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
                      &lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stackSize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AccessControlContext&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
                      &lt;span class=&quot;kt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inheritThreadLocals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  		&lt;span class=&quot;o&quot;&gt;......&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inheritThreadLocals&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;inheritableThreadLocals&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;inheritableThreadLocals&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;
                &lt;span class=&quot;nc&quot;&gt;ThreadLocal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;createInheritedMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;inheritableThreadLocals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
   		&lt;span class=&quot;o&quot;&gt;......&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;可以看到，默认使用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;new  Thread()&lt;/code&gt;创建线程就会继承父线程的ThreadLocals.&lt;/p&gt;

&lt;h4 id=&quot;内存角度&quot;&gt;内存角度&lt;/h4&gt;

&lt;h5 id=&quot;jmm&quot;&gt;JMM&lt;/h5&gt;

&lt;p&gt;首先介绍下Java的内存模型。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/thread-local/jmm.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从抽象的角度看，JMM定义了线程和主内存之间的抽象关系:线程之间的共享变量存储在主内存中，每个线程都有一个私有的本地内存，本地内存存储了该线程以读/写共享变量的副本。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;本地内存是JMM的一个抽象概念，并不真实存在。&lt;/strong&gt;它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。&lt;/p&gt;

&lt;h5 id=&quot;tlabthread-local-allocation-buffer&quot;&gt;TLAB(Thread Local Allocation Buffer)&lt;/h5&gt;

&lt;p&gt;TLAB代表线程本地变量分配缓冲区，这是Eden内部的一个region, 是被划分为一个Thread的区域,属于非线程共享区域。换句话说，只有一个线程可以在一个TLAB里面分配对象。每个Thread都有对应的TLAB.&lt;/p&gt;

&lt;p&gt;所以针对TLAB里面的对象，不需要设置同步操作。&lt;/p&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://dzone.com/articles/thread-local-allocation-buffers&quot;&gt;What is Thread Local Allocation Buffer&lt;/a&gt;&lt;/p&gt;
</description>
                <link>http://www.turbofei.wang/coding/2019/06/20/about-threadLocal</link>
                <guid>http://www.turbofei.wang/coding/2019/06/20/about-threadLocal</guid>
                <pubDate>2019-06-20T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>About Jvm</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#前言&quot; id=&quot;markdown-toc-前言&quot;&gt;前言&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#synchronized&quot; id=&quot;markdown-toc-synchronized&quot;&gt;synchronized&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#happens-before&quot; id=&quot;markdown-toc-happens-before&quot;&gt;happens-before&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#volatile&quot; id=&quot;markdown-toc-volatile&quot;&gt;volatile&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#class-load&quot; id=&quot;markdown-toc-class-load&quot;&gt;Class Load&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#classnotfoundexception--noclassdeffounderror&quot; id=&quot;markdown-toc-classnotfoundexception--noclassdeffounderror&quot;&gt;ClassNotFoundException &amp;amp; NoClassDefFoundError&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#about-oom&quot; id=&quot;markdown-toc-about-oom&quot;&gt;About OOM&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#jvm-args&quot; id=&quot;markdown-toc-jvm-args&quot;&gt;JVM Args&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;简单总结下最近关于jvm的知识，只保证自己能看懂。&lt;/p&gt;

&lt;h3 id=&quot;前言&quot;&gt;前言&lt;/h3&gt;

&lt;p&gt;使用JVM的语言(java, scala)进行开发的工程师有必要对底层的JVM有所了解。&lt;/p&gt;

&lt;p&gt;本文对jvm的分区不再赘述，主要讲以下几方面。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;synchronized 底层实现&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;happens-before： 这是多线程并发的基础&lt;/li&gt;
  &lt;li&gt;volatile: volatile关键字的底层与使用注意事项&lt;/li&gt;
  &lt;li&gt;class load过程&lt;/li&gt;
  &lt;li&gt;ClassNotFoundException &amp;amp; NoClassDefFoundError&lt;/li&gt;
  &lt;li&gt;各种OOM的含义&lt;/li&gt;
  &lt;li&gt;JVM 参数的使用&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;synchronized&quot;&gt;synchronized&lt;/h3&gt;

&lt;p&gt;多线程并发时，需要对线程进行同步，保证各个线程协调有序的进行。&lt;/p&gt;

&lt;p&gt;在java中，有一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;synchronized&lt;/code&gt;关键字，这个关键字可以用于修饰方法，修饰代码块。在java中，每个object都有一个隐藏的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;monitor&lt;/code&gt;, 因此可以对象都可以通过调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Object.wait&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;object.notify&lt;/code&gt;方法进行同步操作。而synchronized的实现也是基于monitor来实现，伪代码如下:&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;monitorenter&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;nc&quot;&gt;CodeBlock&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;monitorexit&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;happens-before&quot;&gt;happens-before&lt;/h3&gt;

&lt;p&gt;把happens-before定义为方法hb(a, b), 表示a的结果对b可见，这不一定代表a一定比b先执行，因为可能会进行指令重排优化。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果 x 和 y在同一个线程中，且在程序中顺序 x 先于 y，那么hb(x, y)&lt;/li&gt;
  &lt;li&gt;一个object的构造方法 happens-before &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;finalizer&lt;/code&gt;方法&lt;/li&gt;
  &lt;li&gt;在一个synchronized代码块中，x 先于y，那么hb(x, y)&lt;/li&gt;
  &lt;li&gt;如果hb(a, b)且hb(b, c)，那么能够推导出hb(a, c)&lt;/li&gt;
  &lt;li&gt;对于一个field的默认值构造happends-before其访问&lt;/li&gt;
  &lt;li&gt;一个monitor的unlock happens-before 于该monitor后续的lock操作&lt;/li&gt;
  &lt;li&gt;对于一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;volatile&lt;/code&gt;的写hb与其读操作，后续会讲&lt;/li&gt;
  &lt;li&gt;一个thread的start操作hb于其线程中的方法调用&lt;/li&gt;
  &lt;li&gt;一个调用join方法的剩余所有操作，hb于被join中的其他执行操作&lt;/li&gt;
  &lt;li&gt;一个对象的默认初始化操作hb于其他访问该对象的操作&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;happens-before对于单线程中的操作是可以保证可见性的，但是对于多线程的线程交互无法保证可见性。&lt;/p&gt;

&lt;p&gt;在多线程中，每个线程都有独占的内存区域，如操作栈、本地变量表等。线程本地内存保存了引用变量在堆内存中的&lt;strong&gt;副本&lt;/strong&gt;，线程对变量的所有操作都在本地内存区域中进行，执行结束后再同步到堆内存中，这里必然有一个时间差，在这个时间差内，该线程对副本的操作，对于其他线程都是不可见的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;happens-before&lt;/strong&gt;可以参考官方文档:https://docs.oracle.com/javase/specs/jls/se8/html/jls-17.html#jls-17.4.5&lt;/p&gt;

&lt;h3 id=&quot;volatile&quot;&gt;volatile&lt;/h3&gt;

&lt;p&gt;volatile的英文意思是”挥发，不稳定的”，也就是敏感的，是java中的一个关键字，用于修饰变量，代表&lt;strong&gt;任何对此变量的操作都是在内存中进行，不会产生副本，以保证共享变量的可见性，局部组织了指令重排的发生&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;讲一下指令重排。&lt;/p&gt;

&lt;p&gt;例如在单列模式中，我们通常使用双重检测来保证。&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DoubleCheckLocking&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Instance&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;instance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
  
  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Instance&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;getInstance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;instance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;kd&quot;&gt;synchronized&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;DoubleCheckLocking&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;instance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;instance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Instance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;instance&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;；&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;上面代码中的一个操作, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;instance = new Instance()&lt;/code&gt;会被分解为下面三行伪代码，如下:&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;memory&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;allocate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;// 1、分配对象的内存空间&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ctorInstance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;memory&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;   &lt;span class=&quot;c1&quot;&gt;// 2、初始化对象&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;instance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;memory&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;      &lt;span class=&quot;c1&quot;&gt;// 3、设置instance指向分配的内存地址&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;上面的三行代码的2，3步可能会被重排序，也就是说可能instance已经指向了分配的内存，但是该对象仍在初始化中。对于多线程来说，如果线程1，调用该单例构造，但是仍在构造中，而此时已经instance已经指向了内存地址，这样另一个线程2就会获得到一个还没有初始化完成的对象，这会造成错误。&lt;/p&gt;

&lt;p&gt;而如果我们对instance使用volatile修饰&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;private static volatile Instance instance;&lt;/code&gt;，禁止指令重排就可以避免这种情况的发生.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;volatile解决的是多线程共享变量的可见性问题，类似于synchronized，但是不具备synchronized的互斥性。&lt;/strong&gt;所以对volatile变量的操作并非都具有原子性。&lt;/p&gt;

&lt;p&gt;例如&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;volatile&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;由于一个++ 操作，包含读取，加1，存入操作，因此volatile不能保证其操作的原子性，可以使用&lt;strong&gt;AtomicLong&lt;/strong&gt;等来替代，JDK8中推荐使用&lt;strong&gt;LongAdder&lt;/strong&gt;类替代AtomicLong，它性能更好，有效地减少了乐观锁的重试次数。&lt;/p&gt;

&lt;p&gt;因此，volatile只是保证共享变量的可见性，并非是一种同步方式，&lt;strong&gt;如果是并发写场景，那么一定会产生线程安全问题。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;如果是&lt;strong&gt;一写多读&lt;/strong&gt;的并发场景，那么使用volatile修饰变量很合适。在实际业务中，如果不能确定是否会并发写，那么保险的做法是使用同步代码块来实现线程同步。另外，因为所有的操作都需要同步给内存变量，所以volatile一定会使线程的执行速度变慢，所以要谨慎定义和使用volatile。&lt;/p&gt;

&lt;h3 id=&quot;class-load&quot;&gt;Class Load&lt;/h3&gt;

&lt;p&gt;此处简单描述一下。JVM中以下几种ClassLoader&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;启动类加载器（Bootstrap ClassLoader）：这个类加载器负责将存放在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$JAVA_HOME/lib&lt;/code&gt;目录中的。启动类加载器无法被Java程序直接引用，用户在编写自定义类加载器时，如果需要把加载请求委派给引导类加载器，那直接使用null代替即可。&lt;/li&gt;
  &lt;li&gt;扩展类加载器（Extension ClassLoader）：这个加载器由sun.misc.Launcher$ExtClassLoader实现，它负责加载&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$JAVA_HOME/lib/ext&lt;/code&gt;目录中的，或者被&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;java.ext.dirs&lt;/code&gt;系统变量所指定的路径中的所有类库，开发者可以直接使用扩展类加载器。&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;应用程序类加载器（Application ClassLoader）：这个类加载器由sun.misc.Launcher$AppClassLoader实现。由于这个类加载器是ClassLoader中的getSystemClassLoader()方法的返回值，所以一般也称它为系统类加载器。它负责加载用户类路径（ClassPath）上所指定的类库，开发者可以直接使用这个类加载器，如果应用程序中没有自定义自己的类加载器，一般情况下这个就是程序中默认的类加载器。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;用户也可以自己实现类加载器。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;两个类只有当类名与使用的类加载器都相同，才能说这两个类是相同的。&lt;/p&gt;

&lt;p&gt;类加载时使用双亲委派模型，加载一个类，首先自顶向下进行判断是否包含这个类，也就是说，首先从Bootstrap  ClassLoader进行加载，如果没有就从Extension ClassLoader进行加载，还没有就从Application ClassLoader进行加载，如果还没有就从用户自定义的ClassLoader进行加载。使用这种方法是为了加载的安全，例如在bootStrap ClassLoader加载的rt.jar里面的String类，如果用户自定义一个和String类名一样的类，那么通过双亲委派，就可以保证我们加载的是jdk中的String类， 这样可以保证放置一些库的类被篡改，更加安全。&lt;/p&gt;

&lt;p&gt;如果有两个jar包，但是版本不同，里面的类名都是一致的，也就是可能产生jar包冲突的类，这样会由什么顺序会加载对应的类呢？&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;java -cp one.jar;two.jar MyMain&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;classLoader 会查找资源第一次出现的地方，这会通过classPath来寻找。如果A出现在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;one.jar&lt;/code&gt;中，那么就从One.jar中来加载类A。
如果&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;java -cp two.jar;one.jar MyMain&lt;/code&gt;, 那么将会加载&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;two.jar&lt;/code&gt;中的类A。&lt;/p&gt;

&lt;h3 id=&quot;classnotfoundexception--noclassdeffounderror&quot;&gt;ClassNotFoundException &amp;amp; NoClassDefFoundError&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;java.lang.ClassNotFoundException&lt;/code&gt;代表这个类没有在classPath中找到。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;java.lang.NoClassDefFoundError&lt;/code&gt;这个异常代表，JVM在其内部类定义数据结构中查找了类的定义，但没有找到对应的类。这和在classPath没有找到类有所不同。通常这代表我们之前尝试从classPath中加载这个类，但是由于某些原因加载失败，现在我们尝试再次去使用这个类(因此需要去load这个类由于上次load失败)，但是我们不准备尝试去load它，因为我们之前load失败(因此推测出我们会再次失败)。前面的Failure可能是一个ClassNotFoundException 或者 ExceptionInInitializerError(静态代码块初始化失败) 或者其他问题。因此NoClassDefFoundError 不一定是因为classPath的问题，要看它前面失败的原因。&lt;/p&gt;

&lt;h3 id=&quot;about-oom&quot;&gt;About OOM&lt;/h3&gt;

&lt;p&gt;JVM区划划分为：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;程序计数器  用于指向指令运行地址的&lt;/li&gt;
  &lt;li&gt;java虚拟机栈： 是线程私有的，每个方法执行会创建一个栈帧，用于存储局部变量表，操作数栈，动态链接，方法出口等信息。&lt;/li&gt;
  &lt;li&gt;本地方法栈： 和虚拟机栈类似，但方法是native方法。&lt;/li&gt;
  &lt;li&gt;Java堆： 用于存储对象&lt;/li&gt;
  &lt;li&gt;方法区： 存储被虚拟机加载的类信息，常量，静态变量，即时编译器编译后的代码等数据。在JDK1.7时被称为永久代，放在JVM中，可以通过设置&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PermSize&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MaxPermSize&lt;/code&gt;来设置永久代大小，每次扩展永久代内存伴随full gc，而且超过最大永久代会造成内存溢出；jdk1.8中使用元空间代替永久代，减小gc，而且默认元空间不设上限，可以扩展。&lt;/li&gt;
  &lt;li&gt;运行时常量池： Class文件中除了有类的版本，字段，方法，接口等描述信息外，还有一项信息是常量池，用于存放编译期生成的各种字面量和方法引用，这部分信息将在类加载后进入方法区的运行时常量池存放。&lt;strong&gt;在JDK1.6中运行时常量池是方法区的一部分；jdk1.7中，运行时常量池从方法区中挪出来， 单独存放在堆中;JDK1.8, 参数发生了改变，JVM使用MetaSpace代替了PermSpace, 元空间是放在堆外本地直接内存，可以设置MaxMetaSpace，而默认是无最大限制。&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;直接内存： 堆外内存，可以使用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sun.misc.unsafe&lt;/code&gt;类进行访问堆外内存，一些框架netty也是默认使用堆外内存进行缓存数据。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;OutOfMemoryError异常分为：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;堆溢出
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;java.lang.OutOfMemoryError: Java heap space&lt;/code&gt;
        &lt;ul&gt;
          &lt;li&gt;代表堆内存溢出了，需要合理设置和使用内存。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;java.lang.OutOfMemoryError: Gc overhead limit exceeded&lt;/code&gt;
        &lt;ul&gt;
          &lt;li&gt;系统大量的时间都在GC（98%）而回收的效果不明显（2% heap空间），就会抛出这个异常。实际这是一个JVM预判性的异常，也就是说抛出这个异常的时候没有真正的内存溢出。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;虚拟机栈和本地方法栈溢出
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;java.lang.StackOverflowError&lt;/code&gt;
        &lt;ul&gt;
          &lt;li&gt;线程请求的栈深度大于虚拟机所允许的最大深度,通常是由于递归造成。&lt;/li&gt;
          &lt;li&gt;在单线程下，无论是由于栈帧太大还是虚拟机栈容量太小，当虚拟机栈内存无法分配都是抛出StackOverflowError.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;java.lang.OutOfMemoryError: unable to create new native thread&lt;/code&gt;
        &lt;ul&gt;
          &lt;li&gt;在建立多线程造成的内存溢出，可以通过减少每个线程栈容量来换取更多地线程数。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;方法区和运行时常量池溢出
    &lt;ul&gt;
      &lt;li&gt;JDK1.7 中有参数&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-XX:PermSize&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-XX:MaxPermSize&lt;/code&gt;来设置永久代大小，放在JVm中的非堆区域；jdk1.8中有参数&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-XX:MetaspaceSize&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-XX:MaxMetaspaceSize&lt;/code&gt;来设置元空间大小，放在本地直接内存，默认最大元空间是无限大的。
        &lt;ul&gt;
          &lt;li&gt;`java.lang.OutOfMemoryError:PermGen space/ Metaspace
            &lt;ul&gt;
              &lt;li&gt;永久代/元空间溢出，可以调大MaxPermSize 和MaxMetaspaceSize (默认无上限，不设置也行).&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;本地直接内存溢出
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;java.lang.OutOfMemoryError at sun.misc.Unsafe.allocateMemory(native Method)&lt;/code&gt;
        &lt;ul&gt;
          &lt;li&gt;可以调大 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-XX:MaxDirectMemorySize&lt;/code&gt;调大最大直接内存容量&lt;/li&gt;
          &lt;li&gt;netty中会默认使用本地直接内存来缓存数据，可以设置&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-Dio.netty.noPreferDirect=true -Dio.netty.recycler.maxCapacity=0 -Dio.netty.noUnsafe=true&lt;/code&gt;来避免使用堆外内存来避免。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;jvm-args&quot;&gt;JVM Args&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;-Xms1024m  -X 表示是JVM参数， ms是memory start&lt;/li&gt;
  &lt;li&gt;-Xmx1024m  mx是memory max， 线上生产环境建议Xms和Xmx设置一样，避免调整堆大小带来的压力。&lt;/li&gt;
  &lt;li&gt;-Xss256k  ss是Stack Space，是每个线程栈空间大小，因此，这个数值影响可以创建的最大线程数量&lt;/li&gt;
  &lt;li&gt;-XX:NewRatio=4：设置年轻代（包括1个Eden和2个Survivor区）与年老代的比值。表示年轻代比年老代为1:4。&lt;/li&gt;
  &lt;li&gt;-XX:SurvivorRatio=4：设置年轻代中Eden区与Survivor区的比值。表示2个Survivor区与1个Eden区的比值为2:4，即1个Survivor区占整个年轻代大小的1/6。&lt;/li&gt;
  &lt;li&gt;-XX:-PrintGCDetails：每次GC时打印详细信息。&lt;/li&gt;
  &lt;li&gt;-Dio.netty.noPreferDirect=true
    &lt;ul&gt;
      &lt;li&gt;格式： java -D&amp;lt;name&amp;gt;=&amp;lt;value&amp;gt;&lt;/li&gt;
      &lt;li&gt;作用: 设置一个系统属性值，如果这个value是一个包含空格的String，那么需要使用双引号包裹这个String.&lt;/li&gt;
      &lt;li&gt;获取设置的值： System.getProperty(“name”)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
                <link>http://www.turbofei.wang/essay/2019/06/07/about-jvm</link>
                <guid>http://www.turbofei.wang/essay/2019/06/07/about-jvm</guid>
                <pubDate>2019-06-07T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>Optimization For Spark Shuffle In Netease</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#前言&quot; id=&quot;markdown-toc-前言&quot;&gt;前言&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#can-fetch&quot; id=&quot;markdown-toc-can-fetch&quot;&gt;Can Fetch&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#描述&quot; id=&quot;markdown-toc-描述&quot;&gt;描述&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#优化方案&quot; id=&quot;markdown-toc-优化方案&quot;&gt;优化方案&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#相关链接&quot; id=&quot;markdown-toc-相关链接&quot;&gt;相关链接&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#fetch-efficiently&quot; id=&quot;markdown-toc-fetch-efficiently&quot;&gt;Fetch Efficiently&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#描述-1&quot; id=&quot;markdown-toc-描述-1&quot;&gt;描述&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#优化方案-1&quot; id=&quot;markdown-toc-优化方案-1&quot;&gt;优化方案&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#相关链接-1&quot; id=&quot;markdown-toc-相关链接-1&quot;&gt;相关链接&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#reliable-fetch&quot; id=&quot;markdown-toc-reliable-fetch&quot;&gt;Reliable Fetch&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#描述-2&quot; id=&quot;markdown-toc-描述-2&quot;&gt;描述&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#优化方案-2&quot; id=&quot;markdown-toc-优化方案-2&quot;&gt;优化方案&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#shuffle-write-phase&quot; id=&quot;markdown-toc-shuffle-write-phase&quot;&gt;Shuffle Write Phase&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#shuffle-read-phase&quot; id=&quot;markdown-toc-shuffle-read-phase&quot;&gt;Shuffle Read Phase&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#性能测试&quot; id=&quot;markdown-toc-性能测试&quot;&gt;性能测试&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#相关链接-2&quot; id=&quot;markdown-toc-相关链接-2&quot;&gt;相关链接&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;

&lt;p&gt;本文讲在网易工作将近一年来关于Spark Shuffle方面所做的三点优化。&lt;/p&gt;

&lt;h3 id=&quot;前言&quot;&gt;前言&lt;/h3&gt;

&lt;p&gt;Spark是目前主流的大数据计算引擎，而Shuffle操作是Spark计算中的的核心操作，也往往是瓶颈所在。首先简单介绍下Shuffle操作。如下图所示.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/spark-shuffle-optimization/shuffle-1.png&quot; alt=&quot;Spark Shuffle 过程&quot; /&gt;&lt;/p&gt;

&lt;p&gt;map端负责对数据进行重新分区(Shuffle Write)，可能有排序操作，而reduce端拉取数据各个mapper对应分区的数据(Shuffle Read)，然后对这些数据进行计算。Shuffle过程中伴随着大量的数据传输。在大数据生产环境中，数据规模日益增长，数据量大了什么事情都有可能发生，可能会产生各种各样的问题，而大多数问题都与shuffle有关。由于Shuffle数据传输是由Shuffle read端fetch数据，因此本文使用fetch代表传输。&lt;/p&gt;

&lt;p&gt;本文主要讲关于Spark Shuffle传输方面的三点优化。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;可以传输  Can Fetch.&lt;/li&gt;
  &lt;li&gt;高效率传输 Fetch Efficiently.&lt;/li&gt;
  &lt;li&gt;可靠的传输 Reliable Fetch.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;can-fetch&quot;&gt;Can Fetch&lt;/h3&gt;

&lt;p&gt;通常来说，Spark作为一个主流的大数据计算引擎，是可以传输大多数的Shuffle数据的。但是在大数据生产中，往往面临一些极端的shuffle情况。下面的案例是来自网易云音乐的用户。&lt;/p&gt;

&lt;h4 id=&quot;描述&quot;&gt;描述&lt;/h4&gt;

&lt;p&gt;一天用户告诉我他有一个任务在Shuffle Read阶段出错，每天都要重试，有时候重试一次，有时候重试几次可以成功。任务报错如下:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;WARN  [shuffle-client-6-2:TransportChannelHandler@78] - Exception in connection from hostName/hostIp:7337
java.lang.IllegalArgumentException: Too large frame: 2991947178
	at org.spark_project.guava.base.Preconditions.checkArgument(Preconditions.java:119)
	at org.apache.spark.network.util.TransportFrameDecoder.decodeNext(TransportFrameDecoder.java:133)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:81)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;通过观察日志，我发现，是用户的一个MapTask发生了严重的数据倾斜，导致了这个MapTask写文件时有一个partition的数据量超过了2GB。而spark 使用netty进行数据传输，单个chunk有一个严格的2GB限制，因此这必然导致了在一次拉取单个partition shuffle 数据大于2GB时的失败。&lt;/p&gt;

&lt;p&gt;那么用户又为什么任务可以重试成功呢？通过观察spark 日志页面.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/spark-shuffle-optimization/shuffle-2.png&quot; alt=&quot;应用日志页面&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以发现此task在shuffle read端读取数据量为2.5GB，而从远端节点读取的数据量仅为42.5MB，原来是因为在该task失败之后，会进行重试，task可能重新调度到该oversize的partition所在的节点，这样数据就在本地，不用从网络中拉取，自然也不会触发到2GB的限制。&lt;/p&gt;

&lt;p&gt;看来用户还是比较幸运的，重试之后可以刚好调度在数据所在节点执行task。那么如果有两个partition的数据都发生了严重的倾斜，而且这两个partition不在同一个节点之上，那样无论任务怎么重新调度，都必然至少有一个partition无法fetch，这必然造成了task的失败，进一步造成application的失败。&lt;/p&gt;

&lt;p&gt;继续分析这个问题，spark有一个参数&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.maxRemoteBlockSizeFetchToMem&lt;/code&gt;,代表着可以从远端拉取数据放入内存的最大size。如果这一批要拉取的数据大小之和小于这个值，那么spark 使用fetch chunk的方式，都是一次拉取一整块的partition数据，然后放在内存里。如果一批要拉取数据大小之和大于这个size，就会采用fetchStream的方式，将这些partition数据流式拉取到本地保存为本地文件。&lt;/p&gt;

&lt;p&gt;在spark2.4之前这个参数默认都是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Long.MaxValue&lt;/code&gt;，这个值是超级大的，所以可以认为spark2.4之前如果你没有对这个参数进行额外设置，比如设置为2G，1500m，就可以说你的所有partition拉取都是一次进行。&lt;/p&gt;

&lt;p&gt;而spark2.4之后，对该参数的默认值更改为&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Integet.MaxValue-512&lt;/code&gt;，也就是说，这样的参数就不会触发到一次性拉取一个大于2GB的数据了。&lt;/p&gt;

&lt;h4 id=&quot;优化方案&quot;&gt;优化方案&lt;/h4&gt;

&lt;p&gt;问题已经分析的很明确。该问题的解决方案可以分为三种。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;通过设置&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.maxRemoteBlockSizeFetchToMem&lt;/code&gt;为小于2GB，来避免发生这个问题，这是最简单的&lt;/li&gt;
  &lt;li&gt;或者是用户解决数据倾斜的问题&lt;/li&gt;
  &lt;li&gt;从平台侧解决这个问题。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;讲一下从平台侧对这个问题的解决，Spark作为一个大数据计算引擎，一个partition有超过2GB的数据并不过分，而作为一个大数据平台开发，自然要积极从平台侧出发。&lt;/p&gt;

&lt;p&gt;而虽然能够通过配置&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.maxRemoteBlockSizeFetchToMem&lt;/code&gt;小于2GB来避免这个问题的发生，但是这也造成了即使我们在资源充足的情况下，也不能将这个参数设为一个大于2GB的值，而这也就造成了有时候即使我们内存资源充足，当我们一批fetch数据大于2GB时也要将这些数据进行落盘，新增了一些I/O开销。因此，我们能不能突破这个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.maxRemoteBlockSizeFetchToMem&lt;/code&gt;不能设置大于2GB的限制，在任何设置下都能成功的取到数据呢？&lt;/p&gt;

&lt;p&gt;其实一开始看到用户的任务可以通过重新调度到partition所在节点上解决之后，曾经想过使用调度优化来解决，但是前面也提过，如果有两个partition oversize，那么这个任务必定失败。&lt;/p&gt;

&lt;p&gt;因此想到了对比较大的partition进行划分，每次拉取一部分数据，这样就不会触发到netty的2GB限制。&lt;/p&gt;

&lt;p&gt;首先描述一下目前Spark &lt;strong&gt;在没有达到&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.maxRemoteBlockSizeFetchToMem&lt;/code&gt;限制时拉取数据的过程&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/spark-shuffle-optimization/shuffle-3.png&quot; alt=&quot;shuffle fetch 数据过程(批量拉取量未超过最大放入内存阈值)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如上图所示，可以看到，shuffle read端将每个partition对应的数据，作为一个ManagedBuffer拉取过来，存放在一个阻塞队列中，之后task会依次去取这些数据进行计算。这就是目前shuffle fetch的不足之处，不管对应的partition有多大，只要这批拉取数据量小于&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.maxRemoteBlockSizeFetchToMem&lt;/code&gt;都一次性去取过来。&lt;/p&gt;

&lt;p&gt;我们针对此方案作出了优化：现简单描述如下:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;设置Shuffle一次可以fetch的阈值&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SHUFFLE_FETCH_THRESHOLD&lt;/code&gt;为2GB&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;设置一个参数&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.shuffle.fetch.split&lt;/code&gt;来控制是否使用本方案拉取数据&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在创建mapStatus阶段，计算每个partition需要被fetch的次数 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;size/SHUFFLE_FETCH_THRESHOLD&lt;/code&gt;保存为map.为了节省内存空间只保存次数1次以上的, 从map中获取不到则为1次。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;定义一种新的BlockId 为&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ShuffleBlockSegmentId&lt;/code&gt;，用来让shuffle 服务端来识别出来我们要使用什么样的方案获取数据。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在shuffle client端，根据&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.shuffle.fetch.split&lt;/code&gt;参数来创建我们要发送到shuffle 服务端的BlockID类型，如果是多次拉取，则创建&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ShuffleBlockSegmentId&lt;/code&gt;,否则还是之前的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ShuffleBlockId&lt;/code&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;对于一个ShuffleBlockID对应的partition数据，使用一个buf的Sequence来保存，而不是原来的只用一个buf来保存。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;由于我们现在分多次拉取一个partition的数据，因此需要这个partition数据完全拉取结束之后才能进入原来的LinkedBlockingQueue, 因此我们使用一个PriorityBlockingQueue来存放一个partition对应的多块数据，而且优先级阻塞队列还提供了排序功能，我们可以保证一个partition的数据是按序排放。当该ShuffleBlockId对应的所有数据都拉取过来之后，将放在优先级队列中的buf出队，然后放入LinkedBlockingQueue中，供task用于取数据计算。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在shuffle服务端，通过识别我们发送的blockId类型来决定如何取数据，如果是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ShuffleBlockSegmentId&lt;/code&gt;,则取一块数据，否则，取全部数据。&lt;/p&gt;

    &lt;p&gt;新方案拉取过程如下图所示:&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/imgs/spark-shuffle-optimization/shuffle-4.png&quot; alt=&quot;新方案Shuffle fetch过程&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;通过此方案，我们就可以突破&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.maxRemoteBlockSizeFetchToMem&lt;/code&gt;2GB和单partition数据量大于2GB的限制，为所欲为。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;相关链接&quot;&gt;相关链接&lt;/h4&gt;

&lt;p&gt;另外由于近期&lt;a href=&quot;https://github.com/apache/spark/pull/24565&quot;&gt;PR-SPARK-27665&lt;/a&gt;的合入，我对新的shuffle fetch消息类型，也进行了适配。&lt;/p&gt;

&lt;p&gt;对应Jira &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-27876&quot;&gt; SPARK-27876&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;对应PR &lt;a href=&quot;https://github.com/apache/spark/pull/24740&quot;&gt;SPARK-27876&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;fetch-efficiently&quot;&gt;Fetch Efficiently&lt;/h3&gt;

&lt;p&gt;除了上面的能够传输，我们还要高效率的传输。下面的案例来自考拉的一个用户。&lt;/p&gt;

&lt;h4 id=&quot;描述-1&quot;&gt;描述&lt;/h4&gt;

&lt;p&gt;考拉的一个用户告诉我，他近期的部分任务大量延迟，虽然没有task失败，但是运行时间比平时多了很多。&lt;/p&gt;

&lt;p&gt;还是看日志，通过观察日志，发现用户的任务中有大量的shuffle-client拉取数据超时，然后重试的操作。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;2019-04-26 12:18:49,848 [25708] - INFO  [Executor task launch worker for task 1689:Logging$class@54] - Started reading broadcast variable 5
2019-04-26 12:18:49,906 [25766] - INFO  [Executor task launch worker for task 1689:TransportClientFactory@254] - Successfully created connection to hadoop3977.jd.163.org/hostIp:38939 after 1 ms (0 ms spent in bootstraps)
2019-04-26 12:18:50,291 [26151] - WARN  [shuffle-client-4-1:TransportChannelHandler@78] - Exception in connection from hadoop3977.jd.163.org/hostIp:38939
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;重试操作是spark shuffle 阶段的一个优化，这可以避免由于网络或者节点暂时繁忙而导致拉取数据失败，而是可以多重试几次，保证数据拉取的健壮性，避免贸然的失败。可以使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.shuffle.io.maxRetries&lt;/code&gt; 和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.shuffle.io.retryWait&lt;/code&gt;来配置最大重试次数与重试时间间隔。&lt;/p&gt;

&lt;p&gt;日志中是说，这个shuffle-client一直连接超时，然后不断重试，直到将重试次数用尽。如果我们配置的最大重试次数为15次，重试间隔为20s的话，这样一个task不断重试下来就要推迟五分钟，如果很多的task推迟，后果很严重。&lt;/p&gt;

&lt;p&gt;首先介绍一下shuffle client， spark中有两种shuffle client。一种是blockTransferService，用于拉取由spark自身管理的数据；另外一种是 ExternalShuffleClient，是用于拉取外部shuffle 服务的数据。常用的ExternalShuffleService是yarn上的shuffle service，它独立运行在yarn集群上的每个nodemanager之上，用于管理spark在运行阶段生成的shuffle数据，因此spark上的executor就不用自己管理自己的shuffle 数据。这也就为executor的动态回收提供了可能，因此如果没有额外的shuffle Service帮助这些executor管理他们的shuffle数据， 如果一个executor回收掉了，那么这些shuffle数据也就不可见。因此在spark中，如果要使用executor动态回收，必须要有对应的外部shuffle Service。&lt;/p&gt;

&lt;p&gt;前面说了有两种shuffle client，blockTransferService是用于拉取由spark自身管理的数据，现在有了ExternalShuffleService用于管理shuffle 数据，那么blockTransferService还有什么作用呢？那就是拉取Broadcast数据。&lt;/p&gt;

&lt;p&gt;上面的日志也是说重试时发生在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;reading broadcast variable&lt;/code&gt;阶段。&lt;/p&gt;

&lt;p&gt;通过对日志进行详细的分析,问题如下:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;executorA 要拉取Broadcast变量，向executorB建立连接，成功。&lt;/li&gt;
  &lt;li&gt;建立连接成功之后，由于executorB到达最大空闲时间，被动态回收。&lt;/li&gt;
  &lt;li&gt;executorA取数据时候发生超时，然后重试，重试必然会失败。&lt;/li&gt;
  &lt;li&gt;不断重试，直到重试此处用尽，之后executorA向Driver索要数据，成功。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;整个流程下来，这个task并没有失败，但是花费了大量的时间在不断的重试之上。&lt;/p&gt;

&lt;h4 id=&quot;优化方案-1&quot;&gt;优化方案&lt;/h4&gt;

&lt;p&gt;通过对问题深入的分析，发现问题出现在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RetryingBlockFetcher&lt;/code&gt;的重试逻辑。&lt;/p&gt;

&lt;p&gt;其重试逻辑如下:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;如果当前异常为IOException(网络也是一种IO)。&lt;/li&gt;
  &lt;li&gt;并且此时还有重试次数未用尽，那就继续重试。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;但是当初设计这个重试逻辑的人可能忽略了ExecutorDynamicAllocation，因为executor很容易被回收，当fetch数据时相关的节点已经死掉时，也会抛出IO异常，因此这会触发&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RetryingBlockFetcher&lt;/code&gt;的重试逻辑，但是这样的重试显然是毫无意义的，因此你永远不可能向一个已经死掉的executor索要数据。&lt;/p&gt;

&lt;p&gt;因此，我对此重试进行了优化。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;设置一种新的消息类型, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;IsExecutorAlive&lt;/code&gt;.在BlockTransferService捕获到IOException时，发往driver。&lt;/li&gt;
  &lt;li&gt;driver根据消息中的executorID来查找自己维护的一个以executorId为key的map，时间复杂度为o(1)，如果此executorId在map中则代表存活，否则，该Executor已经被回收.&lt;/li&gt;
  &lt;li&gt;回复executorId对应的Executor状态给索要信息的executor。&lt;/li&gt;
  &lt;li&gt;根据返回结果，如果该executor依然存活，则重试，否则，抛出ExecutorDeadException，重试结束。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;核心代码如下:&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;OneForOneBlockFetcher&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;client&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;appId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;execId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blockIds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;listener&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;transportConf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tempFileManager&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;IOException&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt;
              &lt;span class=&quot;nc&quot;&gt;Try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;nv&quot;&gt;driverEndPointRef&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;askSync&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Boolean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;IsExecutorAlive&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
              &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Success&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
                  &lt;span class=&quot;k&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ExecutorDeadException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;The relative remote executor(Id: $execId),&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
                    &lt;span class=&quot;s&quot;&gt;&quot; which maintains the block data to fetch is dead.&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;
              &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;通过对shuffle-client(blockTransferService)重试逻辑的优化，我们可以避免无意义的重试，高效率的进行数据传输，提高应用性能。&lt;/p&gt;

&lt;h4 id=&quot;相关链接-1&quot;&gt;相关链接&lt;/h4&gt;

&lt;p&gt;该PR已经合入Spark master分支.&lt;/p&gt;

&lt;p&gt;对应Jira &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-27637&quot;&gt; SPARK-27637&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;对应PR &lt;a href=&quot;https://github.com/apache/spark/pull/24533&quot;&gt;SPARK-27637&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;reliable-fetch&quot;&gt;Reliable Fetch&lt;/h3&gt;

&lt;p&gt;前面提到了Can fetch, fetch efficiently，保证了可以传输任何数据，可以高效率的传输数据，数据传输的可靠性也是必要的，最后一部分聊一聊我们针对spark shuffle数据传输的可靠性做的优化。&lt;/p&gt;

&lt;h4 id=&quot;描述-2&quot;&gt;描述&lt;/h4&gt;

&lt;p&gt;前面已经讲过spark shuffle过程中有大量的网络传输，也讲过shuffle read端fetch数据的过程。既然有大量的网络传输，那么就可能会有数据传输出错，所以对数据的校验是必不可少的。&lt;/p&gt;

&lt;p&gt;shuffle read端在拉取到数据之后，首先会进行数据校验，然后进行后续的计算，如果该校验没有校验出数据的问题，而在后续的计算过程中发现该数据已经损坏，那么就会导致该task失败。&lt;/p&gt;

&lt;p&gt;会报以下类似异常.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;18/11/13 08:10:08 INFO client.TransportClientFactory: Successfully created connection to hadoop2997.lt.163.org/hostIp:7337 after 0 ms (0 ms spent in bootstraps) 18/11/13 08:10:08 ERROR util.Utils: Aborting task java.io.IOException: FAILED_TO_UNCOMPRESS(5) at org.xerial.snappy.SnappyNative.throw_error(SnappyNative.java:98) at org.xerial.snappy.SnappyNative.rawUncompress(Native Method) at org.xerial.snappy.Snappy.rawUncompress(Snappy.java:474) at 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这个异常是在后续计算过程中报的，说明目前的spark shuffle 数据校验机制存在问题。&lt;/p&gt;

&lt;p&gt;首先描述一下在一个&lt;a href=&quot;https://github.com/apache/spark/pull/23453&quot;&gt;相关PR SPARK-26089&lt;/a&gt;合入之前存在的问题.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;只校验使用数据压缩格式(例如snappy,lz4)的数据，而非压缩的数据不进行校验。&lt;/li&gt;
  &lt;li&gt;只能校验小于&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;maxBytesInFlight/3&lt;/code&gt;(默认maxBytesInflight为48M)的数据,大小有局限&lt;/li&gt;
  &lt;li&gt;采用创建的一个outputStream,然后将InputStream传入，然后再基于这个outputStream创建inputStream的方式来校验，会浪费内存&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/pull/23453&quot;&gt;相关PR SPARK-26089&lt;/a&gt;合入解决了部分问题:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;针对较大的数据，也可以校验，但是只校验开头的一小部分，后面的数据不进行校验，如果后面的数据出错依然会造成task失败&lt;/li&gt;
  &lt;li&gt;采用新的校验方法取代之前的流拷贝校验方法，内存浪费情况得到改善。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;但是依然存在以下问题:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;无法校验未使用数据压缩格式的数据，谁又能确定不使用压缩格式就不出错呢？&lt;/li&gt;
  &lt;li&gt;针对较大的数据，只校验起始部分，依然存在后续数据corrupt的风险&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;优化方案-2&quot;&gt;优化方案&lt;/h4&gt;

&lt;p&gt;我们通过针对线上的流数据corrupt异常分析以及对目前spark的校验机制分析，提出了一个相较完善的Spark shuffle 数据校验机制。&lt;/p&gt;

&lt;p&gt;首先，我们需要选择一种数据通信校验码。通过对比了md5, sha系列，以及crc32等几种校验码，我们选取了crc32，因此crc它快速而又简单，完全满足生产需求，hadoop也是使用crc来作为数据校验码.&lt;/p&gt;

&lt;p&gt;我们的方案简单描述如下:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;shuffle map阶段针对每个partition计算其crc值，将这些crc值存储&lt;/li&gt;
  &lt;li&gt;在shuffle read阶段拉取数据时，将数据对应的crc值与数据一起发送&lt;/li&gt;
  &lt;li&gt;shuffle read端针对拉取的数据重新计算crc值，与原有的crc值进行比对，比对相同，则代表数据传输没有问题，反之，有问题。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下面是具体实现。&lt;/p&gt;

&lt;h5 id=&quot;shuffle-write-phase&quot;&gt;Shuffle Write Phase&lt;/h5&gt;

&lt;p&gt;首先简单介绍一下shuffle write。shuffle writer分为三种，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BypassMergeSortShuffleWriter&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SortShuffleWriter&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UnsafeShuffleWriter&lt;/code&gt;. BypassShuffleWriter最后写的shuffle block组织方式与后两种不同，后两种shuffle writer的shuffle block文件组织方式是相同的。&lt;/p&gt;

&lt;p&gt;如下图所示.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/spark-shuffle-optimization/shuffle-5.png&quot; alt=&quot;ShuffleWriter&quot; /&gt;&lt;/p&gt;

&lt;p&gt;由图可见，如果一个shuffle过程有m个mapper, n个reducer。那么BypassShuffleWriter会创建 m*n个shuffle文件，如果m和n都比较大，比如m=n=5000，那么就会创建2500万个文件，这很可怕，所以BypassShuffleWriter默认只会在reducer个数少于200的时候使用，可以通过&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.shuffle.sort.bypassMergeThreshold&lt;/code&gt;配置这个参数。&lt;/p&gt;

&lt;p&gt;而SortShuffleWriter和UnsafeShuffleWriter的组织shuffle文件的方法是一样的，这是针对BypassShuffleWriter的改进。由图可见，这两种shuffleWriter只会针对一个mapTask创建一个shuffle文件，建立一个索引文件记录每个划分之后的partition数据在这个文件中的偏移量(BypassShuffleWriter也有这样的索引文件)。这样每个mapTask只创建了两个文件，一个数据文件，一个索引文件，大大减小了文件的数量，减小了系统的压力。&lt;/p&gt;

&lt;p&gt;而我们会在shuffle阶段数据处理完成之后，根据索引文件中记录的每个partition的偏移量计算每个partition的crc值，这个计算过程是很快的，crc是一个高效的校验码，而且通常(后两种ShuffleWriter是通常使用的)我们只需打开一个输入流，从头计算到尾，这是一个很高效的过程。&lt;/p&gt;

&lt;p&gt;计算完成之后，我们将这些计算的crc值也存到到前面提到的shuffle索引文件，组织方式如下图。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/spark-shuffle-optimization/shuffle-6.png&quot; alt=&quot;Shuffle-index-file&quot; /&gt;&lt;/p&gt;

&lt;p&gt;原有的index文件保存的是每个分区的偏移量，都是long类型，每个偏移量占用8字节，因此其长度是8的倍数。&lt;/p&gt;

&lt;p&gt;如果我们在原有的index文件后面添加计算的crc值，我们会加一个标志位，占用一个字节，之后的每个crc32值都是一个long类型，占用8字节，这样新的index文件长度就是(8y+1)，永远不可能是8的倍数，而原有的shuffle index文件长度一定是8的倍数，这样ExternalSHuffleService也能都轻易识别出我们是否使用了crc校验，和老版本的spark进行兼容。&lt;/p&gt;

&lt;h5 id=&quot;shuffle-read-phase&quot;&gt;Shuffle Read Phase&lt;/h5&gt;

&lt;p&gt;前面已经提到过shuffle fetch数据的过程，只不过这里会在读数据时候，将map阶段计算的对应partition部分的crc值也一起拉取过来，然后与拉取过来的数据重新计算得到的crc值进行对比。&lt;/p&gt;

&lt;p&gt;前面也提到过，如果一批拉取的数据的量小于&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.maxRemoteBlockSizeFetchToMem&lt;/code&gt;是会将数据全部放在内存中的，只有超过这个数量才会将远端的数据先落磁盘然后之后再读取，因此保存在磁盘中的数据，包括本地的shuffle block文件与远端拉取落磁盘的文件。&lt;/p&gt;

&lt;p&gt;针对远端拉取过来放在内存中的数据，由于其本身就在内存，因此对其计算crc值是十分迅速的，而且内存中inputStream支持reset操作，我们在计算crc之后，进行一下reset操作，就可以继续将这个inputStream用于后续的task计算。&lt;/p&gt;

&lt;p&gt;而针对在磁盘中数据，我们对其计算crc值，前面提过了crc是一个高效的校验码，这个过程也是很快的， 在将从磁盘数据得到的inputStream计算完之后，只需要将该inputStream关掉，然后重新从这个磁盘文件创建一个新的inputStream用于后续的task计算。&lt;/p&gt;

&lt;p&gt;而在整个map阶段和reduce阶段，计算crc值只需要一个几十kb的缓冲区。&lt;/p&gt;

&lt;p&gt;在shuffle read端计算完crc值之后，可以跟原来的crc值对比，如果对比一致，则代表该数据没有问题，否则就要进行一系列的处理逻辑，此处不再赘述。&lt;/p&gt;

&lt;p&gt;这样，我们的shuffle校验机制就针对目前的spark shuffle校验机制进行了完善，可以校验非压缩的数据，可以校验任意大小的数据，cover所有场景。&lt;/p&gt;

&lt;h4 id=&quot;性能测试&quot;&gt;性能测试&lt;/h4&gt;

&lt;p&gt;我们使用tpcds测试工具，针对1t和10t的数据进行了该校验算法的性能测试，其测试结果表明该算法不会对spark本身的执行性能造成影响，且在10T测试数据下， 由于最老版本的shuffle校验采用流拷贝，可能开销比较重，我们的shuffle校验机制，对比其有轻微的性能提升。针对最近合入的&lt;a href=&quot;https://github.com/apache/spark/pull/23453&quot;&gt;相关PR SPARK-26089&lt;/a&gt;，我们还没有进行性能测试对比，但是相信，我们的shuffle校验机制对比其不会有性能下降。&lt;/p&gt;

&lt;h4 id=&quot;相关链接-2&quot;&gt;相关链接&lt;/h4&gt;

&lt;p&gt;对应Jira &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-27562&quot;&gt; SPARK-27562&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;对应PR &lt;a href=&quot;https://github.com/apache/spark/pull/24447&quot;&gt;SPARK-27562&lt;/a&gt;&lt;/p&gt;
</description>
                <link>http://www.turbofei.wang/spark/2019/05/30/Optimization-for-spark-shuffle-in-netease</link>
                <guid>http://www.turbofei.wang/spark/2019/05/30/Optimization-for-spark-shuffle-in-netease</guid>
                <pubDate>2019-05-30T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>Java Concurrent Collection</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#linkedblockingqueue&quot; id=&quot;markdown-toc-linkedblockingqueue&quot;&gt;LinkedBlockingQueue&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#use-case&quot; id=&quot;markdown-toc-use-case&quot;&gt;Use Case&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#priorityblockingqueue&quot; id=&quot;markdown-toc-priorityblockingqueue&quot;&gt;PriorityBlockingQueue&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#use-case-1&quot; id=&quot;markdown-toc-use-case-1&quot;&gt;Use Case&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;

&lt;p&gt;java.util.concurrent 包是java中多线程使用的包。里面的内容包括&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;atomic包  提供了一些原子操作的类型，比如atomicLong, atomicReference&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;lock包&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;AbstractQueuedSynchronizer, AQS&lt;/li&gt;
      &lt;li&gt;Condition 用于准确通知解锁&lt;/li&gt;
      &lt;li&gt;LockSupport 提供 park 和 unpark方法&lt;/li&gt;
      &lt;li&gt;ReentrantLock可重入锁&lt;/li&gt;
      &lt;li&gt;ReadWriteLock 读写锁&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;线程池类以及线程相关类&lt;/li&gt;
  &lt;li&gt;并发集合&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;本文讲几个并发集合. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LinkedBlockingQueue&lt;/code&gt; 和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PriorityBlockingQueue&lt;/code&gt;.&lt;/p&gt;

&lt;h4 id=&quot;linkedblockingqueue&quot;&gt;LinkedBlockingQueue&lt;/h4&gt;

&lt;p&gt;首先看一下抽象类BlockingQueue有哪些操作。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;add(e)  成功返回true，空间已满抛异常。&lt;/li&gt;
  &lt;li&gt;offer(e) 插入成功返回true，当前无空间可用返回false。如果是一个空间限制队列，建议用offer方法。&lt;/li&gt;
  &lt;li&gt;put(e)  阻塞一直等待直到插入成功&lt;/li&gt;
  &lt;li&gt;offer(e,timeout,timeunit) 有timeout的offer&lt;/li&gt;
  &lt;li&gt;take 尝试获得队列头部的元素，阻塞直到获得&lt;/li&gt;
  &lt;li&gt;poll(timeout, timeunit) 尝试获得队列头部元素，直到超时&lt;/li&gt;
  &lt;li&gt;remove(object) 移除队列中equal的元素，有多个就移除多个，如果队列中包含这个元素，返回true，否则 false&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;use-case&quot;&gt;Use Case&lt;/h5&gt;

&lt;p&gt;通常用于生产者消费者模型，线程间通信。&lt;/p&gt;

&lt;p&gt;生产者生产任务，然后消费者去取任务。&lt;/p&gt;

&lt;p&gt;如spark中，在shuffleFetchIterator中就使用了LinkedBlockingQueue来保存fetch到的数据，将结果保存到阻塞队列，然后取数据的队列调用take方法来取result。&lt;/p&gt;

&lt;p&gt;在线程池中，就需要一个阻塞队列作为工作队列。&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;ThreadPoolExecutor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;corePoolSize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
                              &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maximumPoolSize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
                              &lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepAliveTime&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
                              &lt;span class=&quot;nc&quot;&gt;TimeUnit&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;unit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
                              &lt;span class=&quot;nc&quot;&gt;BlockingQueue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Runnable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;workQueue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
                              &lt;span class=&quot;nc&quot;&gt;ThreadFactory&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threadFactory&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;corePoolSize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maximumPoolSize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepAliveTime&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;unit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;workQueue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
             &lt;span class=&quot;n&quot;&gt;threadFactory&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;defaultHandler&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里面的阻塞队列用于让用于来提交task到这个工作队列中，然后线程池中的线程来取这个task进行执行。&lt;/p&gt;

&lt;h4 id=&quot;priorityblockingqueue&quot;&gt;PriorityBlockingQueue&lt;/h4&gt;

&lt;p&gt;优先级阻塞队列,是PriorityQueue的线程安全模式。&lt;/p&gt;

&lt;p&gt;所以只需要了解一下PriorityQueue,优先级队列，底层实现为堆,是一个无界队列。&lt;/p&gt;

&lt;p&gt;优先级队列给每个元素提供了一个优先级，然后对这些元素按照优先级进行排序。如果指定了comparator则按照指定的比较规则进行排序，如果没有指定，那么按照自然序进行排序，如数字就比较大小，小的在前，如果是字符串，则按照字典序。&lt;/p&gt;

&lt;p&gt;由于底层为堆，可以用于堆排序，比如获得n个数中前k大的值，属于最优实现。&lt;/p&gt;

&lt;p&gt;因为是最小的值放在堆顶，那么只要新的值大于目前已有k个值的最小值，就可以成为前k大，下面是topK的实现。由于优先级队列是无界的，所以需要我们自己来控制是否插入。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;java.util.PriorityQueue&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.collection.JavaConverters._&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;HeapSortTopK&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;topK&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;maxHeap&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;PriorityQueue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;nf&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;until&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;nv&quot;&gt;maxHeap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;offer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;nv&quot;&gt;maxHeap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;offer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;maxHeap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;poll&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;nv&quot;&gt;maxHeap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;asScala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;toArray&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;其他操作，比如offer 和 Poll 操作和以上的LinkedBlockingQueue是一样的。&lt;/p&gt;

&lt;h5 id=&quot;use-case-1&quot;&gt;Use Case&lt;/h5&gt;

&lt;p&gt;使用场景是一些需要安排优先级的场景。&lt;/p&gt;

&lt;p&gt;在spark中，在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ShutdownHookManager&lt;/code&gt;中使用了优先级队列。因为有些Hook需要先执行，所以需要安排优先级。&lt;/p&gt;

&lt;p&gt;或者是基于无界的PriorityQueue实现有界的优先级队列，只需要在插入元素的时候判断一下目前的size即可，如果已经到达界限，则进行替换。&lt;/p&gt;

&lt;p&gt;下面是spark中有界优先级队列的实现。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;java.io.Serializable&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;java.util.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;PriorityQueue&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;JPriorityQueue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.collection.JavaConverters._&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.collection.generic.Growable&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/**
 * Bounded priority queue. This class wraps the original PriorityQueue
 * class and modifies it such that only the top K elements are retained.
 * The top K elements are defined by an implicit Ordering[A].
 */&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;private&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BoundedPriorityQueue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maxSize&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;implicit&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ord&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Ordering&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Iterable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Growable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Serializable&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;underlying&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;JPriorityQueue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maxSize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;iterator&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;underlying&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;asScala&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;underlying&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;size&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;++=&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xs&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;TraversableOnce&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;this.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;xs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;foreach&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;+=&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;this.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maxSize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;nv&quot;&gt;underlying&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;offer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;nf&quot;&gt;maybeReplaceLowest&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;poll&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;underlying&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;poll&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;+=&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;elem1&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;elem2&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;elems&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;A*&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;this.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;elem1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;elem2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;++=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;elems&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;clear&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;underlying&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;clear&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;maybeReplaceLowest&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Boolean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;head&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;underlying&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;peek&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;ord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;gt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;nv&quot;&gt;underlying&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;poll&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
      &lt;span class=&quot;nv&quot;&gt;underlying&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;offer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
                <link>http://www.turbofei.wang/coding/2019/05/26/java-concurrent-collection</link>
                <guid>http://www.turbofei.wang/coding/2019/05/26/java-concurrent-collection</guid>
                <pubDate>2019-05-26T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>About Spark Streaming</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#spark-streaming&quot; id=&quot;markdown-toc-spark-streaming&quot;&gt;Spark Streaming&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#streamingcontext&quot; id=&quot;markdown-toc-streamingcontext&quot;&gt;StreamingContext&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#jobscheduler&quot; id=&quot;markdown-toc-jobscheduler&quot;&gt;JobScheduler&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#executorallocationmanager&quot; id=&quot;markdown-toc-executorallocationmanager&quot;&gt;ExecutorAllocationManager&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#调度&quot; id=&quot;markdown-toc-调度&quot;&gt;调度&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#structed-streaming&quot; id=&quot;markdown-toc-structed-streaming&quot;&gt;Structed Streaming&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#基本概念&quot; id=&quot;markdown-toc-基本概念&quot;&gt;基本概念&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#example&quot; id=&quot;markdown-toc-example&quot;&gt;Example&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#to-be-continued&quot; id=&quot;markdown-toc-to-be-continued&quot;&gt;To Be Continued&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;

&lt;p&gt;简单讲解下spark streaming, structed streaming&lt;/p&gt;

&lt;p&gt;我们都知道spark中有两种streaming，一种是spark streaming，另一种是structed streaming。spark streaming是微批处理，隔一段时间提交一批job，底层走的还是rdd。&lt;/p&gt;

&lt;p&gt;而structed streaming是spark为了满足低时延的需求，重新设计的一套流式处理机制。相关的PR是&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-20928&quot;&gt;SPARK-29028 SPIP: Continuous Processing Mode for Structured Streaming&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;spark-streaming&quot;&gt;Spark Streaming&lt;/h3&gt;

&lt;p&gt;首先讲一下微批的streaming。这种streaming 使用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DStream&lt;/code&gt;进行操作，其API与RDD编程类似。其对应的Context为StreamingContext.&lt;/p&gt;

&lt;h4 id=&quot;streamingcontext&quot;&gt;StreamingContext&lt;/h4&gt;

&lt;p&gt;构造如下:&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;ssc&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;StreamingContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparkConf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Seconds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;其底层也是会创建一个SparkContext，只不过StreamingContext提供了一些streaming编程的Api。可以看到后面的2s是微批的频率，每2秒钟触发一次批处理。&lt;/p&gt;

&lt;p&gt;下面是一个HDFSWordCount的例子.&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;nv&quot;&gt;StreamingExamples&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;setStreamingLogLevels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;sparkConf&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SparkConf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;setAppName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;HdfsWordCount&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// Create the context&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;ssc&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;StreamingContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparkConf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Seconds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// Create the FileInputDStream on the directory and use the&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// stream to count words in new files created&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;lines&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;ssc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;textFileStream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;words&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;lines&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;flatMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot; &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;wordCounts&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;words&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;reduceByKey&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;wordCounts&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;ssc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;ssc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;awaitTermination&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;可以看到是先指定好调度频率为2s，然后指定每个批次要执行的动作，然后调用start方法开始处理。&lt;/p&gt;

&lt;p&gt;下面是start方法的核心代码：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ThreadUtils.runInNewThread(&quot;streaming-start&quot;) {
 sparkContext.setCallSite(startSite.get)
 sparkContext.clearJobGroup()
 sparkContext.setLocalProperty(SparkContext.SPARK_JOB_INTERRUPT_ON_CANCEL, &quot;false&quot;)
 savedProperties.set(SerializationUtils.clone(sparkContext.localProperties.get()))
 scheduler.start()
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;可以看到是启动一个新的线程，是为了在设置callsite 以及job group这些 thread local时候不影响当前线程。&lt;/p&gt;

&lt;p&gt;然后这里有一个scheduler.start, 这是 streaming任务的核心， JobScheduler.&lt;/p&gt;

&lt;h4 id=&quot;jobscheduler&quot;&gt;JobScheduler&lt;/h4&gt;

&lt;p&gt;下面是JobScheduler的start方法:&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;synchronized&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eventLoop&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// scheduler has already been started&lt;/span&gt;

    &lt;span class=&quot;nf&quot;&gt;logDebug&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Starting JobScheduler&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;eventLoop&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;EventLoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;JobSchedulerEvent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;JobScheduler&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;onReceive&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;JobSchedulerEvent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;processEvent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

      &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;onError&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Throwable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;reportError&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Error in job scheduler&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;eventLoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;// attach rate controllers of input streams to receive batch completion updates&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;inputDStream&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;ssc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;graph&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;getInputStreams&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;rateController&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;inputDStream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;rateController&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;ssc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;addStreamingListener&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rateController&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;nv&quot;&gt;listenerBus&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;receiverTracker&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ReceiverTracker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ssc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;inputInfoTracker&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;InputInfoTracker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ssc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;executorAllocClient&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ExecutorAllocationClient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;ssc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;sparkContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;schedulerBackend&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ExecutorAllocationClient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;asInstanceOf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;ExecutorAllocationClient&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;executorAllocationManager&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;ExecutorAllocationManager&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;createIfEnabled&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;executorAllocClient&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;receiverTracker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nv&quot;&gt;ssc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nv&quot;&gt;ssc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;graph&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;batchDuration&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;milliseconds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;clock&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;executorAllocationManager&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;foreach&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ssc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;addStreamingListener&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;receiverTracker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;jobGenerator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;executorAllocationManager&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;foreach&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;logInfo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Started JobScheduler&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;主要启动了以下组件:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;receiverTracker 用于接受数据，例如接收从kafka发送的数据&lt;/li&gt;
  &lt;li&gt;inputInfoTracker 统计输入信息，用于监控&lt;/li&gt;
  &lt;li&gt;jobGenerator 用于job生成，每个时间间隔生成一批job&lt;/li&gt;
  &lt;li&gt;executorAllocationManager executor动态分配管理器&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;executorallocationmanager&quot;&gt;ExecutorAllocationManager&lt;/h5&gt;

&lt;p&gt;是否打开由&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.streaming.dynamicAllocation.enabled&lt;/code&gt;控制。可以看出和spark core中的参数很像。也新加了几个参数.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;参数&lt;/th&gt;
      &lt;th&gt;说明&lt;/th&gt;
      &lt;th&gt;默认值&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.streaming.dynamicAllocation.scalingInterval&lt;/td&gt;
      &lt;td&gt;动态分配调整间隔&lt;/td&gt;
      &lt;td&gt;60s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.streaming.dynamicAllocation.scalingUpRatio&lt;/td&gt;
      &lt;td&gt;ratio上限&lt;/td&gt;
      &lt;td&gt;0.9&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.streaming.dynamicAllocation.scalingDownRatio&lt;/td&gt;
      &lt;td&gt;ratio下限&lt;/td&gt;
      &lt;td&gt;0.3&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;这个动态分配管理器和Core中的有何不同呢？&lt;/p&gt;

&lt;p&gt;在core中的管理器是基于空闲时间来控制回收这些executor，而在流处理这些微批中，一个executor空闲是不太可能的，因为每隔很少的时间都会有一批作业被调度，那么在streaming里面如何控制executor的分配和回收呢？&lt;/p&gt;

&lt;p&gt;基本策略是基于每批作业处理的时间来确定是否是idle-ness.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;使用streamingListener来获得每批jobs 处理的时间。&lt;/li&gt;
  &lt;li&gt;周期性的(spark.streaming.dynamicAllocation.scalingInterval)拿jobs处理时间和调度周期做对比。&lt;/li&gt;
  &lt;li&gt;如果 平均处理时间/调度间隔 &amp;gt;=  ratio上限，则调大executor数量。&lt;/li&gt;
  &lt;li&gt;如果 平均处理时间/调度间隔 =&amp;lt;  ratio下限，则调小executor数量。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;默认上限是0.9，下限为0.3。即如果间隔为2s，如果平均处理时间大于等于1.8s，那么就要调大executor；如果平均处理时间小于等于0.6s，那么就要调小executor数量。&lt;/p&gt;

&lt;h5 id=&quot;调度&quot;&gt;调度&lt;/h5&gt;

&lt;p&gt;之后的过程就不详细讲了。最近也在做一个跟streamingListener有关的项目，其实了解调度可以从StreamingListener入手，可以看下listener都记录哪些事件。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;trait&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;StreamingListener&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

  &lt;span class=&quot;cm&quot;&gt;/** Called when the streaming has been started */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;onStreamingStarted&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;streamingStarted&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;StreamingListenerStreamingStarted&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;cm&quot;&gt;/** Called when a receiver has been started */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;onReceiverStarted&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;receiverStarted&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;StreamingListenerReceiverStarted&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;cm&quot;&gt;/** Called when a receiver has reported an error */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;onReceiverError&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;receiverError&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;StreamingListenerReceiverError&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;cm&quot;&gt;/** Called when a receiver has been stopped */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;onReceiverStopped&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;receiverStopped&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;StreamingListenerReceiverStopped&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;cm&quot;&gt;/** Called when a batch of jobs has been submitted for processing. */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;onBatchSubmitted&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batchSubmitted&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;StreamingListenerBatchSubmitted&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;cm&quot;&gt;/** Called when processing of a batch of jobs has started.  */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;onBatchStarted&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batchStarted&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;StreamingListenerBatchStarted&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;cm&quot;&gt;/** Called when processing of a batch of jobs has completed. */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;onBatchCompleted&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batchCompleted&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;StreamingListenerBatchCompleted&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;cm&quot;&gt;/** Called when processing of a job of a batch has started. */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;onOutputOperationStarted&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;outputOperationStarted&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;StreamingListenerOutputOperationStarted&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;cm&quot;&gt;/** Called when processing of a job of a batch has completed. */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;onOutputOperationCompleted&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;outputOperationCompleted&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;StreamingListenerOutputOperationCompleted&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;前面与receiver相关的我们不管，只看跟处理有关的。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;BatchSubmitted 是代表提交了一批jobs,对应的是一个JobSet&lt;/li&gt;
  &lt;li&gt;BatchStartted，当对应的jobSet里面的第一个job开始执行时候触发&lt;/li&gt;
  &lt;li&gt;BatchCompleted，当对应的jobSet里面的所有job都完成时触发&lt;/li&gt;
  &lt;li&gt;OutputOperationStarted 这是对应一个job的开始&lt;/li&gt;
  &lt;li&gt;OutputOperationCompleted 对应一个job的完成&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下面是一批jobs 信息的数据结构。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BatchInfo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;batchTime&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;streamIdToInputInfo&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;StreamInputInfo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;submissionTime&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;processingStartTime&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;processingEndTime&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;outputOperationInfos&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;OutputOperationInfo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;可以看到每个batchInfo对应的key就是一个batchTime，这是独一无二的，最后面有一个outputOperationInfos，这是对应里面每个job的信息，里面包含每个job的failureReason，如果那个job出错的话。&lt;/p&gt;

&lt;p&gt;之后就没啥说的了，最终那些streaming的job还是走的底层RDD，这就和普通的批任务没区别了。&lt;/p&gt;

&lt;h3 id=&quot;structed-streaming&quot;&gt;Structed Streaming&lt;/h3&gt;

&lt;p&gt;在spark Streaming中，最小的可能延迟受限于每批的调度间隔以及任务启动时间。因此，这不能满足更低延迟的需求。&lt;/p&gt;

&lt;p&gt;如果能够连续的处理，尤其是简单的处理而没有任何的阻塞操作。这种连续处理的架构可以使得端到端延迟最低降低到1ms级别，而不是目前的10-100ms级别.&lt;/p&gt;

&lt;h4 id=&quot;基本概念&quot;&gt;基本概念&lt;/h4&gt;

&lt;p&gt;介绍下Epoch, waterMark&lt;/p&gt;

&lt;p&gt;EpochTracker是使用一个AtomicLong来计算EpochID，而其&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;incrementCurrentEpoch&lt;/code&gt;方法只有在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ContinuousCoalesceRDD&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ContinuousWriteRDD&lt;/code&gt;中被调用。也就是说只有在进行类似于shuffle 和action的时候才被调用，所以&lt;strong&gt;Epoch&lt;/strong&gt;类似于RDD执行中的StageId。&lt;/p&gt;

&lt;p&gt;而&lt;strong&gt;waterMark&lt;/strong&gt;是一个标记，代表在这个时间点之前的数据全部都已经完成。&lt;/p&gt;

&lt;h4 id=&quot;example&quot;&gt;Example&lt;/h4&gt;

&lt;p&gt;Structed Streaming的Api 和sql比较类似。下面是一个StructuredNetworkWordCount 的例子.&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;StructuredNetworkWordCount&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;nv&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;err&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Usage: StructuredNetworkWordCount &amp;lt;hostname&amp;gt; &amp;lt;port&amp;gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;nv&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;exit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;host&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;port&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;toInt&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;spark&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SparkSession&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;builder&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;appName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;StructuredNetworkWordCount&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;getOrCreate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;spark.implicits._&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;// Create DataFrame representing the stream of input lines from connection to host:port&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;lines&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;readStream&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;socket&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;host&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;port&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;// Split the lines into words&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;words&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;lines&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;as&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;flatMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot; &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;// Generate running word count&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;wordCounts&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;words&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;groupBy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;// Start running the query that prints the running counts to the console&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;wordCounts&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;writeStream&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;outputMode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;complete&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;console&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;nv&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;awaitTermination&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;可以看到这个写法就像是DataSource一样。&lt;/p&gt;

&lt;p&gt;readStream 和 writeStream 对应的是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DataStreamReader&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DataStreamWriter&lt;/code&gt;.&lt;/p&gt;

&lt;h4 id=&quot;to-be-continued&quot;&gt;To Be Continued&lt;/h4&gt;
</description>
                <link>http://www.turbofei.wang/spark/2019/05/26/about-spark-streaming</link>
                <guid>http://www.turbofei.wang/spark/2019/05/26/about-spark-streaming</guid>
                <pubDate>2019-05-26T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>Scala Match And Regex</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#match&quot; id=&quot;markdown-toc-match&quot;&gt;match&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#提取器&quot; id=&quot;markdown-toc-提取器&quot;&gt;提取器&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#正则匹配&quot; id=&quot;markdown-toc-正则匹配&quot;&gt;正则匹配&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#-与-&quot; id=&quot;markdown-toc--与-&quot;&gt;”” 与 ““””““&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#regex&quot; id=&quot;markdown-toc-regex&quot;&gt;Regex&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;

&lt;p&gt;scala的编程非常灵活，里面有很多的语法糖，在scala中模式匹配非常常用，往往用于取代if else，使得代码看起来更加优雅，本文讲一下自己在日常编程中用到模式匹配和正则相关的使用经验总结。&lt;/p&gt;

&lt;h3 id=&quot;match&quot;&gt;match&lt;/h3&gt;

&lt;p&gt;match是和case一起使用。其实有些时候有一些隐式的match。比如下面这两段代码的功能都是一样的，都是过滤掉字符串中的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&apos;_&apos;&lt;/code&gt;字符,其实这段代码可以简单的使用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;str.filterNot(_ != &apos;_&apos;)&lt;/code&gt;，本例子只是讲解match case。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;nv&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;flatMap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;&apos;_&apos;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;$c&quot;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    
    &lt;span class=&quot;nv&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;flatMap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;&apos;_&apos;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;c&quot;&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;其实这个flatMap函数的输入是一个函数，输入是String类型，输出是一个字符集合。因此，这里省去的match实际上是对输入参数的match。&lt;/p&gt;

&lt;p&gt;对于case来说，匹配到的可以是一个具体的value, 比如&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&apos;_&apos;&lt;/code&gt;是一个字符，而&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_&lt;/code&gt;代表任何value。也可以是匹配到一个类型的实例。例如:&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;testMatch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obj&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Any&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;obj&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Int&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Boolean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Boolean&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;String&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Other type&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;提取器&quot;&gt;提取器&lt;/h4&gt;

&lt;p&gt;提取器是也是一个很常见的场景，对于一个object， 如果在 match的时候进行case操作，则会调用这个对象的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;unapply&lt;/code&gt;方法进行提取操作，因为是提取，所以这个unapply方法也对应的是一个match操作，而且可能会有提出不出来的场景，所以返回参数一定是Option类型的，因为有时提取可能为None。&lt;/p&gt;

&lt;p&gt;下面是一个例子，这个例子中使用了一些样例类。&lt;/p&gt;

&lt;p&gt;我们看&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;testClassMatch&lt;/code&gt;方法，前两个case都是匹配到一个样例类的value比较好理解，重点看第三和第四个case。&lt;/p&gt;

&lt;p&gt;我们看到有 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;case dl @ SpecialTypeThree(ExtractLiteral(l1), ExtractLiteral(l2))&lt;/code&gt;的操作，而SpecialTypeThree是一个object，作为抽取器，输入参数是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AbstractType&lt;/code&gt;实例，它的unapply方法用于抽取出两个String. 而此处的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dl&lt;/code&gt;代表的是匹配到的值，也就是一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DoubleLiterals&lt;/code&gt;实例。&lt;/p&gt;

&lt;p&gt;而SpecialTypeThree抽取器返回值是两个string，而后面跟着的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ExtractLiteral(l1), ExtractLiteral(l2)&lt;/code&gt;代表，两个抽取器对返回的两个String再做操作，如果依然能提取出非None的值，那么就代表匹配成功。否则，如果后面的两个ExtractLiteral 有一个返回None，都会代表此次匹配失败。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;k&quot;&gt;abstract&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AbstractType&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TypeOne&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AbstractType&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TypeTwo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Boolean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AbstractType&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DoubleLiterals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lit1&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lit2&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AbstractType&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DoubleString&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;str1&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;str2&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AbstractType&lt;/span&gt;

	&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;testClassMatch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;instance&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;AbstractType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;instance&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
   	&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TypeOne&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Some&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;int&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TypeTwo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Some&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;bool&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dl&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SpecialTypeThree&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ExtractLiteral&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ExtractLiteral&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nf&quot;&gt;assert&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;isInstanceOf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;DoubleLiterals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;Some&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;$l1\t$l2&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ds&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SpecialTypeThree&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ExtractString&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ExtractString&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nf&quot;&gt;assert&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;isInstanceOf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;DoubleString&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;Some&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;$s1\t$s2&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;None&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SpecialTypeThree&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;unapply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;instance&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;AbstractType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;instance&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dl&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;DoubleLiterals&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;Some&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;dl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;lit1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;dl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;lit2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ds&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;DoubleString&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;Some&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;str1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;ds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;str2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;None&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ExtractLiteral&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;reg&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;([0-9]+)&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;r&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;unapply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arg&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;arg&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;reg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;extract literal ing!&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
          &lt;span class=&quot;nc&quot;&gt;Some&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;None&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ExtractString&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;reg&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;([a-zA-Z]+)&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;r&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;unapply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arg&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;arg&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;reg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;extract string ing!&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
          &lt;span class=&quot;nc&quot;&gt;Some&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;None&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;正则匹配&quot;&gt;正则匹配&lt;/h3&gt;

&lt;p&gt;scala中的正则表达式写起来非常的简单。&lt;/p&gt;

&lt;p&gt;例如&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;&quot;&quot;([0-9]+)&quot;&quot;&quot;.r&lt;/code&gt;就代表一个正则表达式，用于匹配一个数字。&lt;/p&gt;

&lt;h4 id=&quot;-与-&quot;&gt;”” 与 ““””““&lt;/h4&gt;

&lt;p&gt;此处讲一下&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;&quot;&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;&quot;&quot;&quot;&quot;&quot;&lt;/code&gt;的区别，在scala中经常看到三引号。其实三引号最大的作用就是可以在里面使用一些需要转义的字符，并且支持换行。&lt;/p&gt;

&lt;p&gt;例如&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;\t&quot;&quot;&quot;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 打印出来是\t而非制表符&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;turbo&quot;fei&quot;&quot;&quot;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;//可在里面加引号&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;turbo
fei&quot;&quot;&quot;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;//可直接换行，不用使用\n表示换行符&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;当然常用的还是下面的方式:&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;turbo
      |fei
    &quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;stripMargin&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这通常是我们打印多行信息的方式，它可以优雅的打印出信息，而这里的stripMargin方法是指定每行开始的字符，默认是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;|&lt;/code&gt;。&lt;/p&gt;

&lt;h4 id=&quot;regex&quot;&gt;Regex&lt;/h4&gt;

&lt;p&gt;scala中的正则类是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scala.util.matching.Regex&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;创建Regex有两种方式:&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;reg1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Regex&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;\\.&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// 后面是用于注释?&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;reg2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)-(\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)-(\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;.r(&quot;year&quot;, &quot;month&quot;, &quot;date&quot;)&quot;&quot;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;正则表达式中的特殊字符在此就不详细列了，请参考官方标准。例如&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\d&lt;/code&gt;表示数字，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.&lt;/code&gt;表示任意一个字符， 所以如果需要匹配&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.&lt;/code&gt;需要进行转义使用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\.&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;而String里面split方式使用的参数其实是一个正则表达式的字符串形式。&lt;/p&gt;

&lt;p&gt;例如，如果我们需要按照&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.&lt;/code&gt;进行分割，那么就要需要使用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\\.&lt;/code&gt; 当做正则传入。如下：&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;\\.&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;所以在使用split方法时不要以为这是一个普通的字符串，其实这是一个toString的正则表达式。&lt;/p&gt;

&lt;p&gt;在scala中，常常将要匹配的部分使用小括号包住，则，就可以配合match，匹配出对应的部分。&lt;/p&gt;

&lt;p&gt;下面是一个例子:&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;reg&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;(\d+) \+ (\d+)&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;n1&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;n2&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;12 + 23&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;reg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;toInt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;toInt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 35&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</description>
                <link>http://www.turbofei.wang/coding/2019/05/25/scala-match-and-regex</link>
                <guid>http://www.turbofei.wang/coding/2019/05/25/scala-match-and-regex</guid>
                <pubDate>2019-05-25T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>Spark Sql Execution</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#关于spark-sql模块&quot; id=&quot;markdown-toc-关于spark-sql模块&quot;&gt;关于spark-sql模块&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#execution包&quot; id=&quot;markdown-toc-execution包&quot;&gt;execution包&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#exchange包&quot; id=&quot;markdown-toc-exchange包&quot;&gt;exchange包&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#exchange--exchangecoordinator&quot; id=&quot;markdown-toc-exchange--exchangecoordinator&quot;&gt;Exchange &amp;amp; ExchangeCoordinator&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#ensurerequirements&quot; id=&quot;markdown-toc-ensurerequirements&quot;&gt;EnsureRequirements&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#join&quot; id=&quot;markdown-toc-join&quot;&gt;Join&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#aggregate&quot; id=&quot;markdown-toc-aggregate&quot;&gt;Aggregate&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#conclusion&quot; id=&quot;markdown-toc-conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;

&lt;p&gt;关于spark sql 的execution部分源码解析&lt;/p&gt;

&lt;h3 id=&quot;关于spark-sql模块&quot;&gt;关于spark-sql模块&lt;/h3&gt;

&lt;p&gt;spark-sql模块下的代码作用有:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;sparkSession，SQLContext，DataSet，DataFrameWriter和reader等类&lt;/li&gt;
  &lt;li&gt;api 包: python，r的api&lt;/li&gt;
  &lt;li&gt;catalog包: catalog以及column，table，function，database的接口类&lt;/li&gt;
  &lt;li&gt;expression包: 包括aggregator，UDF， UDAF以及窗口函数&lt;/li&gt;
  &lt;li&gt;internal包：包括catalogImpl， HiveSerde，sessionState，sharedState等internal类&lt;/li&gt;
  &lt;li&gt;jdbc包： 里面都是方言类 dialect&lt;/li&gt;
  &lt;li&gt;sources包: 用于下推至DataSource的filter以及一些DataSource和sql relation相关接口&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;streaming&lt;/strong&gt;包: DataStreamReader， writer，StreamingQueryException等于streaming有关的类。&lt;/li&gt;
  &lt;li&gt;util包: QueryExecutionListener类&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;execution&lt;/strong&gt;包：本文的重点&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;execution包&quot;&gt;execution包&lt;/h4&gt;

&lt;p&gt;该包下源码分为:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;直接在根目录下
    &lt;ul&gt;
      &lt;li&gt;基本物理操作: coalesceExec, filterExec, projectExec, unionExec, RangeExec, and etc.&lt;/li&gt;
      &lt;li&gt;cacheManager：用于cache table.&lt;/li&gt;
      &lt;li&gt;一些exec: sort, DataSourceScan&lt;/li&gt;
      &lt;li&gt;wholeStageCodegenExec&lt;/li&gt;
      &lt;li&gt;SparkPlanner用于生产物理计划的&lt;/li&gt;
      &lt;li&gt;limit以及其他操作&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;aggregate包: 当然是与聚合相关的exec 以及UDAF&lt;/li&gt;
  &lt;li&gt;arrow包: arrow也是一种列式存储格式，这个包有他的 writer以及工具类.&lt;/li&gt;
  &lt;li&gt;columnar包: 与列状态，访问，类型相关的类&lt;/li&gt;
  &lt;li&gt;command包: 一些命令,ddl, analyzeTableCommand, functions, create等命令&lt;/li&gt;
  &lt;li&gt;DataSources包: 与DataSource有关，parquet, jdbc, orc等等
    &lt;ul&gt;
      &lt;li&gt;关于DataSource options， writer， 工具类等等&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;exchange： 里面有broadcastExchangeExec， exchangeCoordinator，shuffleExchangeExec等相关类，后面会重点分析这个,其实在物理计划中转换的重点就是这部分，所以ensureRequirements就在这个包中。&lt;/li&gt;
  &lt;li&gt;joins: join相关的， hashJoin, broadcastHashJoin, broadcastNestedLoopJoin, sortMergeJoin,shuffleHashJoinExec.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;streaming&lt;/strong&gt;包: 应该是continuous streaming相关的底层实现，应该不是走rdd，是一个真正流式的实现.&lt;/li&gt;
  &lt;li&gt;window包: 窗口函数相关exec。&lt;/li&gt;
  &lt;li&gt;python包，r包，metric包。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下文重点分析 &lt;strong&gt;aggregate&lt;/strong&gt;, &lt;strong&gt;exchange&lt;/strong&gt;, &lt;strong&gt;joins&lt;/strong&gt;包。&lt;/p&gt;

&lt;h3 id=&quot;exchange包&quot;&gt;exchange包&lt;/h3&gt;

&lt;h4 id=&quot;exchange--exchangecoordinator&quot;&gt;Exchange &amp;amp; ExchangeCoordinator&lt;/h4&gt;

&lt;p&gt;首先讲一下Exchange，顾名思义就是交换，是为了在多个线程之间进行数据交换，完成并行。&lt;/p&gt;

&lt;p&gt;Exchange分为两种，一种是BroadcastExchange另外一种是ShuffleExchange。Broadcast就是将数据发送至driver，然后由driver广播，这适合于数据量较小时候的shuffle。另一种ShuffleExchange就比较常见了，就是多对多的分发。&lt;/p&gt;

&lt;p&gt;如果开启了&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.adaptive.enabled&lt;/code&gt;，也就是自适应执行，&lt;/p&gt;

&lt;p&gt;那么在使用ShuffleExchange的时候有对应的ExchangeCoordinator；如果没开启ae，那就不需要协调器。&lt;/p&gt;

&lt;p&gt;ExchangeCoordinator顾名思义，是Exchange协调器，是一个用于决定怎么在stage之间进行shuffle数据的coordinator。这个协调器用于决定之后的shuffle有多少个partition用来需要fetch shuffle 数据。&lt;/p&gt;

&lt;p&gt;一个coordinator有三个参数.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;numExchanges&lt;/li&gt;
  &lt;li&gt;targetPostShuffleInputSize&lt;/li&gt;
  &lt;li&gt;minNumPostShufflePartitions&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;第一个参数是用于表示有多少个ShuffleExchangeExec需要注册到这个coordinator里面。因此，当我们要开始真正执行时，我们需要知道到底有多少个ShuffleExchangeExec。&lt;/p&gt;

&lt;p&gt;第二个参数是表示后面shuffle阶段每个partition的输入数据大小，这是用于adaptive-execution的，用于推测后面的shuffle阶段需要多少个partition。可以通过&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.adaptive.shuffle.targetPostShuffleInputSize&lt;/code&gt;来配置。&lt;/p&gt;

&lt;p&gt;第三个参数是一个可选参数，表示之后shuffle阶段最小的partition数量。如果这个参数被定义，那么之后的shuffle阶段的partition数量不能小于这个值。&lt;/p&gt;

&lt;p&gt;Coordinator的流程如下：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SparkPlan&lt;/code&gt;执行之前，对于一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ShuffleExchangeExec&lt;/code&gt;操作，如果它被指定了一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;coorinator&lt;/code&gt;，那么它将会注册到这个协调器，这发生在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;doPrepare&lt;/code&gt;方法里.&lt;/li&gt;
  &lt;li&gt;当开始执行&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SparkPlan&lt;/code&gt;，注册到这个协调器里面的ShuffleExchangeExec将会调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;postShuffleRDD&lt;/code&gt;方法来相应的 post-shuffle &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ShuffledRowRDD&lt;/code&gt;.如果这个协调器已经决定了如何去shuffle data，那么这个Exec会马上获得它对应的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ShuffledRowRDD&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;如果这个coordinator已经决定了如何shuffle data，它会让注册到自己的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ShuffleExchangeExec&lt;/code&gt;s来提交pos-shuffle stage。然后基于pre-shuffle阶段partition的统计信息，来决定post-shuffle的partition数量，如果post-shuffle需要，它也会将一些需要的连续的partitions放在一起发送给post-shuffle.&lt;/li&gt;
  &lt;li&gt;最后，这个coordinator会为所有注册的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ShuffleExchangeExec&lt;/code&gt;创建post-shuffle &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ShuffledRowRDD&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;目前的ae是比较老版本的ae，intel有一个ae项目，相信会在spark-3.0之后会合入，可以了解一下新的ae。&lt;/p&gt;

&lt;h4 id=&quot;ensurerequirements&quot;&gt;EnsureRequirements&lt;/h4&gt;

&lt;p&gt;这就是前面说的在SparkPlan 之前的do-prepare，需要为sparkplan的可执行做一些准备工作。&lt;/p&gt;

&lt;p&gt;主要分为以下几部分:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;确定distribution和Ordering&lt;/li&gt;
  &lt;li&gt;确定join 的条件和join keys出现顺序匹配&lt;/li&gt;
  &lt;li&gt;创建coordinator
    &lt;ul&gt;
      &lt;li&gt;ae开启&lt;/li&gt;
      &lt;li&gt;支持Coordinator
        &lt;ul&gt;
          &lt;li&gt;有ShuffleExchangeExec且是HashPartitionings&lt;/li&gt;
          &lt;li&gt;支持Distribution并且child个数大于1&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;针对ShuffleExchangeExec创建coordinator&lt;/li&gt;
      &lt;li&gt;针对一个post-shuffle 对应几个pre-shuffle的创建coordinator，例如join 一个对应多个pre-shuffle，而几个pre-shuffle有不同的分区划分方式&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;join&quot;&gt;Join&lt;/h4&gt;

&lt;p&gt;这里的join是执行阶段的join，不是解析阶段的join。&lt;/p&gt;

&lt;p&gt;join包括BroadcastHashJoinExec, ShuffledHashJoinExec以及SortMergeSortMergeJoinExec。&lt;/p&gt;

&lt;p&gt;join策略的选择&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SparkStrategies&lt;/code&gt;类里面，面临join，首先会尝试BroadcastJoin，然后是ShuffledHashJoin最后才是SortMergeHashJoin,只要能满足前面的条件就会优先使用前面的join。&lt;/p&gt;

&lt;p&gt;而这些JoinExec是在前面构建物理之前进行构建，在之后真正执行物理计划的时候执行。&lt;/p&gt;

&lt;h4 id=&quot;aggregate&quot;&gt;Aggregate&lt;/h4&gt;

&lt;p&gt;Agg和join有些类似，都是需要进行shuffle操作，但不同的是Aggregate可以是一个一元操作，而join是多元操作。&lt;/p&gt;

&lt;p&gt;Aggregate操作例如 max, count, min, sum，groupBy， reduce, reduceBy 以及一些UDAF(User Defined Aggregate Function)。而groupBy这些操作可能面临order by.&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;本文大概讲解了下execution包中各个部分的用途，重点是如何进行Exchange，以及什么是ExchangeCoordinator。对于join和Aggregate未涉及太多。&lt;/p&gt;
</description>
                <link>http://www.turbofei.wang/spark/2019/05/20/spark-sql-execution</link>
                <guid>http://www.turbofei.wang/spark/2019/05/20/spark-sql-execution</guid>
                <pubDate>2019-05-20T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>Scala Concurrent Programming: Future And Thread</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#java-future&quot; id=&quot;markdown-toc-java-future&quot;&gt;Java Future&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#scala-future&quot; id=&quot;markdown-toc-scala-future&quot;&gt;Scala Future&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#thread&quot; id=&quot;markdown-toc-thread&quot;&gt;Thread&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#thread状态&quot; id=&quot;markdown-toc-thread状态&quot;&gt;Thread状态&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#thread-方法解析&quot; id=&quot;markdown-toc-thread-方法解析&quot;&gt;Thread 方法解析&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;简单写下scala中的Future以及对Thread的认识&lt;/p&gt;

&lt;p&gt;java和scala中都有Future，那么这两个Future有什么不同呢？Thread是怎么样的，它的状态是如何变化的呢？一些操作比如sleep会涉及到锁么？&lt;/p&gt;

&lt;h3 id=&quot;java-future&quot;&gt;Java Future&lt;/h3&gt;

&lt;p&gt;java中Future类中方法很简单，也很少.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;kt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;cancel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mayInterruptIfRunning&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;isCancelled&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;isDone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;V&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;throws&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;InterruptedException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ExecutionException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;V&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;timeout&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TimeUnit&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;unit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;throws&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;InterruptedException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ExecutionException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TimeoutException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;比较常用的就是get，可以设置超时时间。下面是使用java Future的一个场景，通常是使用线程池submit Callable。记得线程池要放在finally模块关闭。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;testJavaFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;call&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Callable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;call&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nv&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;mi&quot;&gt;123L&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;pool&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;Executors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;newFixedThreadPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;pool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;submit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;call&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;isDone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;TimeUnit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;SECONDS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;finally&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;nv&quot;&gt;pool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;shutdown&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;scala-future&quot;&gt;Scala Future&lt;/h3&gt;

&lt;p&gt;相较于java的Future，scala的Future中方法很丰富。而且scala中伴生对象的apply方法使得创建一个Future非常方便.例如:&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;   &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Future&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;s&quot;&gt;&quot; future!&quot;&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;介绍其中几个方法，用法写在注释中，println结果也在注释中。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.collection.generic.CanBuildFrom&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.concurrent.duration.Duration&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.concurrent.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Await&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ExecutionContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.util.Success&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.util.control.NonFatal&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TestScalaFuture&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;implicit&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;executionContext&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;ExecutionContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;global&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;createIntFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;Future&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;createIntFutureWithFailure&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;Future&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;cm&quot;&gt;/**
   * recover方法是在Future发生异常时的处理。
   */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;testRecover&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;f1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;createIntFutureWithFailure&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;recover&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;Await&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Duration&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;10s&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;// -1&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;cm&quot;&gt;/**
   * 将两个Future zip到一起，这样就只需要使用一个Await就可以等结果。
   */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;testZip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;f1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;createIntFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;f2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;createIntFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;Await&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;f1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Duration&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;10s&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// (1,2)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;cm&quot;&gt;/**
   * 功能类似于zip，是处理更多个，需要指定CanBuildFrom。
   */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;testSequence&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;f1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;createIntFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;f2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;createIntFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;f3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;createIntFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;implicit&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;cbf&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;implicitly&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;CanBuildFrom&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;Iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;Await&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;Future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;sequence&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Duration&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;10s&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;foreach&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;\t&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 1 2 3&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;cm&quot;&gt;/**
   * 这里的map， flatMap等操作是对返回值进行的操作，也是lazy的。
   * 这里的andThen不会改变返回值。
   * Transform是对返回值进行的操作，以及对异常的转换。
   */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;testMisc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;f1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;createIntFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;Await&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Duration&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;10s&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 8&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;f2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;createIntFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;andThen&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Success&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;the value is 2&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 这里只是执行一些操作，但是不会改变Future的返回值&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;Await&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Duration&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;10s&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 2&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;f3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;createIntFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;str:&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;throwable&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;throwable&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;NonFatal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;throwable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;throwable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;throwable&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;})&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;Await&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Duration&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;10s&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// str:3&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;thread&quot;&gt;Thread&lt;/h3&gt;

&lt;p&gt;Thread类实现了Runnable，是一个特殊的Runnable类。&lt;/p&gt;

&lt;p&gt;一个线程代表一个程序的执行。jvm允许一个应用并发执行多个线程。每个线程都有一个优先级，优先级高的线程相对于优先级低的线程，更容易被执行。每个线程都可能被标记为一个守护(daemon)线程。当一个线程创建了一个新的线程，这个新的线程的优先级初始化为和创建它的线程一样。&lt;/p&gt;

&lt;p&gt;当一个JVM 启动时，通常是只有一个非守护线程。JVM会一直运行直到:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;exit方法被调用，并且允许exit。&lt;/li&gt;
  &lt;li&gt;所有非守护线程都已经结束，可以是正常返回结束也可以是异常结束。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;有两种方法生成一个新的执行线程。&lt;/p&gt;

&lt;p&gt;一种是继承Thread类，overwrite run方法，然后start。&lt;/p&gt;

&lt;p&gt;另一种是继承&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Runnable&lt;/code&gt;类，实现run方法，然后 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;new Thread(runnable).start.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;线程的优先级分为1，5，10。1是所允许的最低优先级，5是默认分配，10是能够拥有的最高优先级。&lt;/p&gt;

&lt;p&gt;Thread类里面提供了一些静态工具方法. &lt;strong&gt;Deprecated&lt;/strong&gt;的方法不再列出.&lt;/p&gt;

&lt;h4 id=&quot;thread状态&quot;&gt;Thread状态&lt;/h4&gt;

&lt;p&gt;首先，thread的五种状态.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;NEW 线程被创建，还没start&lt;/li&gt;
  &lt;li&gt;RUNNABLE  在JVM上运行，可能在等操作系统的资源，比如时间片&lt;/li&gt;
  &lt;li&gt;BLOCKED 阻塞状态，等待lock来进入同步代码块&lt;/li&gt;
  &lt;li&gt;WAITING
    &lt;ul&gt;
      &lt;li&gt;Object.wait 没有指定timeout&lt;/li&gt;
      &lt;li&gt;因为Thread.join 无timeout等待&lt;/li&gt;
      &lt;li&gt;LockSupport.park()无限期等待&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;TIMED_WAITING  有timeout的WAITING
    &lt;ul&gt;
      &lt;li&gt;Object.wait(long)&lt;/li&gt;
      &lt;li&gt;Thread.join(long)&lt;/li&gt;
      &lt;li&gt;LockSupport.parkNanos LockSupport.parkUntil&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;TREMINATED  线程退出&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;thread-方法解析&quot;&gt;Thread 方法解析&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;yield&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;yield方法是给调度器一个hint表明自己自愿放弃当前的处理器，调度器可以忽略这个hint。这个方法不推荐，很少使用，可以用于避免cpu过度利用，但是使用之前要做好详细的分析与benchmark。spark项目中没有用到过yield.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;sleep&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;sleep方法比较常用，这是将当前线程放弃执行，休眠一段时间，但是sleep不会放弃自己得到的monitor.&lt;/p&gt;

&lt;p&gt;sleep(0)的意思代表是，大家所有线程重新抢占一下处理器。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;threadGroup&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在创建thread时候可以传入threadGroup参数。如果没有传入group，如果该线程指定了securityManager，则去问securityManager拿group，最终是拿currentThread的group，如果没指定securityManager，则和父线程一组。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;start&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;开始运行线程，jvm调用run()方法。一个线程只能启动一次，否则会报IllegalThreadStateException。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;run&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;实现的Runnable的run方法，用于让jvm调用&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;interrupt&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;如果是线程自己interrupt自己，是允许的，否则，需要securityManager进行checkAccess，可能会抛出SecurityException。&lt;/p&gt;

&lt;p&gt;interrupt之后会加一个标志位interrupted.&lt;/p&gt;

&lt;p&gt;如果此时该线程被 wait, join, sleep, 那么这个interrupted标志位会被清除然后抛出InterruptedException.&lt;/p&gt;

&lt;p&gt;如果线程被&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;java.nio.channels.InterruptibleChannel&lt;/code&gt;的I/O操作阻塞，那么这个channel将被关闭，然后set interrupted标志位，这个线程会收到一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ClosedByInterruptException&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;如果线程被&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;java.nio.channels.Selector&lt;/code&gt;阻塞，那么将会设置interrupted标志位，并马上从selection操作返回。&lt;/p&gt;

&lt;p&gt;如果上述情况都没发生，那么这个线程设置interrup状态标志位.&lt;/p&gt;

&lt;p&gt;如果线程已经dead，interrupt操作没丝毫作用，也不会出错。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;isInterrupted&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;查看是否被设为interrupted.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;setPriority&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;改变线程的优先级。首先会由securityManager进行校验，校验失败抛SecurityException. 校验成功，则取设置的值和当前threadGroup的最大权限中的较小值，作为线程的优先级。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;getPriority&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;获得线程优先级.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;setName, getName&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;设置线程名字，获取线程名字&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;getThreadGroup&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;获得线程的threadGroup&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;activeCount&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;获得当前线程的threadGroup以及subGroup中的线程数.由于线程在动态变化，因此只是一个估计值，主要是用于debug以及monitoring.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;join(time)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;等待线程结束，如果join(0)代表一直等待。如果该线程被其他thread interrupt，那么这个线程的interrupted标志位被清除，然后抛出&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;InterruptedException&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;dumpStack&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;打印当前线程的栈，只用于&lt;strong&gt;debug&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;setDaemon(isDaemon)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;设为守护线程或者用户线程。JVM会在所有用户线程都挂掉之后退出。&lt;/p&gt;

&lt;p&gt;必须在线程启动之前设置，如果线程已经是alive，会抛&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;IllegalThreadStateException&lt;/code&gt;.同样也会检查SecurityManager当前线程是否有权限去设置。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;isDaemon&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;是否是守护线程&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;checkAccess&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;检查当前线程有没有权限去修改这个线程。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;getContextClassLoader, setContextClassLoader&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;classLoader是用于加载classes和resources。默认的classLoader是父线程的classLoader。原始的线程classLoader通常是设置为应用的classLoader。如果classLoader不为空， 且securityManager不为空，将会进行权限校验。&lt;strong&gt;权限校验几乎伴随thread的每个操作&lt;/strong&gt;，后面就不再提了.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;holdsLock(Object obj)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;线程是否持有某个monitor.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;getStackTrace, getAllStackTraces&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一个是打印当前线程的stack，一个是所有线程的stack，用户debug&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;getId&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;获得线程Id&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;getState&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;获得线程状态&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;UncaughtExceptionHandler&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;是一个接口，用于当线程由于一些未捕获的异常而导致终止时的处理。&lt;/p&gt;

&lt;p&gt;里面只有一个方法.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;uncaughtException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Thread&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Throwable&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;get(set)DefaultUncaughtExceptionHandler, get(set)UncaughtExceptionHandler&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;关于设置UncaughtExceptionHandler。ThreadGroup是UncaughtExceptionHandler的一个实现类，如果当前thread没有设置UncaughtExceptionHandler，那么返回threadGroup。&lt;/p&gt;
</description>
                <link>http://www.turbofei.wang/coding/2019/05/19/scala-concurrent-programming-Future-And-Thread</link>
                <guid>http://www.turbofei.wang/coding/2019/05/19/scala-concurrent-programming:-Future-And-Thread</guid>
                <pubDate>2019-05-19T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>[转载] Raft译文</title>
                <description>
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#前言&quot; id=&quot;markdown-toc-前言&quot;&gt;前言&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#寻找一种易于理解的一致性算法扩展版&quot; id=&quot;markdown-toc-寻找一种易于理解的一致性算法扩展版&quot;&gt;寻找一种易于理解的一致性算法（扩展版）&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#摘要&quot; id=&quot;markdown-toc-摘要&quot;&gt;摘要&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#1-介绍&quot; id=&quot;markdown-toc-1-介绍&quot;&gt;1 介绍&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#2-复制状态机&quot; id=&quot;markdown-toc-2-复制状态机&quot;&gt;2 复制状态机&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#3-paxos算法的问题&quot; id=&quot;markdown-toc-3-paxos算法的问题&quot;&gt;3 Paxos算法的问题&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#4-为了可理解性的设计&quot; id=&quot;markdown-toc-4-为了可理解性的设计&quot;&gt;4 为了可理解性的设计&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#5-raft-一致性算法&quot; id=&quot;markdown-toc-5-raft-一致性算法&quot;&gt;5 Raft 一致性算法&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#51-raft-基础&quot; id=&quot;markdown-toc-51-raft-基础&quot;&gt;5.1 Raft 基础&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#52-领导人选举&quot; id=&quot;markdown-toc-52-领导人选举&quot;&gt;5.2 领导人选举&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#53-日志复制&quot; id=&quot;markdown-toc-53-日志复制&quot;&gt;5.3 日志复制&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#54-安全性&quot; id=&quot;markdown-toc-54-安全性&quot;&gt;5.4 安全性&lt;/a&gt;            &lt;ul&gt;
              &lt;li&gt;&lt;a href=&quot;#541-选举限制&quot; id=&quot;markdown-toc-541-选举限制&quot;&gt;5.4.1 选举限制&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#542-提交之前任期内的日志条目&quot; id=&quot;markdown-toc-542-提交之前任期内的日志条目&quot;&gt;5.4.2 提交之前任期内的日志条目&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#543-安全性论证&quot; id=&quot;markdown-toc-543-安全性论证&quot;&gt;5.4.3 安全性论证&lt;/a&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#55-跟随者和候选人崩溃&quot; id=&quot;markdown-toc-55-跟随者和候选人崩溃&quot;&gt;5.5 跟随者和候选人崩溃&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#56-时间和可用性&quot; id=&quot;markdown-toc-56-时间和可用性&quot;&gt;5.6 时间和可用性&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#6-集群成员变化&quot; id=&quot;markdown-toc-6-集群成员变化&quot;&gt;6 集群成员变化&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#7-日志压缩&quot; id=&quot;markdown-toc-7-日志压缩&quot;&gt;7 日志压缩&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#8-客户端交互&quot; id=&quot;markdown-toc-8-客户端交互&quot;&gt;8 客户端交互&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#9-算法实现和评估&quot; id=&quot;markdown-toc-9-算法实现和评估&quot;&gt;9 算法实现和评估&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#91-可理解性&quot; id=&quot;markdown-toc-91-可理解性&quot;&gt;9.1 可理解性&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#92-正确性&quot; id=&quot;markdown-toc-92-正确性&quot;&gt;9.2 正确性&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#93-性能&quot; id=&quot;markdown-toc-93-性能&quot;&gt;9.3 性能&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#10-相关工作&quot; id=&quot;markdown-toc-10-相关工作&quot;&gt;10 相关工作&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#11-结论&quot; id=&quot;markdown-toc-11-结论&quot;&gt;11 结论&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#12-感谢&quot; id=&quot;markdown-toc-12-感谢&quot;&gt;12 感谢&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#参考&quot; id=&quot;markdown-toc-参考&quot;&gt;参考&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;前言&quot;&gt;前言&lt;/h3&gt;

&lt;p&gt;Raft的译文&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/maemual/raft-zh_cn/edit/master/raft-zh_cn.md&quot;&gt;原文地址&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://thesecretlivesofdata.com/raft/&quot;&gt;动画演示&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;寻找一种易于理解的一致性算法扩展版&quot;&gt;寻找一种易于理解的一致性算法（扩展版）&lt;/h1&gt;

&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;

&lt;p&gt;Raft 是一种为了管理复制日志的一致性算法。它提供了和 Paxos 算法相同的功能和性能，但是它的算法结构和 Paxos 不同，使得 Raft 算法更加容易理解并且更容易构建实际的系统。为了提升可理解性，Raft 将一致性算法分解成了几个关键模块，例如领导人选举、日志复制和安全性。同时它通过实施一个更强的一致性来减少需要考虑的状态的数量。从一个用户研究的结果可以证明，对于学生而言，Raft 算法比 Paxos 算法更加容易学习。Raft 算法还包括一个新的机制来允许集群成员的动态改变，它利用重叠的大多数来保证安全性。&lt;/p&gt;

&lt;h2 id=&quot;1-介绍&quot;&gt;1 介绍&lt;/h2&gt;

&lt;p&gt;一致性算法允许一组机器像一个整体一样工作，即使其中一些机器出现故障也能够继续工作下去。正因为如此，一致性算法在构建可信赖的大规模软件系统中扮演着重要的角色。在过去的 10 年里，Paxos  算法统治着一致性算法这一领域：绝大多数的实现都是基于 Paxos 或者受其影响。同时 Paxos 也成为了教学领域里讲解一致性问题时的示例。&lt;/p&gt;

&lt;p&gt;但是不幸的是，尽管有很多工作都在尝试降低它的复杂性，但是 Paxos 算法依然十分难以理解。并且，Paxos 自身的算法结构需要进行大幅的修改才能够应用到实际的系统中。这些都导致了工业界和学术界都对 Paxos 算法感到十分头疼。&lt;/p&gt;

&lt;p&gt;和 Paxos 算法进行过努力之后，我们开始寻找一种新的一致性算法，可以为构建实际的系统和教学提供更好的基础。我们的做法是不寻常的，我们的首要目标是可理解性：我们是否可以在实际系统中定义一个一致性算法，并且能够比 Paxos 算法以一种更加容易的方式来学习。此外，我们希望该算法方便系统构建者的直觉的发展。不仅一个算法能够工作很重要，而且能够显而易见的知道为什么能工作也很重要。&lt;/p&gt;

&lt;p&gt;Raft 一致性算法就是这些工作的结果。在设计 Raft 算法的时候，我们使用一些特别的技巧来提升它的可理解性，包括算法分解（Raft 主要被分成了领导人选举，日志复制和安全三个模块）和减少状态机的状态（相对于 Paxos，Raft 减少了非确定性和服务器互相处于非一致性的方式）。一份针对两所大学 43 个学生的研究表明 Raft 明显比 Paxos 算法更加容易理解。在这些学生同时学习了这两种算法之后，和 Paxos 比起来，其中 33 个学生能够回答有关于 Raft 的问题。&lt;/p&gt;

&lt;p&gt;Raft 算法在许多方面和现有的一致性算法都很相似（主要是 Oki 和 Liskov 的 Viewstamped Replication），但是它也有一些独特的特性：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;强领导者&lt;/strong&gt;：和其他一致性算法相比，Raft 使用一种更强的领导能力形式。比如，日志条目只从领导者发送给其他的服务器。这种方式简化了对复制日志的管理并且使得 Raft 算法更加易于理解。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;领导选举&lt;/strong&gt;：Raft 算法使用一个随机计时器来选举领导者。这种方式只是在任何一致性算法都必须实现的心跳机制上增加了一点机制。在解决冲突的时候会更加简单快捷。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;成员关系调整&lt;/strong&gt;：Raft 使用一种共同一致的方法来处理集群成员变换的问题，在这种方法下，处于调整过程中的两种不同的配置集群中大多数机器会有重叠，这就使得集群在成员变换的时候依然可以继续工作。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们相信，Raft 算法不论出于教学目的还是作为实践项目的基础都是要比 Paxos 或者其他一致性算法要优异的。它比其他算法更加简单，更加容易理解；它的算法描述足以实现一个现实的系统；它有好多开源的实现并且在很多公司里使用；它的安全性已经被证明；它的效率和其他算法比起来也不相上下。&lt;/p&gt;

&lt;p&gt;接下来，这篇论文会介绍以下内容：复制状态机问题（第 2 节），讨论 Paxos 的优点和缺点（第 3 节），讨论我们为了理解能力而使用的方法（第 4 节），阐述 Raft 一致性算法（第 5-8 节），评价 Raft 算法（第 9 节），以及一些相关的工作（第 10 节）。&lt;/p&gt;

&lt;h2 id=&quot;2-复制状态机&quot;&gt;2 复制状态机&lt;/h2&gt;

&lt;p&gt;一致性算法是从复制状态机的背景下提出的（参考英文原文引用37）。在这种方法中，一组服务器上的状态机产生相同状态的副本，并且在一些机器宕掉的情况下也可以继续运行。复制状态机在分布式系统中被用于解决很多容错的问题。例如，大规模的系统中通常都有一个集群领导者，像 GFS、HDFS 和 RAMCloud，典型应用就是一个独立的的复制状态机去管理领导选举和存储配置信息并且在领导人宕机的情况下也要存活下来。比如 Chubby 和 ZooKeeper。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE1.png&quot; alt=&quot;图 1 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 1 ：复制状态机的结构。一致性算法管理着来自客户端指令的复制日志。状态机从日志中处理相同顺序的相同指令，所以产生的结果也是相同的。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;复制状态机通常都是基于复制日志实现的，如图 1。每一个服务器存储一个包含一系列指令的日志，并且按照日志的顺序进行执行。每一个日志都按照相同的顺序包含相同的指令，所以每一个服务器都执行相同的指令序列。因为每个状态机都是确定的，每一次执行操作都产生相同的状态和同样的序列。&lt;/p&gt;

&lt;p&gt;保证复制日志相同就是一致性算法的工作了。在一台服务器上，一致性模块接收客户端发送来的指令然后增加到自己的日志中去。它和其他服务器上的一致性模块进行通信来保证每一个服务器上的日志最终都以相同的顺序包含相同的请求，尽管有些服务器会宕机。一旦指令被正确的复制，每一个服务器的状态机按照日志顺序处理他们，然后输出结果被返回给客户端。因此，服务器集群看起来形成一个高可靠的状态机。&lt;/p&gt;

&lt;p&gt;实际系统中使用的一致性算法通常含有以下特性：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;安全性保证（绝对不会返回一个错误的结果）：在非拜占庭错误情况下，包括网络延迟、分区、丢包、冗余和乱序等错误都可以保证正确。&lt;/li&gt;
  &lt;li&gt;可用性：集群中只要有大多数的机器可运行并且能够相互通信、和客户端通信，就可以保证可用。因此，一个典型的包含 5 个节点的集群可以容忍两个节点的失败。服务器被停止就认为是失败。他们当有稳定的存储的时候可以从状态中恢复回来并重新加入集群。&lt;/li&gt;
  &lt;li&gt;不依赖时序来保证一致性：物理时钟错误或者极端的消息延迟在可能只有在最坏情况下才会导致可用性问题。&lt;/li&gt;
  &lt;li&gt;通常情况下，一条指令可以尽可能快的在集群中大多数节点响应一轮远程过程调用时完成。小部分比较慢的节点不会影响系统整体的性能。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;3-paxos算法的问题&quot;&gt;3 Paxos算法的问题&lt;/h2&gt;

&lt;p&gt;在过去的 10 年里，Leslie Lamport 的 Paxos 算法几乎已经成为一致性的代名词：Paxos 是在课程教学中最经常使用的算法，同时也是大多数一致性算法实现的起点。Paxos 首先定义了一个能够达成单一决策一致的协议，比如单条的复制日志项。我们把这一子集叫做单决策 Paxos。然后通过组合多个 Paxos 协议的实例来促进一系列决策的达成。Paxos 保证安全性和活性，同时也支持集群成员关系的变更。Paxos 的正确性已经被证明，在通常情况下也很高效。&lt;/p&gt;

&lt;p&gt;不幸的是，Paxos 有两个明显的缺点。第一个缺点是 Paxos 算法特别的难以理解。完整的解释是出了名的不透明；通过极大的努力之后，也只有少数人成功理解了这个算法。因此，有了几次用更简单的术语来解释 Paxos 的尝试。尽管这些解释都只关注了单决策的子集问题，但依然很具有挑战性。在 2012 年 NSDI 的会议中的一次调查显示，很少有人对 Paxos 算法感到满意，甚至在经验老道的研究者中也是如此。我们自己也尝试去理解 Paxos；我们一直没能理解 Paxos 直到我们读了很多对 Paxos 的简化解释并且设计了我们自己的算法之后，这一过程花了近一年时间。&lt;/p&gt;

&lt;p&gt;我们假设 Paxos 的不透明性来自它选择单决策问题作为它的基础。单决策 Paxos 是晦涩微妙的，它被划分成了两种没有简单直观解释和无法独立理解的情景。因此，这导致了很难建立起直观的感受为什么单决策 Paxos 算法能够工作。构成多决策 Paxos 增加了很多错综复杂的规则。我们相信，在多决策上达成一致性的问题（一份日志而不是单一的日志记录）能够被分解成其他的方式并且更加直接和明显。&lt;/p&gt;

&lt;p&gt;Paxos算法的第二个问题就是它没有提供一个足够好的用来构建一个现实系统的基础。一个原因是还没有一种被广泛认同的多决策问题的算法。Lamport 的描述基本上都是关于单决策 Paxos 的；他简要描述了实施多决策 Paxos 的方法，但是缺乏很多细节。当然也有很多具体化 Paxos 的尝试，但是他们都互相不一样，和 Paxos 的概述也不同。例如 Chubby 这样的系统实现了一个类似于 Paxos 的算法，但是大多数的细节并没有被公开。&lt;/p&gt;

&lt;p&gt;而且，Paxos 算法的结构也不是十分易于构建实践的系统；单决策分解也会产生其他的结果。例如，独立的选择一组日志条目然后合并成一个序列化的日志并没有带来太多的好处，仅仅增加了不少复杂性。围绕着日志来设计一个系统是更加简单高效的；新日志条目以严格限制的顺序增添到日志中去。另一个问题是，Paxos 使用了一种对等的点对点的方式作为它的核心（尽管它最终提议了一种弱领导人的方法来优化性能）。在只有一个决策会被制定的简化世界中是很有意义的，但是很少有现实的系统使用这种方式。如果有一系列的决策需要被制定，首先选择一个领导人，然后让他去协调所有的决议，会更加简单快速。&lt;/p&gt;

&lt;p&gt;因此，实际的系统中很少有和 Paxos 相似的实践。每一种实现都是从 Paxos 开始研究，然后发现很多实现上的难题，再然后开发了一种和 Paxos 明显不一样的结构。这样是非常费时和容易出错的，并且理解 Paxos 的难度使得这个问题更加糟糕。Paxos 算法在理论上被证明是正确可行的，但是现实的系统和 Paxos 差别是如此的大，以至于这些证明没有什么太大的价值。下面来自 Chubby 实现非常典型：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;在Paxos算法描述和实现现实系统中间有着巨大的鸿沟。最终的系统建立在一种没有经过证明的算法之上。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;由于以上问题，我们认为 Paxos 算法既没有提供一个良好的基础给实践的系统，也没有给教学很好的帮助。基于一致性问题在大规模软件系统中的重要性，我们决定看看我们是否可以设计一个拥有更好特性的替代 Paxos 的一致性算法。Raft算法就是这次实验的结果。&lt;/p&gt;

&lt;h2 id=&quot;4-为了可理解性的设计&quot;&gt;4 为了可理解性的设计&lt;/h2&gt;

&lt;p&gt;设计 Raft 算法我们有几个初衷：它必须提供一个完整的实际的系统实现基础，这样才能大大减少开发者的工作；它必须在任何情况下都是安全的并且在大多数的情况下都是可用的；并且它的大部分操作必须是高效的。但是我们最重要也是最大的挑战是可理解性。它必须保证对于普遍的人群都可以十分容易的去理解。另外，它必须能够让人形成直观的认识，这样系统的构建者才能够在现实中进行必然的扩展。&lt;/p&gt;

&lt;p&gt;在设计 Raft 算法的时候，有很多的点需要我们在各种备选方案中进行选择。在这种情况下，我们评估备选方案基于可理解性原则：解释各个备选方案有多大的难度（例如，Raft 的状态空间有多复杂，是否有微妙的暗示）？对于一个读者而言，完全理解这个方案和暗示是否容易？&lt;/p&gt;

&lt;p&gt;我们意识到对这种可理解性分析上具有高度的主观性；尽管如此，我们使用了两种通常适用的技术来解决这个问题。第一个技术就是众所周知的问题分解：只要有可能，我们就将问题分解成几个相对独立的，可被解决的、可解释的和可理解的子问题。例如，Raft 算法被我们分成领导人选举，日志复制，安全性和角色改变几个部分。&lt;/p&gt;

&lt;p&gt;我们使用的第二个方法是通过减少状态的数量来简化需要考虑的状态空间，使得系统更加连贯并且在可能的时候消除不确定性。特别的，所有的日志是不允许有空洞的，并且 Raft 限制了日志之间变成不一致状态的可能。尽管在大多数情况下我们都试图去消除不确定性，但是也有一些情况下不确定性可以提升可理解性。尤其是，随机化方法增加了不确定性，但是他们有利于减少状态空间数量，通过处理所有可能选择时使用相似的方法。我们使用随机化去简化 Raft 中领导人选举算法。&lt;/p&gt;

&lt;h2 id=&quot;5-raft-一致性算法&quot;&gt;5 Raft 一致性算法&lt;/h2&gt;

&lt;p&gt;Raft 是一种用来管理章节 2 中描述的复制日志的算法。图 2 为了参考之用，总结这个算法的简略版本，图 3 列举了这个算法的一些关键特性。图中的这些元素会在剩下的章节逐一介绍。&lt;/p&gt;

&lt;p&gt;Raft 通过选举一个高贵的领导人，然后给予他全部的管理复制日志的责任来实现一致性。领导人从客户端接收日志条目，把日志条目复制到其他服务器上，并且当保证安全性的时候告诉其他的服务器应用日志条目到他们的状态机中。拥有一个领导人大大简化了对复制日志的管理。例如，领导人可以决定新的日志条目需要放在日志中的什么位置而不需要和其他服务器商议，并且数据都从领导人流向其他服务器。一个领导人可以宕机，可以和其他服务器失去连接，这时一个新的领导人会被选举出来。&lt;/p&gt;

&lt;p&gt;通过领导人的方式，Raft 将一致性问题分解成了三个相对独立的子问题，这些问题会在接下来的子章节中进行讨论：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;领导选举&lt;/strong&gt;：一个新的领导人需要被选举出来，当现存的领导人宕机的时候（章节 5.2）&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;日志复制&lt;/strong&gt;：领导人必须从客户端接收日志然后复制到集群中的其他节点，并且强制要求其他节点的日志保持和自己相同。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;安全性&lt;/strong&gt;：在 Raft 中安全性的关键是在图 3 中展示的状态机安全：如果有任何的服务器节点已经应用了一个确定的日志条目到它的状态机中，那么其他服务器节点不能在同一个日志索引位置应用一个不同的指令。章节 5.4 阐述了 Raft 算法是如何保证这个特性的；这个解决方案涉及到一个额外的选举机制（5.2 节）上的限制。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在展示一致性算法之后，这一章节会讨论可用性的一些问题和系统中的候选人角色的问题。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;状态&lt;/strong&gt;：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;状态&lt;/th&gt;
      &lt;th&gt;所有服务器上持久存在的&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;currentTerm&lt;/td&gt;
      &lt;td&gt;服务器最后一次知道的任期号（初始化为 0，持续递增）&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;votedFor&lt;/td&gt;
      &lt;td&gt;在当前获得选票的候选人的 Id&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;log[]&lt;/td&gt;
      &lt;td&gt;日志条目集；每一个条目包含一个用户状态机执行的指令，和收到时的任期号&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;状态&lt;/th&gt;
      &lt;th&gt;所有服务器上经常变的&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;commitIndex&lt;/td&gt;
      &lt;td&gt;已知的最大的已经被提交的日志条目的索引值&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;lastApplied&lt;/td&gt;
      &lt;td&gt;最后被应用到状态机的日志条目索引值（初始化为 0，持续递增）&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;状态&lt;/th&gt;
      &lt;th&gt;在领导人里经常改变的 （选举后重新初始化）&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;nextIndex[]&lt;/td&gt;
      &lt;td&gt;对于每一个服务器，需要发送给他的下一个日志条目的索引值（初始化为领导人最后索引值加一）&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;matchIndex[]&lt;/td&gt;
      &lt;td&gt;对于每一个服务器，已经复制给他的日志的最高索引值&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;附加日志 RPC&lt;/strong&gt;：&lt;/p&gt;

&lt;p&gt;由领导人负责调用来复制日志指令；也会用作heartbeat&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;参数&lt;/th&gt;
      &lt;th&gt;解释&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;term&lt;/td&gt;
      &lt;td&gt;领导人的任期号&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;leaderId&lt;/td&gt;
      &lt;td&gt;领导人的 Id，以便于跟随者重定向请求&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;prevLogIndex&lt;/td&gt;
      &lt;td&gt;新的日志条目紧随之前的索引值&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;prevLogTerm&lt;/td&gt;
      &lt;td&gt;prevLogIndex 条目的任期号&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;entries[]&lt;/td&gt;
      &lt;td&gt;准备存储的日志条目（表示心跳时为空；一次性发送多个是为了提高效率）&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;leaderCommit&lt;/td&gt;
      &lt;td&gt;领导人已经提交的日志的索引值&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;返回值&lt;/th&gt;
      &lt;th&gt;解释&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;term&lt;/td&gt;
      &lt;td&gt;当前的任期号，用于领导人去更新自己&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;success&lt;/td&gt;
      &lt;td&gt;跟随者包含了匹配上 prevLogIndex 和 prevLogTerm 的日志时为真&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;接收者实现：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;如果 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;term &amp;lt; currentTerm&lt;/code&gt; 就返回 false （5.1 节）&lt;/li&gt;
  &lt;li&gt;如果日志在 prevLogIndex 位置处的日志条目的任期号和 prevLogTerm 不匹配，则返回 false （5.3 节）&lt;/li&gt;
  &lt;li&gt;如果已经存在的日志条目和新的产生冲突（索引值相同但是任期号不同），删除这一条和之后所有的 （5.3 节）&lt;/li&gt;
  &lt;li&gt;附加任何在已有的日志中不存在的条目&lt;/li&gt;
  &lt;li&gt;如果 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;leaderCommit &amp;gt; commitIndex&lt;/code&gt;，令 commitIndex 等于 leaderCommit 和 新日志条目索引值中较小的一个&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;请求投票 RPC&lt;/strong&gt;：&lt;/p&gt;

&lt;p&gt;由候选人负责调用用来征集选票（5.2 节）&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;参数&lt;/th&gt;
      &lt;th&gt;解释&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;term&lt;/td&gt;
      &lt;td&gt;候选人的任期号&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;candidateId&lt;/td&gt;
      &lt;td&gt;请求选票的候选人的 Id&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;lastLogIndex&lt;/td&gt;
      &lt;td&gt;候选人的最后日志条目的索引值&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;lastLogTerm&lt;/td&gt;
      &lt;td&gt;候选人最后日志条目的任期号&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;返回值&lt;/th&gt;
      &lt;th&gt;解释&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;term&lt;/td&gt;
      &lt;td&gt;当前任期号，以便于候选人去更新自己的任期号&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;voteGranted&lt;/td&gt;
      &lt;td&gt;候选人赢得了此张选票时为真&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;接收者实现：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;如果&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;term &amp;lt; currentTerm&lt;/code&gt;返回 false （5.2 节）&lt;/li&gt;
  &lt;li&gt;如果 votedFor 为空或者就是 candidateId，并且候选人的日志至少和自己一样新，那么就投票给他（5.2 节，5.4 节）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;所有服务器需遵守的规则&lt;/strong&gt;：&lt;/p&gt;

&lt;p&gt;所有服务器：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;commitIndex &amp;gt; lastApplied&lt;/code&gt;，那么就 lastApplied 加一，并把&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;log[lastApplied]&lt;/code&gt;应用到状态机中（5.3 节）&lt;/li&gt;
  &lt;li&gt;如果接收到的 RPC 请求或响应中，任期号&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;T &amp;gt; currentTerm&lt;/code&gt;，那么就令 currentTerm 等于 T，并切换状态为跟随者（5.1 节）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;跟随者（5.2 节）：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;响应来自候选人和领导者的请求&lt;/li&gt;
  &lt;li&gt;如果在超过选举超时时间的情况之前都没有收到领导人的心跳，或者是候选人请求投票的，就自己变成候选人&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;候选人（5.2 节）：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在转变成候选人后就立即开始选举过程
    &lt;ul&gt;
      &lt;li&gt;自增当前的任期号（currentTerm）&lt;/li&gt;
      &lt;li&gt;给自己投票&lt;/li&gt;
      &lt;li&gt;重置选举超时计时器&lt;/li&gt;
      &lt;li&gt;发送请求投票的 RPC 给其他所有服务器&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;如果接收到大多数服务器的选票，那么就变成领导人&lt;/li&gt;
  &lt;li&gt;如果接收到来自新的领导人的附加日志 RPC，转变成跟随者&lt;/li&gt;
  &lt;li&gt;如果选举过程超时，再次发起一轮选举&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;领导人：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一旦成为领导人：发送空的附加日志 RPC（心跳）给其他所有的服务器；在一定的空余时间之后不停的重复发送，以阻止跟随者超时（5.2 节）&lt;/li&gt;
  &lt;li&gt;如果接收到来自客户端的请求：附加条目到本地日志中，在条目被应用到状态机后响应客户端（5.3 节）&lt;/li&gt;
  &lt;li&gt;如果对于一个跟随者，最后日志条目的索引值大于等于 nextIndex，那么：发送从 nextIndex 开始的所有日志条目：
    &lt;ul&gt;
      &lt;li&gt;如果成功：更新相应跟随者的 nextIndex 和 matchIndex&lt;/li&gt;
      &lt;li&gt;如果因为日志不一致而失败，减少 nextIndex 重试&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;如果存在一个满足&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N &amp;gt; commitIndex&lt;/code&gt;的 N，并且大多数的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;matchIndex[i] ≥ N&lt;/code&gt;成立，并且&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;log[N].term == currentTerm&lt;/code&gt;成立，那么令 commitIndex 等于这个 N （5.3 和 5.4 节）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE2.png&quot; alt=&quot;图 2 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 2：一个关于 Raft 一致性算法的浓缩总结（不包括成员变换和日志压缩）。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;特性&lt;/th&gt;
      &lt;th&gt;解释&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;选举安全特性&lt;/td&gt;
      &lt;td&gt;对于一个给定的任期号，最多只会有一个领导人被选举出来（5.2 节）&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;领导人只附加原则&lt;/td&gt;
      &lt;td&gt;领导人绝对不会删除或者覆盖自己的日志，只会增加（5.3 节）&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;日志匹配原则&lt;/td&gt;
      &lt;td&gt;如果两个日志在相同的索引位置的日志条目的任期号相同，那么我们就认为这个日志从头到这个索引位置之间全部完全相同（5.3 节）&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;领导人完全特性&lt;/td&gt;
      &lt;td&gt;如果某个日志条目在某个任期号中已经被提交，那么这个条目必然出现在更大任期号的所有领导人中（5.4 节）&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;状态机安全特性&lt;/td&gt;
      &lt;td&gt;如果一个领导人已经在给定的索引值位置的日志条目应用到状态机中，那么其他任何的服务器在这个索引位置不会提交一个不同的日志（5.4.3 节）&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE3.png&quot; alt=&quot;图 3 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 3：Raft 在任何时候都保证以上的各个特性。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;51-raft-基础&quot;&gt;5.1 Raft 基础&lt;/h3&gt;

&lt;p&gt;一个 Raft 集群包含若干个服务器节点；通常是 5 个，这允许整个系统容忍 2 个节点的失效。在任何时刻，每一个服务器节点都处于这三个状态之一：领导人、跟随者或者候选人。在通常情况下，系统中只有一个领导人并且其他的节点全部都是跟随者。跟随者都是被动的：他们不会发送任何请求，只是简单的响应来自领导者或者候选人的请求。领导人处理所有的客户端请求（如果一个客户端和跟随者联系，那么跟随者会把请求重定向给领导人）。第三种状态，候选人，是用来在 5.2 节描述的选举新领导人时使用。图 4 展示了这些状态和他们之间的转换关系；这些转换关系会在接下来进行讨论。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE4.png&quot; alt=&quot;图 4 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 4：服务器状态。跟随者只响应来自其他服务器的请求。如果跟随者接收不到消息，那么他就会变成候选人并发起一次选举。获得集群中大多数选票的候选人将成为领导者。在一个任期内，领导人一直都会是领导人直到自己宕机了。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE5.png&quot; alt=&quot;图 5 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 5：时间被划分成一个个的任期，每个任期开始都是一次选举。在选举成功后，领导人会管理整个集群直到任期结束。有时候选举会失败，那么这个任期就会没有领导人而结束。任期之间的切换可以在不同的时间不同的服务器上观察到。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Raft 把时间分割成任意长度的&lt;strong&gt;任期&lt;/strong&gt;，如图 5。任期用连续的整数标记。每一段任期从一次&lt;strong&gt;选举&lt;/strong&gt;开始，就像章节 5.2 描述的一样，一个或者多个候选人尝试成为领导者。如果一个候选人赢得选举，然后他就在接下来的任期内充当领导人的职责。在某些情况下，一次选举过程会造成选票的瓜分。在这种情况下，这一任期会以没有领导人结束；一个新的任期（和一次新的选举）会很快重新开始。Raft 保证了在一个给定的任期内，最多只有一个领导者。&lt;/p&gt;

&lt;p&gt;不同的服务器节点可能多次观察到任期之间的转换，但在某些情况下，一个节点也可能观察不到任何一次选举或者整个任期全程。任期在 Raft 算法中充当逻辑时钟的作用，这会允许服务器节点查明一些过期的信息比如陈旧的领导者。每一个节点存储一个当前任期号，这一编号在整个时期内单调的增长。当服务器之间通信的时候会交换当前任期号；如果一个服务器的当前任期号比其他人小，那么他会更新自己的编号到较大的编号值。如果一个候选人或者领导者发现自己的任期号过期了，那么他会立即恢复成跟随者状态。如果一个节点接收到一个包含过期的任期号的请求，那么他会直接拒绝这个请求。&lt;/p&gt;

&lt;p&gt;Raft 算法中服务器节点之间通信使用远程过程调用（RPCs），并且基本的一致性算法只需要两种类型的 RPCs。请求投票（RequestVote） RPCs 由候选人在选举期间发起（章节  5.2），然后附加条目（AppendEntries）RPCs 由领导人发起，用来复制日志和提供一种心跳机制（章节 5.3）。第 7 节为了在服务器之间传输快照增加了第三种 RPC。当服务器没有及时的收到 RPC 的响应时，会进行重试， 并且他们能够并行的发起 RPCs 来获得最佳的性能。&lt;/p&gt;

&lt;h3 id=&quot;52-领导人选举&quot;&gt;5.2 领导人选举&lt;/h3&gt;

&lt;p&gt;Raft 使用一种心跳机制来触发领导人选举。当服务器程序启动时，他们都是跟随者身份。一个服务器节点继续保持着跟随者状态只要他从领导人或者候选者处接收到有效的 RPCs。领导者周期性的向所有跟随者发送心跳包（即不包含日志项内容的附加日志项 RPCs）来维持自己的权威。如果一个跟随者在一段时间里没有接收到任何消息，也就是&lt;strong&gt;选举超时&lt;/strong&gt;，那么他就会认为系统中没有可用的领导者,并且发起选举以选出新的领导者。&lt;/p&gt;

&lt;p&gt;要开始一次选举过程，跟随者先要增加自己的当前任期号并且转换到候选人状态。然后他会并行的向集群中的其他服务器节点发送请求投票的 RPCs 来给自己投票。候选人会继续保持着当前状态直到以下三件事情之一发生：(a) 他自己赢得了这次的选举，(b) 其他的服务器成为领导者，(c) 一段时间之后没有任何一个获胜的人。这些结果会分别的在下面的段落里进行讨论。&lt;/p&gt;

&lt;p&gt;当一个候选人从整个集群的大多数服务器节点获得了针对同一个任期号的选票，那么他就赢得了这次选举并成为领导人。每一个服务器最多会对一个任期号投出一张选票，按照先来先服务的原则（注意：5.4 节在投票上增加了一点额外的限制）。要求大多数选票的规则确保了最多只会有一个候选人赢得此次选举（图 3 中的选举安全性）。一旦候选人赢得选举，他就立即成为领导人。然后他会向其他的服务器发送心跳消息来建立自己的权威并且阻止新的领导人的产生。&lt;/p&gt;

&lt;p&gt;在等待投票的时候，候选人可能会从其他的服务器接收到声明它是领导人的附加日志项 RPC。如果这个领导人的任期号（包含在此次的 RPC中）不小于候选人当前的任期号，那么候选人会承认领导人合法并回到跟随者状态。 如果此次 RPC 中的任期号比自己小，那么候选人就会拒绝这次的 RPC 并且继续保持候选人状态。&lt;/p&gt;

&lt;p&gt;第三种可能的结果是候选人既没有赢得选举也没有输：如果有多个跟随者同时成为候选人，那么选票可能会被瓜分以至于没有候选人可以赢得大多数人的支持。当这种情况发生的时候，每一个候选人都会超时，然后通过增加当前任期号来开始一轮新的选举。然而，没有其他机制的话，选票可能会被无限的重复瓜分。&lt;/p&gt;

&lt;p&gt;Raft 算法使用随机选举超时时间的方法来确保很少会发生选票瓜分的情况，就算发生也能很快的解决。为了阻止选票起初就被瓜分，选举超时时间是从一个固定的区间（例如 150-300 毫秒）随机选择。这样可以把服务器都分散开以至于在大多数情况下只有一个服务器会选举超时；然后他赢得选举并在其他服务器超时之前发送心跳包。同样的机制被用在选票瓜分的情况下。每一个候选人在开始一次选举的时候会重置一个随机的选举超时时间，然后在超时时间内等待投票的结果；这样减少了在新的选举中另外的选票瓜分的可能性。9.3 节展示了这种方案能够快速的选出一个领导人。&lt;/p&gt;

&lt;p&gt;领导人选举这个例子，体现了可理解性原则是如何指导我们进行方案设计的。起初我们计划使用一种排名系统：每一个候选人都被赋予一个唯一的排名，供候选人之间竞争时进行选择。如果一个候选人发现另一个候选人拥有更高的排名，那么他就会回到跟随者状态，这样高排名的候选人能够更加容易的赢得下一次选举。但是我们发现这种方法在可用性方面会有一点问题（如果高排名的服务器宕机了，那么低排名的服务器可能会超时并再次进入候选人状态。而且如果这个行为发生得足够快，则可能会导致整个选举过程都被重置掉）。我们针对算法进行了多次调整，但是每次调整之后都会有新的问题。最终我们认为随机重试的方法是更加明显和易于理解的。&lt;/p&gt;

&lt;h3 id=&quot;53-日志复制&quot;&gt;5.3 日志复制&lt;/h3&gt;

&lt;p&gt;一旦一个领导人被选举出来，他就开始为客户端提供服务。客户端的每一个请求都包含一条被复制状态机执行的指令。领导人把这条指令作为一条新的日志条目附加到日志中去，然后并行的发起附加条目 RPCs 给其他的服务器，让他们复制这条日志条目。当这条日志条目被安全的复制（下面会介绍），领导人会应用这条日志条目到它的状态机中然后把执行的结果返回给客户端。如果跟随者崩溃或者运行缓慢，再或者网络丢包，领导人会不断的重复尝试附加日志条目 RPCs （尽管已经回复了客户端）直到所有的跟随者都最终存储了所有的日志条目。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE6.png&quot; alt=&quot;图 6 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 6：日志由有序序号标记的条目组成。每个条目都包含创建时的任期号（图中框中的数字），和一个状态机需要执行的指令。一个条目当可以安全的被应用到状态机中去的时候，就认为是可以提交了。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;日志以图 6 展示的方式组织。每一个日志条目存储一条状态机指令和从领导人收到这条指令时的任期号。日志中的任期号用来检查是否出现不一致的情况，同时也用来保证图 3 中的某些性质。每一条日志条目同时也都有一个整数索引值来表明它在日志中的位置。&lt;/p&gt;

&lt;p&gt;领导人来决定什么时候把日志条目应用到状态机中是安全的；这种日志条目被称为&lt;strong&gt;已提交&lt;/strong&gt;。Raft 算法保证所有已提交的日志条目都是持久化的并且最终会被所有可用的状态机执行。在领导人将创建的日志条目复制到大多数的服务器上的时候，日志条目就会被提交（例如在图 6 中的条目 7）。同时，领导人的日志中之前的所有日志条目也都会被提交，包括由其他领导人创建的条目。5.4 节会讨论某些当在领导人改变之后应用这条规则的隐晦内容，同时他也展示了这种提交的定义是安全的。领导人跟踪了最大的将会被提交的日志项的索引，并且索引值会被包含在未来的所有附加日志 RPCs （包括心跳包），这样其他的服务器才能最终知道领导人的提交位置。一旦跟随者知道一条日志条目已经被提交，那么他也会将这个日志条目应用到本地的状态机中（按照日志的顺序）。&lt;/p&gt;

&lt;p&gt;我们设计了 Raft 的日志机制来维护一个不同服务器的日志之间的高层次的一致性。这么做不仅简化了系统的行为也使得更加可预计，同时他也是安全性保证的一个重要组件。Raft 维护着以下的特性，这些同时也组成了图 3 中的日志匹配特性：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果在不同的日志中的两个条目拥有相同的索引和任期号，那么他们存储了相同的指令。&lt;/li&gt;
  &lt;li&gt;如果在不同的日志中的两个条目拥有相同的索引和任期号，那么他们之前的所有日志条目也全部相同。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;第一个特性来自这样的一个事实，领导人最多在一个任期里在指定的一个日志索引位置创建一条日志条目，同时日志条目在日志中的位置也从来不会改变。第二个特性由附加日志 RPC 的一个简单的一致性检查所保证。在发送附加日志 RPC 的时候，领导人会把新的日志条目紧接着之前的条目的索引位置和任期号包含在里面。如果跟随者在它的日志中找不到包含相同索引位置和任期号的条目，那么他就会拒绝接收新的日志条目。一致性检查就像一个归纳步骤：一开始空的日志状态肯定是满足日志匹配特性的，然后一致性检查保护了日志匹配特性当日志扩展的时候。因此，每当附加日志 RPC 返回成功时，领导人就知道跟随者的日志一定是和自己相同的了。&lt;/p&gt;

&lt;p&gt;在正常的操作中，领导人和跟随者的日志保持一致性，所以附加日志 RPC 的一致性检查从来不会失败。然而，领导人崩溃的情况会使得日志处于不一致的状态（老的领导人可能还没有完全复制所有的日志条目）。这种不一致问题会在领导人和跟随者的一系列崩溃下加剧。图 7 展示了跟随者的日志可能和新的领导人不同的方式。跟随者可能会丢失一些在新的领导人中有的日志条目，他也可能拥有一些领导人没有的日志条目，或者两者都发生。丢失或者多出日志条目可能会持续多个任期。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE7.png&quot; alt=&quot;图 7 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 7：当一个领导人成功当选时，跟随者可能是任何情况（a-f）。每一个盒子表示是一个日志条目；里面的数字表示任期号。跟随者可能会缺少一些日志条目（a-b），可能会有一些未被提交的日志条目（c-d），或者两种情况都存在（e-f）。例如，场景 f 可能会这样发生，某服务器在任期 2 的时候是领导人，已附加了一些日志条目到自己的日志中，但在提交之前就崩溃了；很快这个机器就被重启了，在任期 3 重新被选为领导人，并且又增加了一些日志条目到自己的日志中；在任期 2 和任期 3 的日志被提交之前，这个服务器又宕机了，并且在接下来的几个任期里一直处于宕机状态。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;在 Raft 算法中，领导人处理不一致是通过强制跟随者直接复制自己的日志来解决了。这意味着在跟随者中的冲突的日志条目会被领导人的日志覆盖。5.4 节会阐述如何通过增加一些限制来使得这样的操作是安全的。&lt;/p&gt;

&lt;p&gt;要使得跟随者的日志进入和自己一致的状态，领导人必须找到最后两者达成一致的地方，然后删除从那个点之后的所有日志条目，发送自己的日志给跟随者。所有的这些操作都在进行附加日志 RPCs 的一致性检查时完成。领导人针对每一个跟随者维护了一个 &lt;strong&gt;nextIndex&lt;/strong&gt;，这表示下一个需要发送给跟随者的日志条目的索引地址。当一个领导人刚获得权力的时候，他初始化所有的 nextIndex 值为自己的最后一条日志的index加1（图 7 中的 11）。如果一个跟随者的日志和领导人不一致，那么在下一次的附加日志 RPC 时的一致性检查就会失败。在被跟随者拒绝之后，领导人就会减小 nextIndex 值并进行重试。最终 nextIndex 会在某个位置使得领导人和跟随者的日志达成一致。当这种情况发生，附加日志 RPC 就会成功，这时就会把跟随者冲突的日志条目全部删除并且加上领导人的日志。一旦附加日志 RPC 成功，那么跟随者的日志就会和领导人保持一致，并且在接下来的任期里一直继续保持。&lt;/p&gt;

&lt;p&gt;如果需要的话，算法可以通过减少被拒绝的附加日志 RPCs 的次数来优化。例如，当附加日志 RPC 的请求被拒绝的时候，跟随者可以包含冲突的条目的任期号和自己存储的那个任期的最早的索引地址。借助这些信息，领导人可以减小 nextIndex 越过所有那个任期冲突的所有日志条目；这样就变成每个任期需要一次附加条目 RPC 而不是每个条目一次。在实践中，我们十分怀疑这种优化是否是必要的，因为失败是很少发生的并且也不大可能会有这么多不一致的日志。&lt;/p&gt;

&lt;p&gt;通过这种机制，领导人在获得权力的时候就不需要任何特殊的操作来恢复一致性。他只需要进行正常的操作，然后日志就能自动的在回复附加日志 RPC 的一致性检查失败的时候自动趋于一致。领导人从来不会覆盖或者删除自己的日志（图 3 的领导人只附加特性）。&lt;/p&gt;

&lt;p&gt;日志复制机制展示出了第 2 节中形容的一致性特性：Raft 能够接受，复制并应用新的日志条目只要大部分的机器是工作的；在通常的情况下，新的日志条目可以在一次 RPC 中被复制给集群中的大多数机器；并且单个的缓慢的跟随者不会影响整体的性能。&lt;/p&gt;

&lt;h3 id=&quot;54-安全性&quot;&gt;5.4 安全性&lt;/h3&gt;

&lt;p&gt;前面的章节里描述了 Raft 算法是如何选举和复制日志的。然而，到目前为止描述的机制并不能充分的保证每一个状态机会按照相同的顺序执行相同的指令。例如，一个跟随者可能会进入不可用状态同时领导人已经提交了若干的日志条目，然后这个跟随者可能会被选举为领导人并且覆盖这些日志条目；因此，不同的状态机可能会执行不同的指令序列。&lt;/p&gt;

&lt;p&gt;这一节通过在领导选举的时候增加一些限制来完善 Raft 算法。这一限制保证了任何的领导人对于给定的任期号，都拥有了之前任期的所有被提交的日志条目（图 3 中的领导人完整特性）。增加这一选举时的限制，我们对于提交时的规则也更加清晰。最终，我们将展示对于领导人完整特性的简要证明，并且说明领导人是如何领导复制状态机的做出正确行为的。&lt;/p&gt;

&lt;h4 id=&quot;541-选举限制&quot;&gt;5.4.1 选举限制&lt;/h4&gt;

&lt;p&gt;在任何基于领导人的一致性算法中，领导人都必须存储所有已经提交的日志条目。在某些一致性算法中，例如 Viewstamped Replication，某个节点即使是一开始并没有包含所有已经提交的日志条目，它也能被选为领导者。这些算法都包含一些额外的机制来识别丢失的日志条目并把他们传送给新的领导人，要么是在选举阶段要么在之后很快进行。不幸的是，这种方法会导致相当大的额外的机制和复杂性。Raft 使用了一种更加简单的方法，它可以保证所有之前的任期号中已经提交的日志条目在选举的时候都会出现在新的领导人中，不需要传送这些日志条目给领导人。这意味着日志条目的传送是单向的，只从领导人传给跟随者，并且领导人从不会覆盖自身本地日志中已经存在的条目。&lt;/p&gt;

&lt;p&gt;Raft 使用投票的方式来阻止一个候选人赢得选举除非这个候选人包含了所有已经提交的日志条目。候选人为了赢得选举必须联系集群中的大部分节点，这意味着每一个已经提交的日志条目在这些服务器节点中肯定存在于至少一个节点上。如果候选人的日志至少和大多数的服务器节点一样新（这个新的定义会在下面讨论），那么他一定持有了所有已经提交的日志条目。请求投票 RPC 实现了这样的限制： RPC 中包含了候选人的日志信息，然后投票人会拒绝掉那些日志没有自己新的投票请求。&lt;/p&gt;

&lt;p&gt;Raft 通过比较两份日志中最后一条日志条目的索引值和任期号定义谁的日志比较新。如果两份日志最后的条目的任期号不同，那么任期号大的日志更加新。如果两份日志最后的条目任期号相同，那么日志比较长的那个就更加新。&lt;/p&gt;

&lt;h4 id=&quot;542-提交之前任期内的日志条目&quot;&gt;5.4.2 提交之前任期内的日志条目&lt;/h4&gt;

&lt;p&gt;如同 5.3 节介绍的那样，领导人知道一条当前任期内的日志记录是可以被提交的，只要它被存储到了大多数的服务器上。如果一个领导人在提交日志条目之前崩溃了，未来后续的领导人会继续尝试复制这条日志记录。然而，一个领导人不能断定一个之前任期里的日志条目被保存到大多数服务器上的时候就一定已经提交了。图 8 展示了一种情况，一条已经被存储到大多数节点上的老日志条目，也依然有可能会被未来的领导人覆盖掉。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE8.png&quot; alt=&quot;图 8 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 8：如图的时间序列展示了为什么领导人无法决定对老任期号的日志条目进行提交。在 (a) 中，S1 是领导者，部分的复制了索引位置 2 的日志条目。在 (b) 中，S1 崩溃了，然后 S5 在任期 3 里通过 S3、S4 和自己的选票赢得选举，然后从客户端接收了一条不一样的日志条目放在了索引 2 处。然后到 (c)，S5 又崩溃了；S1 重新启动，选举成功，开始复制日志。在这时，来自任期 2 的那条日志已经被复制到了集群中的大多数机器上，但是还没有被提交。如果 S1 在 (d) 中又崩溃了，S5 可以重新被选举成功（通过来自 S2，S3 和 S4 的选票），然后覆盖了他们在索引 2 处的日志。反之，如果在崩溃之前，S1 把自己主导的新任期里产生的日志条目复制到了大多数机器上，就如 (e) 中那样，那么在后面任期里面这些新的日志条目就会被提交（因为S5 就不可能选举成功）。 这样在同一时刻就同时保证了，之前的所有老的日志条目就会被提交。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;为了消除图 8 里描述的情况，Raft 永远不会通过计算副本数目的方式去提交一个之前任期内的日志条目。只有领导人当前任期里的日志条目通过计算副本数目可以被提交；一旦当前任期的日志条目以这种方式被提交，那么由于日志匹配特性，之前的日志条目也都会被间接的提交。在某些情况下，领导人可以安全的知道一个老的日志条目是否已经被提交（例如，该条目是否存储到所有服务器上），但是 Raft 为了简化问题使用一种更加保守的方法。&lt;/p&gt;

&lt;p&gt;当领导人复制之前任期里的日志时，Raft 会为所有日志保留原始的任期号, 这在提交规则上产生了额外的复杂性。在其他的一致性算法中，如果一个新的领导人要重新复制之前的任期里的日志时，它必须使用当前新的任期号。Raft 使用的方法更加容易辨别出日志，因为它可以随着时间和日志的变化对日志维护着同一个任期编号。另外，和其他的算法相比，Raft 中的新领导人只需要发送更少日志条目（其他算法中必须在他们被提交之前发送更多的冗余日志条目来为他们重新编号）。&lt;/p&gt;

&lt;h4 id=&quot;543-安全性论证&quot;&gt;5.4.3 安全性论证&lt;/h4&gt;

&lt;p&gt;在给定了完整的 Raft 算法之后，我们现在可以更加精确的讨论领导人完整性特性（这一讨论基于 9.2 节的安全性证明）。我们假设领导人完全性特性是不存在的，然后我们推出矛盾来。假设任期 T 的领导人（领导人 T）在任期内提交了一条日志条目，但是这条日志条目没有被存储到未来某个任期的领导人的日志中。设大于 T 的最小任期 U 的领导人 U 没有这条日志条目。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE9.png&quot; alt=&quot;图 9 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 9：如果 S1 （任期 T 的领导者）提交了一条新的日志在它的任期里，然后 S5 在之后的任期 U 里被选举为领导人，然后至少会有一个机器，如 S3，既拥有来自 S1 的日志，也给 S5 投票了。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ol&gt;
  &lt;li&gt;在领导人 U 选举的时候一定没有那条被提交的日志条目（领导人从不会删除或者覆盖任何条目）。&lt;/li&gt;
  &lt;li&gt;领导人 T 复制这条日志条目给集群中的大多数节点，同时，领导人U 从集群中的大多数节点赢得了选票。因此，至少有一个节点（投票者、选民）同时接受了来自领导人T 的日志条目，并且给领导人U 投票了，如图 9。这个投票者是产生这个矛盾的关键。&lt;/li&gt;
  &lt;li&gt;这个投票者必须在给领导人 U 投票之前先接受了从领导人 T 发来的已经被提交的日志条目；否则他就会拒绝来自领导人 T 的附加日志请求（因为此时他的任期号会比 T 大）。&lt;/li&gt;
  &lt;li&gt;投票者在给领导人 U 投票时依然保有这条日志条目，因为任何中间的领导人都包含该日志条目（根据上述的假设），领导人从不会删除条目，并且跟随者只有和领导人冲突的时候才会删除条目。&lt;/li&gt;
  &lt;li&gt;投票者把自己选票投给领导人 U 时，领导人 U 的日志必须和投票者自己一样新。这就导致了两者矛盾之一。&lt;/li&gt;
  &lt;li&gt;首先，如果投票者和领导人 U 的最后一条日志的任期号相同，那么领导人 U 的日志至少和投票者一样长，所以领导人 U 的日志一定包含所有投票者的日志。这是另一处矛盾，因为投票者包含了那条已经被提交的日志条目，但是在上述的假设里，领导人 U 是不包含的。&lt;/li&gt;
  &lt;li&gt;除此之外，领导人 U 的最后一条日志的任期号就必须比投票人大了。此外，他也比 T 大，因为投票人的最后一条日志的任期号至少和 T 一样大（他包含了来自任期 T 的已提交的日志）。创建了领导人 U 最后一条日志的之前领导人一定已经包含了那条被提交的日志（根据上述假设，领导人 U 是第一个不包含该日志条目的领导人）。所以，根据日志匹配特性，领导人 U 一定也包含那条被提交当然日志，这里产生矛盾。&lt;/li&gt;
  &lt;li&gt;这里完成了矛盾。因此，所有比 T 大的领导人一定包含了所有来自 T 的已经被提交的日志。&lt;/li&gt;
  &lt;li&gt;日志匹配原则保证了未来的领导人也同时会包含被间接提交的条目，例如图 8 (d) 中的索引 2。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;通过领导人完全特性，我们就能证明图 3 中的状态机安全特性，即如果已经服务器已经在某个给定的索引值应用了日志条目到自己的状态机里，那么其他的服务器不会应用一个不一样的日志到同一个索引值上。在一个服务器应用一条日志条目到他自己的状态机中时，他的日志必须和领导人的日志，在该条目和之前的条目上相同，并且已经被提交。现在我们来考虑在任何一个服务器应用一个指定索引位置的日志的最小任期；日志完全特性保证拥有更高任期号的领导人会存储相同的日志条目，所以之后的任期里应用某个索引位置的日志条目也会是相同的值。因此，状态机安全特性是成立的。&lt;/p&gt;

&lt;p&gt;最后，Raft 要求服务器按照日志中索引位置顺序应用日志条目。和状态机安全特性结合起来看，这就意味着所有的服务器会应用相同的日志序列集到自己的状态机中，并且是按照相同的顺序。&lt;/p&gt;

&lt;h3 id=&quot;55-跟随者和候选人崩溃&quot;&gt;5.5 跟随者和候选人崩溃&lt;/h3&gt;

&lt;p&gt;到目前为止，我们都只关注了领导人崩溃的情况。跟随者和候选人崩溃后的处理方式比领导人要简单的多，并且他们的处理方式是相同的。如果跟随者或者候选人崩溃了，那么后续发送给他们的 RPCs 都会失败。Raft 中处理这种失败就是简单的通过无限的重试；如果崩溃的机器重启了，那么这些 RPC 就会完整的成功。如果一个服务器在完成了一个 RPC，但是还没有响应的时候崩溃了，那么在他重新启动之后就会再次收到同样的请求。Raft 的 RPCs 都是幂等的，所以这样重试不会造成任何问题。例如一个跟随者如果收到附加日志请求但是他已经包含了这一日志，那么他就会直接忽略这个新的请求。&lt;/p&gt;

&lt;h3 id=&quot;56-时间和可用性&quot;&gt;5.6 时间和可用性&lt;/h3&gt;

&lt;p&gt;Raft 的要求之一就是安全性不能依赖时间：整个系统不能因为某些事件运行的比预期快一点或者慢一点就产生了错误的结果。但是，可用性（系统可以及时的响应客户端）不可避免的要依赖于时间。例如，如果消息交换比服务器故障间隔时间长，候选人将没有足够长的时间来赢得选举；没有一个稳定的领导人，Raft 将无法工作。&lt;/p&gt;

&lt;p&gt;领导人选举是 Raft 中对时间要求最为关键的方面。Raft 可以选举并维持一个稳定的领导人,只要系统满足下面的时间要求：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;广播时间（broadcastTime）  «  选举超时时间（electionTimeout） «  平均故障间隔时间（MTBF）&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;在这个不等式中，广播时间指的是从一个服务器并行的发送 RPCs 给集群中的其他服务器并接收响应的平均时间；选举超时时间就是在 5.2 节中介绍的选举的超时时间限制；然后平均故障间隔时间就是对于一台服务器而言，两次故障之间的平均时间。广播时间必须比选举超时时间小一个量级，这样领导人才能够发送稳定的心跳消息来阻止跟随者开始进入选举状态；通过随机化选举超时时间的方法，这个不等式也使得选票瓜分的情况变得不可能。选举超时时间应该要比平均故障间隔时间小上几个数量级，这样整个系统才能稳定的运行。当领导人崩溃后，整个系统会大约相当于选举超时的时间里不可用；我们希望这种情况在整个系统的运行中很少出现。&lt;/p&gt;

&lt;p&gt;广播时间和平均故障间隔时间是由系统决定的，但是选举超时时间是我们自己选择的。Raft 的 RPCs 需要接收方将信息持久化的保存到稳定存储中去，所以广播时间大约是 0.5 毫秒到 20 毫秒，取决于存储的技术。因此，选举超时时间可能需要在 10 毫秒到 500 毫秒之间。大多数的服务器的平均故障间隔时间都在几个月甚至更长，很容易满足时间的需求。&lt;/p&gt;

&lt;h2 id=&quot;6-集群成员变化&quot;&gt;6 集群成员变化&lt;/h2&gt;

&lt;p&gt;到目前为止，我们都假设集群的配置（加入到一致性算法的服务器集合）是固定不变的。但是在实践中，偶尔是会改变集群的配置的，例如替换那些宕机的机器或者改变复制级别。尽管可以通过暂停整个集群，更新所有配置，然后重启整个集群的方式来实现，但是在更改的时候集群会不可用。另外，如果存在手工操作步骤，那么就会有操作失误的风险。为了避免这样的问题，我们决定自动化配置改变并且将其纳入到 Raft 一致性算法中来。&lt;/p&gt;

&lt;p&gt;为了让配置修改机制能够安全，那么在转换的过程中不能够存在任何时间点使得两个领导人同时被选举成功在同一个任期里。不幸的是，任何服务器直接从旧的配置直接转换到新的配置的方案都是不安全的。一次性自动的转换所有服务器是不可能的，所以在转换期间整个集群存在划分成两个独立的大多数群体的可能性（见图 10）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE10.png&quot; alt=&quot;图 10 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 10：直接从一种配置转到新的配置是十分不安全的，因为各个机器可能在任何的时候进行转换。在这个例子中，集群配额从 3 台机器变成了 5 台。不幸的是，存在这样的一个时间点，两个不同的领导人在同一个任期里都可以被选举成功。一个是通过旧的配置，一个通过新的配置。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;为了保证安全性，配置更改必须使用两阶段方法。目前有很多种两阶段的实现。例如，有些系统在第一阶段停掉旧的配置所以集群就不能处理客户端请求；然后在第二阶段在启用新的配置。在 Raft 中，集群先切换到一个过渡的配置，我们称之为共同一致；一旦共同一致已经被提交了，那么系统就切换到新的配置上。共同一致是老配置和新配置的结合：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;日志条目被复制给集群中新、老配置的所有服务器。&lt;/li&gt;
  &lt;li&gt;新、旧配置的服务器都可以成为领导人。&lt;/li&gt;
  &lt;li&gt;达成一致（针对选举和提交）需要分别在两种配置上获得大多数的支持。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;共同一致允许独立的服务器在不影响安全性的前提下，在不同的时间进行配置转换过程。此外，共同一致可以让集群在配置转换的过程人依然响应客户端的请求。&lt;/p&gt;

&lt;p&gt;集群配置在复制日志中以特殊的日志条目来存储和通信；图 11 展示了配置转换的过程。当一个领导人接收到一个改变配置从 C-old 到 C-new 的请求，他会为了共同一致存储配置（图中的 C-old,new），以前面描述的日志条目和副本的形式。一旦一个服务器将新的配置日志条目增加到它的日志中，他就会用这个配置来做出未来所有的决定（服务器总是使用最新的配置，无论他是否已经被提交）。这意味着领导人要使用  C-old,new 的规则来决定日志条目 C-old,new 什么时候需要被提交。如果领导人崩溃了，被选出来的新领导人可能是使用 C-old 配置也可能是 C-old,new 配置，这取决于赢得选举的候选人是否已经接收到了 C-old,new 配置。在任何情况下， C-new 配置在这一时期都不会单方面的做出决定。&lt;/p&gt;

&lt;p&gt;一旦 C-old,new 被提交，那么无论是 C-old 还是 C-new，在没有经过他人批准的情况下都不可能做出决定，并且领导人完全特性保证了只有拥有 C-old,new 日志条目的服务器才有可能被选举为领导人。这个时候，领导人创建一条关于 C-new 配置的日志条目并复制给集群就是安全的了。再者，每个服务器在见到新的配置的时候就会立即生效。当新的配置在 C-new 的规则下被提交，旧的配置就变得无关紧要，同时不使用新的配置的服务器就可以被关闭了。如图 11，C-old 和 C-new 没有任何机会同时做出单方面的决定；这保证了安全性。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE11.png&quot; alt=&quot;图 11 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 11：一个配置切换的时间线。虚线表示已经被创建但是还没有被提交的条目，实线表示最后被提交的日志条目。领导人首先创建了 C-old,new 的配置条目在自己的日志中，并提交到 C-old,new 中（C-old 的大多数和  C-new 的大多数）。然后他创建 C-new 条目并提交到 C-new 中的大多数。这样就不存在  C-new 和 C-old 可以同时做出决定的时间点。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;在关于重新配置还有三个问题需要提出。第一个问题是，新的服务器可能初始化没有存储任何的日志条目。当这些服务器以这种状态加入到集群中，那么他们需要一段时间来更新追赶，这时还不能提交新的日志条目。为了避免这种可用性的间隔时间，Raft 在配置更新的时候使用了一种额外的阶段，在这个阶段，新的服务器以没有投票权身份加入到集群中来（领导人复制日志给他们，但是不考虑他们是大多数）。一旦新的服务器追赶上了集群中的其他机器，重新配置可以像上面描述的一样处理。&lt;/p&gt;

&lt;p&gt;第二个问题是，集群的领导人可能不是新配置的一员。在这种情况下，领导人就会在提交了 C-new 日志之后退位（回到跟随者状态）。这意味着有这样的一段时间，领导人管理着集群，但是不包括他自己；他复制日志但是不把他自己算作是大多数之一。当 C-new 被提交时，会发生领导人过渡，因为这时是最早新的配置可以独立工作的时间点（将总是能够在 C-new 配置下选出新的领导人）。在此之前，可能只能从 C-old 中选出领导人。&lt;/p&gt;

&lt;p&gt;第三个问题是，移除不在 C-new 中的服务器可能会扰乱集群。这些服务器将不会再接收到心跳，所以当选举超时，他们就会进行新的选举过程。他们会发送拥有新的任期号的请求投票 RPCs，这样会导致当前的领导人回退成跟随者状态。新的领导人最终会被选出来，但是被移除的服务器将会再次超时，然后这个过程会再次重复，导致整体可用性大幅降低。&lt;/p&gt;

&lt;p&gt;为了避免这个问题，当服务器确认当前领导人存在时，服务器会忽略请求投票 RPCs。特别的，当服务器在当前最小选举超时时间内收到一个请求投票 RPC，他不会更新当前的任期号或者投出选票。这不会影响正常的选举，每个服务器在开始一次选举之前，至少等待一个最小选举超时时间。然而，这有利于避免被移除的服务器扰乱：如果领导人能够发送心跳给集群，那么他就不会被更大的任期号废黜。&lt;/p&gt;

&lt;h2 id=&quot;7-日志压缩&quot;&gt;7 日志压缩&lt;/h2&gt;

&lt;p&gt;Raft 的日志在正常操作中不断的增长，但是在实际的系统中，日志不能无限制的增长。随着日志不断增长，他会占用越来越多的空间，花费越来越多的时间来重置。如果没有一定的机制去清除日志里积累的陈旧的信息，那么会带来可用性问题。&lt;/p&gt;

&lt;p&gt;快照是最简单的压缩方法。在快照系统中，整个系统的状态都以快照的形式写入到稳定的持久化存储中，然后到那个时间点之前的日志全部丢弃。快照技术被使用在 Chubby 和 ZooKeeper 中，接下来的章节会介绍 Raft 中的快照技术。&lt;/p&gt;

&lt;p&gt;增量压缩的方法，例如日志清理或者日志结构合并树，都是可行的。这些方法每次只对一小部分数据进行操作，这样就分散了压缩的负载压力。首先，他们先选择一个已经积累的大量已经被删除或者被覆盖对象的区域，然后重写那个区域还活跃的对象，之后释放那个区域。和简单操作整个数据集合的快照相比，需要增加复杂的机制来实现。状态机可以实现 LSM tree 使用和快照相同的接口，但是日志清除方法就需要修改 Raft 了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE12.png&quot; alt=&quot;图 12 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 12：一个服务器用新的快照替换了从 1 到 5 的条目，快照值存储了当前的状态。快照中包含了最后的索引位置和任期号。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;图 12 展示了 Raft 中快照的基础思想。每个服务器独立的创建快照，只包括已经被提交的日志。主要的工作包括将状态机的状态写入到快照中。Raft 也包含一些少量的元数据到快照中：&lt;strong&gt;最后被包含索引&lt;/strong&gt;指的是被快照取代的最后的条目在日志中的索引值（状态机最后应用的日志），&lt;strong&gt;最后被包含的任期&lt;/strong&gt;指的是该条目的任期号。保留这些数据是为了支持快照后紧接着的第一个条目的附加日志请求时的一致性检查，因为这个条目需要最后的索引值和任期号。为了支持集群成员更新（第 6 节），快照中也将最后的一次配置作为最后一个条目存下来。一旦服务器完成一次快照，他就可以删除最后索引位置之前的所有日志和快照了。&lt;/p&gt;

&lt;p&gt;尽管通常服务器都是独立的创建快照，但是领导人必须偶尔的发送快照给一些落后的跟随者。这通常发生在当领导人已经丢弃了下一条需要发送给跟随者的日志条目的时候。幸运的是这种情况不是常规操作：一个与领导人保持同步的跟随者通常都会有这个条目。然而一个运行非常缓慢的跟随者或者新加入集群的服务器（第 6 节）将不会有这个条目。这时让这个跟随者更新到最新的状态的方式就是通过网络把快照发送给他们。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;安装快照 RPC&lt;/strong&gt;：&lt;/p&gt;

&lt;p&gt;在领导人发送快照给跟随者时使用到。领导人总是按顺序发送。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;参数&lt;/th&gt;
      &lt;th&gt;解释&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;term&lt;/td&gt;
      &lt;td&gt;领导人的任期号&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;leaderId&lt;/td&gt;
      &lt;td&gt;领导人的 Id，以便于跟随者重定向请求&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;lastIncludedIndex&lt;/td&gt;
      &lt;td&gt;快照中包含的最后日志条目的索引值&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;lastIncludedTerm&lt;/td&gt;
      &lt;td&gt;快照中包含的最后日志条目的任期号&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;offset&lt;/td&gt;
      &lt;td&gt;分块在快照中的偏移量&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;data[]&lt;/td&gt;
      &lt;td&gt;原始数据&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;done&lt;/td&gt;
      &lt;td&gt;如果这是最后一个分块则为 true&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;结果&lt;/th&gt;
      &lt;th&gt;解释&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;term&lt;/td&gt;
      &lt;td&gt;当前任期号，便于领导人更新自己&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;接收者实现&lt;/strong&gt;：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;如果&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;term &amp;lt; currentTerm&lt;/code&gt;就立即回复&lt;/li&gt;
  &lt;li&gt;如果是第一个分块（offset 为 0）就创建一个新的快照&lt;/li&gt;
  &lt;li&gt;在指定偏移量写入数据&lt;/li&gt;
  &lt;li&gt;如果 done 是 false，则继续等待更多的数据&lt;/li&gt;
  &lt;li&gt;保存快照文件，丢弃索引值小于快照的日志&lt;/li&gt;
  &lt;li&gt;如果现存的日志拥有相同的最后任期号和索引值，则后面的数据继续保持&lt;/li&gt;
  &lt;li&gt;丢弃整个日志&lt;/li&gt;
  &lt;li&gt;使用快照重置状态机&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE13.png&quot; alt=&quot;图 13 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 13：一个关于安装快照的简要概述。为了便于传输，快照都是被分成分块的；每个分块都给了跟随者生命的迹象，所以跟随者可以重置选举超时计时器。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;在这种情况下领导人使用一种叫做安装快照的新的 RPC 来发送快照给太落后的跟随者；见图 13。当跟随者通过这种  RPC 接收到快照时，他必须自己决定对于已经存在的日志该如何处理。通常快照会包含没有在接收者日志中存在的信息。在这种情况下，跟随者直接丢弃他所有的日志；这些会被快照所取代，但是可能会和没有提交的日志产生冲突。如果接收到的快照是自己日志的前面部分（由于网络重传或者错误），那么被快照包含的条目将会被全部删除，但是快照之后的条目必须正确和保留。&lt;/p&gt;

&lt;p&gt;这种快照的方式背离了 Raft 的强领导人原则，因为跟随者可以在不知道领导人情况下创建快照。但是我们认为这种背离是值得的。领导人的存在，是为了解决在达成一致性的时候的冲突，但是在创建快照的时候，一致性已经达成，这时不存在冲突了，所以没有领导人也是可以的。数据依然是从领导人传给跟随者，只是跟随者可以重新组织他们的数据了。&lt;/p&gt;

&lt;p&gt;我们考虑过一种替代的基于领导人的快照方案，即只有领导人创建快照，然后发送给所有的跟随者。但是这样做有两个缺点。第一，发送快照会浪费网络带宽并且延缓了快照处理的时间。每个跟随者都已经拥有了所有产生快照需要的信息，而且很显然，自己从本地的状态中创建快照比通过网络接收别人发来的要经济。第二，领导人的实现会更加复杂。例如，领导人需要发送快照的同时并行的将新的日志条目发送给跟随者，这样才不会阻塞新的客户端请求。&lt;/p&gt;

&lt;p&gt;还有两个问题影响了快照的性能。首先，服务器必须决定什么时候应该创建快照。如果快照创建的过于频繁，那么就会浪费大量的磁盘带宽和其他资源；如果创建快照频率太低，他就要承受耗尽存储容量的风险，同时也增加了从日志重建的时间。一个简单的策略就是当日志大小达到一个固定大小的时候就创建一次快照。如果这个阈值设置的显著大于期望的快照的大小，那么快照对磁盘压力的影响就会很小了。&lt;/p&gt;

&lt;p&gt;第二个影响性能的问题就是写入快照需要花费显著的一段时间，并且我们还不希望影响到正常操作。解决方案是通过写时复制的技术，这样新的更新就可以被接收而不影响到快照。例如，具有函数式数据结构的状态机天然支持这样的功能。另外，操作系统的写时复制技术的支持（如 Linux 上的 fork）可以被用来创建完整的状态机的内存快照（我们的实现就是这样的）。&lt;/p&gt;

&lt;h2 id=&quot;8-客户端交互&quot;&gt;8 客户端交互&lt;/h2&gt;

&lt;p&gt;这一节将介绍客户端是如何和 Raft 进行交互的，包括客户端如何发现领导人和 Raft 是如何支持线性化语义的。这些问题对于所有基于一致性的系统都存在，并且 Raft 的解决方案和其他的也差不多。&lt;/p&gt;

&lt;p&gt;Raft 中的客户端发送所有请求给领导人。当客户端启动的时候，他会随机挑选一个服务器进行通信。如果客户端第一次挑选的服务器不是领导人，那么那个服务器会拒绝客户端的请求并且提供他最近接收到的领导人的信息（附加条目请求包含了领导人的网络地址）。如果领导人已经崩溃了，那么客户端的请求就会超时；客户端之后会再次重试随机挑选服务器的过程。&lt;/p&gt;

&lt;p&gt;我们 Raft 的目标是要实现线性化语义（每一次操作立即执行，只执行一次，在他调用和收到回复之间）。但是，如上述，Raft 是可以执行同一条命令多次的：例如，如果领导人在提交了这条日志之后，但是在响应客户端之前崩溃了，那么客户端会和新的领导人重试这条指令，导致这条命令就被再次执行了。解决方案就是客户端对于每一条指令都赋予一个唯一的序列号。然后，状态机跟踪每条指令最新的序列号和相应的响应。如果接收到一条指令，它的序列号已经被执行了，那么就立即返回结果，而不重新执行指令。&lt;/p&gt;

&lt;p&gt;只读的操作可以直接处理而不需要记录日志。但是，在不增加任何限制的情况下，这么做可能会冒着返回脏数据的风险，因为领导人响应客户端请求时可能已经被新的领导人作废了，但是他还不知道。线性化的读操作必须不能返回脏数据，Raft 需要使用两个额外的措施在不使用日志的情况下保证这一点。首先，领导人必须有关于被提交日志的最新信息。领导人完全特性保证了领导人一定拥有所有已经被提交的日志条目，但是在他任期开始的时候，他可能不知道那些是已经被提交的。为了知道这些信息，他需要在他的任期里提交一条日志条目。Raft 中通过领导人在任期开始的时候提交一个空白的没有任何操作的日志条目到日志中去来实现。第二，领导人在处理只读的请求之前必须检查自己是否已经被废黜了（他自己的信息已经变脏了如果一个更新的领导人被选举出来）。Raft 中通过让领导人在响应只读请求之前，先和集群中的大多数节点交换一次心跳信息来处理这个问题。可选的，领导人可以依赖心跳机制来实现一种租约的机制，但是这种方法依赖时间来保证安全性（假设时间误差是有界的）。&lt;/p&gt;

&lt;h2 id=&quot;9-算法实现和评估&quot;&gt;9 算法实现和评估&lt;/h2&gt;

&lt;p&gt;我们已经为 RAMCloud 实现了 Raft 算法作为存储配置信息的复制状态机的一部分，并且帮助 RAMCloud 协调故障转移。这个 Raft 实现包含大约 2000 行 C++ 代码，其中不包括测试、注释和空行。这些代码是开源的。同时也有大约 25 个其他独立的第三方的基于这篇论文草稿的开源实现，针对不同的开发场景。同时，很多公司已经部署了基于 Raft 的系统。&lt;/p&gt;

&lt;p&gt;这一节会从三个方面来评估 Raft 算法：可理解性、正确性和性能。&lt;/p&gt;

&lt;h3 id=&quot;91-可理解性&quot;&gt;9.1 可理解性&lt;/h3&gt;

&lt;p&gt;为了和 Paxos 比较 Raft 算法的可理解能力，我们针对高层次的本科生和研究生，在斯坦福大学的高级操作系统课程和加州大学伯克利分校的分布式计算课程上，进行了一次学习的实验。我们分别拍了针对 Raft 和 Paxos 的视频课程，并准备了相应的小测验。Raft 的视频讲课覆盖了这篇论文的所有内容除了日志压缩；Paxos 讲课包含了足够的资料来创建一个等价的复制状态机，包括单决策 Paxos，多决策 Paxos，重新配置和一些实际系统需要的性能优化（例如领导人选举）。小测验测试一些对算法的基本理解和解释一些边角的示例。每个学生都是看完第一个视频，回答相应的测试，再看第二个视频，回答相应的测试。大约有一半的学生先进行 Paxos 部分，然后另一半先进行 Raft 部分，这是为了说明两者独立的区别从第一个算法处学来的经验。我们计算参加人员的每一个小测验的得分来看参与者是否在 Raft 算法上更加容易理解。&lt;/p&gt;

&lt;p&gt;我们尽可能的使得 Paxos 和 Raft 的比较更加公平。这个实验偏爱 Paxos 表现在两个方面：43 个参加者中有 15 个人在之前有一些  Paxos 的经验，并且 Paxos 的视频要长 14%。如表格 1 总结的那样，我们采取了一些措施来减轻这种潜在的偏见。我们所有的材料都可供审查。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;关心&lt;/th&gt;
      &lt;th&gt;缓和偏见采取的手段&lt;/th&gt;
      &lt;th&gt;可供查看的材料&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;相同的讲课质量&lt;/td&gt;
      &lt;td&gt;两者使用同一个讲师。Paxos 使用的是现在很多大学里经常使用的。Paxos 会长 14%。&lt;/td&gt;
      &lt;td&gt;视频&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;相同的测验难度&lt;/td&gt;
      &lt;td&gt;问题以难度分组，在两个测验里成对出现。&lt;/td&gt;
      &lt;td&gt;小测验&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;公平评分&lt;/td&gt;
      &lt;td&gt;使用红字标题。随机顺序打分，两个测验交替进行。&lt;/td&gt;
      &lt;td&gt;红字标题&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;blockquote&gt;
  &lt;p&gt;表 1：考虑到可能会存在的偏见，对于每种情况的解决方法，和相应的材料。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;参加者平均在 Raft 的测验中比 Paxos 高 4.9 分（总分 60，那么 Raft 的平均得分是 25.7，而 Paxos 是 20.8）；图 14 展示了每个参与者的得分。一对 t -测试表明，拥有 95% 的可信度，真实的 Raft 分数分布至少比 Paxos 高 2.5 分。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE14.png&quot; alt=&quot;图 14 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 14：一个散点图表示了 43 个学生在 Paxos 和 Raft 的小测验中的成绩。在对角线之上的点表示在 Raft 获得了更高分数的学生。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;我们也建立了一个线性回归模型来预测一个新的学生的测验成绩，基于以下三个因素：他们使用的是哪个小测验，之前对 Paxos 的经验，和学习算法的顺序。模型显示，对小测验的选择会产生 12.5 分的差别在对  Raft 的好感度上。这显著的高于之前的 4.9 分，因为很多学生在之前都已经有了对于   Paxos 的经验，这相当明显的帮助 Paxos，对 Raft 就没什么太大影响了。但是奇怪的是，模型预测对于先进性 Paxos 小测验的人而言，Raft 的小测验得分会比 Paxos 低 6.3 分；我们不知道为什么，但这在统计学上是这样的。&lt;/p&gt;

&lt;p&gt;我们同时也在测验之后调查了参与者，他们认为哪个算法更加容易实现和解释；这个的结果在图 15 上。压倒性的结果表明 Raft 算法更加容易实现和解释（41 人中的 33个）。但是，这种自己报告的结果不如参与者的成绩更加可信，并且参与者可能因为我们的 Raft 更加易于理解的假说而产生偏见。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE15.png&quot; alt=&quot;图 15 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 15：通过一个 5 分制的问题，参与者（左边）被问哪个算法他们觉得在一个高效正确的系统里更容易实现，右边被问哪个更容易向学生解释。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;关于 Raft 用户学习有一个更加详细的讨论。&lt;/p&gt;

&lt;h3 id=&quot;92-正确性&quot;&gt;9.2 正确性&lt;/h3&gt;

&lt;p&gt;在第 5 节，我们已经进行了一个正式的说明，和对一致性机制的安全性证明。这个正式说明让图 2 中的信息非常清晰通过 TLA+ 说明语言。大约 400 行说明充当了证明的主题。同时对于任何想实现的人也是十分有用的。我们非常机械的证明了日志完全特性通过 TLA 证明系统。然而，这个证明依赖的约束前提还没有被机械证明（例如，我们还没有证明这个说明中的类型安全）。而且，我们已经写了一个非正式的证明关于状态机安全性质是完备的，并且是相当清晰的（大约 3500 个词）。&lt;/p&gt;

&lt;h3 id=&quot;93-性能&quot;&gt;9.3 性能&lt;/h3&gt;

&lt;p&gt;Raft 和其他一致性算法例如 Paxos 有着差不多的性能。在性能方面，最重要的关注点是，当领导人被选举成功时，什么时候复制新的日志条目。Raft 通过很少数量的消息包（一轮从领导人到集群大多数机器的消息）就达成了这个目的。同时，进一步提升 Raft 的性能也是可行的。例如，很容易通过支持批量操作和管道操作来提高吞吐量和降低延迟。对于其他一致性算法已经提出过很多性能优化方案；其中有很多也可以应用到 Raft 中来，但是我们暂时把这个问题放到未来的工作中去。&lt;/p&gt;

&lt;p&gt;我们使用我们自己的 Raft 实现来衡量 Raft 领导人选举的性能并且回答两个问题。首先，领导人选举的过程收敛是否快速？第二，在领导人宕机之后，最小的系统宕机时间是多久？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE16.png&quot; alt=&quot;图 16 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 16：发现并替换一个已经崩溃的领导人的时间。上面的图考察了在选举超时时间上的随机化程度，下面的图考察了最小超时时间。每条线代表了 1000 次实验（除了 150-150 毫秒只试了 100 次），和相应的确定的选举超时时间。例如，150-155 毫秒意思是，选举超时时间从这个区间范围内随机选择并确定下来。这个实验在一个拥有 5 个节点的集群上进行，其广播时延大约是 15 毫秒。对于 9 个节点的集群，结果也差不多。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;为了衡量领导人选举，我们反复的使一个拥有五个节点的服务器集群的领导人宕机，并计算需要多久才能发现领导人已经宕机并选出一个新的领导人（见图 16）。为了构建一个最坏的场景，在每一的尝试里，服务器都有不同长度的日志，意味着有些候选人是没有成为领导人的资格的。另外，为了促成选票瓜分的情况，我们的测试脚本在终止领导人之前同步的发送了一次心跳广播（这大约和领导人在崩溃前复制一个新的日志给其他机器很像）。领导人均匀的随机的在心跳间隔里宕机，也就是最小选举超时时间的一半。因此，最小宕机时间大约就是最小选举超时时间的一半。&lt;/p&gt;

&lt;p&gt;图 16 上面的图表表明，只需要在选举超时时间上使用很少的随机化就可以大大避免选票被瓜分的情况。在没有随机化的情况下，在我们的测试里，选举过程往往都需要花费超过 10 秒钟由于太多的选票瓜分的情况。仅仅增加 5 毫秒的随机化时间，就大大的改善了选举过程，现在平均的宕机时间只有 287 毫秒。增加更多的随机化时间可以大大改善最坏情况：通过增加 50 毫秒的随机化时间，最坏的完成情况（1000 次尝试）只要 513 毫秒。&lt;/p&gt;

&lt;p&gt;图 16 中下面的图显示，通过减少选举超时时间可以减少系统的宕机时间。在选举超时时间为 12-24 毫秒的情况下，只需要平均 35 毫秒就可以选举出新的领导人（最长的一次花费了 152 毫秒）。然而，进一步降低选举超时时间的话就会违反 Raft 的时间不等式需求：在选举新领导人之前，领导人就很难发送完心跳包。这会导致没有意义的领导人改变并降低了系统整体的可用性。我们建议使用更为保守的选举超时时间，比如 150-300 毫秒；这样的时间不大可能导致没有意义的领导人改变，而且依然提供不错的可用性。&lt;/p&gt;

&lt;h2 id=&quot;10-相关工作&quot;&gt;10 相关工作&lt;/h2&gt;

&lt;p&gt;已经有很多关于一致性算法的工作被发表出来，其中很多都可以归到下面的类别中：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Lamport 关于 Paxos 的原始描述，和尝试描述的更清晰。&lt;/li&gt;
  &lt;li&gt;关于 Paxos 的更详尽的描述，补充遗漏的细节并修改算法，使得可以提供更加容易的实现基础。&lt;/li&gt;
  &lt;li&gt;实现一致性算法的系统，例如 Chubby，ZooKeeper 和 Spanner。对于 Chubby 和 Spanner 的算法并没有公开发表其技术细节，尽管他们都声称是基于 Paxos 的。ZooKeeper 的算法细节已经发表，但是和 Paxos 着实有着很大的差别。&lt;/li&gt;
  &lt;li&gt;Paxos 可以应用的性能优化。&lt;/li&gt;
  &lt;li&gt;Oki 和 Liskov 的 Viewstamped Replication（VR），一种和 Paxos 差不多的替代算法。原始的算法描述和分布式传输协议耦合在了一起，但是核心的一致性算法在最近的更新里被分离了出来。VR 使用了一种基于领导人的方法，和 Raft 有很多相似之处。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Raft 和 Paxos 最大的不同之处就在于 Raft 的强领导特性：Raft 使用领导人选举作为一致性协议里必不可少的部分，并且将尽可能多的功能集中到了领导人身上。这样就可以使得算法更加容易理解。例如，在 Paxos 中，领导人选举和基本的一致性协议是正交的：领导人选举仅仅是性能优化的手段，而且不是一致性所必须要求的。但是，这样就增加了多余的机制：Paxos 同时包含了针对基本一致性要求的两阶段提交协议和针对领导人选举的独立的机制。相比较而言，Raft 就直接将领导人选举纳入到一致性算法中，并作为两阶段一致性的第一步。这样就减少了很多机制。&lt;/p&gt;

&lt;p&gt;像 Raft 一样，VR 和 ZooKeeper 也是基于领导人的，因此他们也拥有一些 Raft 的优点。但是，Raft 比 VR 和 ZooKeeper 拥有更少的机制因为 Raft 尽可能的减少了非领导人的功能。例如，Raft 中日志条目都遵循着从领导人发送给其他人这一个方向：附加条目 RPC 是向外发送的。在 VR 中，日志条目的流动是双向的（领导人可以在选举过程中接收日志）；这就导致了额外的机制和复杂性。根据 ZooKeeper 公开的资料看，它的日志条目也是双向传输的，但是它的实现更像 Raft。&lt;/p&gt;

&lt;p&gt;和上述我们提及的其他基于一致性的日志复制算法中，Raft 的消息类型更少。例如，我们数了一下 VR 和 ZooKeeper 使用的用来基本一致性需要和成员改变的消息数（排除了日志压缩和客户端交互，因为这些都比较独立且和算法关系不大）。VR 和 ZooKeeper 都分别定义了 10 中不同的消息类型，相对的，Raft 只有 4 中消息类型（两种 RPC 请求和对应的响应）。Raft 的消息都稍微比其他算法的要信息量大，但是都很简单。另外，VR 和 ZooKeeper 都在领导人改变时传输了整个日志；所以为了能够实践中使用，额外的消息类型就很必要了。&lt;/p&gt;

&lt;p&gt;Raft 的强领导人模型简化了整个算法，但是同时也排斥了一些性能优化的方法。例如，平等主义 Paxos （EPaxos）在某些没有领导人的情况下可以达到很高的性能。平等主义 Paxos 充分发挥了在状态机指令中的交换性。任何服务器都可以在一轮通信下就提交指令，除非其他指令同时被提出了。然而，如果指令都是并发的被提出，并且互相之间不通信沟通，那么 EPaxos 就需要额外的一轮通信。因为任何服务器都可以提交指令，所以 EPaxos 在服务器之间的负载均衡做的很好，并且很容易在 WAN 网络环境下获得很低的延迟。但是，他在 Paxos 上增加了非常明显的复杂性。&lt;/p&gt;

&lt;p&gt;一些集群成员变换的方法已经被提出或者在其他的工作中被实现，包括 Lamport 的原始的讨论，VR 和 SMART。我们选择使用共同一致的方法因为他对一致性协议的其他部分影响很小，这样我们只需要很少的一些机制就可以实现成员变换。Lamport 的基于 α 的方法之所以没有被 Raft 选择是因为它假设在没有领导人的情况下也可以达到一致性。和 VR 和 SMART 相比较，Raft 的重新配置算法可以在不限制正常请求处理的情况下进行；相比较的，VR 需要停止所有的处理过程，SMART 引入了一个和 α 类似的方法，限制了请求处理的数量。Raft 的方法同时也需要更少的额外机制来实现，和 VR、SMART 比较而言。&lt;/p&gt;

&lt;h2 id=&quot;11-结论&quot;&gt;11 结论&lt;/h2&gt;

&lt;p&gt;算法的设计通常会把正确性，效率或者简洁作为主要的目标。尽管这些都是很有意义的目标，但是我们相信，可理解性也是一样的重要。在开发者把算法应用到实际的系统中之前，这些目标没有一个会被实现，这些都会必然的偏离发表时的形式。除非开发人员对这个算法有着很深的理解并且有着直观的感觉，否则将会对他们而言很难在实现的时候保持原有期望的特性。&lt;/p&gt;

&lt;p&gt;在这篇论文中，我们尝试解决分布式一致性问题，但是一个广为接受但是十分令人费解的算法 Paxos 已经困扰了无数学生和开发者很多年了。我们创造了一种新的算法 Raft，显而易见的比 Paxos 要容易理解。我们同时也相信，Raft 也可以为实际的实现提供坚实的基础。把可理解性作为设计的目标改变了我们设计 Raft 的方式；这个过程是我们发现我们最终很少有技术上的重复，例如问题分解和简化状态空间。这些技术不仅提升了 Raft 的可理解性，同时也使我们坚信其正确性。&lt;/p&gt;

&lt;h2 id=&quot;12-感谢&quot;&gt;12 感谢&lt;/h2&gt;

&lt;p&gt;这项研究必须感谢以下人员的支持：Ali Ghodsi，David Mazie`res，和伯克利 CS 294-91 课程、斯坦福 CS 240 课程的学生。Scott Klemmer 帮我们设计了用户调查，Nelson Ray 建议我们进行统计学的分析。在用户调查时使用的关于 Paxos 的幻灯片很大一部分是从 Lorenzo Alvisi 的幻灯片上借鉴过来的。特别的，非常感谢 DavidMazieres 和 Ezra Hoch，他们找到了 Raft 中一些难以发现的漏洞。许多人提供了关于这篇论文十分有用的反馈和用户调查材料，包括 Ed Bugnion，Michael Chan，Hugues Evrard，Daniel Giffin，Arjun Gopalan，Jon Howell，Vimalkumar Jeyakumar，Ankita Kejriwal，Aleksandar Kracun，Amit Levy，Joel Martin，Satoshi Matsushita，Oleg Pesok，David Ramos，Robbert van Renesse，Mendel Rosenblum，Nicolas Schiper，Deian Stefan，Andrew Stone，Ryan Stutsman，David Terei，Stephen Yang，Matei Zaharia 以及 24 位匿名的会议审查人员（可能有重复），并且特别感谢我们的领导人 Eddie Kohler。Werner Vogels 发了一条早期草稿链接的推特，给 Raft 带来了极大的关注。我们的工作由 Gigascale 系统研究中心和 Multiscale 系统研究中心给予支持，这两个研究中心由关注中心研究程序资金支持，一个是半导体研究公司的程序，由 STARnet 支持，一个半导体研究公司的程序由 MARCO 和 DARPA 支持，在国家科学基金会的 0963859 号批准，并且获得了来自 Facebook，Google，Mellanox，NEC，NetApp，SAP 和 Samsung 的支持。Diego Ongaro 由 Junglee 公司，斯坦福的毕业团体支持。&lt;/p&gt;

&lt;h2 id=&quot;参考&quot;&gt;参考&lt;/h2&gt;

&lt;p&gt;略&lt;/p&gt;

</description>
                <link>http://www.turbofei.wang/bigdata/2019/05/19/%E8%BD%AC%E8%BD%BD-Raft%E8%AF%91%E6%96%87</link>
                <guid>http://www.turbofei.wang/bigdata/2019/05/19/[转载]-Raft译文</guid>
                <pubDate>2019-05-19T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>About Maven</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#基本概念&quot; id=&quot;markdown-toc-基本概念&quot;&gt;基本概念&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#lifecycle&quot; id=&quot;markdown-toc-lifecycle&quot;&gt;lifecycle&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#phase&quot; id=&quot;markdown-toc-phase&quot;&gt;phase&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#goal&quot; id=&quot;markdown-toc-goal&quot;&gt;goal&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#什么是pom&quot; id=&quot;markdown-toc-什么是pom&quot;&gt;什么是pom?&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#快速察看&quot; id=&quot;markdown-toc-快速察看&quot;&gt;快速察看&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#基本内容&quot; id=&quot;markdown-toc-基本内容&quot;&gt;基本内容：&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#pom关系&quot; id=&quot;markdown-toc-pom关系&quot;&gt;POM关系&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#依赖&quot; id=&quot;markdown-toc-依赖&quot;&gt;依赖&lt;/a&gt;            &lt;ul&gt;
              &lt;li&gt;&lt;a href=&quot;#非开源包处理&quot; id=&quot;markdown-toc-非开源包处理&quot;&gt;非开源包处理&lt;/a&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#继承&quot; id=&quot;markdown-toc-继承&quot;&gt;继承&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#合成&quot; id=&quot;markdown-toc-合成&quot;&gt;合成&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#build设置&quot; id=&quot;markdown-toc-build设置&quot;&gt;build设置&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#resources&quot; id=&quot;markdown-toc-resources&quot;&gt;resources&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#plugins配置&quot; id=&quot;markdown-toc-plugins配置&quot;&gt;plugins配置&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#pluginmanagement配置&quot; id=&quot;markdown-toc-pluginmanagement配置&quot;&gt;pluginManagement配置&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#extensions&quot; id=&quot;markdown-toc-extensions&quot;&gt;Extensions&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#reporting&quot; id=&quot;markdown-toc-reporting&quot;&gt;reporting&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#maven-shade-plugin&quot; id=&quot;markdown-toc-maven-shade-plugin&quot;&gt;Maven-shade-plugin&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#更多项目信息&quot; id=&quot;markdown-toc-更多项目信息&quot;&gt;更多项目信息&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#环境设置&quot; id=&quot;markdown-toc-环境设置&quot;&gt;环境设置&lt;/a&gt;            &lt;ul&gt;
              &lt;li&gt;&lt;a href=&quot;#issuemanagement&quot; id=&quot;markdown-toc-issuemanagement&quot;&gt;issueManagement&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#repositories&quot; id=&quot;markdown-toc-repositories&quot;&gt;Repositories&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#pluginrepositories&quot; id=&quot;markdown-toc-pluginrepositories&quot;&gt;pluginRepositories&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#distributionmanagement&quot; id=&quot;markdown-toc-distributionmanagement&quot;&gt;distributionManagement&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#profiles&quot; id=&quot;markdown-toc-profiles&quot;&gt;profiles&lt;/a&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#references&quot; id=&quot;markdown-toc-references&quot;&gt;References&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;

&lt;p&gt;关于maven的使用&lt;/p&gt;

&lt;h3 id=&quot;基本概念&quot;&gt;基本概念&lt;/h3&gt;

&lt;p&gt;lifecycle, phase, goal&lt;/p&gt;

&lt;p&gt;以下是参考&lt;a href=&quot;http://maven.apache.org/guides/introduction/introduction-to-the-lifecycle.html&quot;&gt;官方文档&lt;/a&gt;。&lt;/p&gt;

&lt;h4 id=&quot;lifecycle&quot;&gt;lifecycle&lt;/h4&gt;

&lt;p&gt;maven的一个中心概念就是build lifecycle, 也就是说build以及发布一个project的过程是明确定义好的。对于build 一个project的人来说，这意味着只需要了解不多的maven命令就可以编译任何maven项目，而且POM可以保证它得到想要的结果。&lt;/p&gt;

&lt;p&gt;有三个内置的build lifecycle: default, clean 和site.&lt;/p&gt;

&lt;p&gt;default 发布项目，clean清空编译，site创建site文档.&lt;/p&gt;

&lt;h4 id=&quot;phase&quot;&gt;phase&lt;/h4&gt;

&lt;p&gt;一个build lifec是由一系列phase组成，每个phase代表build lifecycle的一个阶段。&lt;/p&gt;

&lt;p&gt;例如: default lifecycle由下列phase组成.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;validate: 确定项目是正确的，且需要的information都是available&lt;/li&gt;
  &lt;li&gt;compile: 编译&lt;/li&gt;
  &lt;li&gt;test： 单元测试，不需要打包&lt;/li&gt;
  &lt;li&gt;package: 打包为可发布版本，例如jar&lt;/li&gt;
  &lt;li&gt;verify:  run any checks on results of integration tests to ensure quality criteria are met。应该是确保包可用.&lt;/li&gt;
  &lt;li&gt;install: 在本地库安装，用来作为本地项目的依赖&lt;/li&gt;
  &lt;li&gt;deploy: 编译环境中完成，将包拷贝至远端库，用来分享给其他developers和projects&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;所以只需要 mvn install 就可以从validate一直执行到install，因此使用mvn命令只需要指定最后一个phase，前面的phase不用指定.&lt;/p&gt;

&lt;p&gt;在编译环境中，使用clean 可以清除掉前面编译的classes。 常用下面命令进行打包。&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mvn clean package
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;goal&quot;&gt;goal&lt;/h4&gt;

&lt;p&gt;前面说了lifecycle是由多个phase组成，而每个phase又包含了多个goal。&lt;/p&gt;

&lt;p&gt;每个plugin的goal都是一个指定的任务，一个goal可以绑定至0个或者多个goal。如果一个goal没有指定phase，那么可以在build的lifecycle之外进行显示指定.&lt;/p&gt;

&lt;p&gt;执行的顺序由调用顺序决定。例如,下面的这个命令, clean和package属于编译phases，而dependency:copy-dependencies是一个goal(属于maven-dependency-plugin)。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mvn clean dependency:copy-dependencies package
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这条命令clean 会最下执行，也就是说先运行clean lifecycle,然后运行 dependency:copy-dependencies, 最后进行package(包括package之前的phases).&lt;/p&gt;

&lt;p&gt;如果一个goal被绑定至多个phase，那么每个phase都会去执行这个goal.&lt;/p&gt;

&lt;p&gt;如果一个phase中没有goal，那么那个phase不做任何执行，但如何一个phase有多个goal，则会执行所有的goals。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;有一些phase通常不在命令行中被使用&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一些带前缀(pre-*， post-*, process-*)的命令通常不被直接使用。&lt;/p&gt;

&lt;p&gt;其他文档太长，以后用到再看,&lt;a href=&quot;http://maven.apache.org/guides/introduction/introduction-to-the-lifecycle.html&quot;&gt;官方文档&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&quot;什么是pom&quot;&gt;什么是pom?&lt;/h3&gt;

&lt;p&gt;POM(Project Object Model)作为项目对象模型。通过xml表示maven项目，使用pom.xml来实现。主要描述了项目：包括配置文件；开发者需要遵循的规则，缺陷管理系统，组织和licenses，项目的url，项目的依赖性，以及其他所有的项目相关因素。&lt;/p&gt;

&lt;h4 id=&quot;快速察看&quot;&gt;快速察看&lt;/h4&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;project&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;modelVersion&amp;gt;&lt;/span&gt;4.0.0&lt;span class=&quot;nt&quot;&gt;&amp;lt;/modelVersion&amp;gt;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;&amp;lt;!--maven2.0必须是这样写，现在是maven2唯一支持的版本--&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;c&quot;&gt;&amp;lt;!-- 基础设置 --&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;version&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;packaging&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/packaging&amp;gt;&lt;/span&gt;

  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;

  &lt;span class=&quot;nt&quot;&gt;&amp;lt;url&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/url&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;dependencies&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/dependencies&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;parent&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/parent&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;dependencyManagement&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/dependencyManagement&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;modules&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/modules&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;properties&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/properties&amp;gt;&lt;/span&gt;

  &lt;span class=&quot;c&quot;&gt;&amp;lt;!--构建设置 --&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;build&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/build&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;reporting&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/reporting&amp;gt;&lt;/span&gt;

  &lt;span class=&quot;c&quot;&gt;&amp;lt;!-- 更多项目信息 --&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;url&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/url&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;inceptionYear&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/inceptionYear&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;licenses&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/licenses&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;organization&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/organization&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;developers&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/developers&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;contributors&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/contributors&amp;gt;&lt;/span&gt;

  &lt;span class=&quot;c&quot;&gt;&amp;lt;!-- 环境设置--&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;issueManagement&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/issueManagement&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;ciManagement&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/ciManagement&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;mailingLists&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/mailingLists&amp;gt;&lt;/span&gt; 
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;scm&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/scm&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;prerequisites&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/prerequisites&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;repositories&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/repositories&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;pluginRepositories&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/pluginRepositories&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;distributionManagement&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/distributionManagement&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;profiles&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/profiles&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/project&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;基本内容&quot;&gt;基本内容：&lt;/h4&gt;

&lt;p&gt;POM包括了所有的项目信息&lt;/p&gt;

&lt;p&gt;groupId:项目或者组织的唯一标志，并且配置时生成路径也是由此生成，如org.myproject.mojo生成的相对路径为：/org/myproject/mojo&lt;/p&gt;

&lt;p&gt;artifactId:项目的通用名称&lt;/p&gt;

&lt;p&gt;version:项目的版本&lt;/p&gt;

&lt;p&gt;packaging:打包机制，如pom,jar,maven-plugin,ejb,war,ear,rar,par&lt;/p&gt;

&lt;p&gt;name:用户描述项目的名称，无关紧要的东西，可选&lt;/p&gt;

&lt;p&gt;url:应该是只是写明开发团队的网站，无关紧要，可选&lt;/p&gt;

&lt;p&gt;classifer:分类&lt;/p&gt;

&lt;p&gt;其中groupId,artifactId,version,packaging这四项组成了项目的唯一坐标。一般情况下，前面三项(&lt;strong&gt;groupId:artifactId:version&lt;/strong&gt;)就可以组成项目的唯一坐标了。&lt;/p&gt;

&lt;h4 id=&quot;pom关系&quot;&gt;POM关系&lt;/h4&gt;

&lt;p&gt;POM关系：主要为依赖，继承，合成&lt;/p&gt;

&lt;h5 id=&quot;依赖&quot;&gt;依赖&lt;/h5&gt;

&lt;p&gt;依赖不仅是dependencies的依赖，也包括plugins的依赖等等.&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;dependencies&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;junit&lt;span class=&quot;nt&quot;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;junit&lt;span class=&quot;nt&quot;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;version&amp;gt;&lt;/span&gt;4.0&lt;span class=&quot;nt&quot;&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;type&amp;gt;&lt;/span&gt;jar&lt;span class=&quot;nt&quot;&gt;&amp;lt;/type&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;scope&amp;gt;&lt;/span&gt;test&lt;span class=&quot;nt&quot;&gt;&amp;lt;/scope&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;optional&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/optional&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;com.alibaba.china.shared&lt;span class=&quot;nt&quot;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;alibaba.apollo.webx&lt;span class=&quot;nt&quot;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;version&amp;gt;&lt;/span&gt;2.5.0&lt;span class=&quot;nt&quot;&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
				&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- 这里用于排除掉一些依赖jar，避免一些jar包冲突 --&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;exclusions&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;exclusion&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;org.slf4j.slf4j-api&lt;span class=&quot;nt&quot;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;com.alibaba.external&lt;span class=&quot;nt&quot;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/exclusion&amp;gt;&lt;/span&gt;
          ....
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/exclusions&amp;gt;&lt;/span&gt;
......
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/dependencies&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;其中groupId, artifactId, version这三个组合标示依赖的具体工程，而且 这个依赖工程必需是maven中心包管理范围内的，如果碰上非开源包，maven支持不了这个包，那么则有有三种 方法处理：&lt;/p&gt;

&lt;h6 id=&quot;非开源包处理&quot;&gt;非开源包处理&lt;/h6&gt;

&lt;p&gt;1.本地安装这个插件install plugin&lt;/p&gt;

&lt;p&gt;例如：mvn install:intall-file -Dfile=non-maven-proj.jar -DgroupId=som.group -DartifactId=non-maven-proj -Dversion=1&lt;/p&gt;

&lt;p&gt;2.创建自己的repositories并且部署这个包，使用类似上面的deploy:deploy-file命令，&lt;/p&gt;

&lt;p&gt;3.设置scope为system,并且指定系统路径。&lt;/p&gt;

&lt;p&gt;dependency里属性介绍：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;type&lt;/strong&gt;：默认为jar类型，常用的类型有：jar,ejb-client,test-jar…,可设置plugins中的extensions值为true后在增加 新的类型，&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;scope&lt;/strong&gt;：是用来指定当前包的依赖范围&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;compile 依赖打入包&lt;/li&gt;
  &lt;li&gt;provided 次之，除了最后不打入包&lt;/li&gt;
  &lt;li&gt;runtime，只在运行和测试时使用这些依赖&lt;/li&gt;
  &lt;li&gt;test 只在测试时使用这些依赖&lt;/li&gt;
  &lt;li&gt;system 手动指定的本地依赖&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;继承&quot;&gt;继承&lt;/h5&gt;

&lt;p&gt;子模块的pom继承父模块的POM.&lt;/p&gt;

&lt;p&gt;如果一个工程是parent或者aggregation（即mutil-module的）的，那么必须在packing赋值为pom,child工程从&lt;strong&gt;parent继承&lt;/strong&gt;的包括：dependencies,developers,contributors,plugin lists,reports lists,plugin execution with matching ids,plugin configuration&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;parent&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.codehaus.mojo&lt;span class=&quot;nt&quot;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;my-parent&lt;span class=&quot;nt&quot;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;version&amp;gt;&lt;/span&gt;2.0&lt;span class=&quot;nt&quot;&gt;&amp;lt;/version&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;relativePath&amp;gt;&lt;/span&gt;../my-parent&lt;span class=&quot;nt&quot;&gt;&amp;lt;/relativePath&amp;gt;&lt;/span&gt; 
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;/parent&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;个人认为继承还包括一些依赖被继承。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;optional&lt;/strong&gt;:设置指依赖是否可选，默认为false,即子项目默认都&lt;strong&gt;继承&lt;/strong&gt;，为true,则子项目必需显示的引入，与dependencyManagement里定义的依赖类似 。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;exclusions&lt;/strong&gt;：如果X需要A,A包含B依赖，那么X可以声明不要B依赖，只要在exclusions中声明exclusion.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;exclusion&lt;/strong&gt;:是将B从依赖树中删除，如上配置，alibaba.apollo.webx不想使用com.alibaba.external  ,但是alibaba.apollo.webx是集成了com.alibaba.external,r所以就需要排除掉.&lt;/p&gt;

&lt;p&gt;relativePath是可选的,maven会首先搜索这个地址,在搜索本地远程repositories之前.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;dependencyManagement&lt;/strong&gt;：是用于帮助管理chidren的dependencies的。例如如果parent使用dependencyManagement定义了一个dependencyon junit:junit4.0,那么 它的children就可以只引用 groupId和artifactId,而version就可以通过parent来设置，这样的好处就是可以集中管理 依赖的详情&lt;/p&gt;

&lt;h5 id=&quot;合成&quot;&gt;合成&lt;/h5&gt;

&lt;p&gt;对于多模块的project,outer-module没有必需考虑inner-module的dependencies,当列出modules的时候，modules的顺序是不重要的，因为maven会自动根据依赖关系来拓扑排序，&lt;/p&gt;

&lt;p&gt;modules例子如下 ：&lt;/p&gt;
&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;module&amp;gt;&lt;/span&gt;my-project&lt;span class=&quot;nt&quot;&gt;&amp;lt;/module&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;module&amp;gt;&lt;/span&gt;other-project&lt;span class=&quot;nt&quot;&gt;&amp;lt;/module&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;properties&lt;/strong&gt;:是为pom定义一些常量，在pom中的其它地方可以直接引用。&lt;/p&gt;

&lt;p&gt;定义方式如下：&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;properties&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;file.encoding&amp;gt;&lt;/span&gt;UTF-8&lt;span class=&quot;nt&quot;&gt;&amp;lt;/file_encoding&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;java.source.version&amp;gt;&lt;/span&gt;1.5&lt;span class=&quot;nt&quot;&gt;&amp;lt;/java_source_version&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;java.target.version&amp;gt;&lt;/span&gt;1.5&lt;span class=&quot;nt&quot;&gt;&amp;lt;/java_target_version&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/properties&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;使用方式 如下 ：&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;${file.encoding}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;还可以使用project.xx引用pom里定义的其它属性：如$(project.version}&lt;/p&gt;

&lt;h4 id=&quot;build设置&quot;&gt;build设置&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;defaultGoal&lt;/strong&gt;:默认的目标，必须跟命令行上的参数相同，如：jar:jar,或者与phase相同,例如install&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;directory&lt;/strong&gt;:指定build target目标的目录，默认为$(basedir}/target,即项目根目录下的target&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;finalName&lt;/strong&gt;:指定去掉后缀的工程名字，例如：默认为${artifactId}-${version}&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;filters&lt;/strong&gt;:用于定义指定filter属性的位置，例如filter元素赋值filters/filter1.properties,那么这个文件里面就可以定义name=value对，这个name=value对的值就可以在工程pom中通过${name}引用，默认的filter目录是${basedir}/src/main/fiters/&lt;/p&gt;

&lt;h5 id=&quot;resources&quot;&gt;resources&lt;/h5&gt;

&lt;p&gt;构建Maven项目的时候，如果没有进行特殊的配置，Maven会按照标准的目录结构查找和处理各种类型文件。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;src/main/java和src/test/java&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;这两个目录中的所有*.java文件会分别在comile和test-comiple阶段被编译，编译结果分别放到了target/classes和targe/test-classes目录中，但是这两个目录中的其他文件都会被忽略掉。&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;src/main/resouces和src/test/resources&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;这两个目录中的文件也会分别被复制到target/classes和target/test-classes目录中。&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;target/classes&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;打包插件默认会把这个目录中的所有内容打入到jar包或者war包中。&lt;/p&gt;

  &lt;p&gt;maven项目的结构一般如下:&lt;/p&gt;

  &lt;ul&gt;
    &lt;li&gt;src
      &lt;ul&gt;
        &lt;li&gt;main
          &lt;ul&gt;
            &lt;li&gt;&lt;strong&gt;java&lt;/strong&gt;         源文件&lt;/li&gt;
            &lt;li&gt;&lt;strong&gt;resources&lt;/strong&gt;    资源文件&lt;/li&gt;
            &lt;li&gt;filters   资源过滤文件&lt;/li&gt;
            &lt;li&gt;config   配置文件&lt;/li&gt;
            &lt;li&gt;scripts   脚本文件&lt;/li&gt;
            &lt;li&gt;webapp   web应用文件&lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
        &lt;li&gt;test
          &lt;ul&gt;
            &lt;li&gt;&lt;strong&gt;java&lt;/strong&gt;    测试源文件&lt;/li&gt;
            &lt;li&gt;resources    测试资源文件&lt;/li&gt;
            &lt;li&gt;filters    测试资源过滤文件&lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
        &lt;li&gt;it       集成测试&lt;/li&gt;
        &lt;li&gt;assembly    assembly descriptors&lt;/li&gt;
        &lt;li&gt;site    Site&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;target
      &lt;ul&gt;
        &lt;li&gt;generated-sources&lt;/li&gt;
        &lt;li&gt;classes&lt;/li&gt;
        &lt;li&gt;generated-test-sources&lt;/li&gt;
        &lt;li&gt;test-classes&lt;/li&gt;
        &lt;li&gt;xxx.jar&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;pom.xml&lt;/strong&gt;&lt;/li&gt;
    &lt;li&gt;LICENSE.txt&lt;/li&gt;
    &lt;li&gt;NOTICE.txt&lt;/li&gt;
    &lt;li&gt;README.txt&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;resources&lt;/code&gt;标签用于描述工程中资源的位置.&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;			&lt;span class=&quot;nt&quot;&gt;&amp;lt;resource&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;targetPath&amp;gt;&lt;/span&gt;META-INF/plexus&lt;span class=&quot;nt&quot;&gt;&amp;lt;/targetPath&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;filtering&amp;gt;&lt;/span&gt;false&lt;span class=&quot;nt&quot;&gt;&amp;lt;/filtering&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;directory&amp;gt;&lt;/span&gt;${basedir}/src/main/plexus&lt;span class=&quot;nt&quot;&gt;&amp;lt;/directory&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;includes&amp;gt;&lt;/span&gt; 
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;include&amp;gt;&lt;/span&gt;configuration.xml&lt;span class=&quot;nt&quot;&gt;&amp;lt;/include&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/includes&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;excludes&amp;gt;&lt;/span&gt; 
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;exclude&amp;gt;&lt;/span&gt;**/*.properties&lt;span class=&quot;nt&quot;&gt;&amp;lt;/exclude&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/excludes&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;/resource&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;targetPath&lt;/strong&gt;:指定build资源到哪个目录，默认是base directory&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;filtering&lt;/strong&gt;:指定是否将filter文件(即上面说的filters里定义的*.property文件)的变量值在这个resource文件有效,例如上面就指定那些变量值在configuration文件无效。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;directory&lt;/strong&gt;:指定属性文件的目录，build的过程需要找到它，并且将其放到targetPath下，默认的directory是${basedir}/src/main/resources&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;includes&lt;/strong&gt;:指定包含文件的patterns,符合样式并且在directory目录下的文件将会包含进project的资源文件。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;excludes&lt;/strong&gt;:指定不包含在内的patterns,如果inclues与excludes有冲突，那么excludes胜利，那些符合冲突的样式的文件是不会包含进来的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;testResources&lt;/strong&gt;:这个模块包含测试资源元素，其内容定义与resources类似，不同的一点是默认的测试资源路径是${basedir}/src/test/resources,测试资源是不部署的。&lt;/p&gt;

&lt;h5 id=&quot;plugins配置&quot;&gt;plugins配置&lt;/h5&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;			&lt;span class=&quot;nt&quot;&gt;&amp;lt;plugin&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.apache.maven.plugins&lt;span class=&quot;nt&quot;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;maven-jar-plugin&lt;span class=&quot;nt&quot;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;version&amp;gt;&lt;/span&gt;2.0&lt;span class=&quot;nt&quot;&gt;&amp;lt;/version&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;extensions&amp;gt;&lt;/span&gt;false&lt;span class=&quot;nt&quot;&gt;&amp;lt;/extensions&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;inherited&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/inherited&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt; 
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;classifier&amp;gt;&lt;/span&gt;test&lt;span class=&quot;nt&quot;&gt;&amp;lt;/classifier&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;dependencies&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/dependencies&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;executions&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/executions&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;/plugin&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;extensions&lt;/strong&gt;:true or false, 决定是否要load这个plugin的extensions，默认为true.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;inherited&lt;/strong&gt;:是否让子pom继承，ture or false 默认为true.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;configuration&lt;/strong&gt;:通常用于私有不开源的plugin,不能够详细了解plugin的内部工作原理，但使plugin满足的properties&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;dependencies&lt;/strong&gt;:与pom基础的dependencies的结构和功能都相同，只是plugin的dependencies用于plugin,而pom的denpendencies用于项目本身。在plugin的dependencies主要用于改变plugin原来的dependencies，例如排除一些用不到的dependency或者修改dependency的版本等，详细请看pom的denpendencies.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;executions&lt;/strong&gt;:plugin也有很多个目标，每个目标具有不同的配置，executions就是设定plugin的目标，&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;					&lt;span class=&quot;nt&quot;&gt;&amp;lt;execution&amp;gt;&lt;/span&gt; 
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;id&amp;gt;&lt;/span&gt;echodir&lt;span class=&quot;nt&quot;&gt;&amp;lt;/id&amp;gt;&lt;/span&gt; 
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;goals&amp;gt;&lt;/span&gt; 
              &lt;span class=&quot;nt&quot;&gt;&amp;lt;goal&amp;gt;&lt;/span&gt;run&lt;span class=&quot;nt&quot;&gt;&amp;lt;/goal&amp;gt;&lt;/span&gt; 
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;/goals&amp;gt;&lt;/span&gt; 
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;phase&amp;gt;&lt;/span&gt;verify&lt;span class=&quot;nt&quot;&gt;&amp;lt;/phase&amp;gt;&lt;/span&gt; 
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;inherited&amp;gt;&lt;/span&gt;false&lt;span class=&quot;nt&quot;&gt;&amp;lt;/inherited&amp;gt;&lt;/span&gt; 
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt; 
              &lt;span class=&quot;nt&quot;&gt;&amp;lt;tasks&amp;gt;&lt;/span&gt; 
                &lt;span class=&quot;nt&quot;&gt;&amp;lt;echo&amp;gt;&lt;/span&gt;Build Dir: ${project.build.directory}&lt;span class=&quot;nt&quot;&gt;&amp;lt;/echo&amp;gt;&lt;/span&gt; 
              &lt;span class=&quot;nt&quot;&gt;&amp;lt;/tasks&amp;gt;&lt;/span&gt; 
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt; 
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/execution&amp;gt;&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;id&lt;/strong&gt;:标识符&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;goals&lt;/strong&gt;:里面列出一系列的goals元素，例如上面的run goal&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;phase&lt;/strong&gt;:声明goals执行的时期，例如：verify&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;inherited&lt;/strong&gt;:是否传递execution到子pom里。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;configuration&lt;/strong&gt;:设置execution下列表的goals的设置，而不是plugin所有的goals的设置&lt;/p&gt;

&lt;h5 id=&quot;pluginmanagement配置&quot;&gt;pluginManagement配置&lt;/h5&gt;

&lt;p&gt;pluginManagement的作用类似于denpendencyManagement,只是denpendencyManagement是用于管理项目jar包依赖，pluginManagement是用于管理plugin。与pom build里的plugins区别是，&lt;strong&gt;这里的plugin是列出来，然后让子pom来决定是否引用。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;例如：&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;	&lt;span class=&quot;nt&quot;&gt;&amp;lt;pluginManagement&amp;gt;&lt;/span&gt; 
     &lt;span class=&quot;nt&quot;&gt;&amp;lt;plugins&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;plugin&amp;gt;&lt;/span&gt; 
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.apache.maven.plugins&lt;span class=&quot;nt&quot;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt; 
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;maven-jar-plugin&lt;span class=&quot;nt&quot;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt; 
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;version&amp;gt;&lt;/span&gt;2.2&lt;span class=&quot;nt&quot;&gt;&amp;lt;/version&amp;gt;&lt;/span&gt; 
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;executions&amp;gt;&lt;/span&gt; 
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;execution&amp;gt;&lt;/span&gt; 
              &lt;span class=&quot;nt&quot;&gt;&amp;lt;id&amp;gt;&lt;/span&gt;pre-process-classes&lt;span class=&quot;nt&quot;&gt;&amp;lt;/id&amp;gt;&lt;/span&gt; 
              &lt;span class=&quot;nt&quot;&gt;&amp;lt;phase&amp;gt;&lt;/span&gt;compile&lt;span class=&quot;nt&quot;&gt;&amp;lt;/phase&amp;gt;&lt;/span&gt; 
              &lt;span class=&quot;nt&quot;&gt;&amp;lt;goals&amp;gt;&lt;/span&gt; 
                &lt;span class=&quot;nt&quot;&gt;&amp;lt;goal&amp;gt;&lt;/span&gt;jar&lt;span class=&quot;nt&quot;&gt;&amp;lt;/goal&amp;gt;&lt;/span&gt; 
              &lt;span class=&quot;nt&quot;&gt;&amp;lt;/goals&amp;gt;&lt;/span&gt; 
              &lt;span class=&quot;nt&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt; 
                &lt;span class=&quot;nt&quot;&gt;&amp;lt;classifier&amp;gt;&lt;/span&gt;pre-process&lt;span class=&quot;nt&quot;&gt;&amp;lt;/classifier&amp;gt;&lt;/span&gt; 
              &lt;span class=&quot;nt&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt; 
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;/execution&amp;gt;&lt;/span&gt; 
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/executions&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/plugin&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;/plugins&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/pluginManagement&amp;gt;&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;子pom引用方法： 
在pom的build里的plugins引用： &lt;/p&gt;
&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;nt&quot;&gt;&amp;lt;plugins&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;plugin&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.apache.maven.plugins&lt;span class=&quot;nt&quot;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;maven-jar-plugin&lt;span class=&quot;nt&quot;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;/plugin&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/plugins&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;build里的directories:&lt;/p&gt;
&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;		&lt;span class=&quot;nt&quot;&gt;&amp;lt;sourceDirectory&amp;gt;&lt;/span&gt;${basedir}/src/main/java&lt;span class=&quot;nt&quot;&gt;&amp;lt;/sourceDirectory&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;scriptSourceDirectory&amp;gt;&lt;/span&gt;${basedir}/src/main/scripts&lt;span class=&quot;nt&quot;&gt;&amp;lt;/scriptSourceDirectory&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;testSourceDirectory&amp;gt;&lt;/span&gt;${basedir}/src/test/java&lt;span class=&quot;nt&quot;&gt;&amp;lt;/testSourceDirectory&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;outputDirectory&amp;gt;&lt;/span&gt;${basedir}/target/classes&lt;span class=&quot;nt&quot;&gt;&amp;lt;/outputDirectory&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;testOutputDirectory&amp;gt;&lt;/span&gt;${basedir}/target/test-classes&lt;span class=&quot;nt&quot;&gt;&amp;lt;/testOutputDirectory&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;这几个元素只在parent build element里面定义，他们设置多种路径结构，他们并不在profile里，所以不能通过profile来修改&lt;/p&gt;

&lt;h5 id=&quot;extensions&quot;&gt;Extensions&lt;/h5&gt;

&lt;p&gt;它们是一系列build过程中要使用的产品，他们会包含在running bulid‘s classpath里面。他们可以开启extensions，也可以通过提供条件来激活plugins。简单来讲，&lt;strong&gt;extensions是在build过程被激活的产品&lt;/strong&gt; .&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;nt&quot;&gt;&amp;lt;extensions&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;extension&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.apache.maven.wagon&lt;span class=&quot;nt&quot;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;wagon-ftp&lt;span class=&quot;nt&quot;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;version&amp;gt;&lt;/span&gt;1.0-alpha-3&lt;span class=&quot;nt&quot;&gt;&amp;lt;/version&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;/extension&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/extensions&amp;gt;&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;reporting&quot;&gt;reporting&lt;/h5&gt;

&lt;p&gt;reporting包含site生成阶段的一些元素，某些maven plugin可以生成reports并且在reporting下配置。例如javadoc,maven site等，在reporting下配置的report plugin的方法与build几乎一样，最不同的是build的plugin goals在executions下设置，而reporting的configures goals在reporttest。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;excludeDefaults&lt;/strong&gt;:是否排除site generator默认产生的reports&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;outputDirectory&lt;/strong&gt;，默认的dir变成:${basedir}/target/site&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;reportSets&lt;/strong&gt;:设置execution goals,相当于build里面的executions,不同的是不能够bind a report to another phase,只能够是site&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;reporting&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;plugins&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;plugin&amp;gt;&lt;/span&gt; 
        ... 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;reportSets&amp;gt;&lt;/span&gt; 
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;reportSet&amp;gt;&lt;/span&gt; 
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;id&amp;gt;&lt;/span&gt;sunlink&lt;span class=&quot;nt&quot;&gt;&amp;lt;/id&amp;gt;&lt;/span&gt; 
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;reports&amp;gt;&lt;/span&gt; 
              &lt;span class=&quot;nt&quot;&gt;&amp;lt;report&amp;gt;&lt;/span&gt;javadoc&lt;span class=&quot;nt&quot;&gt;&amp;lt;/report&amp;gt;&lt;/span&gt; 
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;/reports&amp;gt;&lt;/span&gt; 
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;inherited&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/inherited&amp;gt;&lt;/span&gt; 
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt; 
              &lt;span class=&quot;nt&quot;&gt;&amp;lt;links&amp;gt;&lt;/span&gt; 
                &lt;span class=&quot;nt&quot;&gt;&amp;lt;link&amp;gt;&lt;/span&gt;http://java.sun.com/j2se/1.5.0/docs/api/&lt;span class=&quot;nt&quot;&gt;&amp;lt;/link&amp;gt;&lt;/span&gt; 
              &lt;span class=&quot;nt&quot;&gt;&amp;lt;/links&amp;gt;&lt;/span&gt; 
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt; 
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/reportSet&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/reportSets&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;/plugin&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/plugins&amp;gt;&lt;/span&gt; 
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;/reporting&amp;gt;&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;reporting里面的reportSets和build里面的executions的作用都是控制pom的不同粒度去控制build的过程，我们不单要配置plugins，还要配置那些plugins单独的goals。&lt;/p&gt;

&lt;h5 id=&quot;maven-shade-plugin&quot;&gt;Maven-shade-plugin&lt;/h5&gt;

&lt;p&gt;如果是作为使用方可以使用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;exclusions&lt;/code&gt;来去掉一些依赖包避免冲突，而如果是作为提供方，有时候需要在提供jar包时候避免产生依赖冲突，而&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;maven-shade-plugin&lt;/code&gt;非常适合这个场景.&lt;/p&gt;

&lt;p&gt;下面这个例子。&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;nt&quot;&gt;&amp;lt;build&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;plugins&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;plugin&amp;gt;&lt;/span&gt;
                &lt;span class=&quot;nt&quot;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.apache.maven.plugins&lt;span class=&quot;nt&quot;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
                &lt;span class=&quot;nt&quot;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;maven-shade-plugin&lt;span class=&quot;nt&quot;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
                &lt;span class=&quot;nt&quot;&gt;&amp;lt;version&amp;gt;&lt;/span&gt;3.1.1&lt;span class=&quot;nt&quot;&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
                &lt;span class=&quot;nt&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
                    &lt;span class=&quot;nt&quot;&gt;&amp;lt;artifactSet&amp;gt;&lt;/span&gt;
                      	&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- 把哪些包打进去 --&amp;gt;&lt;/span&gt;
                        &lt;span class=&quot;nt&quot;&gt;&amp;lt;includes&amp;gt;&lt;/span&gt;
                            &lt;span class=&quot;nt&quot;&gt;&amp;lt;include&amp;gt;&lt;/span&gt;redis.clients:jedis&lt;span class=&quot;nt&quot;&gt;&amp;lt;/include&amp;gt;&lt;/span&gt;
                            &lt;span class=&quot;nt&quot;&gt;&amp;lt;include&amp;gt;&lt;/span&gt;org.apache.commons:commons-pool2&lt;span class=&quot;nt&quot;&gt;&amp;lt;/include&amp;gt;&lt;/span&gt;
                        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/includes&amp;gt;&lt;/span&gt;
                    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/artifactSet&amp;gt;&lt;/span&gt;
                    &lt;span class=&quot;nt&quot;&gt;&amp;lt;filters&amp;gt;&lt;/span&gt;
                        &lt;span class=&quot;nt&quot;&gt;&amp;lt;filter&amp;gt;&lt;/span&gt;
                            &lt;span class=&quot;nt&quot;&gt;&amp;lt;artifact&amp;gt;&lt;/span&gt;*:*&lt;span class=&quot;nt&quot;&gt;&amp;lt;/artifact&amp;gt;&lt;/span&gt;
                          	&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- 排除一些文件 --&amp;gt;&lt;/span&gt;
                            &lt;span class=&quot;nt&quot;&gt;&amp;lt;excludes&amp;gt;&lt;/span&gt;
                                &lt;span class=&quot;nt&quot;&gt;&amp;lt;exclude&amp;gt;&lt;/span&gt;META-INF/*.SF&lt;span class=&quot;nt&quot;&gt;&amp;lt;/exclude&amp;gt;&lt;/span&gt;
                                &lt;span class=&quot;nt&quot;&gt;&amp;lt;exclude&amp;gt;&lt;/span&gt;META-INF/*.DSA&lt;span class=&quot;nt&quot;&gt;&amp;lt;/exclude&amp;gt;&lt;/span&gt;
                                &lt;span class=&quot;nt&quot;&gt;&amp;lt;exclude&amp;gt;&lt;/span&gt;META-INF/*.RSA&lt;span class=&quot;nt&quot;&gt;&amp;lt;/exclude&amp;gt;&lt;/span&gt;
                            &lt;span class=&quot;nt&quot;&gt;&amp;lt;/excludes&amp;gt;&lt;/span&gt;
                        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/filter&amp;gt;&lt;/span&gt;
                    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/filters&amp;gt;&lt;/span&gt;
                    &lt;span class=&quot;nt&quot;&gt;&amp;lt;relocations&amp;gt;&lt;/span&gt;
                      	&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- 对一些包名重定位，以解决冲突. --&amp;gt;&lt;/span&gt;
                        &lt;span class=&quot;nt&quot;&gt;&amp;lt;relocation&amp;gt;&lt;/span&gt;
                            &lt;span class=&quot;nt&quot;&gt;&amp;lt;pattern&amp;gt;&lt;/span&gt;redis&lt;span class=&quot;nt&quot;&gt;&amp;lt;/pattern&amp;gt;&lt;/span&gt;
                            &lt;span class=&quot;nt&quot;&gt;&amp;lt;shadedPattern&amp;gt;&lt;/span&gt;scyuan.maven.shaded.redis&lt;span class=&quot;nt&quot;&gt;&amp;lt;/shadedPattern&amp;gt;&lt;/span&gt;
                        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/relocation&amp;gt;&lt;/span&gt;
                        &lt;span class=&quot;nt&quot;&gt;&amp;lt;relocation&amp;gt;&lt;/span&gt;
                            &lt;span class=&quot;nt&quot;&gt;&amp;lt;pattern&amp;gt;&lt;/span&gt;org.apache.commons&lt;span class=&quot;nt&quot;&gt;&amp;lt;/pattern&amp;gt;&lt;/span&gt;
                            &lt;span class=&quot;nt&quot;&gt;&amp;lt;shadedPattern&amp;gt;&lt;/span&gt;scyuan.maven.shaded.org.apache.commons&lt;span class=&quot;nt&quot;&gt;&amp;lt;/shadedPattern&amp;gt;&lt;/span&gt;
                        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/relocation&amp;gt;&lt;/span&gt;
                    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/relocations&amp;gt;&lt;/span&gt;
                &lt;span class=&quot;nt&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
                &lt;span class=&quot;nt&quot;&gt;&amp;lt;executions&amp;gt;&lt;/span&gt;
                    &lt;span class=&quot;nt&quot;&gt;&amp;lt;execution&amp;gt;&lt;/span&gt;
                        &lt;span class=&quot;c&quot;&gt;&amp;lt;!-- 在package阶段执行shade goal,这些goal是定好的 --&amp;gt;&lt;/span&gt;
                     		&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- 可在maven-shade-plugin-${ver}.jar/META-INF/maven/plugin.xml中查看有哪些goal --&amp;gt;&lt;/span&gt;
                        &lt;span class=&quot;nt&quot;&gt;&amp;lt;phase&amp;gt;&lt;/span&gt;package&lt;span class=&quot;nt&quot;&gt;&amp;lt;/phase&amp;gt;&lt;/span&gt;
                        &lt;span class=&quot;nt&quot;&gt;&amp;lt;goals&amp;gt;&lt;/span&gt;
                            &lt;span class=&quot;nt&quot;&gt;&amp;lt;goal&amp;gt;&lt;/span&gt;shade&lt;span class=&quot;nt&quot;&gt;&amp;lt;/goal&amp;gt;&lt;/span&gt;
                        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/goals&amp;gt;&lt;/span&gt;
                    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/execution&amp;gt;&lt;/span&gt;
                &lt;span class=&quot;nt&quot;&gt;&amp;lt;/executions&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;/plugin&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/plugins&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/build&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;更多项目信息&quot;&gt;更多项目信息&lt;/h4&gt;

&lt;p&gt;name:项目除了artifactId外，可以定义多个名称
description: 项目描述
url: 项目url
inceptionYear:创始年份&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Licenses&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;licenses&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;license&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;Apache 2&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;url&amp;gt;&lt;/span&gt;http://www.apache.org/licenses/LICENSE-2.0.txt&lt;span class=&quot;nt&quot;&gt;&amp;lt;/url&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;distribution&amp;gt;&lt;/span&gt;repo&lt;span class=&quot;nt&quot;&gt;&amp;lt;/distribution&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;comments&amp;gt;&lt;/span&gt;A business-friendly OSS license&lt;span class=&quot;nt&quot;&gt;&amp;lt;/comments&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;/license&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/licenses&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;列出本工程直接的licenses，而不要列出dependencies的licenses&lt;/p&gt;

&lt;p&gt;配置组织信息:&lt;/p&gt;
&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;nt&quot;&gt;&amp;lt;organization&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;Codehaus Mojo&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;url&amp;gt;&lt;/span&gt;http://mojo.codehaus.org&lt;span class=&quot;nt&quot;&gt;&amp;lt;/url&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;/organization&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;很多工程都受到某些组织运行，这里设置基本信息&lt;/p&gt;

&lt;p&gt;配置开发者信息:&lt;/p&gt;

&lt;p&gt;例如：一个开发者可以有多个roles，properties是 &lt;/p&gt;
&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;developers&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;developer&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;id&amp;gt;&lt;/span&gt;eric&lt;span class=&quot;nt&quot;&gt;&amp;lt;/id&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;Eric&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;email&amp;gt;&lt;/span&gt;eredmond@codehaus.org&lt;span class=&quot;nt&quot;&gt;&amp;lt;/email&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;url&amp;gt;&lt;/span&gt;http://eric.propellors.net&lt;span class=&quot;nt&quot;&gt;&amp;lt;/url&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;organization&amp;gt;&lt;/span&gt;Codehaus&lt;span class=&quot;nt&quot;&gt;&amp;lt;/organization&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;organizationUrl&amp;gt;&lt;/span&gt;http://mojo.codehaus.org&lt;span class=&quot;nt&quot;&gt;&amp;lt;/organizationUrl&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;roles&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;role&amp;gt;&lt;/span&gt;architect&lt;span class=&quot;nt&quot;&gt;&amp;lt;/role&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;role&amp;gt;&lt;/span&gt;developer&lt;span class=&quot;nt&quot;&gt;&amp;lt;/role&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;/roles&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;timezone&amp;gt;&lt;/span&gt;-6&lt;span class=&quot;nt&quot;&gt;&amp;lt;/timezone&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;properties&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;picUrl&amp;gt;&lt;/span&gt;http://tinyurl.com/prv4t&lt;span class=&quot;nt&quot;&gt;&amp;lt;/picUrl&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;/properties&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/developer&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;/developers&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;环境设置&quot;&gt;环境设置&lt;/h5&gt;

&lt;h6 id=&quot;issuemanagement&quot;&gt;issueManagement&lt;/h6&gt;

&lt;p&gt;bug跟踪管理系统,定义defect tracking system缺陷跟踪系统，比如有（bugzilla,testtrack,clearquest等）.
例如:&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;nt&quot;&gt;&amp;lt;issueManagement&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;system&amp;gt;&lt;/span&gt;Bugzilla&lt;span class=&quot;nt&quot;&gt;&amp;lt;/system&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;url&amp;gt;&lt;/span&gt;http://127.0.0.1/bugzilla/&lt;span class=&quot;nt&quot;&gt;&amp;lt;/url&amp;gt;&lt;/span&gt; 
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;/issueManagement&amp;gt;&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h6 id=&quot;repositories&quot;&gt;Repositories&lt;/h6&gt;

&lt;p&gt;pom里面的仓库与setting.xml里的仓库功能是一样的。主要的区别在于，pom里的仓库是个性化的。比如一家大公司里的setting文件是公用 的，所有项目都用一个setting文件，但各个子项目却会引用不同的第三方库，所以就需要在pom里设置自己需要的仓库地址。&lt;/p&gt;

&lt;p&gt;repositories：要成为maven2的repository artifact，必须具有pom文件在$BASE_REPO/groupId/artifactId/version/artifactId-version.pom 
BASE_REPO可以是本地，也可以是远程的。repository元素就是声明那些去查找的repositories 
默认的central Maven repository在http://repo1.maven.org/maven2/&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;repositories&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;repository&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;releases&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;enabled&amp;gt;&lt;/span&gt;false&lt;span class=&quot;nt&quot;&gt;&amp;lt;/enabled&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;updatePolicy&amp;gt;&lt;/span&gt;always&lt;span class=&quot;nt&quot;&gt;&amp;lt;/updatePolicy&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;checksumPolicy&amp;gt;&lt;/span&gt;warn&lt;span class=&quot;nt&quot;&gt;&amp;lt;/checksumPolicy&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;/releases&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;snapshots&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;enabled&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/enabled&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;updatePolicy&amp;gt;&lt;/span&gt;never&lt;span class=&quot;nt&quot;&gt;&amp;lt;/updatePolicy&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;checksumPolicy&amp;gt;&lt;/span&gt;fail&lt;span class=&quot;nt&quot;&gt;&amp;lt;/checksumPolicy&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;/snapshots&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;id&amp;gt;&lt;/span&gt;codehausSnapshots&lt;span class=&quot;nt&quot;&gt;&amp;lt;/id&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;Codehaus Snapshots&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;url&amp;gt;&lt;/span&gt;http://snapshots.maven.codehaus.org/maven2&lt;span class=&quot;nt&quot;&gt;&amp;lt;/url&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;layout&amp;gt;&lt;/span&gt;default&lt;span class=&quot;nt&quot;&gt;&amp;lt;/layout&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/repository&amp;gt;&lt;/span&gt; 
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;/repositories&amp;gt;&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;release和snapshots：是artifact的两种policies，pom可以选择那种政策有效。 
enable：本别指定两种类型是否可用，true or false 
updatePolicy:说明更新发生的频率always 或者 never 或者 daily（默认的）或者 interval:X（X是分钟数）&lt;/p&gt;

&lt;p&gt;checksumPolicy：当Maven的部署文件到仓库中，它也部署了相应的校验和文件。您可以选择忽略，失败，或缺少或不正确的校验和警告。&lt;/p&gt;

&lt;p&gt;layout：maven1.x与maven2有不同的layout，所以可以声明为default或者是legacy（遗留方式maven1.x）。&lt;/p&gt;

&lt;h6 id=&quot;pluginrepositories&quot;&gt;pluginRepositories&lt;/h6&gt;

&lt;p&gt;与Repositories具有类似的结构，只是Repositories是dependencies的home，而这个是plugins 的home。&lt;/p&gt;

&lt;h6 id=&quot;distributionmanagement&quot;&gt;distributionManagement&lt;/h6&gt;

&lt;p&gt;管理distribution和supporting files。&lt;/p&gt;

&lt;p&gt;downloadUrl：是其他项目为了抓取本项目的pom’s artifact而指定的url，就是说告诉pom upload的地址也就是别人可以下载的地址。 
status：这里的状态不要受到我们的设置，maven会自动设置project的状态，有效的值：none：没有声明状态，pom默认的；converted：本project是管理员从原先的maven版本convert到maven2的；partner：以前叫做synched，意思是与partner repository已经进行了同步；deployed：至今为止最经常的状态，意思是制品是从maven2 instance部署的，人工在命令行deploy的就会得到这个；verified：本制品已经经过验证，也就是已经定下来了最终版。 
repository：声明deploy过程中current project会如何变成repository，说明部署到repository的信息。&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;nt&quot;&gt;&amp;lt;repository&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;uniqueVersion&amp;gt;&lt;/span&gt;false&lt;span class=&quot;nt&quot;&gt;&amp;lt;/uniqueVersion&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;id&amp;gt;&lt;/span&gt;corp1&lt;span class=&quot;nt&quot;&gt;&amp;lt;/id&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;Corporate Repository&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;url&amp;gt;&lt;/span&gt;scp://repo1/maven2&lt;span class=&quot;nt&quot;&gt;&amp;lt;/url&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;layout&amp;gt;&lt;/span&gt;default&lt;span class=&quot;nt&quot;&gt;&amp;lt;/layout&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/repository&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;snapshotRepository&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;uniqueVersion&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/uniqueVersion&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;id&amp;gt;&lt;/span&gt;propSnap&lt;span class=&quot;nt&quot;&gt;&amp;lt;/id&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;Propellors Snapshots&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;url&amp;gt;&lt;/span&gt;sftp://propellers.net/maven&lt;span class=&quot;nt&quot;&gt;&amp;lt;/url&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;layout&amp;gt;&lt;/span&gt;legacy&lt;span class=&quot;nt&quot;&gt;&amp;lt;/layout&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/snapshotRepository&amp;gt;&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;id, name:：唯一性的id，和可读性的name 
uniqueVersion：指定是否产生一个唯一性的version number还是使用address里的其中version部分。true or false 
url：说明location和transport protocol 
layout：default或者legacy&lt;/p&gt;

&lt;h6 id=&quot;profiles&quot;&gt;profiles&lt;/h6&gt;

&lt;p&gt;pom4.0的一个新特性就是具有根据environment来修改设置的能力&lt;/p&gt;

&lt;p&gt;它包含可选的activation（profile的触发器）和一系列的changes。例如test过程可能会指向不同的数据库（相对最终的deployment）或者不同的dependencies或者不同的repositories，并且是根据不同的JDK来改变的。那么结构如下： &lt;/p&gt;
&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;nt&quot;&gt;&amp;lt;profiles&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;profile&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;id&amp;gt;&lt;/span&gt;test&lt;span class=&quot;nt&quot;&gt;&amp;lt;/id&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;activation&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/activation&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;build&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/build&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;modules&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/modules&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;repositories&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/repositories&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;pluginRepositories&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/pluginRepositories&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;dependencies&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/dependencies&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;reporting&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/reporting&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;dependencyManagement&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/dependencyManagement&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;distributionManagement&amp;gt;&lt;/span&gt;...&lt;span class=&quot;nt&quot;&gt;&amp;lt;/distributionManagement&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/profile&amp;gt;&lt;/span&gt; 
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;/profiles&amp;gt;&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Activation&lt;/strong&gt;
触发这个profile的条件配置如下例：（只需要其中一个成立就可以激活profile，如果第一个条件满足了，那么后面就不会在进行匹配。 &lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;nt&quot;&gt;&amp;lt;profile&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;id&amp;gt;&lt;/span&gt;test&lt;span class=&quot;nt&quot;&gt;&amp;lt;/id&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;activation&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;activeByDefault&amp;gt;&lt;/span&gt;false&lt;span class=&quot;nt&quot;&gt;&amp;lt;/activeByDefault&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;jdk&amp;gt;&lt;/span&gt;1.5&lt;span class=&quot;nt&quot;&gt;&amp;lt;/jdk&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;os&amp;gt;&lt;/span&gt; 
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;Windows XP&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt; 
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;family&amp;gt;&lt;/span&gt;Windows&lt;span class=&quot;nt&quot;&gt;&amp;lt;/family&amp;gt;&lt;/span&gt; 
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;arch&amp;gt;&lt;/span&gt;x86&lt;span class=&quot;nt&quot;&gt;&amp;lt;/arch&amp;gt;&lt;/span&gt; 
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;version&amp;gt;&lt;/span&gt;5.1.2600&lt;span class=&quot;nt&quot;&gt;&amp;lt;/version&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/os&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt; 
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;mavenVersion&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt; 
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;2.0.3&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;file&amp;gt;&lt;/span&gt; 
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;exists&amp;gt;&lt;/span&gt;${basedir}/file2.properties&lt;span class=&quot;nt&quot;&gt;&amp;lt;/exists&amp;gt;&lt;/span&gt; 
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;missing&amp;gt;&lt;/span&gt;${basedir}/file1.properties&lt;span class=&quot;nt&quot;&gt;&amp;lt;/missing&amp;gt;&lt;/span&gt; 
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/file&amp;gt;&lt;/span&gt; 
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;/activation&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/profile&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;激活profile的方法有多个：setting文件的activeProfile元素明确指定激活的profile的ID，在命令行上明确激活Profile用-P flag 参数&lt;/p&gt;

&lt;p&gt;如:&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;        &lt;span class=&quot;nt&quot;&gt;&amp;lt;profile&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;id&amp;gt;&lt;/span&gt;spark-2.3&lt;span class=&quot;nt&quot;&gt;&amp;lt;/id&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;properties&amp;gt;&lt;/span&gt;
                &lt;span class=&quot;nt&quot;&gt;&amp;lt;spark.version&amp;gt;&lt;/span&gt;2.3.2&lt;span class=&quot;nt&quot;&gt;&amp;lt;/spark.version&amp;gt;&lt;/span&gt;
                &lt;span class=&quot;nt&quot;&gt;&amp;lt;scalatest.version&amp;gt;&lt;/span&gt;3.0.3&lt;span class=&quot;nt&quot;&gt;&amp;lt;/scalatest.version&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;/properties&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/profile&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./build/mvn clean install -Pspark-2.3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里就激活了spark-2.3对应的properties.&lt;/p&gt;

&lt;p&gt;查看某个build会激活的profile列表可以用：mvn help:active-profiles&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;http://maven.apache.org/guides/introduction/introduction-to-the-lifecycle.html&lt;/p&gt;

&lt;p&gt;https://www.cnblogs.com/qq78292959/p/3711501.html&lt;/p&gt;
</description>
                <link>http://www.turbofei.wang/coding/2019/05/19/About-Maven</link>
                <guid>http://www.turbofei.wang/coding/2019/05/19/About-Maven</guid>
                <pubDate>2019-05-19T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>Scala Concurrent Programing: Promise And Forkjoinpool</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#promise&quot; id=&quot;markdown-toc-promise&quot;&gt;Promise&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#nonfatal--controlthrowable&quot; id=&quot;markdown-toc-nonfatal--controlthrowable&quot;&gt;Nonfatal &amp;amp; ControlThrowable&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#try&quot; id=&quot;markdown-toc-try&quot;&gt;Try&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#forkjoinpool&quot; id=&quot;markdown-toc-forkjoinpool&quot;&gt;ForkJoinPool&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#work-steamling机制&quot; id=&quot;markdown-toc-work-steamling机制&quot;&gt;work-steamling机制&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;

&lt;p&gt;关于并发编程的一些总结与思考，包括promise, forkJoinPool, and etc.
在使用scala进行并发编程时，常用的一个就是Promise，Promise和Future是相关的。在生产中，Promise往往和Thread结合一起用，在一个线程中去执行Promise.trySuccess.提到线程就不得不提线程池，而ForkJoinPool是一个特殊的线程池，它比较适合计算密集型的场景。&lt;/p&gt;

&lt;h3 id=&quot;promise&quot;&gt;Promise&lt;/h3&gt;

&lt;p&gt;Promise是scala中独有的，java中没有。中文意思就是承诺，它可以在获得承诺的value时成功结束，也可以在遇到异常时失败。
一个Promise只能承诺一次，如果它已经完成承诺，或者失败，或者超时，再对它进行调用就会抛出IllegalStateException。在promize中有很多方法,如下&lt;/p&gt;
&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;tryComplete&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tryCompleteWith&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;complete&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;，&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tryFailureWith&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;success&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;failure&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trySuccess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tryFailure&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;isCompleted&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;，&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;future&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这些方法有所不同，例如complete系列(包括tryComplete， tryCompleteWith)是可以返回值，也可以是异常的。&lt;/p&gt;

&lt;p&gt;而failure系列只能是异常，而success系列智能是返回value。因此，complete系列更像是一个对后两者的并集。&lt;/p&gt;

&lt;p&gt;在使用中，我们可以按照自己的需求去选择这些方法。&lt;/p&gt;

&lt;p&gt;比如我们可以直接使用complete系列将所有系列包容，也可以使用trySuccess 然后在捕获异常之后，将异常直接给failure方法。&lt;/p&gt;

&lt;p&gt;isComplete是用于判断Promise是否已经完成，而future是一个包含Promise结果的Future。&lt;/p&gt;

&lt;p&gt;我们通常将Promise和Await一起用。如果Promise在执行中出现了异常，Await是可以将其抛出，而如果Promise没有在规定时间内返回，那么将会抛出TimeoutException.&lt;/p&gt;

&lt;p&gt;例子如下:&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.concurrent.duration.Duration&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.concurrent.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Await&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ExecutionContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Promise&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.util.Try&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.util.control.NonFatal&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TestPromise&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;cm&quot;&gt;/**
     * 此处是为了校验超时异常
     * 以及执行中异常.
     */&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// Thread.sleep(13000)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// throw new Exception(&quot;this is an exception&quot;)&lt;/span&gt;
    &lt;span class=&quot;mi&quot;&gt;123L&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;trySuccess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;promisedLong&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Promise&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;test promise&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;nv&quot;&gt;promisedLong&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;trySuccess&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nf&quot;&gt;method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;NonFatal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nv&quot;&gt;promisedLong&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;failure&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//            promisedLong.tryFailure(e)&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;tryComplete&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;promisedLong&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Promise&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;test promise&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;nv&quot;&gt;promisedLong&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;tryComplete&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nc&quot;&gt;Try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
              &lt;span class=&quot;nf&quot;&gt;method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;tryCompleteWith&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;promisedLong&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Promise&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;implicit&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;global&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;nv&quot;&gt;ExecutionContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;global&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;test promise&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;nv&quot;&gt;promisedLong&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;tryCompleteWith&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nc&quot;&gt;Future&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
              &lt;span class=&quot;nf&quot;&gt;method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;promisedLong&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Promise&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;tryComplete&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;promisedLong&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;Await&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;promisedLong&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Duration&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;12s&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
      &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nv&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;printStackTrace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;nonfatal--controlthrowable&quot;&gt;Nonfatal &amp;amp; ControlThrowable&lt;/h4&gt;

&lt;p&gt;上面的例子中提到了Nonfatal，这在生产中是一个常用的类。&lt;/p&gt;

&lt;p&gt;顾名思义，Nonfatal代表非致命的，方法体也很短.&lt;/p&gt;

&lt;p&gt;可以看出致命的错误有，虚拟机Error，ThreadDeath，中断异常，链接Error，以及&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ControlThrowable&lt;/code&gt;。除了这几种，其他都是非致命的。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;NonFatal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
   &lt;span class=&quot;cm&quot;&gt;/**
    * Returns true if the provided `Throwable` is to be considered non-fatal, or false if it is to be considered fatal
    */&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Throwable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Boolean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;c1&quot;&gt;// VirtualMachineError includes OutOfMemoryError and other fatal errors&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;VirtualMachineError&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ThreadDeath&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;InterruptedException&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;LinkageError&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ControlThrowable&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;cm&quot;&gt;/**
   * Returns Some(t) if NonFatal(t) == true, otherwise None
   */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;unapply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Throwable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Throwable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Some&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;None&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;一般在程序中，都是对Nonfatal进行catch处理， 而致命的就不catch了。&lt;/p&gt;

&lt;p&gt;那么什么是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ControlThrowable&lt;/code&gt;呢？&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;trait&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ControlThrowable&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Throwable&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;NoStackTrace&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;我们可以看到它继承了NoStackTrace类，也就是说这个异常栈是不能打印的。ControlThrowable代表这个Throwable是被放在控制流中。因为这个异常时作为控制流异常（比如BreadControl等等）， 因此发生这种异常，需要propagate，而不能catch，不过这一切都被封装在了Nonfatal，我们在编程中只要判断Nonfatal就可以。&lt;/p&gt;

&lt;h4 id=&quot;try&quot;&gt;Try&lt;/h4&gt;

&lt;p&gt;关于Try，它和try catch中的try不同，它代表执行一个程序块，通常和match，以及Success， Failure一起使用。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;testTry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;Try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//      throw new Exception(&quot;this is an exception&quot;)&lt;/span&gt;
      &lt;span class=&quot;mi&quot;&gt;123L&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Success&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Failure&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;getMessage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;forkjoinpool&quot;&gt;ForkJoinPool&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;其实看源码中注释是理解源码最好的方式。&lt;/strong&gt;
ForkJoinPool是一个用于运行ForkJoinTask的线程池. ForkJoinPool和其他的ExecutorService不同，他有一套work-窃取机制，每个线程都可以尝试去find和执行pool中或者其他task提交的任务，这样就可以更加高效，因为每个线程的执行都不是限制死的，如果它空闲了就可以去窃取其他forkJointask的任务，这样也减少了线程的上下文切换，所以对于计算密集型的任务效率会很高，所以，如果你的任务是计算密集型，不妨试一下ForkJoinPool。相当于大家同心协力去把pool中的所有task运行完，这样避免了因为倾斜带来的低效。&lt;/p&gt;

&lt;p&gt;asyncMode默认是false，当设为true，这更适合于事件类型的任务，从来不会有join。&lt;/p&gt;

&lt;p&gt;下面是一个计算从1到n和的一个程序，采用了普通线程池和ForkJoinPool来实现，实验证明，forkjoinpool性能领先很大。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;java.util.ArrayList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;java.util.concurrent.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TestForkJoinPool&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;current&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;currentTimeMillis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;nv&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sumWithExecutorService&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100000000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;currentTimeMillis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;current&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;nv&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Cost Time is:&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;ms!&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;current&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;currentTimeMillis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;nv&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;executeWithForkJoinPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100000000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;currentTimeMillis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;current&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;nv&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ForkJoinPoll Cost Time is:&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;ms!&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sumWithExecutorService&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threadNum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;ExecutorService&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pool&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;Executors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;newFixedThreadPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;threadNum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;cm&quot;&gt;/**
             * 这里，如果前面不进行强制类型转换，那么除了之后就是一个int
             * 就没有必要取ceil 了，切记。
             */&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;Math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;ceil&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;double&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;threadNum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;nc&quot;&gt;ArrayList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;futures&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ArrayList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;();&lt;/span&gt;
            &lt;span class=&quot;nf&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threadNum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;Math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                    &lt;span class=&quot;nv&quot;&gt;futures&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;pool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;submit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SumTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
                            &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;Math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))));&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;nf&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;future&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;futures&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;catch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ignore&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;finally&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nv&quot;&gt;pool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;shutdown&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SumTask&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;implements&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Callable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SumTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;nd&quot;&gt;@Override&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;call&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;throws&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;nf&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;executeWithForkJoinPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thresHold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;ForkJoinPool&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forkJoinPool&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ForkJoinPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;forkJoinPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;invoke&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ForkJoinSumTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thresHold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;finally&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nv&quot;&gt;forkJoinPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;shutdown&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ForkJoinSumTask&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RecursiveTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thresHold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ForkJoinSumTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thresHold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;thresHold&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thresHold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

        &lt;span class=&quot;nd&quot;&gt;@Override&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;compute&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thresHold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;nf&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;nc&quot;&gt;ForkJoinSumTask&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;leftTask&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ForkJoinSumTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thresHold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
                &lt;span class=&quot;nc&quot;&gt;ForkJoinSumTask&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rightTask&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ForkJoinSumTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thresHold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
                &lt;span class=&quot;nv&quot;&gt;leftTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;fork&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
                &lt;span class=&quot;nv&quot;&gt;rightTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;fork&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;leftTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;rightTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;work-steamling机制&quot;&gt;work-steamling机制&lt;/h4&gt;

&lt;p&gt;ForkJoinPool中的fork和join是unix中创建线程的方法，在Unix中使用fork可以创建一个子进程，然后join是让父进程等待子进程执行完毕才进行。但是在ForkJoinPool中并不是每次fork都要创建一个子线程，我们可以设置poolSize，规定线程数目的上限。&lt;/p&gt;

&lt;p&gt;ForkJoinPool中的每个线程会维护一个工作队列.这个队列是双端队列，在每次执行自己队列的任务时会尝试随机窃取一个task，窃取对应队列的顺序是FIFO，而执行自己队列中的任务在同步模式下是LIFO。可以看到fork函数是将task放置在队列的尾部。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ForkJoinTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fork&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;Thread&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;currentThread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;instanceof&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ForkJoinWorkerThread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ForkJoinWorkerThread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;workQueue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
            &lt;span class=&quot;nv&quot;&gt;ForkJoinPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;common&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;externalPush&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;而join操作呢?&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;判断该任务是否已经完成，如果完成返回，否则2&lt;/li&gt;
  &lt;li&gt;这个任务是自己的工作队列中，如果在，则执行，等待其完成。&lt;/li&gt;
  &lt;li&gt;如果不在自己的工作队列中，则已经被小偷窃取。&lt;/li&gt;
  &lt;li&gt;找到小偷，窃取他队列中的任务，FIFO方式窃取，帮助他早日完成任务。&lt;/li&gt;
  &lt;li&gt;如果小偷已经做完自己的任务，自己在等待被其他小偷窃取走的任务时，帮助他。&lt;/li&gt;
  &lt;li&gt;递归5，直到返回结果。&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;doJoin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Thread&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ForkJoinWorkerThread&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;ForkJoinPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;WorkQueue&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Thread.currentThread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;instanceof&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ForkJoinWorkerThread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wt&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ForkJoinWorkerThread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;workQueue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;
            &lt;span class=&quot;nf&quot;&gt;tryUnpush&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;doExec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;kt&quot;&gt;wt.pool.awaitJoin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;kt&quot;&gt;externalAwaitDone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;cm&quot;&gt;/**
     * Blocks a non-worker-thread until completion.
     * @return status upon completion
     */&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;externalAwaitDone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;instanceof&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;CountedCompleter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// try helping&lt;/span&gt;
                 &lt;span class=&quot;nv&quot;&gt;ForkJoinPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;common&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;externalHelpComplete&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
                     &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;CountedCompleter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;?&amp;gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;
                 &lt;span class=&quot;kt&quot;&gt;ForkJoinPool.common.tryExternalUnpush&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;doExec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;interrupted&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;do&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;U&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;compareAndSwapInt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;STATUS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SIGNAL&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                    &lt;span class=&quot;nf&quot;&gt;synchronized&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                        &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;status&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                            &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                                &lt;span class=&quot;nf&quot;&gt;wait&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
                            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;catch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;InterruptedException&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ie&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                                &lt;span class=&quot;n&quot;&gt;interrupted&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
                            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
                        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
                        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
                            &lt;span class=&quot;nf&quot;&gt;notifyAll&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;interrupted&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;nv&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;currentThread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;interrupt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</description>
                <link>http://www.turbofei.wang/coding/2019/05/18/scala-concurrent-programing-Promise-And-ForkJoinPool</link>
                <guid>http://www.turbofei.wang/coding/2019/05/18/scala-concurrent-programing:-Promise-And-ForkJoinPool</guid>
                <pubDate>2019-05-18T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>Transactions Suuport For Spark Greenlum</title>
                <description>
&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;

&lt;p&gt;spark-greenplum是一个spark DataSource为greenplum的实现。通过使用postgresql copy命令的方式从dataframe分区向greenplum拷贝数据，相较于spark sql本身jbdc DataSource的速度提升了上百倍。本文讲解关于实现从spark sql向gp拷贝数据事务的实现。&lt;/p&gt;

&lt;p&gt;相关PR为:&lt;a href=&quot;https://github.com/yaooqinn/spark-greenplum/7&quot;&gt;SPARK-GREENPLUM-4&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;spark-greenplum&quot;&gt;Spark-greenplum&lt;/h3&gt;

&lt;p&gt;Spark-greenplum的项目地址为:https://github.com/yaooqinn/spark-greenplum.&lt;/p&gt;

&lt;p&gt;spark本身有jdbc的DataSource支持，可以进行spark sql 到greenplum的传输，但是速度慢。
查看JdbcUtils中的savePartition方法，其中的拷贝模块为:&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;        &lt;span class=&quot;nf&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;hasNext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
          &lt;span class=&quot;nf&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numFields&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;isNullAt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
              &lt;span class=&quot;nv&quot;&gt;stmt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;setNull&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;nullTypes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
              &lt;span class=&quot;nf&quot;&gt;setters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stmt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
          &lt;span class=&quot;nv&quot;&gt;stmt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;addBatch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;rowCount&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
          &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rowCount&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batchSize&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nv&quot;&gt;stmt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;executeBatch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;rowCount&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里看到，他是针对迭代器进行遍历，达到batchSize（默认为1000）之后进行一次insert操作，因此针对大批量的拷贝操作，速度较慢。&lt;/p&gt;

&lt;p&gt;在postgresql中，有一个copy命令，可以参考文档：https://www.postgresql.org/docs/9.2/sql-copy.html.&lt;/p&gt;

&lt;p&gt;下面的命令为将一个文件中的数据拷贝到一个表中.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table_name&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;column_name&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...]&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;filename&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;STDIN&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;option&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...]&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这是一个原子操作，这个copy的速度相较于jdbc DataSource中的按批插入，性能提升极大。&lt;/p&gt;

&lt;p&gt;通过将每个dataFrame中partition的数据写入一个文件，然后使用copy from命令将这个文件中的数据拷贝到greenplum表中，针对每个分区中的copy操作分别是原子操作，但是如何针对所有分区实现事务呢？事务对于生产环境中是非常必要的。&lt;/p&gt;

&lt;p&gt;在讲解事务实现之前，先讲下在针对文件中一些特殊字符的处理.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Backslash characters (\) can be used in the COPY data to quote data characters that might otherwise be taken as row or column delimiters. In particular, the following characters must be preceded by a backslash if they appear as part of a column value: backslash itself, newline, carriage return, and the current delimiter character.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;从sparksql 写数据到文件的过程是将每个Row写到文件中的一行，而且各个column之间使用指定的delimiter间隔。因此，在写文件时需要对于一些特殊字符进行处理，比如换行符合回车符，这些肯定是需要特殊处理的，因此不处理，就会导致一个row写了多行，之后copy命令就无法正确识别，其次就是 row中如果有column的值包含和delimiter相同的字符也要进行转义，不然copy命令就无法通过delimiter识别出列的值，除此之外还有’\‘需要特殊处理，因为对delimiter的处理是在demiter前加’\‘因此，也要针对’\‘进行处理避免与delimiter的处理方式混淆。&lt;/p&gt;

&lt;h3 id=&quot;事务实现&quot;&gt;事务实现&lt;/h3&gt;

&lt;p&gt;前面提到针对每个partition的copy命令都是原子操作，但是针对整体的partition如何实现原子操作呢？&lt;/p&gt;

&lt;p&gt;从spark sql向greenplum插入数据分为以下几种情况:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;gp表存在，是overwrite操作，但是这个表是一个级联删除表，因此我们不能使用drop再create的操作，只能truncate再进行append。&lt;/li&gt;
  &lt;li&gt;gp表存在，向表中append数据。&lt;/li&gt;
  &lt;li&gt;gp表存在，是overwrite操作，是非级联表，因此可以对该表进行drop再create的操作。&lt;/li&gt;
  &lt;li&gt;gp表不存在，可以直接进行create操作。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上面四种情况，可以分为两种:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;可以drop if exists，再导入数据&lt;/li&gt;
  &lt;li&gt;必须append数据。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;case1&quot;&gt;case1&lt;/h4&gt;

&lt;p&gt;针对第一种情况，实现事务很简单，方案如下:&lt;/p&gt;

&lt;p&gt;首先创建一个临时表，然后针对每个分区，使用copy命令，将各个分区的数据拷贝到这个临时表中。最后，如果所有分区都成功拷贝。&lt;/p&gt;

&lt;p&gt;那么在driver中进行以下两步操作:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;drop $table if exists&lt;/li&gt;
  &lt;li&gt;alter table $tempTable rename to $table&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;如果这两步都成功，那么则完成了事务。&lt;/p&gt;

&lt;p&gt;如果有分区未成功拷贝，或者在以上两步中失败，则进行删除临时表的操作。并且抛出异常，提醒用户，事务未成功。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;如何判断分区成功数&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;如何判断分区是否全部成功呢？我们使用 &lt;strong&gt;LongAccmulator&lt;/strong&gt;来实现，在driver中注册一个累加器，然后每个分区成功时则累加器加一，如果最终累加器的值，等于dataFrame的分区数，那么代表全部成功，否则是部分失败。&lt;/p&gt;

&lt;p&gt;关于LongAccmulator，想了解的可以去搜索了解，相当于一个分布式的atomicLong.&lt;/p&gt;

&lt;h4 id=&quot;case2&quot;&gt;case2&lt;/h4&gt;

&lt;p&gt;针对第二种情况，我们添加一个transactionOn 的option。如果为true，那么我们将dataFrame进行coalesce(1)的操作，这样dataFrame就只有一个分区，针对这个分区中copy操作就是原子性的，这样就保证了事务。&lt;/p&gt;

&lt;p&gt;关于coalesce操作，它与reparation操作不同。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; def coalesce(numPartitions: Int, shuffle: Boolean = false,
               partitionCoalescer: Option[PartitionCoalescer] = Option.empty)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;对于coalesce操作，从m个分区编程n个分区，如果m&amp;lt;n是一定要进行shuffle的，如果m&amp;gt;n, 则如果非指定shuffle为true，则不需要进行shuffle。&lt;/p&gt;

&lt;p&gt;因此coalesce(1)操作，不会造成shuffle压力，而且rdd操作是迭代读取，之后进行落盘(参考&lt;a href=&quot;https://netease-bigdata.github.io/ne-spark-courseware/slides/spark_core/rdd_basics.html#1&quot;&gt;rdd-basic&lt;/a&gt;）。只是每个partition分区的数据都发向一个节点，数据拷贝需要进行串行，然后就是可能造成磁盘压力，如果存储不够的话就很尴尬。&lt;/p&gt;

&lt;p&gt;如果transactionOn为false，则不保障事务。&lt;/p&gt;
</description>
                <link>http://www.turbofei.wang/spark/2019/05/12/transactions-suuport-for-spark-greenlum</link>
                <guid>http://www.turbofei.wang/spark/2019/05/12/transactions-suuport-for-spark-greenlum</guid>
                <pubDate>2019-05-12T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>Spark External Shuffle Service</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#what-is-external-shuffle-service&quot; id=&quot;markdown-toc-what-is-external-shuffle-service&quot;&gt;What is external shuffle service?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#why-need-external-shuffle-service&quot; id=&quot;markdown-toc-why-need-external-shuffle-service&quot;&gt;Why need external shuffle service?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#how-it-works&quot; id=&quot;markdown-toc-how-it-works&quot;&gt;How it works？&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#reference&quot; id=&quot;markdown-toc-reference&quot;&gt;Reference&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;External shuffle service(ESS)是独立运行一个外部shuffle服务，用于管理spark的shuffle数据，本文讲解为什么要使用ESS，以及需要注意的地方.此处特指yarnShuffleService.&lt;/p&gt;

&lt;h2 id=&quot;what-is-external-shuffle-service&quot;&gt;What is external shuffle service?&lt;/h2&gt;

&lt;p&gt;首先，什么是外部shuffle服务。&lt;/p&gt;

&lt;p&gt;在工作之前，我没有使用过spark on yarn，都是在standalone模式下跑实验。所以之前没有注意到External shuffle service。&lt;/p&gt;

&lt;p&gt;那首先聊一下shuffle service。 shuffle分为两部分，shuffle write和shuffle read，在write端，对每个task的数据，按照key值进行hash，得到新的partitionId，然后将这些数据写到一个partitionFile里面，在paritionFile里面的数据是partitionId有序的，外加会生成一个索引，索引每个partitionFile对应偏移量和长度。&lt;/p&gt;

&lt;p&gt;而shuffle read 端就是从这些partitionFile里面拉取相应partitionId的数据，注意是拉取所有partitionFile的相应部分。&lt;/p&gt;

&lt;p&gt;External shuffle Service就是管理这些shuffle write端生成的shuffle数据，ESS是和yarn一起使用的， 在yarn集群上的每一个nodemanager上面都运行一个ESS，是一个常驻进程。一个ESS管理每个nodemanager上的executor生成的shuffle数据。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;cm&quot;&gt;/** Registers a new Executor with all the configuration we need to find its shuffle files. */&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;registerExecutor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;appId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;execId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;ExecutorShuffleInfo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;executorInfo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在注册executor时，使用appId, execId和ExecutorShuffleInfo(localDirs, shuffleManager类型).所以说ESS维护的是一个索引，这些shuffle数据会在application运行结束之后，清除这些localDirs来删除。&lt;/p&gt;

&lt;p&gt;针对每个App， 都会有一个LoadingCache来保存Shuffle 的IndexFile，默认是100m, 由&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.shuffle.service.index.cache.size&lt;/code&gt;控制。因此这个参数不能设置太大， 如果太大，在nodemanager上有多个应用运行，势必造成ESS的压力。&lt;/p&gt;

&lt;h2 id=&quot;why-need-external-shuffle-service&quot;&gt;Why need external shuffle service?&lt;/h2&gt;

&lt;p&gt;Spark系统在运行含shuffle过程的应用时，Executor进程除了运行task，还要负责写shuffle 数据，给其他Executor提供shuffle数据。当Executor进程任务过重，导致GC而不能为其他Executor提供shuffle数据时，会影响任务运行。同时，ESS的存在也使得，即使executor挂掉或者回收，都不影响其shuffle数据，因此只有在ESS开启情况下才能开启动态调整executor数目。&lt;/p&gt;

&lt;p&gt;因此，spark提供了external shuffle service这个接口，常见的就是spark on yarn中的，YarnShuffleService。这样，在yarn的nodemanager中会常驻一个externalShuffleService服务进程来为所有的executor服务，默认为7337端口。&lt;/p&gt;

&lt;p&gt;其实在spark中shuffleClient有两种，一种是blockTransferService，另一种是externalShuffleClient。如果在ESS开启，那么externalShuffleClient用来fetch  shuffle数据，而blockTransferService用于获取broadCast等其他BlockManager保存的数据。&lt;/p&gt;

&lt;p&gt;如果ESS没有开启，那么spark就只能使用自己的blockTransferService来拉取所有数据，包括shuffle数据以及broadcast数据。&lt;/p&gt;

&lt;h2 id=&quot;how-it-works&quot;&gt;How it works？&lt;/h2&gt;

&lt;p&gt;与外部shuffle service对应的参数有以下几个。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.shuffle.service.enabled&lt;/code&gt;&lt;/th&gt;
      &lt;th&gt;false&lt;/th&gt;
      &lt;th&gt;Enables the external shuffle service. This service preserves the shuffle files written by executors so the executors can be safely removed. This must be enabled if &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.dynamicAllocation.enabled&lt;/code&gt; is “true”. The external shuffle service must be set up in order to enable it. See&lt;a href=&quot;http://spark.apache.org/docs/latest/job-scheduling.html#configuration-and-setup&quot;&gt;dynamic allocation configuration and setup documentation&lt;/a&gt; for more information.&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.shuffle.service.port&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;7337&lt;/td&gt;
      &lt;td&gt;Port on which the external shuffle service will run.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.shuffle.registration.timeout&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;5000&lt;/td&gt;
      &lt;td&gt;Timeout in milliseconds for registration to the external shuffle service.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.shuffle.registration.maxAttempts&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;When we fail to register to the external shuffle service, we will retry for maxAttempts times.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;第一个参数是打开外部服务，这里看到描述里面写当打开动态分配时，必须设置为true，是为了让外部shuffle service管理shuffle output files，方便释放闲置的executor。&lt;/p&gt;

&lt;p&gt;第二个参数是设置shuffle 服务的端口。&lt;/p&gt;

&lt;p&gt;后面两个参数，就是注册超时时长与重试次数，在 shuffle需要传输大量数据时，shuffle service比较繁忙，回复这些注册信息的时延较高，因此可能会发生注册失败错误，此时要将这两个参数调大。&lt;/p&gt;

&lt;p&gt;在spark on yarn中，会设置以下参数。&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;property&amp;gt;

&amp;lt;name&amp;gt;yarn.nodemanager.aux-services&amp;lt;/name&amp;gt;

&amp;lt;value&amp;gt;spark_shuffle&amp;lt;/value&amp;gt;

&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;

&amp;lt;name&amp;gt;yarn.nodemanager.aux-services.spark_shuffle.class&amp;lt;/name&amp;gt;

&amp;lt;value&amp;gt;org.apache.spark.network.yarn.YarnShuffleService&amp;lt;/value&amp;gt;

&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;

&amp;lt;name&amp;gt;spark.shuffle.service.port&amp;lt;/name&amp;gt;

&amp;lt;value&amp;gt;7337&amp;lt;/value&amp;gt;

&amp;lt;/property&amp;gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://spark.apache.org/docs/latest/configuration.html&quot;&gt;Spark Configuration&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-ExternalShuffleService.html&quot;&gt;External Shuffle Service&lt;/a&gt;&lt;/p&gt;

</description>
                <link>http://www.turbofei.wang/spark/2018/12/10/spark-external-shuffle-service</link>
                <guid>http://www.turbofei.wang/spark/2018/12/10/spark-external-shuffle-service</guid>
                <pubDate>2018-12-10T00:00:00-08:00</pubDate>
        </item>

        <item>
                <title>Spark Cbo Code Analysis</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#spark-cbo-源码分析&quot; id=&quot;markdown-toc-spark-cbo-源码分析&quot;&gt;Spark CBO 源码分析&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#统计信息类&quot; id=&quot;markdown-toc-统计信息类&quot;&gt;统计信息类&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#statistics的计算&quot; id=&quot;markdown-toc-statistics的计算&quot;&gt;Statistics的计算&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#拿到数据之后怎么用&quot; id=&quot;markdown-toc-拿到数据之后怎么用&quot;&gt;拿到数据之后怎么用&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#costbasedjoinreorder&quot; id=&quot;markdown-toc-costbasedjoinreorder&quot;&gt;CostBasedJoinReorder&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#joinselection&quot; id=&quot;markdown-toc-joinselection&quot;&gt;JoinSelection&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;对Spark的CBO(cost based optimization) 进行源码分析&lt;/p&gt;

&lt;h2 id=&quot;spark-cbo-源码分析&quot;&gt;Spark CBO 源码分析&lt;/h2&gt;

&lt;p&gt;CBO是基于Cost来优化plan。&lt;/p&gt;

&lt;p&gt;要计算cost就需要统计一些参与计算的表的相关信息，因此spark添加了&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Statistics和ColumnStat&lt;/code&gt;类来统计相关信息。&lt;/p&gt;

&lt;p&gt;CBO主要是针对join来计算cost,目前spark-2.3 版本中与CBO相关的参数如下：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;参数&lt;/th&gt;
      &lt;th&gt;默认值&lt;/th&gt;
      &lt;th&gt;说明&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.sql.cbo.enabled&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;Enables CBO for estimation of plan statistics when set true.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.sql.cbo.joinReorder.enabled&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;Enables join reorder in CBO.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.sql.cbo.joinReorder.dp.star.filter&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;Applies star-join filter heuristics to cost based join enumeration.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.sql.cbo.joinReorder.dp.threshold&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;The maximum number of joined nodes allowed in the dynamic programming algorithm.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.sql.cbo.starSchemaDetection&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;When true, it enables join reordering based on star schema detection.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;下文按照逻辑顺序分析spark cbo 源码。&lt;/p&gt;

&lt;h2 id=&quot;统计信息类&quot;&gt;统计信息类&lt;/h2&gt;

&lt;p&gt;CBO相关的统计信息类有两个，一个是ColumnStat,代表的是表中列的详细，例如最大值，最小值，空值个数，平均长度，最大长度。另外一个类是Statistics，这个类是对应一个LogicalPlan的统计信息，例如join，aggregate，logicalRelation。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-Scala&quot;&gt;case class Statistics(
    sizeInBytes: BigInt,
    rowCount: Option[BigInt] = None,
    attributeStats: AttributeMap[ColumnStat] = AttributeMap(Nil),
    hints: HintInfo = HintInfo()) 

case class ColumnStat(
    distinctCount: BigInt,
    min: Option[Any],
    max: Option[Any],
    nullCount: BigInt,
    avgLen: Long,
    maxLen: Long,
    histogram: Option[Histogram] = None) 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如上所示，可以看到ColumnStat表示列的详细信息。&lt;/p&gt;

&lt;p&gt;而Statistics，中的sizeInBytes和rowCount就代表这个logicalPlan输出数据的大小和行数，而attributeStats 代表这个logicalPlan涉及到的列的统计信息（一个expressID到列信息的映射），和hints。&lt;/p&gt;

&lt;p&gt;对于join来说，它的Statistics里的信息就代表join操作输出的大小，行数以及attributeStats。&lt;/p&gt;

&lt;p&gt;对于logicalRelation，它的Statistics代表其对应表中schema相关数据的大小，行数，attributeStats。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CatalogStatistics&lt;/code&gt;这个类表示存储在外部catalog(例如hive metastore）中的表的信息.&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;CatalogStatistics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sizeInBytes&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;BigInt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;rowCount&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;BigInt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;colStats&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;ColumnStat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;Map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这些表的信息需要使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;analyze table&lt;/code&gt;命令来计算，然后存储到catalog里。&lt;/p&gt;

&lt;p&gt;每种LogicalPlan计算Statistics的方法是不同的。&lt;/p&gt;

&lt;p&gt;对于LogicalRelation来说，它是读取对应表中schema，使用CatalogStatistics类的toPlanStats可以生成Statistics。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;toPlanStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;planOutput&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Attribute&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cboEnabled&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Boolean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Statistics&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cboEnabled&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;rowCount&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;isDefined&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;attrStats&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AttributeMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;planOutput&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;flatMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;colStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// Estimate size as number of rows * row size.&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;EstimationUtils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;getOutputSize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;planOutput&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;rowCount&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attrStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;Statistics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sizeInBytes&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rowCount&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rowCount&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attributeStats&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attrStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// When CBO is disabled or the table doesn&apos;t have other statistics, we apply the size-only&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// estimation strategy and only propagate sizeInBytes in statistics.&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;Statistics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sizeInBytes&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sizeInBytes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;下面将介绍其他LogicalPlan的Statistics计算。&lt;/p&gt;

&lt;h2 id=&quot;statistics的计算&quot;&gt;Statistics的计算&lt;/h2&gt;

&lt;p&gt;看LogicalPlanStats类，可以看出，这里，判断cbo是否开启，如果cbo打开，则采用BasicStatsPlanVisitor类来计算相关的Statistics，如果没有cbo，则使用SizeInBytesOnlyStatsPlanVisitor来计算。&lt;/p&gt;

&lt;p&gt;从类的名字就可以看出来，只有cbo开启，才会计算rowCount以及attributeStats信息，如果没有cbo,SizeInBytesOnlyStatsPlanVisitor只会计算 size信息。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;trait&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LogicalPlanStats&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;LogicalPlan&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Statistics&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;statsCache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;getOrElse&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;cboEnabled&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;statsCache&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;BasicStatsPlanVisitor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;visit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;statsCache&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;SizeInBytesOnlyStatsPlanVisitor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;visit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;statsCache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;get&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;其实在BasicStatsPlanVisitor类中对于大部分类型的LogicalPlan都还是调用SizeInBytesOnlyStatsPlanVisitor的方法来计算。&lt;/p&gt;

&lt;p&gt;只有针对Aggregate，Join，Filter，Project有另外的计算方法。&lt;/p&gt;

&lt;p&gt;这里讲下join操作的Statistics计算过程。&lt;/p&gt;

&lt;p&gt;如果没有开启CBO，join操作首先判断是否是 leftAntiJoin或者是LeftSemiJoin，如果是，则把leftChild的sizeInBytes作为计算结果，因为对于leftAntiJoin和leftSemiJoin来说，join之后表的大小是小于leftChild的。而对于其他类型的join，把左右child的sizeInBytes相乘作为join之后的大小，并且关闭掉broadcastHint，因为这些join类型可能造成很大的output。而这种粗糙的代价估计造成的结果就是，对代价估计不准确，如果该join是可以进行broadcastjoin，也可能由于粗糙的代价估计变得不可进行。&lt;/p&gt;

&lt;p&gt;如果开启了CBO，对于join操作就不止计算sizeInBytes，还需要计算rowCount，AttributeStats。&lt;/p&gt;

&lt;p&gt;代码如下，首先是判断join类型，如果是 inner,cross,leftOuter,RightOuter,FullOuter中的一种，则使用estimateInnerOuterJoin方法。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;estimate&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Statistics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;joinType&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Inner&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Cross&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LeftOuter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RightOuter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;FullOuter&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nf&quot;&gt;estimateInnerOuterJoin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LeftSemi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LeftAnti&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nf&quot;&gt;estimateLeftSemiAntiJoin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nf&quot;&gt;logDebug&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;[CBO] Unsupported join type: ${join.joinType}&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;None&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里只针对针对estimateInnerOuterJoin方法，用语言描述一下：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;如果是equiJoin:&lt;/p&gt;

  &lt;blockquote&gt;
    &lt;p&gt;1、首先估算被equi条件选择的记录条数,即等于innerJoin选择的条数，命名为numInnerJoinedRows；以及这些equi涉及的key在join之后的stats。&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;即在join中，存在类似 a.co1=b.co1, a.co2=b.co2 这些类似条件，现在是估计满足这些相等条件的记录条数。&lt;/p&gt;

      &lt;p&gt;使用的公式是： T(A J B) = T(A) * T(B) / max(V(A.ki), V(B.ki)).&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;2、 预估得到结果的行数。&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;因为即使满足这些相等条件，也不会只输出这些满足条件的记录。&lt;/p&gt;

      &lt;p&gt;如果是leftOuterJoin，则会对左边表中所有记录都会输出，不管右边匹配是否为空。&lt;/p&gt;

      &lt;p&gt;因此，对于leftOuterJoin来说，输出的记录条数等于max(左边表条数，numInnerJoinedRows)。&lt;/p&gt;

      &lt;p&gt;同样还有rightOuterJoin,输出记录条数=max(右边表条数，numInnerJoinedRows)。&lt;/p&gt;

      &lt;p&gt;对于全连接，输出记录条数=max(左边表条数，numInnerJoinedRows)+max(右边表条数，numInnerJoinedRows)-numInnerJoinedRows。即类似于A与B的并集-A与B的交集。&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;3、然后是根据前面的计算结果更新Statistics，包括attributeStats。&lt;/p&gt;
  &lt;/blockquote&gt;

  &lt;p&gt;如果不是equiJoin：&lt;/p&gt;

  &lt;blockquote&gt;
    &lt;p&gt;则按照笛卡尔积来计算，输出行数为两个表行数的乘积&lt;/p&gt;

  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;拿到数据之后怎么用&quot;&gt;拿到数据之后怎么用&lt;/h2&gt;

&lt;p&gt;这些Statistics的结果，会怎么运用呢？&lt;/p&gt;

&lt;p&gt;spark sql中plan的处理过程可以参考&lt;a href=&quot;./spark-sql-catalyst.md&quot;&gt;Spark sql catalyst过程详解&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;在unresolvedLogicalPlan-&amp;gt;resolvedLogicalPlan过程中收集Statistics，然后在&lt;/p&gt;

&lt;p&gt;resolvedLogicalPlan-&amp;gt;optimizedLogicalPlan过程中，基于这些统计信息，进行costBasedJoinRecorder，即基于统计信息，对join顺序重排序，寻求最优join方案。&lt;/p&gt;

&lt;p&gt;在optimizedLogicalPlan-&amp;gt;phsicalPlan过程中，基于Statistics中的sizeInBytes信息以及hint选择合适的join策略(broadcastJoin,hashShuffledJoin,sortMergeJoin).&lt;/p&gt;

&lt;h4 id=&quot;costbasedjoinreorder&quot;&gt;CostBasedJoinReorder&lt;/h4&gt;

&lt;p&gt;这是一个使用plan的stats信息，来选择合适的join顺序的类。&lt;/p&gt;

&lt;p&gt;类&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Optimizer&lt;/code&gt;中有两个跟join 顺序有关的rule，一个是reoderJoin，另外一个是CostBasedJoinRecorder。reorderjoin是没有cbo也会触发的rule，这个不会使用统计的信息，只是负责将filter下推，这样最底层的join至少会有一个filter。如果这些join已经每个都有一条condition，那么这些plan就不会变化，因此reorder join不涉及基于代价的优化。&lt;/p&gt;

&lt;p&gt;首先看下对cost的定义。cost是有一个基数，是rowCount，然后一个sizeInBytes。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cm&quot;&gt;/**
 * This class defines the cost model for a plan.
 * @param card Cardinality (number of rows).
 * @param size Size in bytes.
 */&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Cost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;card&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;BigInt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;BigInt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;other&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Cost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Cost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;card&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;other&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;card&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;other&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;而判断cost的方法是：&lt;/p&gt;

&lt;p&gt;A: Cost(ac,as)  B: Cost(bc,bs)&lt;/p&gt;

&lt;p&gt;如果&lt;/p&gt;

&lt;p&gt;(ac/bc)*joinReorderCardWeight +(as/bs)*(1-joinReorderCardWeight)&amp;lt;1，&lt;/p&gt;

&lt;p&gt;则认为A比B好。&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.cbo.joinReorder.card.weight&lt;/code&gt;默认为0.7。代码如下：&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;betterThan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;other&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;JoinPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SQLConf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Boolean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;other&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;planCost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;card&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;other&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;planCost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;relativeRows&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BigDecimal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;planCost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;card&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BigDecimal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;other&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;planCost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;card&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;relativeSize&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BigDecimal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;planCost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BigDecimal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;other&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;planCost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;relativeRows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;joinReorderCardWeight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;relativeSize&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;joinReorderCardWeight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;costBasedJoinReorder是使用一个动态规划来进行选择合适的join顺序。&lt;/p&gt;

&lt;p&gt;下面讲一个这个动态规划算法。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;假设有  a j b j c j d   a.k1=b.k1 and b.k2 = c.k2 and c.k3=d.k3&lt;/p&gt;

  &lt;p&gt;将会分为4层来进行：&lt;/p&gt;

  &lt;blockquote&gt;
    &lt;p&gt;level 0: p({A}), p({B}), p({C}), p({D})
level 1: p({A, B}), p({B, C}), p({C, D})
level 2: p({A, B, C}), p({B, C, D})
level 3: p({A, B, C, D})&lt;/p&gt;
  &lt;/blockquote&gt;

  &lt;p&gt;首先就是生成第0层，第0层的founfPlans={p{a},p{b},p{c},p{d}}.&lt;/p&gt;

  &lt;p&gt;如果设层级为level，那么每层的任务就是找到（level+1)个plan进行join最优的版本。&lt;/p&gt;

  &lt;p&gt;因此 k层和level-k层的所包含的表的个数之和，就是(k+1+level-k+1)=level+2，也就是说是level+1层所需要的foundPlan。&lt;/p&gt;

  &lt;p&gt;而我们在每次生成新的join之后，就判断他的itemSet是否已经存在，如果不存在就存储；如果存在，就取出其对应的plan，对比看是不是优于之前的plan（betterThan)，保存最优的。&lt;/p&gt;

  &lt;p&gt;这样。每个level里面保存的都是相应个数个多join最优的plan，最终也得到了最优的plan。&lt;/p&gt;

  &lt;p&gt;当然，在形成plan时有很多判断，比如在level1 里面，就不能形成p({A,C})。&lt;/p&gt;

  &lt;p&gt;因为不存在condition 使得A,C可以进行join。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;当然，在动态规划进行search的时候，有一个filter。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;spark.sql.cbo.joinReorder.dp.star.filter&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这是一个星型join过滤器，用来确保star schema 中的tables是被plan在一起。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;spark.sql.cbo.joinReorder.dp.threshold&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;代表在dp进行costbasedReorder时，最多支持的表的数量。&lt;/p&gt;

&lt;p&gt;**spark.sql.cbo.starSchemaDetection  **&lt;/p&gt;

&lt;p&gt;这个参数是在reorderJoin中触发，而且只在&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.cbo.starSchemaDetection=true spark.sql.cbo.enabled=false&lt;/code&gt;时才触发，很奇怪，这个参数以cbo命名，但是却在cbo.enable=false才触发。&lt;/p&gt;

&lt;p&gt;这个是用来观察是否存在starJoin。&lt;/p&gt;

&lt;h4 id=&quot;joinselection&quot;&gt;JoinSelection&lt;/h4&gt;

&lt;p&gt;在SparkPlanner类中，有几个优化策略会对LogicalPlan进行优化。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SparkPlanner&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;sparkContext&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SparkContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SQLConf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;experimentalMethods&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ExperimentalMethods&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SparkStrategies&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;strategies&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Strategy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;experimentalMethods&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;extraStrategies&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;extraPlanningStrategies&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;++&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;DataSourceV2Strategy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;FileSourceStrategy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;DataSourceStrategy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;SpecialLimits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;Aggregation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;JoinSelection&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;InMemoryScans&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;BasicOperators&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Nil&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;里面有一个JoinSelection方法，这个方法是主要是用来判断是否可以使用broadcastjoin，然后决定是使用broadcastJoin，还是shuffledHashJoin还是sortMergeJoin。&lt;/p&gt;

&lt;p&gt;broadcastjoin可以避免shuffle，如果使用得当，可以提升程序的性能。&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;这是针对一个大表和一个极小表&lt;/code&gt;在spark中有一个参数是，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.autoBroadcastJoinThreshold&lt;/code&gt;，这个参数是一个数字，单位字节，代表如果一个表的szie小于这个数值，就可以进行broadcastjoin。但是这里只使用size作为估计是不准确的，还应该使用rowCount作为参考，因为在join中，join的结果是与两个表的条数强相关，只使用size做判断是不准确的。&lt;/p&gt;

&lt;p&gt;在spark中，有BroadCastHint，前面也提到过，如果没有开启cbo，那么如果判断join类型是非leftAntiJoin和leftSemiJoin，则会觉得join之后的大小无法估测，可能会爆炸式增长，因此会关掉BroadcastHint。&lt;/p&gt;

&lt;p&gt;对于shuffledHashJoin，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;这是针对一个大表和一个小表（判断标准为a.stats.sizeInBytes * 3 &amp;lt;= b.stats.sizeInBytes)&lt;/code&gt;，简单描述一下过程就是两个表A和B，首先，选择一个表进行shuffle write操作，即针对每个分区，按照key的hash值进行排序，将相同hash值的key放在一起，形成一个partitionFile，然后在read端拉取write端所有相应key的数据，作为localhashMap和另外一个标的分区进行join。&lt;/p&gt;

&lt;p&gt;这里也使用stats进行判断，如果&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;plan.stats.sizeInBytes &amp;lt; conf.autoBroadcastJoinThreshold * conf.numShufflePartitions&lt;/code&gt;，则判断该表的size可以满足每个分区构建localhashMap的可能，可以看到这里也是以&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;autoBroadcastJoinThreshold&lt;/code&gt;作为衡量标准。&lt;/p&gt;

&lt;p&gt;如果是两张大表，则需要使用sortmergeJoin，类似于先排序，即按照keypair排序，然后进行归并。&lt;/p&gt;

&lt;p&gt;这些join selection的操作，不管是否开启CBO都会进行。但是和CBO相关的是，这些数据的统计是和CBO有关，前面提过，如果开启CBO则使用BasicStatsPlanVisitor来进行统计。&lt;/p&gt;

&lt;p&gt;上述的这些估测，都是基于size信息。但是即使是基于size信息，如果没有开启cbo，这些信息也是粗糙的，没有CBO那种更细致的估计，因此可能会造成Join种类选择不合适。&lt;/p&gt;

&lt;p&gt;上述的判断，很多是基于&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.autoBroadcastJoinThreshold&lt;/code&gt;，因此在运行环境中，一定要结合集群环境设置合适的值。&lt;/p&gt;

&lt;p&gt;而且，在joinSelection中，也应该基于rowCount来判断join的种类。&lt;/p&gt;
</description>
                <link>http://www.turbofei.wang/spark/2018/12/04/spark-cbo-code-analysis</link>
                <guid>http://www.turbofei.wang/spark/2018/12/04/spark-cbo-code-analysis</guid>
                <pubDate>2018-12-04T00:00:00-08:00</pubDate>
        </item>

        <item>
                <title>Spark Sql Catalyst</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#spark-sql-catalyst&quot; id=&quot;markdown-toc-spark-sql-catalyst&quot;&gt;Spark Sql Catalyst&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#treenode-and-rule&quot; id=&quot;markdown-toc-treenode-and-rule&quot;&gt;TreeNode And Rule&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#treenode&quot; id=&quot;markdown-toc-treenode&quot;&gt;TreeNode&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#rule&quot; id=&quot;markdown-toc-rule&quot;&gt;Rule&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#catalyst-in-spark-sql&quot; id=&quot;markdown-toc-catalyst-in-spark-sql&quot;&gt;Catalyst In Spark Sql&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#analysis&quot; id=&quot;markdown-toc-analysis&quot;&gt;Analysis&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#logical-optimizations&quot; id=&quot;markdown-toc-logical-optimizations&quot;&gt;Logical Optimizations&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#物理计划&quot; id=&quot;markdown-toc-物理计划&quot;&gt;物理计划&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#code-generation&quot; id=&quot;markdown-toc-code-generation&quot;&gt;Code Generation&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#添加自己的rule&quot; id=&quot;markdown-toc-添加自己的rule&quot;&gt;添加自己的Rule&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#参考文献&quot; id=&quot;markdown-toc-参考文献&quot;&gt;参考文献&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;关于spark的catalyst&lt;/p&gt;

&lt;h1 id=&quot;spark-sql-catalyst&quot;&gt;Spark Sql Catalyst&lt;/h1&gt;

&lt;p&gt;Catalyst是spark官方为spark sql设计的query优化框架， 基于函数式编程语言Scala实现。Catalyst有一个优化规则库，可以针对spark sql语句进行自动分析优化。而且Catalyst利用Scala的强大语言特性，例如模式匹配和运行时元程序设计(&lt;a href=&quot;https://docs.scala-lang.org/overviews/quasiquotes/intro.html&quot;&gt;基于scala quasiquotes&lt;/a&gt;)，使得开发者可以简单方便的定制优化规则。&lt;/p&gt;

&lt;h3 id=&quot;treenode-and-rule&quot;&gt;TreeNode And Rule&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TreeNode&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Rule&lt;/code&gt;是Catalyst重要的两种类型。&lt;/p&gt;

&lt;h4 id=&quot;treenode&quot;&gt;TreeNode&lt;/h4&gt;

&lt;p&gt;在sql语句中，每条sql语句都会被解析为一个AST(abstract syntax tree)，而TreeNode就是spark sql抽象语法树中的节点。&lt;/p&gt;

&lt;p&gt;TreeNode是一个抽象类，子类有很多种，比如可以是Projection，Attribute, Literal(常量)，或者是一个操作(比如Sum,Add)，或者是join,hashAggregate这些，或者filter,scan等等。&lt;/p&gt;

&lt;p&gt;比如下面这条sql语句。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;ta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;   &lt;span class=&quot;n&quot;&gt;ta&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tb&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;ta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; 
 &lt;span class=&quot;n&quot;&gt;tb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;90&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;它会解析为一个AST。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;== Parsed Logical Plan ==
&apos;Project [unresolvedalias(&apos;sum(&apos;v), None)]
+- &apos;SubqueryAlias tmp
   +- &apos;Project [&apos;ta.key, ((1 + 2) + &apos;ta.value) AS v#12]
      +- &apos;Filter ((&apos;ta.key = &apos;tb.key) &amp;amp;&amp;amp; (&apos;tb.value &amp;gt; 90))
         +- &apos;Join Inner
            :- &apos;UnresolvedRelation `ta`
            +- &apos;UnresolvedRelation `tb`
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/spark-catalyst/sql-ast.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;rule&quot;&gt;Rule&lt;/h4&gt;

&lt;p&gt;而Rule就是运用在这个AST上面的规则。通过规则对树里面的TreeNode进行转化。&lt;/p&gt;

&lt;p&gt;观察TreeNode，里面有一个很重要的方法：&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rule&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;PartialFunction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;BaseType&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;BaseType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;BaseType&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;transformDown&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rule&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;默认是对树中的TreeNode使用前序遍历方式（transformDown)进行转化，也可以使用后续遍历(transformUp)对TreeNode进行转化。&lt;/p&gt;

&lt;p&gt;查看Rule的子类，发现有很多规则, 这些规则是很多种，在AST转换的各个阶段的规则都有，比如列裁剪，谓词下推，合并filter，展开projection等等。&lt;/p&gt;

&lt;p&gt;RuleExecutor是一个用来执行rule的执行器，里面有一个batch字段，是一系列的rule，这些是作用在treeNode组成的tree之上，rule的执行策略有两种，一种是Once，只执行一次，另外一种是fixedPoint，意思是在rule一直作用在tree之上，直到tree达到一个不动点，不再改变。&lt;/p&gt;

&lt;h3 id=&quot;catalyst-in-spark-sql&quot;&gt;Catalyst In Spark Sql&lt;/h3&gt;

&lt;p&gt;spark sql是 apache spark的其中一个模块，主要用于进行结构化数据的处理。spark sql的底层执行还是调用rdd来执行。一条sql语句从String到RddChain的过程如下图所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/spark-catalyst/catalyst.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;SQL语句到转换为rdd总共分为以下阶段，&lt;a href=&quot;./Spark-sql-Analysis.md&quot;&gt;具体参考Spark sql 执行流程-从sql string 到 rdd&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;SQL 语句经过 SqlParser(ANTLR4) 解析成 Unresolved LogicalPlan;&lt;/li&gt;
  &lt;li&gt;使用 analyzer 结合数据数据字典 (catalog) 进行绑定, 生成 resolved LogicalPlan;&lt;/li&gt;
  &lt;li&gt;对 resolved LogicalPlan 进行优化, 生成 optimized LogicalPlan;&lt;/li&gt;
  &lt;li&gt;将 LogicalPlan 转换成 PhysicalPlan;&lt;/li&gt;
  &lt;li&gt;将 PhysicalPlan 转换成可执行物理计划;&lt;/li&gt;
  &lt;li&gt;使用 execute() 执行可执行物理计划;&lt;/li&gt;
  &lt;li&gt;生成 RDD。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;而Catalyst参与其中的四个阶段，分别是：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;将Unresolved Logical Plan转化为resolved logical plan&lt;/li&gt;
  &lt;li&gt;logical plan 到optimized logical plan&lt;/li&gt;
  &lt;li&gt;optimized logical plan 到physical plan&lt;/li&gt;
  &lt;li&gt;code generation(在转换为可执行物理计划阶段)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在生成physical plan阶段，可能会使用CBO(cost based optimization，目前是用于join策略的选择),其他阶段都是RBO(rule based optimization)。&lt;/p&gt;

&lt;h4 id=&quot;analysis&quot;&gt;Analysis&lt;/h4&gt;

&lt;p&gt;Analysis阶段的输入是一个AST(抽象语法树)或者是一个DataFrame，称之为unresolved logic plan。因为这些plan中的元素属性都是未知的。比如上面举例的sql语句，是否存在ta这个表，ta这个表有没有key 和 value字段，以及这些字段的类型都是未知的。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;org.apache.spark.sql.catalyst.analysisAnalyzer&lt;/code&gt;是一个用于执行analysis的类，这个类继承RuleExecutor，其中定义了一系列的解析规则顺序执行来解析这些字段和函数等里面的属性。&lt;/p&gt;

&lt;p&gt;Spark sql使用Catalyst规则和catalog来查询这些表是否存在，并来获得查询需要的具体属性。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;向catalog查询relations&lt;/li&gt;
  &lt;li&gt;根据属性的名字做映射&lt;/li&gt;
  &lt;li&gt;对名字相同的attribute给unique id标注：例如前面sql语句的ta.key =  tb.key， 会被解析为 key#1 = key#6&lt;/li&gt;
  &lt;li&gt;对expressions的类型做解析：例如 (cast((1 + 2) as bigint) + value#1L),  sum(v#12L) AS sum(v)#28L&lt;/li&gt;
  &lt;li&gt;如果有UDF，还要解析UDF&lt;/li&gt;
  &lt;li&gt;等等&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下面就是resolved logical plan：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;== Analyzed Logical Plan ==
sum(v): bigint
Aggregate [sum(v#12L) AS sum(v)#28L]
+- SubqueryAlias tmp
   +- Project [key#0, (cast((1 + 2) as bigint) + value#1L) AS v#12L]
      +- Filter ((key#0 = key#6) &amp;amp;&amp;amp; (value#7L &amp;gt; cast(90 as bigint)))
         +- Join Inner
            :- SubqueryAlias ta, `ta`
            :  +- Relation[key#0,value#1L] json
            +- SubqueryAlias tb, `tb`
               +- Relation[key#6,value#7L] json
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;可以看出，每个attribute都有一个Unique ID，例如 key#0, sum(v)#28L&lt;/p&gt;

&lt;h4 id=&quot;logical-optimizations&quot;&gt;Logical Optimizations&lt;/h4&gt;

&lt;p&gt;在获得resolved logical plan之后，就对这个plan进行优化。&lt;/p&gt;

&lt;p&gt;这个其实类似analyzer，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;org.apache.spark.sql.catalyst.optimizer.Optimizer&lt;/code&gt;同样是继承RuleExecutor，然后里面包含了一系列的优化策略。然后每个策略对Tree进行transform。主要的优化策略列表如下：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;PushProjectionThroughUnion,
ReorderJoin,
EliminateOuterJoin,
PushPredicateThroughJoin,
PushDownPredicate,
LimitPushDown,
ColumnPruning,
InferFiltersFromConstraints,
// Operator combine
CollapseRepartition,
CollapseProject,
CollapseWindow,
CombineFilters,
CombineLimits,
CombineUnions,
// Constant folding and strength reduction
NullPropagation,
FoldablePropagation,
OptimizeIn(conf),
ConstantFolding,
ReorderAssociativeOperator,
LikeSimplification,
BooleanSimplification,
SimplifyConditionals,
RemoveDispensableExpressions,
SimplifyBinaryComparison,
PruneFilters,
EliminateSorts,
SimplifyCasts,
SimplifyCaseConversionExpressions,
RewriteCorrelatedScalarSubquery,
EliminateSerialization,
RemoveRedundantAliases,
RemoveRedundantProject
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;常见的谓词下推啊，常数合并，filter合并等等。&lt;/p&gt;

&lt;p&gt;在我们上面的那条sql语句中，用到了谓词下推和常数合并，以及添加了isNotNull判断和filter合并等。下面就是优化之后逻辑计划。&lt;/p&gt;

&lt;p&gt;我们可以看到在resolved logical plan中，filter条件在join之上，在优化之后，filter条件下推，这样可以提早过滤掉一部分数据，减小join部分的压力。&lt;/p&gt;

&lt;p&gt;还有就是之前的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1+2&lt;/code&gt;在这里已经转化为3，还有就是在filter里面都加了 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;isNotNull&lt;/code&gt;判断。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;== Optimized Logical Plan ==
Aggregate [sum(v#12L) AS sum(v)#28L]
+- Project [(3 + value#1L) AS v#12L]
   +- Join Inner, (key#0 = key#6)
      :- Filter isnotnull(key#0)
      :  +- Relation[key#0,value#1L] json
      +- Project [key#6]
         +- Filter ((isnotnull(value#7L) &amp;amp;&amp;amp; (value#7L &amp;gt; 90)) &amp;amp;&amp;amp; isnotnull(key#6))
            +- Relation[key#6,value#7L] json
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;物理计划&quot;&gt;物理计划&lt;/h4&gt;

&lt;p&gt;在获得 optimized logical plan之后，接下来就要准备可以执行的物理计划。观察上面的优化之后的逻辑计划，只说了join，但是怎么join，是broadcastJoin 还是 SortMergeJoin。 只有Relation[key#6,value#7L] json，但是去哪里获得数据，等等。物理计划就是要完善这部分。&lt;/p&gt;

&lt;p&gt;同前面几个阶段相同，这个阶段也是一系列的策略：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def strategies: Seq[Strategy] =
    extraStrategies ++ (
    FileSourceStrategy ::
    DataSourceStrategy ::
    DDLStrategy ::
    SpecialLimits ::
    Aggregation ::
    JoinSelection ::
    InMemoryScans ::
    BasicOperators :: Nil)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;可以看出这些策略是选择输入源相关，DDL策略相关，join等等。&lt;/p&gt;

&lt;p&gt;前面部分粗略的提到过，Spark sql关于其他阶段的优化都是RBO，而join选择是基于CBO。目前CBO还在逐渐完善，可以关注&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-16026&quot;&gt;相关JIRA&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;因为join的选择必须要基于表的大小相关的信息，才能做出好的选择。关注这个JoinSelection策略。&lt;/p&gt;

&lt;p&gt;此处就选择一个方法，不再展开。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;canBroadcast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plan&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;LogicalPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Boolean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;plan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;statistics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;isBroadcastable&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;plan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;statistics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;sizeInBytes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt;
      &lt;span class=&quot;nv&quot;&gt;plan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;statistics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;sizeInBytes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;autoBroadcastJoinThreshold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;可以看到这个方法判断是否能够broadcast的规则就是通过统计的数据, statistics中的sizeInBytes大小，来判断这个表的大小是否超过broadcast参数设置的阈值，如果小于阈值，则选用broadcastJoin，这样可以避免shuffle。&lt;/p&gt;

&lt;h4 id=&quot;code-generation&quot;&gt;Code Generation&lt;/h4&gt;

&lt;p&gt;上面的物理计划阶段得到的只是一个中间阶段的物理计划，要想物理计划阶段得以运行还要进行一系列操作，这部分体现在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;org.apache.spark.sql.execution.QueryExecution类的preparations方法中&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cm&quot;&gt;/** A sequence of rules that will be applied in order to the physical plan before execution. */&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;preparations&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Rule&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;SparkPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;python&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;ExtractPythonUDFs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;nc&quot;&gt;PlanSubqueries&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;nc&quot;&gt;EnsureRequirements&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;sparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;sessionState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;nc&quot;&gt;CollapseCodegenStages&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;sparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;sessionState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;nc&quot;&gt;ReuseExchange&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;sparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;sessionState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;nc&quot;&gt;ReuseSubquery&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;sparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;sessionState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里会添加排序，分区策略，codegen。&lt;/p&gt;

&lt;p&gt;排序，分区就是类似于 spark core中的shuffle阶段。而codegen是Catalyst中的重要内容。&lt;/p&gt;

&lt;p&gt;由于spark sql是操纵内存中的datasets，cpu是一个重要的瓶颈，因此codegen就是为了生成高效的代码，来加速性能。Catalyst的codegen依赖scala的一个特性 &lt;a href=&quot;https://docs.scala-lang.org/overviews/quasiquotes/intro.html&quot;&gt;quasiquotes&lt;/a&gt;来使得codegen变得简单。&lt;/p&gt;

&lt;p&gt;codeGen是给一些可以进行codeGen的例子，制定了一套通用的模板，固定的部分是相同的，定制的部分传入一些具体的参数，然后可以运行时编程运行，如下。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;source&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
  public Object generate(Object[] references) {
    return new GeneratedIterator(references);
  }

  ${ctx.registerComment(s&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Codegend&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pipeline&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n$&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;child&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;treeString&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;trim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;)}
  final class GeneratedIterator extends org.apache.spark.sql.execution.BufferedRowIterator {

    private Object[] references;
    private scala.collection.Iterator[] inputs;
    ${ctx.declareMutableStates()}

    public GeneratedIterator(Object[] references) {
      this.references = references;
    }

    public void init(int index, scala.collection.Iterator[] inputs) {
      partitionIndex = index;
      this.inputs = inputs;
      ${ctx.initMutableStates()}
      ${ctx.initPartition()}
    }

    ${ctx.declareAddedFunctions()}

    protected void processNext() throws java.io.IOException {
      ${code.trim}
    }
  }
  &quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;trim&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;最终得到可执行的物理计划，如下所示。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;== Physical Plan ==
*HashAggregate(keys=[], functions=[sum(v#12L)], output=[sum(v)#28L])
+- Exchange SinglePartition
   +- *HashAggregate(keys=[], functions=[partial_sum(v#12L)], output=[sum#30L])
      +- *Project [(3 + value#1L) AS v#12L]
         +- *BroadcastHashJoin [key#0], [key#6], Inner, BuildRight
            :- *Project [key#0, value#1L]
            :  +- *Filter isnotnull(key#0)
            :     +- *FileScan json [key#0,value#1L] Batched: false, Format: JSON, Location: InMemoryFileIndex[file:/Users/bbw/todo/sparkApp/data/kv.json], PartitionFilters: [], PushedFilters: [IsNotNull(key)], ReadSchema: struct&amp;lt;key:string,value:bigint&amp;gt;
            +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]))
               +- *Project [key#6]
                  +- *Filter ((isnotnull(value#7L) &amp;amp;&amp;amp; (value#7L &amp;gt; 90)) &amp;amp;&amp;amp; isnotnull(key#6))
                     +- *FileScan json [key#6,value#7L] Batched: false, Format: JSON, Location: InMemoryFileIndex[file:/Users/bbw/todo/sparkApp/data/kv.json], PartitionFilters: [], PushedFilters: [IsNotNull(value), GreaterThan(value,90), IsNotNull(key)], ReadSchema: struct&amp;lt;key:string,value:bigint&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;可以看出，可执行计划里给了Location，到哪里去读数据。broadcastExchange，怎么分配数据。BroadcastHashJoin，进行什么种类的join等等。&lt;/p&gt;

&lt;p&gt;后面就可以转化为RDD。&lt;/p&gt;

&lt;h3 id=&quot;添加自己的rule&quot;&gt;添加自己的Rule&lt;/h3&gt;

&lt;p&gt;这里有一个查询，如下：&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.sql.functions._&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;tableA&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20000000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;as&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;&apos;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;tableB&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10000000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;as&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;&apos;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;tableA&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tableB&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;groupBy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;物理计划如下，耗时33秒：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;== Physical Plan ==
*HashAggregate(keys=[], functions=[count(1)])
+- Exchange SinglePartition
   +- *HashAggregate(keys=[], functions=[partial_count(1)])
      +- *Project
         +- *SortMergeJoin [id#0L], [id#4L], Inner
            :- *Sort [id#0L ASC NULLS FIRST], false, 0
            :  +- Exchange hashpartitioning(id#0L, 200)
            :     +- *Range (0, 20000000, step=1, splits=Some(1))
            +- *Sort [id#4L ASC NULLS FIRST], false, 0
               +- Exchange hashpartitioning(id#4L, 200)
                  +- *Range (0, 10000000, step=1, splits=Some(1))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;tableA 和tableB 都是一个range，一个是[0,19999999]，另外一个[0,9999999],让两个表求交集。&lt;/p&gt;

&lt;p&gt;其实可以添加优化规则，判断两个range的start 和 end，来求区间的交集。&lt;/p&gt;

&lt;p&gt;因此我们添加了一个Rule，如下。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.SparkConf&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.sql.SparkSession&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.sql.execution.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ProjectExec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RangeExec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SparkPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.sql.Strategy&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.sql.catalyst.expressions.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Alias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;EqualTo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.sql.catalyst.plans.Inner&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.sql.catalyst.plans.logical.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Join&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LogicalPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;IntervalJoin&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Strategy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Serializable&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plan&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;LogicalPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;SparkPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plan&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Join&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;part1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)),&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;Range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;part2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)),&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;Inner&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Some&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;EqualTo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt;
      &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;semanticEquals&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;semanticEquals&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;semanticEquals&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;semanticEquals&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;part&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;part1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;getOrElse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;part2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;getOrElse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RangeExec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Some&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;part&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Nil&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;twoColumns&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ProjectExec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
          &lt;span class=&quot;nc&quot;&gt;Alias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;o1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exprId&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;o1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;exprId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Nil&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;twoColumns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Nil&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;Nil&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Nil&lt;/span&gt;


  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;//添加规则到外部规则列表中， spark is a spark session&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;experimental&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;extraStrategies&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;IntervalJoin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Nil&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;物理计划如下，耗时0.5s:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;== Physical Plan ==
*HashAggregate(keys=[], functions=[count(1)])
+- Exchange SinglePartition
   +- *HashAggregate(keys=[], functions=[partial_count(1)])
      +- *Project
         +- *Project [id#0L AS id#0L]
            +- *Range (0, 10000000, step=1, splits=Some(1))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;参考文献&quot;&gt;参考文献&lt;/h3&gt;

&lt;p&gt;https://databricks.com/session/a-deep-dive-into-spark-sqls-catalyst-optimizer&lt;/p&gt;

&lt;p&gt;https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html&lt;/p&gt;

&lt;p&gt;https://databricks.com/blog/2017/08/31/cost-based-optimizer-in-apache-spark-2-2.html&lt;/p&gt;

</description>
                <link>http://www.turbofei.wang/spark/2018/08/01/spark-sql-catalyst</link>
                <guid>http://www.turbofei.wang/spark/2018/08/01/spark-sql-catalyst</guid>
                <pubDate>2018-08-01T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>Spark Sql Analysis</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#spark-sql概述&quot; id=&quot;markdown-toc-spark-sql概述&quot;&gt;Spark Sql概述##&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#源码跟踪&quot; id=&quot;markdown-toc-源码跟踪&quot;&gt;源码跟踪&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#sql-语句--unresolved-logicalplan&quot; id=&quot;markdown-toc-sql-语句--unresolved-logicalplan&quot;&gt;sql 语句-&amp;gt; Unresolved LogicalPlan###&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#resolved-logicalplan&quot; id=&quot;markdown-toc-resolved-logicalplan&quot;&gt;Resolved LogicalPlan###&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#optimizedlogicalplan&quot; id=&quot;markdown-toc-optimizedlogicalplan&quot;&gt;OptimizedLogicalPlan###&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#physicalplan&quot; id=&quot;markdown-toc-physicalplan&quot;&gt;PhysicalPlan###&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#可执行的物理计划&quot; id=&quot;markdown-toc-可执行的物理计划&quot;&gt;可执行的物理计划###&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#执行&quot; id=&quot;markdown-toc-执行&quot;&gt;执行&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;p&gt;从源码层面解释一个sparkSql语句是如何执行的，从sql到与底层RDD如何对接&lt;/p&gt;

&lt;h2 id=&quot;spark-sql概述&quot;&gt;Spark Sql概述##&lt;/h2&gt;

&lt;p&gt;spark sql是 apache spark的其中一个模块，主要用于进行结构化数据的处理。spark sql的底层执行还是调用rdd，在之前的文章中提过rdd的执行流程，因此本文主要讲解一下从sql到底层rdd的对接。通过观察spark sql 模块的源码，源码分为四个部分，如下图。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/public/img/spark-sql/sql-model.png&quot; title=&quot;sql-model&quot; width=&quot;60%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;在官方github的sql模块readme文件有如下描述。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Catalyst (sql/catalyst) - An implementation-agnostic framework for manipulating trees of relational operators and expressions.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Execution (sql/core) - A query planner / execution engine for translating Catalyst’s logical query plans into Spark RDDs. This component also includes a new public interface, SQLContext, that allows users to execute SQL or LINQ statements against existing RDDs and Parquet files.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Hive Support (sql/hive) - Includes an extension of SQLContext called HiveContext that allows users to write queries using a subset of HiveQL and access data from a Hive Metastore using Hive SerDes. There are also wrappers that allow users to run queries that include Hive UDFs, UDAFs, and UDTFs.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;HiveServer and CLI support (sql/hive-thriftserver) - Includes support for the SQL CLI (bin/spark-sql) and a HiveServer2 (for JDBC/ODBC) compatible server.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;本文主要讲解core和catalyst模块。首先给一个spark sql语句执行流程，来方便对后续内容进行整体把握。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;SQL 语句经过 SqlParser 解析成 Unresolved LogicalPlan;&lt;/li&gt;
  &lt;li&gt;使用 analyzer 结合数据数据字典 (catalog) 进行绑定, 生成 resolved LogicalPlan;&lt;/li&gt;
  &lt;li&gt;使用 optimizer 对 resolved LogicalPlan 进行优化, 生成 optimized LogicalPlan;&lt;/li&gt;
  &lt;li&gt;使用 SparkPlan 将 LogicalPlan 转换成 PhysicalPlan;&lt;/li&gt;
  &lt;li&gt;使用 prepareForExecution() 将 PhysicalPlan 转换成可执行物理计划;&lt;/li&gt;
  &lt;li&gt;使用 execute() 执行可执行物理计划;&lt;/li&gt;
  &lt;li&gt;生成 RDD。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;源码跟踪&quot;&gt;源码跟踪&lt;/h2&gt;

&lt;p&gt;首先是要创建sparkSession然后导入数据，此处不赘述。我们从执行sql语句开始跟踪。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;val teenagersDF = spark.sql(&quot;SELECT SUM(v) FROM (SELECT score.id, 100+80+ score.math_score +score.english_score AS v FROM people JOIN score WHERE  people.id=score.id AND people.age &amp;gt;100) tmp&quot;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;sql-语句--unresolved-logicalplan&quot;&gt;sql 语句-&amp;gt; Unresolved LogicalPlan###&lt;/h3&gt;

&lt;p&gt;此部分主要是对sql语句进行解析。判断一条sql语句是否符合要求，并且进行各部分的划分，比如哪些是操作，哪些是得到的结果等等。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/spark-sql/parser.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这样一句sql 调用，跟进去。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def sql(sqlText: String): DataFrame = {
  Dataset.ofRows(self, sessionState.sqlParser.parsePlan(sqlText))
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;我们可以看到sql语句会返回一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dataFrame&lt;/code&gt;。而在spark中DataFrame的定义就是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Dataset[Row]&lt;/code&gt; .值得一提的是，在spark源码中用到了许多&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lazy&lt;/code&gt;变量，这些变量虽然是声明在类中，但是并不是在创建对象的时候就初始化这些变量，而是在第一次调用是才进行初始化，因此在跟踪源码时一定要注意这些lazy变量的调用，因为很多lazy变量的初始化都涉及到一系列函数的调用。如果不注意，会失去对很多函数的跟踪。具体lazy变量的介绍，&lt;a href=&quot;https://stackoverflow.com/questions/7484928/what-does-a-lazy-val-do&quot;&gt;可以参考&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;lazy val sqlParser: ParserInterface = new SparkSqlParser(conf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;可以看到sqlParser就是一个lazy变量，它会创建一个解析器。上述的sql函数在创建解析器之后调用parsePlan函数，如下。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/** Creates LogicalPlan for a given SQL string. */
override def parsePlan(sqlText: String): LogicalPlan = parse(sqlText) { parser =&amp;gt;
  astBuilder.visitSingleStatement(parser.singleStatement()) match {
    case plan: LogicalPlan =&amp;gt; plan
    case _ =&amp;gt;
      val position = Origin(None, None)
      throw new ParseException(Option(sqlText), &quot;Unsupported SQL statement&quot;, position, position)
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这个函数是使用了Scala柯里化特性。其实是调用的parse函数。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  protected def parse[T](command: String)(toResult: SqlBaseParser =&amp;gt; T): T = {
    logInfo(s&quot;Parsing command: $command&quot;)
    val lexer = new SqlBaseLexer(new ANTLRNoCaseStringStream(command))
    lexer.removeErrorListeners()
    lexer.addErrorListener(ParseErrorListener)
    val tokenStream = new CommonTokenStream(lexer)
    val parser = new SqlBaseParser(tokenStream)
    parser.addParseListener(PostProcessor)
    parser.removeErrorListeners()
    parser.addErrorListener(ParseErrorListener)

    try {
      try {
        // first, try parsing with potentially faster SLL mode
        parser.getInterpreter.setPredictionMode(PredictionMode.SLL)
        toResult(parser)
      }
      catch {
     ...
      }
    }
    catch {
      ...
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;而此处的parse函数是使用的Antlr(一个开源语法分析器)来对sql语句进行解析，lexer是其词法分析器，然后spark使用自身的sqlBaseParser对sql语句进行语法分析，结合parse和parsePlan函数，得到了sql语句的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UnresolvedLogicalPlan&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&quot;resolved-logicalplan&quot;&gt;Resolved LogicalPlan###&lt;/h3&gt;

&lt;p&gt;此部分是对之前得到的逻辑计划进行分析，比如这个字段到底应该是什么类型，等等，不是很熟悉编译。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/spark-sql/analysis.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;进入到Dataset类的ofRows函数。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def ofRows(sparkSession: SparkSession, logicalPlan: LogicalPlan): DataFrame = {
  val qe = sparkSession.sessionState.executePlan(logicalPlan)
  qe.assertAnalyzed()
  new Dataset[Row](sparkSession, qe, RowEncoder(qe.analyzed.schema))
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这个函数很短，跟踪executePlan函数，可以看到它是创建了一个queryExecution对象。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def executePlan(plan: LogicalPlan): QueryExecution = new QueryExecution(sparkSession, plan)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这个对象是很重要的一个对象,涉及到前面的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UnresolvedLogicalPlan&lt;/code&gt;的分析、优化、转物理计划以及ToRDD所有操作。&lt;/p&gt;

&lt;p&gt;ofRows函数第二行是对逻辑计划进行确认分析，里面涉及到分析操作，分析是对之前逻辑计划里面的属性进行分析。分析的源码我就不贴了，分析是使用一套既定的规则，然后进行多次迭代，知道分析结果达到一个固定点或者到达最高迭代次数停止。得到&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;resolvedLogicalPlan&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&quot;optimizedlogicalplan&quot;&gt;OptimizedLogicalPlan###&lt;/h3&gt;

&lt;p&gt;此部分主要是对逻辑计划进行优化， 例如谓词下推等等。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/spark-sql/optimizer.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;然后第三行，就是生成一个Dataset[Row]，前面提到过，其实这就是dataFrame。&lt;/p&gt;

&lt;p&gt;跟踪进入Dataset的this函数。里面有一个变量会在创建对象时执行&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@transient private[sql] val logicalPlan: LogicalPlan = {
  def hasSideEffects(plan: LogicalPlan): Boolean = plan match {
    case _: Command |
         _: InsertIntoTable =&amp;gt; true
    case _ =&amp;gt; false
  }

  queryExecution.analyzed match {
    // For various commands (like DDL) and queries with side effects, we force query execution
    // to happen right away to let these side effects take place eagerly.
    case p if hasSideEffects(p) =&amp;gt;
      LogicalRDD(queryExecution.analyzed.output, queryExecution.toRdd)(sparkSession)
    case Union(children) if children.forall(hasSideEffects) =&amp;gt;
      LogicalRDD(queryExecution.analyzed.output, queryExecution.toRdd)(sparkSession)
    case _ =&amp;gt;
      queryExecution.analyzed
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;看到里面有一行调用了LogicalRDD函数，第一个参数是输出位置，第一个参数，queryExecution.toRdd. 一系列的lazy变量。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;lazy val toRdd: RDD[InternalRow] = executedPlan.execute()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;lazy val executedPlan: SparkPlan = prepareForExecution(sparkPlan)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;lazy val sparkPlan: SparkPlan = {
  SparkSession.setActiveSession(sparkSession)
  // TODO: We use next(), i.e. take the first plan returned by the planner, here for now,
  //       but we will implement to choose the best plan.
  planner.plan(ReturnAnswer(optimizedPlan)).next()
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;lazy val optimizedPlan: LogicalPlan = sparkSession.sessionState.optimizer.execute(withCachedData)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里调用了一些列，调用到optimizedPlan，其实也是进行规则优化，基于一系列规则，到不动点或者最大迭代次数退出优化。这就得到了&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;optimizedLogicalPlan&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&quot;physicalplan&quot;&gt;PhysicalPlan###&lt;/h3&gt;

&lt;p&gt;回到前面的sparkPlan懒变量，最后一句，planner.plan对之前的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;optimizedLogicalPlan&lt;/code&gt;进行转化生成phsicalPlan。此处的next是操作是获得返回的physicalPlan迭代器中的第一个physicalPlan。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;lazy val sparkPlan: SparkPlan = {
  SparkSession.setActiveSession(sparkSession)
  // TODO: We use next(), i.e. take the first plan returned by the planner, here for now,
  //       but we will implement to choose the best plan.
  planner.plan(ReturnAnswer(optimizedPlan)).next()
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里的planner为SparkPlanner，类中有一系列的策略，还可以从外部加策略。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def strategies: Seq[Strategy] =
    extraStrategies ++ (
    FileSourceStrategy ::
    DataSourceStrategy ::
    DDLStrategy ::
    SpecialLimits ::
    Aggregation ::
    JoinSelection ::
    InMemoryScans ::
    BasicOperators :: Nil)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;然后进行转化的函数如下。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def plan(plan: LogicalPlan): Iterator[PhysicalPlan] = {
  // Obviously a lot to do here still...

  // Collect physical plan candidates.
  val candidates = strategies.iterator.flatMap(_(plan))

  // The candidates may contain placeholders marked as [[planLater]],
  // so try to replace them by their child plans.
  val plans = candidates.flatMap { candidate =&amp;gt;
    val placeholders = collectPlaceholders(candidate)

    if (placeholders.isEmpty) {
      // Take the candidate as is because it does not contain placeholders.
      Iterator(candidate)
    } else {
      // Plan the logical plan marked as [[planLater]] and replace the placeholders.
      placeholders.iterator.foldLeft(Iterator(candidate)) {
        case (candidatesWithPlaceholders, (placeholder, logicalPlan)) =&amp;gt;
          // Plan the logical plan for the placeholder.
          val childPlans = this.plan(logicalPlan)

          candidatesWithPlaceholders.flatMap { candidateWithPlaceholders =&amp;gt;
            childPlans.map { childPlan =&amp;gt;
              // Replace the placeholder by the child plan
              candidateWithPlaceholders.transformUp {
                case p if p == placeholder =&amp;gt; childPlan
              }
            }
          }
      }
    }
  }

  val pruned = prunePlans(plans)
  assert(pruned.hasNext, s&quot;No plan for $plan&quot;)
  pruned
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;没看明白，知识欠缺。大概就是得到一系列physicalPlan，然后进行剪枝，筛除掉性能不好的，这就得到了&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;physicalPlan&lt;/code&gt;迭代器，然后通过前面说的next函数，得到迭代器头部的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;physicalPlan&lt;/code&gt;，应该是最好的那个。&lt;/p&gt;

&lt;h3 id=&quot;可执行的物理计划&quot;&gt;可执行的物理计划###&lt;/h3&gt;

&lt;p&gt;在得到物理计划sparkPlan之后会执行下面的函数，prepareForExecution(sparkPlan)，得到可执行的物理计划。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;lazy val executedPlan: SparkPlan = prepareForExecution(sparkPlan)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * Prepares a planned [[SparkPlan]] for execution by inserting shuffle operations and internal
 * row format conversions as needed.
 */
protected def prepareForExecution(plan: SparkPlan): SparkPlan = {
  preparations.foldLeft(plan) { case (sp, rule) =&amp;gt; rule.apply(sp) }
}

/** A sequence of rules that will be applied in order to the physical plan before execution. */
protected def preparations: Seq[Rule[SparkPlan]] = Seq(
  python.ExtractPythonUDFs,
  PlanSubqueries(sparkSession),
  EnsureRequirements(sparkSession.sessionState.conf),
  CollapseCodegenStages(sparkSession.sessionState.conf),
  ReuseExchange(sparkSession.sessionState.conf),
  ReuseSubquery(sparkSession.sessionState.conf))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;看注释以及源码，理解，就是又是一些规则，然后对逻辑计划不断使用这些规则进行完善，就是把规则按顺序运用一遍，&lt;a href=&quot;https://blog.csdn.net/oopsoom/article/details/23447317&quot;&gt;scala的 foldleft用法参考这里&lt;/a&gt;,不得不说scala语法真多。&lt;/p&gt;

&lt;h3 id=&quot;执行&quot;&gt;执行&lt;/h3&gt;

&lt;p&gt;可以看到在获得获得可执行计划之后就是执行，&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;lazy val toRdd: RDD[InternalRow] = executedPlan.execute()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;final def execute(): RDD[InternalRow] = executeQuery {
  doExecute()
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;//class sparkPlan
protected def doExecute(): RDD[InternalRow]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这个函数对应很多子类，每个子类的第一句基本都是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;child.execute()&lt;/code&gt;,可见这是在构建lineage。也就是一条链，把所有可执行计划串联起来。&lt;/p&gt;

&lt;p&gt;这里的doExecute返回的是一个中间类型的RDD。&lt;/p&gt;

</description>
                <link>http://www.turbofei.wang/spark/2018/07/27/Spark-Sql-Analysis</link>
                <guid>http://www.turbofei.wang/spark/2018/07/27/Spark-Sql-Analysis</guid>
                <pubDate>2018-07-27T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>Rdd Basics</title>
                <description>
&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;从RDD入手, 对Spark进行深入理解&lt;/p&gt;

&lt;h3 id=&quot;正文&quot;&gt;正文&lt;/h3&gt;
&lt;p&gt;是之前做的html格式的PPT，&lt;a href=&quot;https://netease-bigdata.github.io/ne-spark-courseware/slides/spark_core/rdd_basics.html#1&quot;&gt;链接&lt;/a&gt;&lt;/p&gt;
</description>
                <link>http://www.turbofei.wang/spark/2018/07/12/rdd-basics</link>
                <guid>http://www.turbofei.wang/spark/2018/07/12/rdd-basics</guid>
                <pubDate>2018-07-12T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>[转载]Spark Security面面观</title>
                <description>&lt;h3 id=&quot;背景&quot;&gt;背景&lt;/h3&gt;

&lt;p&gt;作为一款成熟的商业软件，安全往往鲜少被提及但又不可忽略，大数据软件也是如此。在生产环境中，对于一款成熟的大数据软件的考量，不仅需要考虑其功能完备性和性能，同时安全也是不可缺少的一环。为什么安全如此重要呢？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;首先，商业环境通常是多租户环境，不同的用户/组对于不同的数据/应用有不同的安全考量。我们需要保证相应的用户不能做出超越权限的操作。&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;同时，分布式架构会将端口、数据暴露出去，如果没有相应的认证、加密措施，这会大大增加了匿名攻击的概率。&lt;/p&gt;

    &lt;p&gt;举个简单的例子，Spark通过RPC通信协调&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;driver&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;executor&lt;/code&gt;之间的任务分发，如果一个匿名用户通过伪造协议与&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;executor&lt;/code&gt;进行通信，会产生什么后果呢？&lt;/p&gt;

    &lt;p&gt;在一个可控的环境下（比如防火墙物理隔离）这样的风险相对可控。但是随着越来越多的云计算厂商提供EMR类似产品，这样的风险不可谓不存在。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;再者，对于一个完整的大数据生态系统，安全往往是相互衔接的。如果中间有一款软件没有相应的支持，那么它就会成为整体的薄弱点，或者说会造成整体完备性的缺失。&lt;/p&gt;

    &lt;p&gt;比方说，Hadoop系统的认证体系是建立在Kerberos基础上的，一款软件要融入Hadoop生态系统，它必定也要支持Kerberos认证，不然它是无法与其他系统进行交互的。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;当然还有很多其他的原因，在这就不一一赘述了。&lt;/p&gt;

&lt;p&gt;回到我们今天的话题上来，Spark作为大数据生态圈中的重要一环，许多厂商已经在其生产环境中大量部署了Spark集群，Spark本身在安全上面有哪些点值得我们关注呢？&lt;/p&gt;

&lt;h2 id=&quot;spark-security&quot;&gt;Spark Security&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://spark.apache.org/docs/latest/security.html&quot;&gt;Apache Spark&lt;/a&gt;在其演化过程中，安全的支持也是逐渐添加和完善的。在Spark开发的早期，是没有任何安全上面的考量的，随着各大厂商在生产环境中的部署，对于安全的支持也是在逐步的完善。&lt;/p&gt;

&lt;p&gt;总结前面提到的三个方面，对于Spark本身，我们需要考虑的三个方面是：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;权限管理&lt;/li&gt;
  &lt;li&gt;数据/链路加密&lt;/li&gt;
  &lt;li&gt;与其他安全系统交互&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;下文会就以上3点进行讨论，来看看在Spark中安全是如何实现的。&lt;/p&gt;

&lt;h3 id=&quot;权限管理&quot;&gt;权限管理&lt;/h3&gt;

&lt;p&gt;上文所提到的第一个问题是&lt;strong&gt;保证相应的用户不能做出超越权限的操作&lt;/strong&gt;，那么在Spark中如何做到这一点呢？&lt;/p&gt;

&lt;h4 id=&quot;acl&quot;&gt;ACL&lt;/h4&gt;

&lt;p&gt;Spark支持基本的ACL(Access Control List)，通过配置不同用户的角色，能为不同的用户赋予不同的权限范围。&lt;/p&gt;

&lt;p&gt;为了启动ACL机制，用户需要配置&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.acls.enable&lt;/code&gt;为&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;true&lt;/code&gt;。然后将不同的用户名置于不同的配置中：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.ui.view.acls&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.modify.acls&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.admin.acls&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这3个配置分别对应了可读、可改、和可管理三种不同的权限。集群管理者可将用户名置于相应的列表以赋予不同的权限。&lt;/p&gt;

&lt;p&gt;对于大型集群来说，按用户来配置过于繁琐，Spark也可以支持按组进行配置，如：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.ui.view.acls.groups&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.modify.acls.groups&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.admin.acls.groups&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;那么进行了上述这些配置以后会带来什么变化呢？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;首先，只有具有相应权限的用户才能在UI上浏览每个Spark应用的具体内容，包括配置、作业、任务等等。&lt;/li&gt;
  &lt;li&gt;其次，只要具有可改权限的用户才能在UI上停止作业。&lt;/li&gt;
  &lt;li&gt;最后，默认当前spark应用启动用户具有可读和可改的权限。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;当前Spark的ACL主要用于UI权限的管理，以保证用户只能浏览相应权限的内容。对于HistoryServer，则有另一套类似的配置，如&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.history.ui.acls.enable&lt;/code&gt;，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.history.ui.admin.acls&lt;/code&gt;，在这就不具体展开了。&lt;/p&gt;

&lt;h4 id=&quot;spnego-authentication&quot;&gt;Spnego Authentication&lt;/h4&gt;

&lt;p&gt;开启了ACL就能对UI进行权限隔离了吗？其实我们还只走了一半路。为了使web server（Spark内嵌Jetty）能够对用户进行隔离，首先Jetty需要知道是谁发起了HTTP请求，换句话说，只有用户的HTTP请求中包含了用户信息，UI和ACL才能根据用户信息进行正确的隔离。但是不幸的是，普通的HTTP请求是不包含用户信息。&lt;/p&gt;

&lt;p&gt;为此需要为Jetty servlet加入authentication filter以获取认证用户的信息。在这之中，最常用的就是&lt;a href=&quot;https://en.wikipedia.org/wiki/SPNEGO&quot;&gt;Spnego authentication&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Spnego是一套以Kerberos为基础的HTTP认证机制，只有经过Kerberos授权的HTTP请求才能被web server所接受。Hadoop生态系统下的各个组件的UI大都采用Spnego作为认证机制，如HDFS，YARN等。&lt;/p&gt;

&lt;p&gt;为了使Spark UI能够使用Spnego认证，用户需要实现相应的authentication filter并将其添加到Jetty中。幸运的是Hadoop已经帮我们实现了相应的filter，只需将其配置就可使用。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spark.ui.filters=org.apache.hadoop.security.authentication.server.AuthenticationFilter

spark.org.apache.hadoop.security.authentication.server.AuthenticationFilter.params=type=kerberos,kerberos.pricipal=&amp;lt;kerberos-principal&amp;gt;,kerberos.keytab=&amp;lt;kerberos-keytab&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在这里，需要为Spark UI创建Kerberos principal和keytab。这样Spark UI就有了Spnego authentication的能力了，任何用户在发起HTTP请求之前必须先获得Kerberos tgt。使用curl的话，如：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kinit
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;curl &lt;span class=&quot;nt&quot;&gt;--negotiate&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-u&lt;/span&gt; : &amp;lt;host&amp;gt;:&amp;lt;port&amp;gt;/&amp;lt;xxx&amp;gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;经过Spnego认证的HTTP请求在其HTTP头部包含用户信息，Spark UI和ACL机制会从其中获取用户名并在相应的权限列表中进行比对。&lt;/p&gt;

&lt;h4 id=&quot;ldap-and-others&quot;&gt;LDAP and Others&lt;/h4&gt;

&lt;p&gt;当然，Spengo认证只是众多authentication中的一种，其他还有如&lt;a href=&quot;https://www.ldap.com/getting-started-with-ldap&quot;&gt;LDAP&lt;/a&gt;或是basic authentication等等。其中LDAP已经在&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-12082&quot;&gt;Hadoop 2.8&lt;/a&gt;中实现了，用户可以采用以上类似的配置实现LDAP认证。&lt;/p&gt;

&lt;p&gt;同样，用户可以是实现并配置自己的authentication filter，只要依照servlet和Jetty的规范即可。&lt;/p&gt;

&lt;h3 id=&quot;数据链路加密&quot;&gt;数据/链路加密&lt;/h3&gt;

&lt;p&gt;数据/链路加密是Spark安全中最为重要的一块，它主要是为了防止匿名用户通过端口获取报文，发送malicious数据，同时也需要防止用户伪造spilled数据（如shuffle数据）以破坏运行作业。下文就将数据和链路加密分别进行介绍。&lt;/p&gt;

&lt;h4 id=&quot;数据加密&quot;&gt;数据加密&lt;/h4&gt;

&lt;p&gt;在Spark中，往local disk上写的数据主要包含：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Shuffle数据，包括shuffle data和shuffle index file。&lt;/li&gt;
  &lt;li&gt;Shuffle spill数据，当内存无法容纳时向disk spill的数据。&lt;/li&gt;
  &lt;li&gt;BlockManager存储在disk的block数据。&lt;/li&gt;
  &lt;li&gt;等等。。。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;所有这些数据都是以二进制的方式将序列化（压缩后）的数据写入到local文件系统中。举例来说，比如匿名用户知道了Spark中shuffle数据的命名方式和映射规律，那么他就能伪造一份新的shuffle数据。为了防止此种情况的发生，我们需要对写到disk上的数据进行加密。&lt;/p&gt;

&lt;p&gt;为此我们需要配置如下：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Property&lt;/th&gt;
      &lt;th&gt;Default&lt;/th&gt;
      &lt;th&gt;Meaning&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.io.encryption.enabled&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;Enable IO encryption. Currently supported by all modes except Mesos. It’s recommended that RPC encryption be enabled when using this feature.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.io.encryption.keySizeBits&lt;/td&gt;
      &lt;td&gt;128&lt;/td&gt;
      &lt;td&gt;IO encryption key size in bits. Supported values are 128, 192 and 256.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.io.encryption.keygen.algorithm&lt;/td&gt;
      &lt;td&gt;HmacSHA1&lt;/td&gt;
      &lt;td&gt;The algorithm to use when generating the IO encryption key. The supported algorithms are described in the KeyGenerator section of the Java Cryptography Architecture Standard Algorithm Name Documentation.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;当配置了这些选项以后，所有写入local disk的数据都会以加密方式写入。&lt;/p&gt;

&lt;h4 id=&quot;链路加密&quot;&gt;链路加密&lt;/h4&gt;

&lt;p&gt;链路加密，就是所谓的wire encryption，在Spark中主要包含两种类型的链路：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;HTTP连接。Spark的live UI和History UI提供了WEB UI供用户浏览应用的具体细节。我们希望HTTP链路能够加密以防止匿名用户的劫持。&lt;/li&gt;
  &lt;li&gt;Binary连接。主要包含RPC链路、Shuffle链路和Block传输。在Spark中这一部分是由Netty实现的。我们希望所有的端到端的传输都是可信赖的，一个不被信赖的链接是无法发送数据的。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;根据上面两种类型的链路，我们来看看应该如何配置Spark使链路能得到加密。&lt;/p&gt;

&lt;h5 id=&quot;httpsssl&quot;&gt;HTTPS/SSL&lt;/h5&gt;

&lt;p&gt;在Spark中，包含HTTP的链路分别有：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Live UI，Spark应用的WEB UI。&lt;/li&gt;
  &lt;li&gt;History UI，Spark history Server的WEB UI。&lt;/li&gt;
  &lt;li&gt;Standalone UI，Spark Standalone cluster manager中master和worker node的WEB UI&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;为此Spark可以以统一的SSL配置来配置所有的HTTPS endpoint，也可以对每一个组件分别进行配置.&lt;/p&gt;

&lt;p&gt;当用户配置了&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.ssl.enabled&lt;/code&gt;，这表示所有HTTPS endpoint都启动了SSL并使用相同的配置。用户也可以通过配置&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.ssl.ui.xxxx&lt;/code&gt;只启动和配置Live UI的SSL。当前支持的component包括&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ui&lt;/code&gt;，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;standalone&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;historyServer&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;在配置之前，用户需要生成相应的keystore和truststore，可以通过使用Java keytool工具来生成相应的keystore和truststore，具体可以参考Oracle的&lt;a href=&quot;https://docs.oracle.com/javase/8/docs/technotes/tools/unix/keytool.html&quot;&gt;官方文档&lt;/a&gt;。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Property Name&lt;/th&gt;
      &lt;th&gt;Default&lt;/th&gt;
      &lt;th&gt;Meaning&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.ssl.enabled&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;Whether to enable SSL connections on all supported protocols. When spark.ssl.enabled is configured, spark.ssl.protocol is required. All the SSL settings like spark.ssl.xxx where xxx is a particular configuration property, denote the global configuration for all the supported protocols. In order to override the global configuration for the particular protocol, the properties must be overwritten in the protocol-specific namespace. Use spark.ssl.YYY.XXX settings to overwrite the global configuration for particular protocol denoted by YYY. Example values for YYY include fs, ui, standalone, and historyServer. See SSL Configuration for details on hierarchical SSL configuration for services.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.ssl.[namespace].port&lt;/td&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;The port where the SSL service will listen on. The port must be defined within a namespace configuration; see SSL Configuration for the available namespaces. When not set, the SSL port will be derived from the non-SSL port for the same service. A value of “0” will make the service bind to an ephemeral port.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.ssl.enabledAlgorithms&lt;/td&gt;
      &lt;td&gt;Empty&lt;/td&gt;
      &lt;td&gt;A comma separated list of ciphers. The specified ciphers must be supported by JVM. The reference list of protocols one can find on this page. Note: If not set, it will use the default cipher suites of JVM.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.ssl.keyPassword&lt;/td&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;A password to the private key in key-store.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.ssl.keyStore&lt;/td&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;A path to a key-store file. The path can be absolute or relative to the directory where the component is started in.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.ssl.keyStorePassword&lt;/td&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;A password to the key-store.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.ssl.keyStoreType&lt;/td&gt;
      &lt;td&gt;JKS&lt;/td&gt;
      &lt;td&gt;The type of the key-store.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.ssl.protocol&lt;/td&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;A protocol name. The protocol must be supported by JVM. The reference list of protocols one can find on this page.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.ssl.needClientAuth&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;Set true if SSL needs client authentication.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.ssl.trustStore&lt;/td&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;A path to a trust-store file. The path can be absolute or relative to the directory where the component is started in.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.ssl.trustStorePassword&lt;/td&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;A password to the trust-store.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.ssl.trustStoreType&lt;/td&gt;
      &lt;td&gt;JKS&lt;/td&gt;
      &lt;td&gt;The type of the trust-store.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;需要注意的是：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;keystore和truststore是保存在本地文件系统中的，这意味着当你需要为standalone cluster manager启动SSL时，需要在所有的节点上生成和保存相应的keystore，truststore。&lt;/li&gt;
  &lt;li&gt;当前YARN并不支持proxy HTTPS request，所以在使用YARN的时候enable SSL会带来一定的问题。&lt;/li&gt;
  &lt;li&gt;当你在需要mutual authentication的时候才需要enable &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.ssl.needClientAuth&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;sasl&quot;&gt;SASL&lt;/h5&gt;

&lt;p&gt;说完了HTTPS/SSL之后，让我们来看看另一种类型的链路，Netty连接。在Spark中Netty连接也可以进行&lt;a href=&quot;https://en.wikipedia.org/wiki/Simple_Authentication_and_Security_Layer&quot;&gt;SASL认证&lt;/a&gt;。用户只需要进行如下的配置，所有的Netty链路，包括RPC和Block transfer，都会进行认证。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Property Name&lt;/th&gt;
      &lt;th&gt;Default&lt;/th&gt;
      &lt;th&gt;Meaning&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.authenticate&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;Whether Spark authenticates its internal connections. See spark.authenticate.secret if not running on YARN.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.authenticate.secret&lt;/td&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;Set the secret key used for Spark to authenticate between components. This needs to be set if not running on YARN and authentication is enabled.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.authenticate.enableSaslEncryption&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;Enable encrypted communication when authentication is enabled. This is supported by the block transfer service and the RPC endpoints.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.network.sasl.serverAlwaysEncrypt&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;Disable unencrypted connections for services that support SASL authentication.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;需要注意的是，当用户使用的不是YARN cluster manager运行Spark应用，用户需要配置&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.authenticate.secret&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;另外，当前Spark SASL所使用的认证方式是&lt;a href=&quot;https://en.wikipedia.org/wiki/Digest_access_authentication&quot;&gt;DIGEST-MD5&lt;/a&gt;，它是一种比较弱的认证方式，容易被暴力破解，因此现在并不推荐使用（&lt;a href=&quot;https://tools.ietf.org/html/rfc6331&quot;&gt;Moving DIGEST-MD5 to Historic&lt;/a&gt;）。在Spark中提供了另一种较强的认证方式，可以通过配置开启：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Property Name&lt;/th&gt;
      &lt;th&gt;Default&lt;/th&gt;
      &lt;th&gt;Meaning&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.network.crypto.enabled&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;Enable encryption using the commons-crypto library for RPC and block transfer service. Requires spark.authenticate to be enabled.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.network.crypto.keyLength&lt;/td&gt;
      &lt;td&gt;128&lt;/td&gt;
      &lt;td&gt;The length in bits of the encryption key to generate. Valid values are 128, 192 and 256.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.network.crypto.keyFactoryAlgorithm&lt;/td&gt;
      &lt;td&gt;PBKDF2WithHmacSHA1&lt;/td&gt;
      &lt;td&gt;The key factory algorithm to use when generating encryption keys. Should be one of the algorithms supported by the javax.crypto.SecretKeyFactory class in the JRE being used.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.network.crypto.saslFallback&lt;/td&gt;
      &lt;td&gt;true&lt;/td&gt;
      &lt;td&gt;Whether to fall back to SASL authentication if authentication fails using Spark’s internal mechanism. This is useful when the application is connecting to old shuffle services that do not support the internal Spark authentication protocol. On the server side, this can be used to block older clients from authenticating against a new shuffle service.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;与其他安全系统交互&quot;&gt;与其他安全系统交互&lt;/h3&gt;

&lt;p&gt;在一个完整的生产环境集群中，Spark并不是唯一的系统，通常还需要与其他的调度、存储系统进行交互，如HDFS，YARN等。如果其他的系统都是需要安全认证的，Spark作为其他系统的使用方，如何进行交互呢？&lt;/p&gt;

&lt;p&gt;每种系统的认证方式各不相同，没有一个普适的框架能够满足所有的认证方式，在这就以最常见的认证方式Kerberos来解释Spark是如何与其他Kerberized系统机型交互的。&lt;/p&gt;

&lt;p&gt;首先每个Spark应用的提交者都需要通过Kerberos的认证，获取Kerberos的TGT。以HDFS为例，当Spark应用拿到TGT后就可以与HDFS进行交互，HDFS在通过验证后会给予Spark应用一个有效的Delegation Token来代表此用户，后续的交互都是采用Delegation Token验证的方式，而无需在进行Kerberos认证。&lt;/p&gt;

&lt;p&gt;但是Delegation Token会过期，当它过期后就不再能够使用，为此Spark应用需要重新获得新的Delegation Token，获取的方式与上面介绍的一样（首先获得Kerberos TGT，通过Kerberos TGT获得Delegation Token）。当然TGT也会过期，过期后需要用户重新kinit，或是使用keytab和principal的方式让应用自己去更新TGT。&lt;/p&gt;

&lt;p&gt;对于Kerberos和Delegation Token，在这就不做过多的介绍。关于Hadoop Security的设计，有一个非常好的&lt;a href=&quot;http://www.carfield.com.hk/document/distributed/hadoop-security-design.pdf?&quot;&gt;设计文档&lt;/a&gt;，对于分布式系统安全设计有非常大的指导意义。&lt;/p&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;

&lt;p&gt;本文从总体上介绍了Spark中关于安全的各个方面，以及如何开启和配置这些安全机制。本文并未从原理和代码上阐述所有这些安全机制背后的原理以及实现，因为对于每一种安全机制都可以长篇大论赘述其由来。相反的是，相比于原理，怎么去使用它更为重要，毕竟绝大多数的用户/开发者不会涉及到里面真正的细节。&lt;/p&gt;
</description>
                <link>http://www.turbofei.wang/jerryshao/2018/01/15/spark-security-overview</link>
                <guid>http://www.turbofei.wang/jerryshao/2018/01/15/spark-security-overview</guid>
                <pubDate>2018-01-15T00:00:00-08:00</pubDate>
        </item>

        <item>
                <title>Deca项目总结</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;Deca项目是研究生期间参加的重要科研项目，项目主要是采用去对象化的思想，减少大数据平台在运行过程中，数据的占有空间与对象的数量，从而减小内存的压力，也减小GC的压力。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;实现的功能&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;deca主要实现的功能就是减小了大数据平台在运行任务过程中的数据在内存中的占用量以及在运行过程中对象的数量。&lt;/p&gt;

&lt;p&gt;当前的主流分布式内存计算系统均采用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;高级托管语言&lt;/code&gt;开发，这样开发进度快，方便部署和维护。&lt;/p&gt;

&lt;p&gt;GC是托管语言（JAVA,SCALA等）的运行时系统自主管理对象的基础，GC操作会检索当前堆中存活的对象，并释放已经死亡对象的空间。&lt;/p&gt;

&lt;p&gt;大量数据均以对象形式存放在内存中，这对导致两个问题&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;内存膨胀问题&lt;/p&gt;

    &lt;p&gt;对象形式的内存布局会存储大量引用结构和元数据（对象头），而不是直接存储数据，空间利用率较低。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Full GC 问题&lt;/p&gt;

    &lt;p&gt;内存膨胀会导致JVM更加频繁的触发full gc（检索整个JVM堆内存），而GC开销与&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;存活对象数量&lt;/code&gt;成正比，导致GC时间过长。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这里引申一下gc的分类，gc分为minor gc, major gc 和 full gc。其中minor是清理年轻代，major是清理老年代，而full是清理整个堆空间。&lt;/p&gt;

&lt;p&gt;因此在面临使用内存空间有限的情况下，必须在软件层面对内存管理进行优化。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;技术和架构&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;问题分析&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;spark是开源系统中主导的数据并行计算框架，提供函数式编程模型RDD，并增加了基于shuffle的GroupBy系列运算符扩展，支持中间数据的内存缓存和基于哈希的shuffle聚合操作。&lt;/p&gt;

&lt;p&gt;spark将数据封装在RDD中，然后通过action划分job，再通过shuffle操作划分stage，然后在jvm中运行数据。&lt;/p&gt;

&lt;p&gt;因此spark中的内存主要分为三部分。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Cache RDD到内存&lt;/p&gt;

    &lt;p&gt;这部分内存需要一直维护，只要用户进行unpersist操作，所以这部分内存生命周期较长。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;shuffle操作(生命周期是一个stage)&lt;/p&gt;

    &lt;p&gt;shuffle操作需要落磁盘，进行磁盘I/O,因此需要维护所有磁盘I/O的数据，生命周期也长。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;stage内部的操作&lt;/p&gt;

    &lt;p&gt;产生大量的临时对象，属于内存中的临时对象，很快会被gc回收。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;长时间存活对象&lt;/code&gt;会一直活在内存中，每次Full GC 要扫描的对象数量很多，计算开销很大。而且对象一直存活，会大量占用内存，频繁导致full gc。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;方法设计&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;核心思想是减少数据&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;对象的数量&lt;/code&gt;，而非数据的大小。&lt;/p&gt;

&lt;p&gt;使用对象拆解，暴露出数据对象中的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;裸数据&lt;/code&gt;：原生字段类型；去除对象头和引用结构。&lt;/p&gt;

&lt;p&gt;基于生命周期的内存管理：将相同/相近生命周期的一组数据对象中的裸数据存放在连续的内存块（数组）中。&lt;/p&gt;

&lt;p&gt;数据无需访问时即可一次回收整个内存块空间。&lt;/p&gt;

&lt;p&gt;这样GC的索引由大量的对象变为少量的容器，gc开销大大减小。&lt;/p&gt;

&lt;p&gt;将UDT(用户定义类型）分为三类：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;静态定长：原生类型及其组合，如int, long, (int, long)&lt;/li&gt;
  &lt;li&gt;动态定长：原生类型的数组及组合，如int[], (int[], long)&lt;/li&gt;
  &lt;li&gt;变长对象和递归类型对象：实例化对象长度不确定，如TreeNode（TreeNode里面有一个TreeNode引用的left,right)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;前两种可以安全拆解，第三种不行。&lt;/p&gt;

&lt;p&gt;针对以上的三种内存，其中cache RDD，当cache的数据对象可以拆解时候，可以拆解为Bytes数组依次存放在page中，同时根据page对象中对象offset可以获得对象成员变量。&lt;/p&gt;

&lt;p&gt;而针对shuffle内存，也是放在page里面，针对shuffle阶段的排序，使用指针，避免大量数据的移动。&lt;/p&gt;

&lt;p&gt;在shuffle 阶段存在很多变长的成员，在shuffle阶段，reduceByKey尚能拆解，因为reduce之后的value依然是定长的。但是针对groupByKey这个算子，他的操作对象是（K,combinerBuffer)，combiner是变长的，group之后也是变长，是不确定的。&lt;/p&gt;

&lt;p&gt;Spark-1.4里groupByKey在shuffle write端可以利用到堆外的内存，也就是tungsten-sort，所有的数据都会写在堆外并在堆外排序，但是shuffle-read端Spark默认还是用的HashShuffleReader,所有的聚合操作都在堆内完成，这个我们已经实现了read端的堆外版本，聚合操作运行在堆外。大致介绍下原理，这里就用到了VST拆解的原理，我们知道shuffle read端读出来的(K,C)对的基本类型，于是先实现了一个简易的map(UnsafeUnfixedWidthAggregationFlintMap),嗯名字略长。。这是一个针对系统的定制的map，也是用到了Hash原理，不过所有操作都是在堆外进行。这个map用于存储key和&lt;strong&gt;valueAddress&lt;/strong&gt;，这个&lt;strong&gt;valueAddress&lt;/strong&gt;是一个long型值，我们会将K对应的一组Value在堆外开辟一片疆土用于存储他们，当然每次新来value时我们会检查是否扩容，若扩容会改变这块疆土(堆外空间)的起始地址，因为涉及到内存的拷贝，所以map中的&lt;strong&gt;valueAddress&lt;/strong&gt;就是这块存储区域的初始偏移地址。&lt;strong&gt;valueAddress&lt;/strong&gt;指向的存储区域结构为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://kzx1025.github.io/img/map.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如果每个partition相同的key不多，而且每个key存在大量value时，采用mapsideCombine的groupBykey是一个不错的选择。如果不存在hot key，那收益就很小。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;担当的责任&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;主要是担任shuffle groupByKey read 阶段的内存优化，我实现了read端的堆外版本，聚合操作运行在堆外。大致介绍下原理，这里就用到了VST拆解的原理，我们知道shuffle read端读出来的(K,C)对的基本类型，于是先实现了一个简易的map(UnsafeUnfixedWidthAggregationFlintMap),嗯名字略长。。这是一个针对系统的定制的map，也是用到了Hash原理，不过所有操作都是在堆外进行。这个map用于存储key和&lt;strong&gt;valueAddress&lt;/strong&gt;，这个&lt;strong&gt;valueAddress&lt;/strong&gt;是一个long型值，我们会将K对应的一组Value在堆外开辟一片疆土用于存储他们，当然每次新来value时我们会检查是否扩容，若扩容会改变这块疆土(堆外空间)的起始地址，因为涉及到内存的拷贝，所以map中的&lt;strong&gt;valueAddress&lt;/strong&gt;就是这块存储区域的初始偏移地址。&lt;/p&gt;

&lt;p&gt;这样就处理了变长类型的处理，之前是只实现了reduceBykey的。&lt;/p&gt;

&lt;p&gt;后面我们也尝试了&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;列式存储&lt;/code&gt;，把之前page中的数组形式，转换为列式存储。&lt;/p&gt;

&lt;p&gt;同时负责实验的设计，实验过程中遇到bug的解决以及gc统计分析的工作。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;难点&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;spark是惰性执行，代码中充满着各种各样的迭代器，追踪代码时都不知道哪个迭代器被调用了。修改代码需要连环的修改多个文件。&lt;/p&gt;

&lt;p&gt;然后就是有时候单机测试可以通过，但是分布式时候就。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;收获&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mark&lt;/code&gt;&lt;/p&gt;
</description>
                <link>http://www.turbofei.wang/essay/2017/07/01/deca%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93</link>
                <guid>http://www.turbofei.wang/essay/2017/07/01/deca项目总结</guid>
                <pubDate>2017-07-01T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>Spark源码分析shuffle实现</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#shuffle&quot; id=&quot;markdown-toc-shuffle&quot;&gt;Shuffle##&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#bypassmergesortshufflewriter&quot; id=&quot;markdown-toc-bypassmergesortshufflewriter&quot;&gt;BypassMergeSortShuffleWriter###&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#sortshufflewriter&quot; id=&quot;markdown-toc-sortshufflewriter&quot;&gt;SortShuffleWriter&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#unsafeshufflewriter&quot; id=&quot;markdown-toc-unsafeshufflewriter&quot;&gt;unsafeShuffleWriter&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#blockstoreshufflereader&quot; id=&quot;markdown-toc-blockstoreshufflereader&quot;&gt;BlockStoreShuffleReader###&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#总结&quot; id=&quot;markdown-toc-总结&quot;&gt;总结##&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;spark shuff部分是spark源码的重要组成部分，shuffle发生在stage的交界处，对于spark的性能有重要影响，源码更新后，spark的shuffle机制也不一样，本文分析spark2.0的shuffle实现。&lt;/p&gt;

&lt;p&gt;本文基于spark2.0。&lt;/p&gt;

&lt;h2 id=&quot;shuffle&quot;&gt;Shuffle##&lt;/h2&gt;

&lt;p&gt;shuffle是Mapreduce框架中一个特定的phase，介于Map和Reduce之间。shuffle的英文意思是混洗，包含两个部分，shuffle write 和shuffle read。这里有一篇文章:&lt;a href=&quot;http://jerryshao.me/architecture/2014/01/04/spark-shuffle-detail-investigation/&quot;&gt;详细探究Spark的shuffle实现&lt;/a&gt;，这篇文章写于2014年，讲的是早期版本的shuffle实现。随着源码的更新，shuffle机制也做出了相应的优化，下面分析spark-2.0的shuffle机制。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;shuffleWriter&lt;/code&gt;是一个抽象类，具体实现有三种，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BypassMergeSortShuffleWriter&lt;/code&gt;,&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sortShuffleWriter&lt;/code&gt;,&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UnsafeShuffleWriter&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&quot;bypassmergesortshufflewriter&quot;&gt;BypassMergeSortShuffleWriter###&lt;/h3&gt;

&lt;p&gt;-_-,我先翻译下这个类开头给的注释，注释是很好的全局理解代码的工具，要好好理解。如下：&lt;/p&gt;

&lt;p&gt;这个类实现了基于sort-shuffle的hash风格的shuffle fallback path（回退路径？怎么翻）。这个write路径把数据写到不同的文件里，每个文件对应一个reduce分区，然后把这些文件整合到一个单独的文件，这个文件的不同区域服务不同的reducer。数据不是缓存在内存中。这个类本质上和之前的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HashShuffleReader&lt;/code&gt;，除了这个类的输出格式可以通过&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;org.apache.spark.shuffle.IndexShuffleBlockResolver&lt;/code&gt;来调用。这个写路径对于有许多reduce分区的shuffle来说是不高效的，因为他同时打开很多serializers和文件流。因此只有在以下情况下才会选择这个路径：&lt;/p&gt;

&lt;p&gt;1、没有排序  2、没有聚合操作  3、partition的数量小于bypassMergeThreshold&lt;/p&gt;

&lt;p&gt;这个代码曾经是ExternalSorter的一部分，但是为了减少代码复杂度就独立了出来。好，翻译结束。-_-&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@Override
public void write(Iterator&amp;lt;Product2&amp;lt;K, V&amp;gt;&amp;gt; records) throws IOException {
  assert (partitionWriters == null);
  if (!records.hasNext()) {
    partitionLengths = new long[numPartitions];
    shuffleBlockResolver.writeIndexFileAndCommit(shuffleId, mapId, partitionLengths, null);
    mapStatus = MapStatus$.MODULE$.apply(blockManager.shuffleServerId(), partitionLengths);
    return;
  }
  final SerializerInstance serInstance = serializer.newInstance();
  final long openStartTime = System.nanoTime();
  partitionWriters = new DiskBlockObjectWriter[numPartitions];
  for (int i = 0; i &amp;lt; numPartitions; i++) {
    final Tuple2&amp;lt;TempShuffleBlockId, File&amp;gt; tempShuffleBlockIdPlusFile =
      blockManager.diskBlockManager().createTempShuffleBlock();
    final File file = tempShuffleBlockIdPlusFile._2();
    final BlockId blockId = tempShuffleBlockIdPlusFile._1();
    partitionWriters[i] =
      blockManager.getDiskWriter(blockId, file, serInstance, fileBufferSize, writeMetrics);
  }
  // Creating the file to write to and creating a disk writer both involve interacting with
  // the disk, and can take a long time in aggregate when we open many files, so should be
  // included in the shuffle write time.
  writeMetrics.incWriteTime(System.nanoTime() - openStartTime);

  while (records.hasNext()) {
    final Product2&amp;lt;K, V&amp;gt; record = records.next();
    final K key = record._1();
    partitionWriters[partitioner.getPartition(key)].write(key, record._2());
  }

  for (DiskBlockObjectWriter writer : partitionWriters) {
    writer.commitAndClose();
  }

  File output = shuffleBlockResolver.getDataFile(shuffleId, mapId);
  File tmp = Utils.tempFileWith(output);
  try {
    partitionLengths = writePartitionedFile(tmp);
    shuffleBlockResolver.writeIndexFileAndCommit(shuffleId, mapId, partitionLengths, tmp);
  } finally {
    if (tmp.exists() &amp;amp;&amp;amp; !tmp.delete()) {
      logger.error(&quot;Error while deleting temp file {}&quot;, tmp.getAbsolutePath());
    }
  }
  mapStatus = MapStatus$.MODULE$.apply(blockManager.shuffleServerId(), partitionLengths);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;前面都很好理解，就是根据key的哈希值写到不同的文件里面，然后就是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;writePartitionedFile&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;writeIndexFileAndCommit&lt;/code&gt;。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * Concatenate all of the per-partition files into a single combined file.
 *
 * @return array of lengths, in bytes, of each partition of the file (used by map output tracker).
 */
private long[] writePartitionedFile(File outputFile) throws IOException {
  // Track location of the partition starts in the output file
  final long[] lengths = new long[numPartitions];
  if (partitionWriters == null) {
    // We were passed an empty iterator
    return lengths;
  }

  final FileOutputStream out = new FileOutputStream(outputFile, true);
  final long writeStartTime = System.nanoTime();
  boolean threwException = true;
  try {
    for (int i = 0; i &amp;lt; numPartitions; i++) {
      final File file = partitionWriters[i].fileSegment().file();
      if (file.exists()) {
        final FileInputStream in = new FileInputStream(file);
        boolean copyThrewException = true;
        try {
          lengths[i] = Utils.copyStream(in, out, false, transferToEnabled);
          copyThrewException = false;
        } finally {
          Closeables.close(in, copyThrewException);
        }
        if (!file.delete()) {
          logger.error(&quot;Unable to delete file for partition {}&quot;, i);
        }
      }
    }
    threwException = false;
  } finally {
    Closeables.close(out, threwException);
    writeMetrics.incWriteTime(System.nanoTime() - writeStartTime);
  }
  partitionWriters = null;
  return lengths;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这个就是按顺序把之前写的分区文件里的数据合并到一个大文件里面，然后返回每个分区文件的长度。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * Write an index file with the offsets of each block, plus a final offset at the end for the
 * end of the output file. This will be used by getBlockData to figure out where each block
 * begins and ends.
 *
 * It will commit the data and index file as an atomic operation, use the existing ones, or
 * replace them with new ones.
 *
 * Note: the `lengths` will be updated to match the existing index file if use the existing ones.
 * */
def writeIndexFileAndCommit(
    shuffleId: Int,
    mapId: Int,
    lengths: Array[Long],
    dataTmp: File): Unit = {
  val indexFile = getIndexFile(shuffleId, mapId)
  val indexTmp = Utils.tempFileWith(indexFile)
  try {
    val out = new DataOutputStream(new BufferedOutputStream(new FileOutputStream(indexTmp)))
    Utils.tryWithSafeFinally {
      // We take in lengths of each block, need to convert it to offsets.
      var offset = 0L
      out.writeLong(offset)
      for (length &amp;lt;- lengths) {
        offset += length
        out.writeLong(offset)
      }
    } {
      out.close()
    }

    val dataFile = getDataFile(shuffleId, mapId)
    // There is only one IndexShuffleBlockResolver per executor, this synchronization make sure
    // the following check and rename are atomic.
    synchronized {
      val existingLengths = checkIndexAndDataFile(indexFile, dataFile, lengths.length)
      if (existingLengths != null) {
        // Another attempt for the same task has already written our map outputs successfully,
        // so just use the existing partition lengths and delete our temporary map outputs.
        System.arraycopy(existingLengths, 0, lengths, 0, lengths.length)
        if (dataTmp != null &amp;amp;&amp;amp; dataTmp.exists()) {
          dataTmp.delete()
        }
        indexTmp.delete()
      } else {
        // This is the first successful attempt in writing the map outputs for this task,
        // so override any existing index and data files with the ones we wrote.
        if (indexFile.exists()) {
          indexFile.delete()
        }
        if (dataFile.exists()) {
          dataFile.delete()
        }
        if (!indexTmp.renameTo(indexFile)) {
          throw new IOException(&quot;fail to rename file &quot; + indexTmp + &quot; to &quot; + indexFile)
        }
        if (dataTmp != null &amp;amp;&amp;amp; dataTmp.exists() &amp;amp;&amp;amp; !dataTmp.renameTo(dataFile)) {
          throw new IOException(&quot;fail to rename file &quot; + dataTmp + &quot; to &quot; + dataFile)
        }
      }
    }
  } finally {
    if (indexTmp.exists() &amp;amp;&amp;amp; !indexTmp.delete()) {
      logError(s&quot;Failed to delete temporary index file at ${indexTmp.getAbsolutePath}&quot;)
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;解释下这段代码，上来先写indexTmp，是把分区文件长度写进去，便于索引需要的那部分数据。然后就判断这个任务是不是第一次执行到这里，如果之前执行成功过，那就不用写了，直接用以前的结果就行。&lt;/p&gt;

&lt;p&gt;如果是第一次执行到这里，那么就把之前的indexTmp重命名为indexFile，dataTmp重命名为dataFile然后返回。&lt;/p&gt;

&lt;p&gt;这里要注意下，每个executor上面只有一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;IndexShuffleBlockResolver&lt;/code&gt;，这个管理这个executor上所有的indexFile.&lt;/p&gt;

&lt;p&gt;等这个indexFile也写好之后，就返回&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mapStatus&lt;/code&gt;。shuffleWrite就结束了。&lt;/p&gt;

&lt;h3 id=&quot;sortshufflewriter&quot;&gt;SortShuffleWriter&lt;/h3&gt;

&lt;p&gt;首先描述下大概。因为是sort，所以要排序，这里就用到了ExternalSoter这个数据结构。然后把要处理的数据全部插入到ExternalSorter里面，在插入的过程中是不排序的，就是插入，插入数据是(partitionId,key,value)。然后是调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt; sorter.writePartitionedFile&lt;/code&gt;,在这里会排序，会按照partitionId和key（或者key的hashcode）进行排序，其他的就和上面bypassShuffleWriter的差不多了，最后也是写到一个indexFile里面。返回mapStatus。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/** Write a bunch of records to this task&apos;s output */
override def write(records: Iterator[Product2[K, V]]): Unit = {
  sorter = if (dep.mapSideCombine) {
    require(dep.aggregator.isDefined, &quot;Map-side combine without Aggregator specified!&quot;)
    new ExternalSorter[K, V, C](
      context, dep.aggregator, Some(dep.partitioner), dep.keyOrdering, dep.serializer)
  } else {
    // In this case we pass neither an aggregator nor an ordering to the sorter, because we don&apos;t
    // care whether the keys get sorted in each partition; that will be done on the reduce side
    // if the operation being run is sortByKey.
    new ExternalSorter[K, V, V](
      context, aggregator = None, Some(dep.partitioner), ordering = None, dep.serializer)
  }
  sorter.insertAll(records)

  // Don&apos;t bother including the time to open the merged output file in the shuffle write time,
  // because it just opens a single file, so is typically too fast to measure accurately
  // (see SPARK-3570).
  val output = shuffleBlockResolver.getDataFile(dep.shuffleId, mapId)
  val tmp = Utils.tempFileWith(output)
  try {
    val blockId = ShuffleBlockId(dep.shuffleId, mapId, IndexShuffleBlockResolver.NOOP_REDUCE_ID)
    val partitionLengths = sorter.writePartitionedFile(blockId, tmp)
    shuffleBlockResolver.writeIndexFileAndCommit(dep.shuffleId, mapId, partitionLengths, tmp)
    mapStatus = MapStatus(blockManager.shuffleServerId, partitionLengths)
  } finally {
    if (tmp.exists() &amp;amp;&amp;amp; !tmp.delete()) {
      logError(s&quot;Error while deleting temp file ${tmp.getAbsolutePath}&quot;)
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里面ExternalSorter是核心。看它的源码，它存数据是使用的两种数据结构。&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PartitionedAppendOnlyMap&lt;/code&gt;、&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PartitionedPairBuffer&lt;/code&gt;，其中有聚合操作使用map，没有聚合操作使用buffer。PartitionedAppendOnlyMap 继承了SizeTrackingAppendOnlyMap 和WritablePartitionedPairCollection 。 其中SizeTrackingAppendOnlyMap是用于预测空间（SizeTracker），然后加存储数据（AppendOnlyMap）,然后WritablePartitionedPairCollection是用于插入数据时候插入partitionId（insert(partition: Int, key: K, value: V)）加上里面实现了对数据按照partitionId和Key排序的方法。&lt;/p&gt;

&lt;p&gt;我主要是对AppendOnlyMap怎么存储数据比较感兴趣。看下AppendOnlyMap。&lt;/p&gt;

&lt;p&gt;看源码，它存储数据是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;private var data = new Array[AnyRef](2 * capacity)&lt;/code&gt;,是使用数组存储的，key和value挨着，这样做是为了节省空间。&lt;/p&gt;

&lt;p&gt;然后map的Update和changeValue函数是差不多的，只不过后者的changeValue是由计算函数计算的value，所以我们就看update方法。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/** Set the value for a key */
def update(key: K, value: V): Unit = {
  assert(!destroyed, destructionMessage)
  val k = key.asInstanceOf[AnyRef]
  if (k.eq(null)) {
    if (!haveNullValue) {
      incrementSize()
    }
    nullValue = value
    haveNullValue = true
    return
  }
  var pos = rehash(key.hashCode) &amp;amp; mask
  var i = 1
  while (true) {
    val curKey = data(2 * pos)
    if (curKey.eq(null)) {
      data(2 * pos) = k
      data(2 * pos + 1) = value.asInstanceOf[AnyRef]
      incrementSize()  // Since we added a new key
      return
    } else if (k.eq(curKey) || k.equals(curKey)) {
      data(2 * pos + 1) = value.asInstanceOf[AnyRef]
      return
    } else {
      val delta = i
      pos = (pos + delta) &amp;amp; mask
      i += 1
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;看源码可以看出，这里插入数据，采用的二次探测法。java.util.collection的HashMap在hash冲突时候采用的是链接法，而这里的二次探测法缺点就是删除元素时候比较复杂，不能简单的把数组中的相应位置设为null，这样就没办法查找元素，通常是把被删除的元素标记为已删除，但是又需要占据额外的空间。但是此处是appendOnlyMap，也就是只会追加（插入或者更新），不会删除，所以这个自定义的map更省内存。&lt;/p&gt;

&lt;p&gt;然后这个AppendOnlyMap会在growMap的时候重新hash。在sorter.insertall时候是不排序的。&lt;/p&gt;

&lt;p&gt;然后writePartitionedFile 里面调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;collection.destructiveSortedWritablePartitionedIterator(comparator)	&lt;/code&gt;会对数据排序，之后就跟上一小节里面的writePartitionedFile差不多了，无非就是把内存里面的数据和spill的数据合并之后写入大文件里面，之后的writeIndexFile是一样的，就不细说。&lt;/p&gt;

&lt;h3 id=&quot;unsafeshufflewriter&quot;&gt;unsafeShuffleWriter&lt;/h3&gt;

&lt;p&gt;这里之所以叫作unsafe，是因为要操纵堆外内存，把数据写到堆外，堆外内存是不受jvm控制的，需要手动进行申请内存与释放内存空间，所以是unsafe的。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@Override
public void write(scala.collection.Iterator&amp;lt;Product2&amp;lt;K, V&amp;gt;&amp;gt; records) throws IOException {
  // Keep track of success so we know if we encountered an exception
  // We do this rather than a standard try/catch/re-throw to handle
  // generic throwables.
  boolean success = false;
  try {
    while (records.hasNext()) {
      insertRecordIntoSorter(records.next());
    }
    closeAndWriteOutput();
    success = true;
  } finally {
    if (sorter != null) {
      try {
        sorter.cleanupResources();
      } catch (Exception e) {
        // Only throw this error if we won&apos;t be masking another
        // error.
        if (success) {
          throw e;
        } else {
          logger.error(&quot;In addition to a failure during writing, we failed during &quot; +
                       &quot;cleanup.&quot;, e);
        }
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;除了是写到堆外，其他应该跟sortShuffleWriter 差不多吧，懒得写了，以后发现有什么特别之处再补充。&lt;/p&gt;

&lt;h3 id=&quot;blockstoreshufflereader&quot;&gt;BlockStoreShuffleReader###&lt;/h3&gt;

&lt;p&gt;前面三个shuffleWriter，shuffle分为shuffleWriter和shuffleReader。shuffleReadr只有一个具体实现类就是BlockStoreShuffleReader。看开头注释为：读取（startPartition和endPartition）之间的partition的数据，从其他节点。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/** Read the combined key-values for this reduce task */
override def read(): Iterator[Product2[K, C]] = {
  val blockFetcherItr = new ShuffleBlockFetcherIterator(
    context,
    blockManager.shuffleClient,
    blockManager,
    mapOutputTracker.getMapSizesByExecutorId(handle.shuffleId, startPartition, endPartition),
    // Note: we use getSizeAsMb when no suffix is provided for backwards compatibility
    SparkEnv.get.conf.getSizeAsMb(&quot;spark.reducer.maxSizeInFlight&quot;, &quot;48m&quot;) * 1024 * 1024,
    SparkEnv.get.conf.getInt(&quot;spark.reducer.maxReqsInFlight&quot;, Int.MaxValue))

  // Wrap the streams for compression based on configuration
  val wrappedStreams = blockFetcherItr.map { case (blockId, inputStream) =&amp;gt;
    serializerManager.wrapForCompression(blockId, inputStream)
  }

  val serializerInstance = dep.serializer.newInstance()

  // Create a key/value iterator for each stream
  val recordIter = wrappedStreams.flatMap { wrappedStream =&amp;gt;
    // Note: the asKeyValueIterator below wraps a key/value iterator inside of a
    // NextIterator. The NextIterator makes sure that close() is called on the
    // underlying InputStream when all records have been read.
    serializerInstance.deserializeStream(wrappedStream).asKeyValueIterator
  }

  // Update the context task metrics for each record read.
  val readMetrics = context.taskMetrics.createTempShuffleReadMetrics()
  val metricIter = CompletionIterator[(Any, Any), Iterator[(Any, Any)]](
    recordIter.map { record =&amp;gt;
      readMetrics.incRecordsRead(1)
      record
    },
    context.taskMetrics().mergeShuffleReadMetrics())

  // An interruptible iterator must be used here in order to support task cancellation
  val interruptibleIter = new InterruptibleIterator[(Any, Any)](context, metricIter)

  val aggregatedIter: Iterator[Product2[K, C]] = if (dep.aggregator.isDefined) {
    if (dep.mapSideCombine) {
      // We are reading values that are already combined
      val combinedKeyValuesIterator = interruptibleIter.asInstanceOf[Iterator[(K, C)]]
      dep.aggregator.get.combineCombinersByKey(combinedKeyValuesIterator, context)
    } else {
      // We don&apos;t know the value type, but also don&apos;t care -- the dependency *should*
      // have made sure its compatible w/ this aggregator, which will convert the value
      // type to the combined type C
      val keyValuesIterator = interruptibleIter.asInstanceOf[Iterator[(K, Nothing)]]
      dep.aggregator.get.combineValuesByKey(keyValuesIterator, context)
    }
  } else {
    require(!dep.mapSideCombine, &quot;Map-side combine without Aggregator specified!&quot;)
    interruptibleIter.asInstanceOf[Iterator[Product2[K, C]]]
  }

  // Sort the output if there is a sort ordering defined.
  dep.keyOrdering match {
    case Some(keyOrd: Ordering[K]) =&amp;gt;
      // Create an ExternalSorter to sort the data. Note that if spark.shuffle.spill is disabled,
      // the ExternalSorter won&apos;t spill to disk.
      val sorter =
        new ExternalSorter[K, C, C](context, ordering = Some(keyOrd), serializer = dep.serializer)
      sorter.insertAll(aggregatedIter)
      context.taskMetrics().incMemoryBytesSpilled(sorter.memoryBytesSpilled)
      context.taskMetrics().incDiskBytesSpilled(sorter.diskBytesSpilled)
      context.taskMetrics().incPeakExecutionMemory(sorter.peakMemoryUsedBytes)
      CompletionIterator[Product2[K, C], Iterator[Product2[K, C]]](sorter.iterator, sorter.stop())
    case None =&amp;gt;
      aggregatedIter
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;首先是建立一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ShuffleBlockFetcherIterator&lt;/code&gt;，传入的参数有&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mapOutputTracker.getMapSizesByExecutorId(handle.shuffleId, startPartition, endPartition)&lt;/code&gt;,这个是必须的，只取需要的partition的数据。&lt;/p&gt;

&lt;p&gt;点进去ShuffleBlockFetcherIterator这个类，发现这个类会自动调用initialize()方法。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private[this] def initialize(): Unit = {
  // Add a task completion callback (called in both success case and failure case) to cleanup.
  context.addTaskCompletionListener(_ =&amp;gt; cleanup())

  // Split local and remote blocks.
  val remoteRequests = splitLocalRemoteBlocks()
  // Add the remote requests into our queue in a random order
  fetchRequests ++= Utils.randomize(remoteRequests)
  assert ((0 == reqsInFlight) == (0 == bytesInFlight),
    &quot;expected reqsInFlight = 0 but found reqsInFlight = &quot; + reqsInFlight +
    &quot;, expected bytesInFlight = 0 but found bytesInFlight = &quot; + bytesInFlight)

  // Send out initial requests for blocks, up to our maxBytesInFlight
  fetchUpToMaxBytes()

  val numFetches = remoteRequests.size - fetchRequests.size
  logInfo(&quot;Started &quot; + numFetches + &quot; remote fetches in&quot; + Utils.getUsedTimeMs(startTime))

  // Get Local Blocks
  fetchLocalBlocks()
  logDebug(&quot;Got local blocks in &quot; + Utils.getUsedTimeMs(startTime))
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这个方法里面会&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fetchUpToMaxBytes()&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fetchLocalBlocks()&lt;/code&gt;,一个是取远程数据一个是取本地数据。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def fetchUpToMaxBytes(): Unit = {
  // Send fetch requests up to maxBytesInFlight
  while (fetchRequests.nonEmpty &amp;amp;&amp;amp;
    (bytesInFlight == 0 ||
      (reqsInFlight + 1 &amp;lt;= maxReqsInFlight &amp;amp;&amp;amp;
        bytesInFlight + fetchRequests.front.size &amp;lt;= maxBytesInFlight))) {
    sendRequest(fetchRequests.dequeue())
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里会设置一个阈值，避免过度负载的。&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sendRequest&lt;/code&gt;来请求数据。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private[this] def sendRequest(req: FetchRequest) {
  logDebug(&quot;Sending request for %d blocks (%s) from %s&quot;.format(
    req.blocks.size, Utils.bytesToString(req.size), req.address.hostPort))
  bytesInFlight += req.size
  reqsInFlight += 1

  // so we can look up the size of each blockID
  val sizeMap = req.blocks.map { case (blockId, size) =&amp;gt; (blockId.toString, size) }.toMap
  val remainingBlocks = new HashSet[String]() ++= sizeMap.keys
  val blockIds = req.blocks.map(_._1.toString)

  val address = req.address
  shuffleClient.fetchBlocks(address.host, address.port, address.executorId, blockIds.toArray,
    new BlockFetchingListener {
      override def onBlockFetchSuccess(blockId: String, buf: ManagedBuffer): Unit = {
        // Only add the buffer to results queue if the iterator is not zombie,
        // i.e. cleanup() has not been called yet.
        ShuffleBlockFetcherIterator.this.synchronized {
          if (!isZombie) {
            // Increment the ref count because we need to pass this to a different thread.
            // This needs to be released after use.
            buf.retain()
            remainingBlocks -= blockId
            results.put(new SuccessFetchResult(BlockId(blockId), address, sizeMap(blockId), buf,
              remainingBlocks.isEmpty))
            logDebug(&quot;remainingBlocks: &quot; + remainingBlocks)
          }
        }
        logTrace(&quot;Got remote block &quot; + blockId + &quot; after &quot; + Utils.getUsedTimeMs(startTime))
      }

      override def onBlockFetchFailure(blockId: String, e: Throwable): Unit = {
        logError(s&quot;Failed to get block(s) from ${req.address.host}:${req.address.port}&quot;, e)
        results.put(new FailureFetchResult(BlockId(blockId), address, e))
      }
    }
  )
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;后面一大堆代码，反正就是取数据吗，就不细看了。&lt;/p&gt;

&lt;p&gt;取完数据之后，就通过dep.mapSideCombine判断是否在map端做了聚合操作，如果做了聚合操作，这里的(k,v)的v就是CompactBuffer类型，就调用combineCombinersByKey，如果在map端没有聚合，就还是value类型，就combineValuesByKey。&lt;/p&gt;

&lt;p&gt;之后就判断是否定义了排序，如果需要排序就用ExternalSorter排序。&lt;/p&gt;

&lt;p&gt;到这里shuffle过程就结束啦。&lt;/p&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结##&lt;/h2&gt;

&lt;p&gt;前两种shuffleWriter（UnsafeShuffleWriter没细看）里的shuffleWrite端最后得到的文件都只是一个IndexFile，这跟&lt;a href=&quot;http://jerryshao.me/architecture/2014/01/04/spark-shuffle-detail-investigation/&quot;&gt;早期的shuffle机制&lt;/a&gt;还是不一样的。&lt;/p&gt;
</description>
                <link>http://www.turbofei.wang/spark/2016/12/26/spark%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90Shuffle%E5%AE%9E%E7%8E%B0</link>
                <guid>http://www.turbofei.wang/spark/2016/12/26/spark源码分析Shuffle实现</guid>
                <pubDate>2016-12-26T00:00:00-08:00</pubDate>
        </item>

        <item>
                <title>Spark内存预测</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#sizetracker&quot; id=&quot;markdown-toc-sizetracker&quot;&gt;sizeTracker&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#sizeestimator&quot; id=&quot;markdown-toc-sizeestimator&quot;&gt;SizeEstimator&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;spark是一个内存计算框架，因此内存是重要的资源，合理的使用的内存在spark应用在执行过程中非常重要。在使用内存的过程，spark会采用抽样的方法预测出所需要的内存，并预先分配内存。本文会就内存预测机制进行源码的解读。&lt;/p&gt;

&lt;h2 id=&quot;sizetracker&quot;&gt;sizeTracker&lt;/h2&gt;

&lt;p&gt;spark里面内存预测有一个trait，叫做&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt; SizeTracker&lt;/code&gt;，然后有一些类实现了它，比如PartitionedAppendOnlyMap、SizeTrackingAppendOnlyMap。&lt;/p&gt;

&lt;p&gt;SizeTracker的estimateSize方法就是预测当前集合的size。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * Estimate the current size of the collection in bytes. O(1) time.
 */
def estimateSize(): Long = {
  assert(samples.nonEmpty)
  val extrapolatedDelta = bytesPerUpdate * (numUpdates - samples.last.numUpdates)
  (samples.last.size + extrapolatedDelta).toLong
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;其实这个sizeTracker类有四个方法，其他三个方法分别是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;resetSamples&lt;/code&gt;,&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;afterUpdate&lt;/code&gt;,&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;takeSample&lt;/code&gt;.看了下SizeTrackingAppendOnlyMap的流程，afterUpdata方法是在update或者changeValue之后会调用，其实updata和changeValue没有什么区别，只不过一个是直接更新k-v，另一个是使用一个函数计算后更新k-v。然后resetSamples是在growTable之后调用（SizeTrackingAppendOnlyMap的growTable就是空间翻一倍）。&lt;/p&gt;

&lt;p&gt;看下sizeTracker里面的参数。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * Controls the base of the exponential which governs the rate of sampling.
 * E.g., a value of 2 would mean we sample at 1, 2, 4, 8, ... elements.
 */
private val SAMPLE_GROWTH_RATE = 1.1

/** Samples taken since last resetSamples(). Only the last two are kept for extrapolation. */
private val samples = new mutable.Queue[Sample]

/** The average number of bytes per update between our last two samples. */
private var bytesPerUpdate: Double = _

/** Total number of insertions and updates into the map since the last resetSamples(). */
private var numUpdates: Long = _

/** The value of &apos;numUpdates&apos; at which we will take our next sample. */
private var nextSampleNum: Long = _
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SAMPLE_GROWTH_RATE&lt;/code&gt;是一个斜率，代表下次抽样时候更新的次数应该是这次抽样更新次数的1.1倍，比如上次是更新10000次时候抽样，下次抽样就得是更新11000次时候再抽样，可以避免每次更新都抽样，减少抽样花销。&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;samples&lt;/code&gt;是一个队列， 里面的类型是样例类&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sample&lt;/code&gt;。然后&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bytesPerUpdate&lt;/code&gt;是抽样之后得到区间增长量/个数增长量，就是一个斜率。然后&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;numUpdates&lt;/code&gt;就是代表抽样集合里面元素个数，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nextSampleNum&lt;/code&gt;代表下次要抽样的时候集合的个数，前面说过，就是此次抽样时候的个数*1.1.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * Reset samples collected so far.
 * This should be called after the collection undergoes a dramatic change in size.
 */
protected def resetSamples(): Unit = {
  numUpdates = 1
  nextSampleNum = 1
  samples.clear()
  takeSample()
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;resetSamples会在每次翻倍增长后，重置抽样参数，没啥好说的。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * Callback to be invoked after every update.
 */
protected def afterUpdate(): Unit = {
  numUpdates += 1
  if (nextSampleNum == numUpdates) {
    takeSample()
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这个是每次更新后，都更新次数+1，然后当他等于下次抽样次数时候就进行抽样。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * Take a new sample of the current collection&apos;s size.
 */
private def takeSample(): Unit = {
  samples.enqueue(Sample(SizeEstimator.estimate(this), numUpdates))
  // Only use the last two samples to extrapolate
  if (samples.size &amp;gt; 2) {
    samples.dequeue()
  }
  val bytesDelta = samples.toList.reverse match {
    case latest :: previous :: tail =&amp;gt;
      (latest.size - previous.size).toDouble / (latest.numUpdates - previous.numUpdates)
    // If fewer than 2 samples, assume no change
    case _ =&amp;gt; 0
  }
  bytesPerUpdate = math.max(0, bytesDelta)
  nextSampleNum = math.ceil(numUpdates * SAMPLE_GROWTH_RATE).toLong
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;抽样就是找出最近的两个sample，然后计算增长斜率，size增长量/num增长量，然后把下次抽样的次数*1.1更新下。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * Estimate the current size of the collection in bytes. O(1) time.
 */
def estimateSize(): Long = {
  assert(samples.nonEmpty)
  val extrapolatedDelta = bytesPerUpdate * (numUpdates - samples.last.numUpdates)
  (samples.last.size + extrapolatedDelta).toLong
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;然后这个estimateSize 就是上次的size+增长率*增长量。增长率和size就是上次抽样得到的。&lt;/p&gt;

&lt;p&gt;可以看到在takeSample方法里面加入队列时候size的预测用到了&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SizeEstimator.estimate&lt;/code&gt;.看下这个SizeEstimator类。&lt;/p&gt;

&lt;h2 id=&quot;sizeestimator&quot;&gt;SizeEstimator&lt;/h2&gt;

&lt;p&gt;看下这类的estimate方法。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def estimate(obj: AnyRef, visited: IdentityHashMap[AnyRef, AnyRef]): Long = {
  val state = new SearchState(visited)
  state.enqueue(obj)
  while (!state.isFinished) {
    visitSingleObject(state.dequeue(), state)
  }
  state.size
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里主要是调用visitSingleObject。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def visitSingleObject(obj: AnyRef, state: SearchState) {
  val cls = obj.getClass
  if (cls.isArray) {
    visitArray(obj, cls, state)
  } else if (cls.getName.startsWith(&quot;scala.reflect&quot;)) {
    // Many objects in the scala.reflect package reference global reflection objects which, in
    // turn, reference many other large global objects. Do nothing in this case.
  } else if (obj.isInstanceOf[ClassLoader] || obj.isInstanceOf[Class[_]]) {
    // Hadoop JobConfs created in the interpreter have a ClassLoader, which greatly confuses
    // the size estimator since it references the whole REPL. Do nothing in this case. In
    // general all ClassLoaders and Classes will be shared between objects anyway.
  } else {
    obj match {
      case s: KnownSizeEstimation =&amp;gt;
        state.size += s.estimatedSize
      case _ =&amp;gt;
        val classInfo = getClassInfo(cls)
        state.size += alignSize(classInfo.shellSize)
        for (field &amp;lt;- classInfo.pointerFields) {
          state.enqueue(field.get(obj))
        }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;如果是Array类型，就visitArray。如果是scala.reflect开头的类，因为这个包里面涉及全局反射对象，因此涉及很多其他的大对象，所以这种对象不做任何操作。然后如果是classLoader类型，hadoop 作业在解释器中创建了classLoader，因为涉及整个REPL（读取-求值-处理-循环），所以很难处理。一般，所有classLoader和classes都是共享的。然后有的就是已经预测过的，直接读取。然后其他类型，就是拆解，拆成实际对象和引用，实际对象算出size相加，然后指针类型就把它指向的对象加入state队列，然后再进入while循环。直到state isFinished。&lt;/p&gt;

&lt;p&gt;接下来看看visitArray.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// Estimate the size of arrays larger than ARRAY_SIZE_FOR_SAMPLING by sampling.
private val ARRAY_SIZE_FOR_SAMPLING = 400
private val ARRAY_SAMPLE_SIZE = 100 // should be lower than ARRAY_SIZE_FOR_SAMPLING

private def visitArray(array: AnyRef, arrayClass: Class[_], state: SearchState) {
  val length = ScalaRunTime.array_length(array)
  val elementClass = arrayClass.getComponentType()

  // Arrays have object header and length field which is an integer
  var arrSize: Long = alignSize(objectSize + INT_SIZE)

  if (elementClass.isPrimitive) {
    arrSize += alignSize(length.toLong * primitiveSize(elementClass))
    state.size += arrSize
  } else {
    arrSize += alignSize(length.toLong * pointerSize)
    state.size += arrSize

    if (length &amp;lt;= ARRAY_SIZE_FOR_SAMPLING) {
      var arrayIndex = 0
      while (arrayIndex &amp;lt; length) {
        state.enqueue(ScalaRunTime.array_apply(array, arrayIndex).asInstanceOf[AnyRef])
        arrayIndex += 1
      }
    } else {
      // Estimate the size of a large array by sampling elements without replacement.
      // To exclude the shared objects that the array elements may link, sample twice
      // and use the min one to calculate array size.
      val rand = new Random(42)
      val drawn = new OpenHashSet[Int](2 * ARRAY_SAMPLE_SIZE)
      val s1 = sampleArray(array, state, rand, drawn, length)
      val s2 = sampleArray(array, state, rand, drawn, length)
      val size = math.min(s1, s2)
      state.size += math.max(s1, s2) +
        (size * ((length - ARRAY_SAMPLE_SIZE) / (ARRAY_SAMPLE_SIZE))).toLong
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这段代码，首先要把&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Array 的object 头部,长度 filed&lt;/code&gt;算进去，然后如果array里面的元素是基本类型，那么长度就固定，就可以直接算出来。&lt;/p&gt;

&lt;p&gt;如果不是基本类型，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;就有指向对象的引用？&lt;/code&gt;所以代码里面先把length个指针占用的空间加上。&lt;/p&gt;

&lt;p&gt;如果这时候数组长度，小于采样时候数组长度那个界限，就把数组里面引用指向的对象加入state队列，也就是小于界限就全部计算size。&lt;/p&gt;

&lt;p&gt;如果数组长度大于采样时候数组长度的界限，就准备采样。然后采样两组，两组采样数据都是不重复的。计算公式如下:&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;math.max(s1, s2) + (math.min(s1, s2) * ((length - ARRAY_SAMPLE_SIZE) / (ARRAY_SAMPLE_SIZE)))&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;这个计算公式不知道有什么合理的地方，反正spark用这个公式，应该是有一定道理。&lt;/p&gt;

&lt;p&gt;就是  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;math.min(s1,s2)*(length-ARRAY_SAMPLE_SIZE)+abs(s1-s2)&lt;/code&gt;，这应该是为了不让内存预估过大，以免占用太多，同时用一个小的增量对这个偏小的预估进行补偿。&lt;/p&gt;

</description>
                <link>http://www.turbofei.wang/spark/2016/12/26/spark%E5%86%85%E5%AD%98%E9%A2%84%E6%B5%8B</link>
                <guid>http://www.turbofei.wang/spark/2016/12/26/spark内存预测</guid>
                <pubDate>2016-12-26T00:00:00-08:00</pubDate>
        </item>

        <item>
                <title>Spark应用执行流程</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#word-count&quot; id=&quot;markdown-toc-word-count&quot;&gt;Word Count&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#理论剖析&quot; id=&quot;markdown-toc-理论剖析&quot;&gt;理论剖析&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#源码剖析&quot; id=&quot;markdown-toc-源码剖析&quot;&gt;源码剖析&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#提交job&quot; id=&quot;markdown-toc-提交job&quot;&gt;提交job&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#划分stage&quot; id=&quot;markdown-toc-划分stage&quot;&gt;划分stage&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#提交tasks&quot; id=&quot;markdown-toc-提交tasks&quot;&gt;提交tasks###&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#执行task&quot; id=&quot;markdown-toc-执行task&quot;&gt;执行task###&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#shufflemaptask&quot; id=&quot;markdown-toc-shufflemaptask&quot;&gt;ShuffleMapTask&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#resulttask&quot; id=&quot;markdown-toc-resulttask&quot;&gt;ResultTask####&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#rdd-迭代链&quot; id=&quot;markdown-toc-rdd-迭代链&quot;&gt;rdd 迭代链&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#检查点&quot; id=&quot;markdown-toc-检查点&quot;&gt;检查点####&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#compute-链&quot; id=&quot;markdown-toc-compute-链&quot;&gt;compute 链&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#参考&quot; id=&quot;markdown-toc-参考&quot;&gt;参考##&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;从最简单的spark应用WordCount入手，分析rdd链，分析job如何提交，task如何提交，从全局了解spark应用的执行流程。&lt;/p&gt;

&lt;h2 id=&quot;word-count&quot;&gt;Word Count&lt;/h2&gt;

&lt;p&gt;word count是spark 最基本的小程序，主要功能就是统计一个文件里面各个单词出现的个数。代码很简洁，如下。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import org.apache.spark.{SparkConf, SparkContext}

object SparkWC {
  def main(args: Array[String]) {
    val sparkConf = new SparkConf()
    val sparkContext = new SparkContext(sparkConf)
    sparkContext.textFile(args(0))
          .flatMap(line =&amp;gt; line.split(&quot; &quot;))
          .map(word =&amp;gt; (word, 1))
          .reduceByKey(_ + _)
          .saveAsTextFile(args(1))
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;理论剖析&quot;&gt;理论剖析&lt;/h3&gt;
&lt;p&gt;里面的RDD链，用他们的操作表示，就是textFile-&amp;gt;flatMap-&amp;gt;map-&amp;gt;reduceBykey-&amp;gt;saveAsTextFile.&lt;/p&gt;

&lt;p&gt;spark里面有两种操作，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;action&lt;/code&gt; 和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;transformation&lt;/code&gt;，其中action会触发提交job的操作，transformation不会触发job，只是进行rdd的转换。而不同transformation操作的rdd链两端的依赖关系也不同，spark中的rdd依赖有两种，分别是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;narrow dependency&lt;/code&gt; 和 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;wide dependency&lt;/code&gt; ,这两种依赖如下图所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/spark-basic/rdd_dependency.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;左边图是窄依赖，右边图是宽依赖，窄依赖里面的partition的对应顺序是不变的，款依赖会涉及shuffle操作，会造成partition混洗，因此往往以款依赖划分stage。在上面的操作中，saveAsTextFile是action，reduceByKey是宽依赖，因此这个应用总共有1个job，两个stage，然后在不同的stage中会执行tasks。&lt;/p&gt;

&lt;h3 id=&quot;源码剖析&quot;&gt;源码剖析&lt;/h3&gt;

&lt;p&gt;从rdd链开始分析。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def textFile(
      path: String,
      minPartitions: Int = defaultMinPartitions): RDD[String] = withScope {
    assertNotStopped()
    hadoopFile(path, classOf[TextInputFormat], classOf[LongWritable], classOf[Text],
      minPartitions).map(pair =&amp;gt; pair._2.toString).setName(path)
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;textFile 这个算子的返回结果是一个RDD，然后RDD链就开始了，可以看出来他调用了一些新的函数，比如hadoopFile啥的，这些我们都不管，因为他们都没有触发 commitJob，所以这些中间过程我们就省略，直到saveAsTextFile这个action。&lt;/p&gt;

&lt;h3 id=&quot;提交job&quot;&gt;提交job&lt;/h3&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  def saveAsTextFile(path: String): Unit = withScope {
    // https://issues.apache.org/jira/browse/SPARK-2075
    //
    // NullWritable is a `Comparable` in Hadoop 1.+, so the compiler cannot find an implicit
    // Ordering for it and will use the default `null`. However, it&apos;s a `Comparable[NullWritable]`
    // in Hadoop 2.+, so the compiler will call the implicit `Ordering.ordered` method to create an
    // Ordering for `NullWritable`. That&apos;s why the compiler will generate different anonymous
    // classes for `saveAsTextFile` in Hadoop 1.+ and Hadoop 2.+.
    //
    // Therefore, here we provide an explicit Ordering `null` to make sure the compiler generate
    // same bytecodes for `saveAsTextFile`.
    val nullWritableClassTag = implicitly[ClassTag[NullWritable]]
    val textClassTag = implicitly[ClassTag[Text]]
    val r = this.mapPartitions { iter =&amp;gt;
      val text = new Text()
      iter.map { x =&amp;gt;
        text.set(x.toString)
        (NullWritable.get(), text)
      }
    }
    RDD.rddToPairRDDFunctions(r)(nullWritableClassTag, textClassTag, null)
      .saveAsHadoopFile[TextOutputFormat[NullWritable, Text]](path)
  }
  
  
  //接下来调用这个
  def saveAsHadoopFile[F &amp;lt;: OutputFormat[K, V]](
      path: String)(implicit fm: ClassTag[F]): Unit = self.withScope {
    saveAsHadoopFile(path, keyClass, valueClass, fm.runtimeClass.asInstanceOf[Class[F]])
  }
  
//省略一部分调用过程
...
...

//最后调用这个函数
  def saveAsHadoopDataset(conf: JobConf): Unit = self.withScope {
    // Rename this as hadoopConf internally to avoid shadowing (see SPARK-2038).
    val hadoopConf = conf
    val outputFormatInstance = hadoopConf.getOutputFormat
    val keyClass = hadoopConf.getOutputKeyClass
    val valueClass = hadoopConf.getOutputValueClass
    if (outputFormatInstance == null) {
      throw new SparkException(&quot;Output format class not set&quot;)
    }
    if (keyClass == null) {
      throw new SparkException(&quot;Output key class not set&quot;)
    }
    if (valueClass == null) {
      throw new SparkException(&quot;Output value class not set&quot;)
    }
    SparkHadoopUtil.get.addCredentials(hadoopConf)

    logDebug(&quot;Saving as hadoop file of type (&quot; + keyClass.getSimpleName + &quot;, &quot; +
      valueClass.getSimpleName + &quot;)&quot;)

    if (isOutputSpecValidationEnabled) {
      // FileOutputFormat ignores the filesystem parameter
      val ignoredFs = FileSystem.get(hadoopConf)
      hadoopConf.getOutputFormat.checkOutputSpecs(ignoredFs, hadoopConf)
    }

    val writer = new SparkHadoopWriter(hadoopConf)
    writer.preSetup()

    val writeToFile = (context: TaskContext, iter: Iterator[(K, V)]) =&amp;gt; {
      // Hadoop wants a 32-bit task attempt ID, so if ours is bigger than Int.MaxValue, roll it
      // around by taking a mod. We expect that no task will be attempted 2 billion times.
      val taskAttemptId = (context.taskAttemptId % Int.MaxValue).toInt

      val outputMetricsAndBytesWrittenCallback: Option[(OutputMetrics, () =&amp;gt; Long)] =
        initHadoopOutputMetrics(context)

      writer.setup(context.stageId, context.partitionId, taskAttemptId)
      writer.open()
      var recordsWritten = 0L

      Utils.tryWithSafeFinallyAndFailureCallbacks {
        while (iter.hasNext) {
          val record = iter.next()
          writer.write(record._1.asInstanceOf[AnyRef], record._2.asInstanceOf[AnyRef])

          // Update bytes written metric every few records
          maybeUpdateOutputMetrics(outputMetricsAndBytesWrittenCallback, recordsWritten)
          recordsWritten += 1
        }
      }(finallyBlock = writer.close())
      writer.commit()
      outputMetricsAndBytesWrittenCallback.foreach { case (om, callback) =&amp;gt;
        om.setBytesWritten(callback())
        om.setRecordsWritten(recordsWritten)
      }
    }

    self.context.runJob(self, writeToFile)
    writer.commitJob()
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;上面是saveAstextFile的调用过程，中间省略了一个函数，看代码的最后两行。可以看出调用了&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt; self.context.runJob()&lt;/code&gt;可以知道这里触发了job的提交。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; def runJob[T, U: ClassTag](
      rdd: RDD[T],
      func: (TaskContext, Iterator[T]) =&amp;gt; U,
      partitions: Seq[Int],
      resultHandler: (Int, U) =&amp;gt; Unit): Unit = {
    if (stopped.get()) {
      throw new IllegalStateException(&quot;SparkContext has been shutdown&quot;)
    }
    val callSite = getCallSite
    val cleanedFunc = clean(func)
    logInfo(&quot;Starting job: &quot; + callSite.shortForm)
    if (conf.getBoolean(&quot;spark.logLineage&quot;, false)) {
      logInfo(&quot;RDD&apos;s recursive dependencies:\n&quot; + rdd.toDebugString)
    }
    dagScheduler.runJob(rdd, cleanedFunc, partitions, callSite, resultHandler, localProperties.get)
    progressBar.foreach(_.finishAll())
    rdd.doCheckpoint() //是否cache rdd
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;可以看出上面代码有 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dagScheduler.runJob&lt;/code&gt;，开始进行调度。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  def runJob[T, U](
      rdd: RDD[T],
      func: (TaskContext, Iterator[T]) =&amp;gt; U,
      partitions: Seq[Int],
      callSite: CallSite,
      resultHandler: (Int, U) =&amp;gt; Unit,
      properties: Properties): Unit = {
    val start = System.nanoTime
    val waiter = submitJob(rdd, func, partitions, callSite, resultHandler, properties)
    // Note: Do not call Await.ready(future) because that calls `scala.concurrent.blocking`,
    // which causes concurrent SQL executions to fail if a fork-join pool is used. Note that
    // due to idiosyncrasies in Scala, `awaitPermission` is not actually used anywhere so it&apos;s
    // safe to pass in null here. For more detail, see SPARK-13747.
    val awaitPermission = null.asInstanceOf[scala.concurrent.CanAwait]
    waiter.completionFuture.ready(Duration.Inf)(awaitPermission)
    waiter.completionFuture.value.get match {
      case scala.util.Success(_) =&amp;gt;
        logInfo(&quot;Job %d finished: %s, took %f s&quot;.format
          (waiter.jobId, callSite.shortForm, (System.nanoTime - start) / 1e9))
      case scala.util.Failure(exception) =&amp;gt;
        logInfo(&quot;Job %d failed: %s, took %f s&quot;.format
          (waiter.jobId, callSite.shortForm, (System.nanoTime - start) / 1e9))
        // SPARK-8644: Include user stack trace in exceptions coming from DAGScheduler.
        val callerStackTrace = Thread.currentThread().getStackTrace.tail
        exception.setStackTrace(exception.getStackTrace ++ callerStackTrace)
        throw exception
    }
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在 dagScheduler.runJob()里面有 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;submitJob&lt;/code&gt;的操作，提交job。
看下面&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;submitJob&lt;/code&gt;的代码。&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  def submitJob[T, U](
      rdd: RDD[T],
      func: (TaskContext, Iterator[T]) =&amp;gt; U,
      partitions: Seq[Int],
      callSite: CallSite,
      resultHandler: (Int, U) =&amp;gt; Unit,
      properties: Properties): JobWaiter[U] = {
    // Check to make sure we are not launching a task on a partition that does not exist.
    val maxPartitions = rdd.partitions.length
    partitions.find(p =&amp;gt; p &amp;gt;= maxPartitions || p &amp;lt; 0).foreach { p =&amp;gt;
      throw new IllegalArgumentException(
        &quot;Attempting to access a non-existent partition: &quot; + p + &quot;. &quot; +
          &quot;Total number of partitions: &quot; + maxPartitions)
    }

    val jobId = nextJobId.getAndIncrement()
    if (partitions.size == 0) {
      // Return immediately if the job is running 0 tasks
      return new JobWaiter[U](this, jobId, 0, resultHandler)
    }

    assert(partitions.size &amp;gt; 0)
    val func2 = func.asInstanceOf[(TaskContext, Iterator[_]) =&amp;gt; _]
    val waiter = new JobWaiter(this, jobId, partitions.size, resultHandler)
    eventProcessLoop.post(JobSubmitted(
      jobId, rdd, func2, partitions.toArray, callSite, waiter,
      SerializationUtils.clone(properties)))
    waiter
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;然后eventProcessLoop.post(JobSubmitted … 然后就有循环程序处理 这个post。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def doOnReceive(event: DAGSchedulerEvent): Unit = event match {
  case JobSubmitted(jobId, rdd, func, partitions, callSite, listener, properties) =&amp;gt;
    dagScheduler.handleJobSubmitted(jobId, rdd, func, partitions, callSite, listener, properties)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;划分stage&quot;&gt;划分stage&lt;/h3&gt;

&lt;p&gt;提交完job之后，会对stage进行划分。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;handleJobSubmitted&lt;/code&gt;,如下代码。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private[scheduler] def handleJobSubmitted(jobId: Int,
    finalRDD: RDD[_],
    func: (TaskContext, Iterator[_]) =&amp;gt; _,
    partitions: Array[Int],
    callSite: CallSite,
    listener: JobListener,
    properties: Properties) {
  var finalStage: ResultStage = null
  try {
    // New stage creation may throw an exception if, for example, jobs are run on a
    // HadoopRDD whose underlying HDFS files have been deleted.
    finalStage = newResultStage(finalRDD, func, partitions, jobId, callSite)
  } catch {
    case e: Exception =&amp;gt;
      logWarning(&quot;Creating new stage failed due to exception - job: &quot; + jobId, e)
      listener.jobFailed(e)
      return
  }

  val job = new ActiveJob(jobId, finalStage, callSite, listener, properties)
  clearCacheLocs()
  logInfo(&quot;Got job %s (%s) with %d output partitions&quot;.format(
    job.jobId, callSite.shortForm, partitions.length))
  logInfo(&quot;Final stage: &quot; + finalStage + &quot; (&quot; + finalStage.name + &quot;)&quot;)
  logInfo(&quot;Parents of final stage: &quot; + finalStage.parents)
  logInfo(&quot;Missing parents: &quot; + getMissingParentStages(finalStage))

  val jobSubmissionTime = clock.getTimeMillis()
  jobIdToActiveJob(jobId) = job
  activeJobs += job
  finalStage.setActiveJob(job)
  val stageIds = jobIdToStageIds(jobId).toArray
  val stageInfos = stageIds.flatMap(id =&amp;gt; stageIdToStage.get(id).map(_.latestInfo))
  listenerBus.post(
    SparkListenerJobStart(job.jobId, jobSubmissionTime, stageInfos, properties))
  submitStage(finalStage)

  submitWaitingStages()
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;解释下这段代码，先是找到最后一个stage， finalStage，然后就生成stageId还有stage的一些信息，然后post 出job开始的消息，然后提交最后一个stage，最后一行是提交等待的stages。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/** Submits stage, but first recursively submits any missing parents. */
private def submitStage(stage: Stage) {
  val jobId = activeJobForStage(stage)
  if (jobId.isDefined) {
    logDebug(&quot;submitStage(&quot; + stage + &quot;)&quot;)
    if (!waitingStages(stage) &amp;amp;&amp;amp; !runningStages(stage) &amp;amp;&amp;amp; !failedStages(stage)) {
      val missing = getMissingParentStages(stage).sortBy(_.id)
      logDebug(&quot;missing: &quot; + missing)
      if (missing.isEmpty) {
        logInfo(&quot;Submitting &quot; + stage + &quot; (&quot; + stage.rdd + &quot;), which has no missing parents&quot;)
        submitMissingTasks(stage, jobId.get)
      } else {
        for (parent &amp;lt;- missing) {
          submitStage(parent)
        }
        waitingStages += stage
      }
    }
  } else {
    abortStage(stage, &quot;No active job for stage &quot; + stage.id, None)
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;解释下这段代码，就是递归提交之前都没有提交的stage，因为之前是提交最后一个stage吗，但是前面stage也没操作，所以要不断地提交parentStage，直到job的头部。如果说这个stage没有未完成的parentStage，那就代表它前面都执行完毕。&lt;/p&gt;

&lt;h3 id=&quot;提交tasks&quot;&gt;提交tasks###&lt;/h3&gt;

&lt;p&gt;找到最开始还没完成的stage，那么提交这个stage的Tasks。调用的函数是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;submitMissingTasks(stage,jobId.get)&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;下面是 这个函数的代码，有点长。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def submitMissingTasks(stage: Stage, jobId: Int) {
  logDebug(&quot;submitMissingTasks(&quot; + stage + &quot;)&quot;)
  // Get our pending tasks and remember them in our pendingTasks entry
  stage.pendingPartitions.clear()

  // First figure out the indexes of partition ids to compute.
  val partitionsToCompute: Seq[Int] = stage.findMissingPartitions()

  // Use the scheduling pool, job group, description, etc. from an ActiveJob associated
  // with this Stage
  val properties = jobIdToActiveJob(jobId).properties

  runningStages += stage
  // SparkListenerStageSubmitted should be posted before testing whether tasks are
  // serializable. If tasks are not serializable, a SparkListenerStageCompleted event
  // will be posted, which should always come after a corresponding SparkListenerStageSubmitted
  // event.
  stage match {
    case s: ShuffleMapStage =&amp;gt;
      outputCommitCoordinator.stageStart(stage = s.id, maxPartitionId = s.numPartitions - 1)
    case s: ResultStage =&amp;gt;
      outputCommitCoordinator.stageStart(
        stage = s.id, maxPartitionId = s.rdd.partitions.length - 1)
  }
  val taskIdToLocations: Map[Int, Seq[TaskLocation]] = try {
    stage match {
      case s: ShuffleMapStage =&amp;gt;
        partitionsToCompute.map { id =&amp;gt; (id, getPreferredLocs(stage.rdd, id))}.toMap
      case s: ResultStage =&amp;gt;
        val job = s.activeJob.get
        partitionsToCompute.map { id =&amp;gt;
          val p = s.partitions(id)
          (id, getPreferredLocs(stage.rdd, p))
        }.toMap
    }
  } catch {
    case NonFatal(e) =&amp;gt;
      stage.makeNewStageAttempt(partitionsToCompute.size)
      listenerBus.post(SparkListenerStageSubmitted(stage.latestInfo, properties))
      abortStage(stage, s&quot;Task creation failed: $e\n${Utils.exceptionString(e)}&quot;, Some(e))
      runningStages -= stage
      return
  }

  stage.makeNewStageAttempt(partitionsToCompute.size, taskIdToLocations.values.toSeq)
  listenerBus.post(SparkListenerStageSubmitted(stage.latestInfo, properties))

  // TODO: Maybe we can keep the taskBinary in Stage to avoid serializing it multiple times.
  // Broadcasted binary for the task, used to dispatch tasks to executors. Note that we broadcast
  // the serialized copy of the RDD and for each task we will deserialize it, which means each
  // task gets a different copy of the RDD. This provides stronger isolation between tasks that
  // might modify state of objects referenced in their closures. This is necessary in Hadoop
  // where the JobConf/Configuration object is not thread-safe.
  var taskBinary: Broadcast[Array[Byte]] = null
  try {
    // For ShuffleMapTask, serialize and broadcast (rdd, shuffleDep).
    // For ResultTask, serialize and broadcast (rdd, func).
    val taskBinaryBytes: Array[Byte] = stage match {
      case stage: ShuffleMapStage =&amp;gt;
        JavaUtils.bufferToArray(
          closureSerializer.serialize((stage.rdd, stage.shuffleDep): AnyRef))
      case stage: ResultStage =&amp;gt;
        JavaUtils.bufferToArray(closureSerializer.serialize((stage.rdd, stage.func): AnyRef))
    }

    taskBinary = sc.broadcast(taskBinaryBytes)
  } catch {
    // In the case of a failure during serialization, abort the stage.
    case e: NotSerializableException =&amp;gt;
      abortStage(stage, &quot;Task not serializable: &quot; + e.toString, Some(e))
      runningStages -= stage

      // Abort execution
      return
    case NonFatal(e) =&amp;gt;
      abortStage(stage, s&quot;Task serialization failed: $e\n${Utils.exceptionString(e)}&quot;, Some(e))
      runningStages -= stage
      return
  }

  val tasks: Seq[Task[_]] = try {
    stage match {
      case stage: ShuffleMapStage =&amp;gt;
        partitionsToCompute.map { id =&amp;gt;
          val locs = taskIdToLocations(id)
          val part = stage.rdd.partitions(id)
          new ShuffleMapTask(stage.id, stage.latestInfo.attemptId,
            taskBinary, part, locs, stage.latestInfo.taskMetrics, properties)
        }

      case stage: ResultStage =&amp;gt;
        val job = stage.activeJob.get
        partitionsToCompute.map { id =&amp;gt;
          val p: Int = stage.partitions(id)
          val part = stage.rdd.partitions(p)
          val locs = taskIdToLocations(id)
          new ResultTask(stage.id, stage.latestInfo.attemptId,
            taskBinary, part, locs, id, properties, stage.latestInfo.taskMetrics)
        }
    }
  } catch {
    case NonFatal(e) =&amp;gt;
      abortStage(stage, s&quot;Task creation failed: $e\n${Utils.exceptionString(e)}&quot;, Some(e))
      runningStages -= stage
      return
  }

  if (tasks.size &amp;gt; 0) {
    logInfo(&quot;Submitting &quot; + tasks.size + &quot; missing tasks from &quot; + stage + &quot; (&quot; + stage.rdd + &quot;)&quot;)
    stage.pendingPartitions ++= tasks.map(_.partitionId)
    logDebug(&quot;New pending partitions: &quot; + stage.pendingPartitions)
    taskScheduler.submitTasks(new TaskSet(
      tasks.toArray, stage.id, stage.latestInfo.attemptId, jobId, properties))
    stage.latestInfo.submissionTime = Some(clock.getTimeMillis())
  } else {
    // Because we posted SparkListenerStageSubmitted earlier, we should mark
    // the stage as completed here in case there are no tasks to run
    markStageAsFinished(stage, None)

    val debugString = stage match {
      case stage: ShuffleMapStage =&amp;gt;
        s&quot;Stage ${stage} is actually done; &quot; +
          s&quot;(available: ${stage.isAvailable},&quot; +
          s&quot;available outputs: ${stage.numAvailableOutputs},&quot; +
          s&quot;partitions: ${stage.numPartitions})&quot;
      case stage : ResultStage =&amp;gt;
        s&quot;Stage ${stage} is actually done; (partitions: ${stage.numPartitions})&quot;
    }
    logDebug(debugString)
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;上面的代码出现了多次&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ResultStage&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ShuffleMapStage&lt;/code&gt;，先介绍一下这个stage。&lt;/p&gt;

&lt;p&gt;前面我们说过，WordCount只有一个job，然后reduceByKey是shuffle操作，以这个为stage的边界。那么前面的stage就是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ShuffleMapStage&lt;/code&gt;，后面的stage就是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ResultStage&lt;/code&gt;.因为前面会有shuffle操作，而后面是整个job的计算结果，所以叫ResultStage.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ResultStage&lt;/code&gt;是有一个函数，应用于rdd的一些partition来计算出这个action的结果。但有些action并不是在每个partition都执行的，比如&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;first()&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;接下来介绍下这个函数的执行流程。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;首先是计算出 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;paritionsToCompute&lt;/code&gt;，即用于计算的partition，数据。&lt;/li&gt;
  &lt;li&gt;然后就是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;outputCommitCoordinator.stageStart&lt;/code&gt;,这个类是用来输出到hdfs上的，然后stageStart的两个参数，就是用于发出信息，两个参数分别是stageId和他要用于计算的partition数目。&lt;/li&gt;
  &lt;li&gt;然后就是计算这个stage用于计算的TaskId对应的task所在的location。因为TaskId和partitionId是对应的，所以也就是计算partitionId对应的taskLocation。然后taskLocation是一个host或者是一个（host,executorId）二元组。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;stage.makeNewStageAttempt(partitionsToCompute.size, taskIdToLocations.values.toSeq)&lt;/code&gt;这里创建新的attempt 就是代表这个stage执行了几次。因为stage可能会失败的。如果失败就要接着执行，这个attempt从0开始。&lt;/li&gt;
  &lt;li&gt;然后就是创建广播变量，然后braocast。广播是用于executor来解析tasks。首先要序列化，给每个task都一个完整的rdd，这样可以让task独立性更强，这对于非线程安全是有必要的。对于ShuffleMapTask我们序列化的数据是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(rdd,shuffleDep)&lt;/code&gt;，对于resultTask,序列化数据为&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(rdd,func)&lt;/code&gt;。&lt;/li&gt;
  &lt;li&gt;然后是创建tasks，当然Tasks分为shuffleMapTask和resultTask，这都是跟stage类型对应的。这里创建tasks，需要用到一个参数&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;stage.latestInfo.attemptId&lt;/code&gt;,这里是前面提到的。&lt;/li&gt;
  &lt;li&gt;创建完tasks就是后面的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;taskScheduler.submitTasks()&lt;/code&gt;，这样任务就交由taskScheduler调度了。&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;override def submitTasks(taskSet: TaskSet) {
  val tasks = taskSet.tasks
  logInfo(&quot;Adding task set &quot; + taskSet.id + &quot; with &quot; + tasks.length + &quot; tasks&quot;)
  this.synchronized {
    val manager = createTaskSetManager(taskSet, maxTaskFailures)
    val stage = taskSet.stageId
    val stageTaskSets =
      taskSetsByStageIdAndAttempt.getOrElseUpdate(stage, new HashMap[Int, TaskSetManager])
    stageTaskSets(taskSet.stageAttemptId) = manager
    val conflictingTaskSet = stageTaskSets.exists { case (_, ts) =&amp;gt;
      ts.taskSet != taskSet &amp;amp;&amp;amp; !ts.isZombie
    }
    if (conflictingTaskSet) {
      throw new IllegalStateException(s&quot;more than one active taskSet for stage $stage:&quot; +
        s&quot; ${stageTaskSets.toSeq.map{_._2.taskSet.id}.mkString(&quot;,&quot;)}&quot;)
    }
    schedulableBuilder.addTaskSetManager(manager, manager.taskSet.properties)

    if (!isLocal &amp;amp;&amp;amp; !hasReceivedTask) {
      starvationTimer.scheduleAtFixedRate(new TimerTask() {
        override def run() {
          if (!hasLaunchedTask) {
            logWarning(&quot;Initial job has not accepted any resources; &quot; +
              &quot;check your cluster UI to ensure that workers are registered &quot; +
              &quot;and have sufficient resources&quot;)
          } else {
            this.cancel()
          }
        }
      }, STARVATION_TIMEOUT_MS, STARVATION_TIMEOUT_MS)
    }
    hasReceivedTask = true
  }
  backend.reviveOffers()
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这段代码前面部分就是先创建taskManager，然后判断是否有超过一个数目的tasks存在，如果冲突就报异常。&lt;/p&gt;

&lt;p&gt;然后把这个TaskSetManager加入&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;schedulableBuilder&lt;/code&gt;，这个变量在初始化时候会选择调度策略，比如fifo啥的，加入之后就会按照相应的策略进行调度。&lt;/p&gt;

&lt;p&gt;然后之后的判断是否为本地，和是否已经接收过任务，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;isLocal&lt;/code&gt;代表本地模式。如果非本地模式，而且还没接收到过任务，就会建立一个TimerTask，然后一直查看有没有接收到任务，因为如果没任务就是空转吗。&lt;/p&gt;

&lt;p&gt;最后backend就会让这个tasks唤醒。&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;backend.reviveOffers()&lt;/code&gt;,这里我们的backend通常是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CoarseGrainedSchedulerBackend&lt;/code&gt;，在执行reviveOffers之后，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;driverEndpoint&lt;/code&gt;会send消息，然后backend的receive函数会接收到消息，然后执行操作。看CoarseGrainedSchedulerBackend 的receive函数。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;override def receive: PartialFunction[Any, Unit] = {
...
case ReviveOffers =&amp;gt;
  makeOffers()
...
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def makeOffers() {
  // Filter out executors under killing
  val activeExecutors = executorDataMap.filterKeys(executorIsAlive)
  val workOffers = activeExecutors.map { case (id, executorData) =&amp;gt;
    new WorkerOffer(id, executorData.executorHost, executorData.freeCores)
  }.toSeq
  launchTasks(scheduler.resourceOffers(workOffers))
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;上面代码显示筛选出存活的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Executors&lt;/code&gt;，然后就创建出&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;workerOffers&lt;/code&gt;,参数是executorId,host,frescoers.&lt;/p&gt;

&lt;h3 id=&quot;执行task&quot;&gt;执行task###&lt;/h3&gt;

&lt;p&gt;然后就launchTasks。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def launchTasks(tasks: Seq[Seq[TaskDescription]]) {
  for (task &amp;lt;- tasks.flatten) {
    val serializedTask = ser.serialize(task)
    if (serializedTask.limit &amp;gt;= maxRpcMessageSize) {
      scheduler.taskIdToTaskSetManager.get(task.taskId).foreach { taskSetMgr =&amp;gt;
        try {
          var msg = &quot;Serialized task %s:%d was %d bytes, which exceeds max allowed: &quot; +
            &quot;spark.rpc.message.maxSize (%d bytes). Consider increasing &quot; +
            &quot;spark.rpc.message.maxSize or using broadcast variables for large values.&quot;
          msg = msg.format(task.taskId, task.index, serializedTask.limit, maxRpcMessageSize)
          taskSetMgr.abort(msg)
        } catch {
          case e: Exception =&amp;gt; logError(&quot;Exception in error callback&quot;, e)
        }
      }
    }
    else {
      val executorData = executorDataMap(task.executorId)
      executorData.freeCores -= scheduler.CPUS_PER_TASK

      logInfo(s&quot;Launching task ${task.taskId} on executor id: ${task.executorId} hostname: &quot; +
        s&quot;${executorData.executorHost}.&quot;)

      executorData.executorEndpoint.send(LaunchTask(new SerializableBuffer(serializedTask)))
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;上面的代码显示将task序列化，然后根据task.executorId 给他分配executor，然后就&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;executorData.executorEndpoint.send(LaunchTask(new SerializableBuffer(serializedTask)))&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;这里有一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;executorEndPoint&lt;/code&gt;,之前前面有driverEndPoint(出现在backend.reviveOffer那里)，这两个端口的基类都是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RpcEndpointRef&lt;/code&gt;。RpcEndpointRef是RpcEndPoint的远程引用，是线程安全的。&lt;/p&gt;

&lt;p&gt;RpcEndpoint是 RPC[Remote Procedure Call ：远程过程调用]中定义了收到的消息将触发哪个方法。&lt;/p&gt;

&lt;p&gt;同时清楚的阐述了生命周期，构造-&amp;gt; onStart -&amp;gt; receive* -&amp;gt; onStop&lt;/p&gt;

&lt;p&gt;这里receive* 是指receive 和 receiveAndReply。&lt;/p&gt;

&lt;p&gt;他们的区别是：&lt;/p&gt;

&lt;p&gt;receive是无需等待答复，而receiveAndReply是会阻塞线程，直至有答复的。(参考：http://www.07net01.com/2016/04/1434116.html)&lt;/p&gt;

&lt;p&gt;然后这里的driverEndPoint就是代表这个信息会发给&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CoarseGrainedSchedulerBackEnd&lt;/code&gt;，executorEndPoint就是发给&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;coarseGrainedExecutorBackEnd&lt;/code&gt;当然就是发给&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;coarseGrainedExecutorBackEnd&lt;/code&gt;。接下来去看相应的recieve代码。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;override def receive: PartialFunction[Any, Unit] = {
...

    case LaunchTask(data) =&amp;gt;
      if (executor == null) {
        exitExecutor(1, &quot;Received LaunchTask command but executor was null&quot;)
      } else {
        val taskDesc = ser.deserialize[TaskDescription](data.value)
        logInfo(&quot;Got assigned task &quot; + taskDesc.taskId)
        executor.launchTask(this, taskId = taskDesc.taskId, attemptNumber = taskDesc.attemptNumber,
          taskDesc.name, taskDesc.serializedTask)
      }
...
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里先将传过来的数据反序列化，然后&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;executor.launchTask&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def launchTask(
    context: ExecutorBackend,
    taskId: Long,
    attemptNumber: Int,
    taskName: String,
    serializedTask: ByteBuffer): Unit = {
  val tr = new TaskRunner(context, taskId = taskId, attemptNumber = attemptNumber, taskName,
    serializedTask)
  runningTasks.put(taskId, tr)
  threadPool.execute(tr)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里新建了taskRunner，然后之后交由线程池来运行，线程池既然要运行taskRunner，必定是运行taskRunner的run方法。看taskRunner的run方法，代码太长，懒得贴，大概描述下。&lt;/p&gt;

&lt;p&gt;主要就是设置参数，属性，反序列化出task等等，之后就要调用task.runTask方法。这里的task可能是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ShuffleMapTask&lt;/code&gt;也可能是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ResultTask&lt;/code&gt;，所以我们分别看这两种task的run方法。&lt;/p&gt;

&lt;h4 id=&quot;shufflemaptask&quot;&gt;ShuffleMapTask&lt;/h4&gt;

&lt;p&gt;先看&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ShuffleMapTask&lt;/code&gt;。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;override def runTask(context: TaskContext): MapStatus = {
  // Deserialize the RDD using the broadcast variable.
  val deserializeStartTime = System.currentTimeMillis()
  val ser = SparkEnv.get.closureSerializer.newInstance()
  val (rdd, dep) = ser.deserialize[(RDD[_], ShuffleDependency[_, _, _])](
    ByteBuffer.wrap(taskBinary.value), Thread.currentThread.getContextClassLoader)
  _executorDeserializeTime = System.currentTimeMillis() - deserializeStartTime

  var writer: ShuffleWriter[Any, Any] = null
  try {
    val manager = SparkEnv.get.shuffleManager
    writer = manager.getWriter[Any, Any](dep.shuffleHandle, partitionId, context)
    writer.write(rdd.iterator(partition, context).asInstanceOf[Iterator[_ &amp;lt;: Product2[Any, Any]]])
    writer.stop(success = true).get
  } catch {
    case e: Exception =&amp;gt;
      try {
        if (writer != null) {
          writer.stop(success = false)
        }
      } catch {
        case e: Exception =&amp;gt;
          log.debug(&quot;Could not stop writer&quot;, e)
      }
      throw e
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;前面部分代码就是反序列化那些，主要看中间的代码。获得shuffleManager,然后getWriter。因为shuffleMapTask有Shuffle操作，所以要shuffleWrite。&lt;/p&gt;

&lt;h4 id=&quot;resulttask&quot;&gt;ResultTask####&lt;/h4&gt;

&lt;p&gt;看下ResultTask的runTask。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  override def runTask(context: TaskContext): U = {
    // Deserialize the RDD and the func using the broadcast variables.
    val deserializeStartTime = System.currentTimeMillis()
    val ser = SparkEnv.get.closureSerializer.newInstance()
    val (rdd, func) = ser.deserialize[(RDD[T], (TaskContext, Iterator[T]) =&amp;gt; U)](
      ByteBuffer.wrap(taskBinary.value), Thread.currentThread.getContextClassLoader)
    _executorDeserializeTime = System.currentTimeMillis() - deserializeStartTime

    func(context, rdd.iterator(partition, context))
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;跟那个差不多，只不过不是shuffleWrite，是func.&lt;/p&gt;

&lt;h4 id=&quot;rdd-迭代链&quot;&gt;rdd 迭代链&lt;/h4&gt;

&lt;p&gt;看这行代码&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;writer.write(rdd.iterator(partition, context).asInstanceOf[Iterator[_ &amp;lt;: Product2[Any, Any]]])&lt;/code&gt;，看write方法里面的参数，rdd.iterator方法。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;final def iterator(split: Partition, context: TaskContext): Iterator[T] = {
  if (storageLevel != StorageLevel.NONE) {
    getOrCompute(split, context)
  } else {
    computeOrReadCheckpoint(split, context)
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这个方法，是从后面的rdd开始迭代，首先判断这个rdd是否是已经被cache。&lt;/p&gt;

&lt;p&gt;如果已经被cache，getOrCompute，直接get，或者如果没找到就重算一遍，这个代码比较简单，我就不贴了。&lt;/p&gt;

&lt;p&gt;如果没有被cache，则调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;computeOrReadCheckpoint&lt;/code&gt;。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private[spark] def computeOrReadCheckpoint(split: Partition, context: TaskContext): Iterator[T] =
{
  if (isCheckpointedAndMaterialized) {
    firstParent[T].iterator(split, context)
  } else {
    compute(split, context)
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;如果是检查点，先介绍下检查点。&lt;/p&gt;

&lt;h4 id=&quot;检查点&quot;&gt;检查点####&lt;/h4&gt;

&lt;p&gt;检查点机制的实现和持久化的实现有着较大的区别。检查点并非第一次计算就将结果进行存储，而是等到一个作业结束后启动专门的一个作业完成存储的操作。&lt;/p&gt;

&lt;p&gt;checkPoint操作的实现在RDD类中，&lt;em&gt;checkPoint&lt;/em&gt;方法会实例化ReliableRDDCheckpointData用于标记当前的RDD&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * Mark this RDD for checkpointing. It will be saved to a file inside the checkpoint
 * directory set with `SparkContext#setCheckpointDir` and all references to its parent
 * RDDs will be removed. This function must be called before any job has been
 * executed on this RDD. It is strongly recommended that this RDD is persisted in
 * memory, otherwise saving it on a file will require recomputation.
 */
def checkpoint(): Unit = RDDCheckpointData.synchronized {
  // NOTE: we use a global lock here due to complexities downstream with ensuring
  // children RDD partitions point to the correct parent partitions. In the future
  // we should revisit this consideration.
  if (context.checkpointDir.isEmpty) {
    throw new SparkException(&quot;Checkpoint directory has not been set in the SparkContext&quot;)
  } else if (checkpointData.isEmpty) {
    checkpointData = Some(new ReliableRDDCheckpointData(this))
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;RDDCheckpointData类内部有一个枚举类型 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CheckpointState &lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/** 
 * Enumeration to manage state transitions of an RDD through checkpointing 
 * [ Initialized --&amp;gt; checkpointing in progress --&amp;gt; checkpointed ]. 
 */  
private[spark] object CheckpointState extends Enumeration {  
  type CheckpointState = Value  
  val Initialized, CheckpointingInProgress, Checkpointed = Value  
} 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;用于表示RDD检查点的当前状态，其值有Initialized 、CheckpointingInProgress、 checkpointed。其转换过程如下
(1)Initialized状态&lt;/p&gt;

&lt;p&gt;该状态是实例化ReliableRDDCheckpointData后的默认状态，用于标记当前的RDD已经建立了检查点(较v1.4.x少一个MarkForCheckPiont状态)&lt;/p&gt;

&lt;p&gt;(2)CheckpointingInProgress状态&lt;/p&gt;

&lt;p&gt;每个作业结束后都会对作业的末RDD调用其doCheckPoint方法，该方法会顺着RDD的关系依赖链往前遍历，直到遇见内部RDDCheckpointData对象被标记为Initialized的为止，此时将RDD的RDDCheckpointData对象标记为CheckpointingInProgress，并启动一个作业完成数据的写入操作。&lt;/p&gt;

&lt;p&gt;(3)Checkpointed状态&lt;/p&gt;

&lt;p&gt;新启动作业完成数据写入操作之后，将建立检查点的RDD的所有依赖全部清除，将RDD内部的RDDCheckpointData对象标记为Checkpointed，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;将父RDD重新设置为一个CheckPointRDD对象，父RDD的compute方法会直接从系统中读取数据&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;如上只简单地介绍了相关概念，详细介绍请参看：&lt;a href=&quot;https://github.com/JerryLead/SparkInternals/blob/master/markdown/6-CacheAndCheckpoint.md&quot;&gt;https://github.com/JerryLead/SparkInternals/blob/master/markdown/6-CacheAndCheckpoint.md&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;compute-链&quot;&gt;compute 链&lt;/h3&gt;
&lt;p&gt;上面有检查点的就直接去父Rdd的compute读取数据了。而非检查点，就compute，compute是一个链。
拿&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MapPartitionsRDD&lt;/code&gt;举个例子，看看它的compute方法。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;override def compute(split: Partition, context: TaskContext): Iterator[U] =
f(context, split.index, firstParent[T].iterator(split, context))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;看这里 compute还是调用了iterator，所以还是接着往前找了，直到找到checkpoint或者就是到rdd头。&lt;/p&gt;

&lt;p&gt;再看看其他的rdd的compute方法吧。&lt;/p&gt;

&lt;p&gt;看看&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ShuffleRdd&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;override def compute(split: Partition, context: TaskContext): Iterator[(K, C)] = {
  val dep = dependencies.head.asInstanceOf[ShuffleDependency[K, V, C]]
  SparkEnv.get.shuffleManager.getReader(dep.shuffleHandle, split.index, split.index + 1, context)
    .read()
    .asInstanceOf[Iterator[(K, C)]]
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;然后这里shuffleRdd的compute方法就是从shuffle 那里read 数据，这算是一个stage的开始了。&lt;/p&gt;

&lt;p&gt;当然一个stage的开始未必是shuffleRead开始啦，比如textFile，它最终是返回一个HadoopRdd，然后他的compute方法，就是返回一个迭代器。&lt;/p&gt;

&lt;h2 id=&quot;参考&quot;&gt;参考##&lt;/h2&gt;

&lt;p&gt; &lt;a href=&quot;http://blog.csdn.net/jiangpeng59/article/details/53213694&quot;&gt;Spark核心RDD：计算函数compute&lt;/a&gt;&lt;/p&gt;

&lt;p&gt; &lt;a href=&quot;http://blog.csdn.net/jiangpeng59/article/details/53212416&quot;&gt;Spark基础随笔：持久化&amp;amp;检查点&lt;/a&gt;&lt;/p&gt;

</description>
                <link>http://www.turbofei.wang/spark/2016/12/22/spark%E5%BA%94%E7%94%A8%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B</link>
                <guid>http://www.turbofei.wang/spark/2016/12/22/spark应用执行流程</guid>
                <pubDate>2016-12-22T00:00:00-08:00</pubDate>
        </item>

        <item>
                <title>spark统一内存管理</title>
                <description>
&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;spark统一内存管理是spark1.6.0的新特性，是对shuffle memory 和 storage memory 进行统一的管理，打破了以往的参数限制。&lt;/p&gt;

&lt;h2 id=&quot;非统一内存管理&quot;&gt;非统一内存管理&lt;/h2&gt;

&lt;p&gt;spark在1.6 之前都是非统一内存管理，通过设置&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.shuffle.memoryFraction&lt;/code&gt; 和 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.storage.memoryFraction&lt;/code&gt;来设置shuffle 和storage的memory 大小。看下&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;StaticMemoryManager&lt;/code&gt;的获得最大shuffle和storage memory的函数。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def getMaxStorageMemory(conf: SparkConf): Long = {
  val systemMaxMemory = conf.getLong(&quot;spark.testing.memory&quot;, Runtime.getRuntime.maxMemory)
  val memoryFraction = conf.getDouble(&quot;spark.storage.memoryFraction&quot;, 0.6)
  val safetyFraction = conf.getDouble(&quot;spark.storage.safetyFraction&quot;, 0.9)
  (systemMaxMemory * memoryFraction * safetyFraction).toLong
}

/**
 * Return the total amount of memory available for the execution region, in bytes.
 */
private def getMaxExecutionMemory(conf: SparkConf): Long = {
  val systemMaxMemory = conf.getLong(&quot;spark.testing.memory&quot;, Runtime.getRuntime.maxMemory)
...
  val memoryFraction = conf.getDouble(&quot;spark.shuffle.memoryFraction&quot;, 0.2)
  val safetyFraction = conf.getDouble(&quot;spark.shuffle.safetyFraction&quot;, 0.8)
  (systemMaxMemory * memoryFraction * safetyFraction).toLong
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;可以看出，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;systemMaxMemory&lt;/code&gt;是通过参数&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.testing.memory&lt;/code&gt;来获得，如果这个参数没有设置，就取虚拟机内存，然后shuffle 和 storage都有安全系数，最后可用的最大内存都是：系统最大内存*比例系数*安全系数。&lt;/p&gt;

&lt;h2 id=&quot;统一内存管理&quot;&gt;统一内存管理&lt;/h2&gt;

&lt;p&gt;spark 1.6.0 出现了统一内存管理，是打破了shuffle 内存和storage内存的静态限制。通俗的描述，就是如果storage内存不够，而shuffle内存剩余就能借内存，如果shuffle内存不足，此时如果storage已经超出了&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;storageRegionSize&lt;/code&gt;，那么就驱逐当前使用storage内存-&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;storageRegionSize&lt;/code&gt;，如果storage 使用没有超过&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;storageRegionSize&lt;/code&gt;，那么则把它剩余的都可以借给shuffle使用。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  private def getMaxMemory(conf: SparkConf): Long = {
    val systemMemory = conf.getLong(&quot;spark.testing.memory&quot;, Runtime.getRuntime.maxMemory)
    val reservedMemory = conf.getLong(&quot;spark.testing.reservedMemory&quot;,
      if (conf.contains(&quot;spark.testing&quot;)) 0 else RESERVED_SYSTEM_MEMORY_BYTES)
    val minSystemMemory = (reservedMemory * 1.5).ceil.toLong
    if (systemMemory &amp;lt; minSystemMemory) {
      throw new IllegalArgumentException(s&quot;System memory $systemMemory must &quot; +
        s&quot;be at least $minSystemMemory. Please increase heap size using the --driver-memory &quot; +
        s&quot;option or spark.driver.memory in Spark configuration.&quot;)
    }
    // SPARK-12759 Check executor memory to fail fast if memory is insufficient
    if (conf.contains(&quot;spark.executor.memory&quot;)) {
      val executorMemory = conf.getSizeAsBytes(&quot;spark.executor.memory&quot;)
      if (executorMemory &amp;lt; minSystemMemory) {
        throw new IllegalArgumentException(s&quot;Executor memory $executorMemory must be at least &quot; +
          s&quot;$minSystemMemory. Please increase executor memory using the &quot; +
          s&quot;--executor-memory option or spark.executor.memory in Spark configuration.&quot;)
      }
    }
    val usableMemory = systemMemory - reservedMemory
    val memoryFraction = conf.getDouble(&quot;spark.memory.fraction&quot;, 0.6)
    (usableMemory * memoryFraction).toLong
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;这个是统一内存管理的获得最大内存的函数，因为shuffle和storage是统一管理的，所以只有一个获得统一最大内存的函数。&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;usableMemory = systemMemory - reservedMemory&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;最大内存=&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;usableMemory * memoryFraction&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;统一内存管理的使用&quot;&gt;统一内存管理的使用##&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UnifiedMemoryManager&lt;/code&gt;是在一个静态类里面的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;apply&lt;/code&gt;方法调用的。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def apply(conf: SparkConf, numCores: Int): UnifiedMemoryManager = {
  val maxMemory = getMaxMemory(conf)
  new UnifiedMemoryManager(
    conf,
    maxHeapMemory = maxMemory,
    onHeapStorageRegionSize =
      (maxMemory * conf.getDouble(&quot;spark.memory.storageFraction&quot;, 0.5)).toLong,
    numCores = numCores)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;然后通过 find Uages 找到是在 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sparkEnv&lt;/code&gt;里面调用。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;val memoryManager: MemoryManager =
  if (useLegacyMemoryManager) {
    new StaticMemoryManager(conf, numUsableCores)
  } else {
    UnifiedMemoryManager(conf, numUsableCores)
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;是通过判断参数，判断是使用统一内存管理还是非内存管理。&lt;/p&gt;

&lt;p&gt;然后通过查看usages 发现是在 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CoarseGrainedExecutorBackEnd&lt;/code&gt; 和 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MesosExecutorBackEnd&lt;/code&gt;里面调用的，所以是每个executor都有一个统一内存管理的实例(…很显然，逻辑也是这样)。&lt;/p&gt;
</description>
                <link>http://www.turbofei.wang/spark/2016/12/19/spark%E7%BB%9F%E4%B8%80%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86</link>
                <guid>http://www.turbofei.wang/spark/2016/12/19/spark统一内存管理</guid>
                <pubDate>2016-12-19T00:00:00-08:00</pubDate>
        </item>

        <item>
                <title>java unsafe类的使用</title>
                <description>
&lt;p&gt;&lt;strong&gt;Overview&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;最近在写堆外操作的代码，需要用到unsafe 类，记录下。&lt;/p&gt;

&lt;h1 id=&quot;unsafe-简介&quot;&gt;unsafe 简介&lt;/h1&gt;

&lt;p&gt;unsafe类位于 sun.misc包,之所以叫unsafe是因为他操作堆外内存，即不受JVM控制的内存。由于最近要做点把数据存储在堆外的工作，所以了解了下unsafe。&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;下面是关于unsafe做测试的代码。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-JAVA&quot;&gt;import sun.misc.Unsafe;

import java.lang.reflect.Field;

/**
 * Created by bbw on 2016/11/11.
 */
class cat{
    public Integer name;
    public Integer age;
    public cat(Integer name,Integer age){
        this.name=name;
        this.age=age;
    }

}
public class testUnSafe {
    private static int apple = 10;
    private int orange = 10;
    private int banana=10;
    public   cat ki=new cat(233,3);

 //这是获得对象里面对象field的方法，根据这个对象在类里面的偏移量来获得
    public Object getObject(long offset) throws SecurityException, NoSuchFieldException, IllegalArgumentException,
            IllegalAccessException{
        return getUnsafeInstance().getObject(this,offset);
    }


    public static void main(String[] args) throws Exception {
        Unsafe unsafe = getUnsafeInstance();
        testUnSafe tus=new testUnSafe();

        Field appleField = testUnSafe.class.getDeclaredField(&quot;apple&quot;);
        // 获得field的偏移量
        System.out.println(&quot;Location of Apple: &quot; + unsafe.staticFieldOffset(appleField));

        Field orangeField = testUnSafe.class.getDeclaredField(&quot;orange&quot;);
        System.out.println(&quot;Location of Orange: &quot; + unsafe.objectFieldOffset(orangeField));



//这是field 是一个cat类的实例化对象，根据他的便宜地址获得对象，然后强制类型转化
        Field catField = testUnSafe.class.getDeclaredField(&quot;ki&quot;);
        System.out.println(&quot;Location of cat: &quot; + unsafe.objectFieldOffset(catField));
        long offset=unsafe.objectFieldOffset(catField);
        Object rki=tus.getObject(offset);
        cat rrki=(cat)rki;
        System.out.println(rrki.name);

        // follow is addressTest
        cat ncat=new cat(333,444);
        cat ncat2=new cat(555,666);
        cat[] ca={ncat,ncat2};
        long catArrayOffset=unsafe.arrayBaseOffset(cat[].class);
        System.out.println(catArrayOffset+&quot; &quot;+unsafe.arrayIndexScale(cat[].class));
        //cat rncat=((cat[])(tus.getObject(catArrayOffset)))[0];
       // System.out.println(rncat.name+rncat.age);
        Field bananaField = testUnSafe.class.getDeclaredField(&quot;banana&quot;);
        System.out.println(&quot;Location of banana: &quot; + unsafe.objectFieldOffset(bananaField));
    }
    
    //获得unsafe 的方法，是单例模式
    private static Unsafe getUnsafeInstance() throws SecurityException, NoSuchFieldException, IllegalArgumentException,
            IllegalAccessException {
        Field theUnsafeInstance = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;);
        theUnsafeInstance.setAccessible(true);
        return (Unsafe) theUnsafeInstance.get(Unsafe.class);
    }
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;unsafe 是单例模式，所以全局就只有一个unsafe，必须用它提供的方法来获取。
然后里面有获得里面字段 和静态字段偏移地址的方法，偏移地址是相对于在这个对象里面的偏移地址，可以根据偏移地址获得这个field。
例如，我在这个类里面声明的 cat 类 field ，就可以根据它在对象里面偏移地址来取得这个类。&lt;/p&gt;

&lt;p&gt;至于如何获得方法里面变量的内存地址以及如何通过这个获得的内存地址来取得这个变量对象，我还不是很明白，只知道unsafe.arrayBaseOffset 来获得对象数据的偏移地址。&lt;/p&gt;

&lt;p&gt;下面是我写的一个静态类，可以用来实现unsafe的放置变量，并且可以把这块堆外内存里面存的数据转化为迭代器。
我是这样存数据的，首先是申请一块堆外内存，然后前四个字节存储这块内存的大小，然后紧接着四个字节存储已经使用的大小。然后存储数据的类型是从外部传进去的，0代表int,1代表long，2代表double。
然后每次在写入数据的时候，都会判断这块内存的大小够不够写入数据，如果不够就申请一个更大的内存，然后把原来的数据拷贝到新的内存里面，重新对这块内存的前八个字节赋值，即内存的大小和使用情况。
然后这个类的静态参数在每次传入内存的起始地址后会首先读取这块内存的前八个字节，获得内存大小以及使用情况。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-JAVA&quot;&gt;
package org.apache.spark.unsafe;
import java.util.Iterator;
/**
 * Created by bbw on 2016/11/14.
 */
public  final class UnsafeBuffer&amp;lt;T&amp;gt; {



    public  static int  MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;

    public static   int  hugeCapacity(int minCapacity) {
        if (minCapacity &amp;lt; 0) throw new OutOfMemoryError();
        if ((minCapacity &amp;gt; MAX_ARRAY_SIZE))
            return Integer.MAX_VALUE;
        else
            return MAX_ARRAY_SIZE;
        }


    public static long  copyBuf2New ( long baseAddress,int vType,int  minCapacity) {
        // read the size and count of this buf(the format size,count)
        int size=PlatformDependent.UNSAFE.getInt(null,baseAddress);
        int sizeCount=PlatformDependent.UNSAFE.getInt(null,baseAddress+4);



        long address = PlatformDependent.UNSAFE.allocateMemory(minCapacity);
        // write the size and count

        PlatformDependent.UNSAFE.putInt(null,address,minCapacity);
        PlatformDependent.UNSAFE.putInt(null,address+4,sizeCount);


        int   i= 8;
        switch (vType) {
            case 0 :
        while (i &amp;lt; sizeCount) {
        PlatformDependent.UNSAFE.putInt(null, address + i, PlatformDependent.UNSAFE.getInt(null, baseAddress + i));
        i = i + 4;
        }
            case 1 :
        while (i &amp;lt; sizeCount) {
        PlatformDependent.UNSAFE.putLong(null, address + i, PlatformDependent.UNSAFE.getLong(null, baseAddress + i));
        i = i + 8;
        }
            case 2 :
        while (i &amp;lt; sizeCount) {
        PlatformDependent.UNSAFE.putDouble(null, address + i, PlatformDependent.UNSAFE.getDouble(null, baseAddress + i));
        i = i + 8;
        }
        default:
            assert (1==0);
        }
        return address;

        }


        public static long putInt(long baseAddress, int vType,int value){
            int size=PlatformDependent.UNSAFE.getInt(null,baseAddress);
            int sizeCount=PlatformDependent.UNSAFE.getInt(null,baseAddress+4);

           long address= ensureCapacity(baseAddress,vType,sizeCount+4);

            PlatformDependent.UNSAFE.putInt(null,address+sizeCount,value);

            PlatformDependent.UNSAFE.putInt(null,address+4,sizeCount+4);

            return address;


        }
    public static long putLong(long baseAddress, int vType,long value){
        int size=PlatformDependent.UNSAFE.getInt(null,baseAddress);
        int sizeCount=PlatformDependent.UNSAFE.getInt(null,baseAddress+4);

        long address= ensureCapacity(baseAddress,vType,sizeCount+8);

        PlatformDependent.UNSAFE.putLong(null,address+sizeCount,value);

        PlatformDependent.UNSAFE.putInt(null,address+4,sizeCount+8);

        return address;


    }
    public static long putDouble(long baseAddress, int vType,double value){
        int size=PlatformDependent.UNSAFE.getInt(null,baseAddress);
        int sizeCount=PlatformDependent.UNSAFE.getInt(null,baseAddress+4);

        long address= ensureCapacity(baseAddress,vType,sizeCount+8);

        PlatformDependent.UNSAFE.putDouble(null,address+sizeCount,value);

        PlatformDependent.UNSAFE.putInt(null,address+4,sizeCount+8);

        return address;


    }


public  static long grow (long  baseAddress,int vType,int minCapacity) {

    int size=PlatformDependent.UNSAFE.getInt(null,baseAddress);
    int sizeCount=PlatformDependent.UNSAFE.getInt(null,baseAddress+4);
        int  oldCapacity=size;
        int  newCapacity = oldCapacity &amp;lt;&amp;lt; 1;
        if (newCapacity - minCapacity &amp;lt; 0) newCapacity = minCapacity;
        if (newCapacity - MAX_ARRAY_SIZE &amp;gt; 0) newCapacity = hugeCapacity(minCapacity);
        //buf = Arrays.copyOf(buf, newCapacity)
        //重新分配空间
        // baseAddress=PlatformDependent.UNSAFE.allocateMemory(newCapacity)
        long  temp=copyBuf2New(baseAddress,vType,minCapacity);
        PlatformDependent.UNSAFE.freeMemory(baseAddress);

    return temp;
}

    public static  long   ensureCapacity (long baseAddress,int vType,int minCapacity) {

    int size=PlatformDependent.UNSAFE.getInt(null,baseAddress);
    int sizeCount=PlatformDependent.UNSAFE.getInt(null,baseAddress+4);


        if (minCapacity - size &amp;gt; 0)
           return grow(baseAddress,vType,minCapacity);
    else return baseAddress;
}




    public static   Iterator&amp;lt;Integer&amp;gt; intIterator( long baseAddress) {
        // int size=PlatformDependent.UNSAFE.getInt(null,baseAddress);
        final int sizeCount = PlatformDependent.UNSAFE.getInt(null, baseAddress + 4);
        final long address = baseAddress;
        return new Iterator&amp;lt;Integer&amp;gt;() {
            int offset = 8;

            @Override
            public boolean hasNext() {
                if (offset &amp;lt; sizeCount)
                    return true;
                else {
                    PlatformDependent.UNSAFE.freeMemory(address);
                    return false;
                }
            }

            @Override
            public Integer next() {
                offset += 4;
                return PlatformDependent.UNSAFE.getInt(null, address + offset - 4);
            }
        };
    }

    public static   Iterator&amp;lt;Long&amp;gt; longIterator( long baseAddress) {
        // int size=PlatformDependent.UNSAFE.getInt(null,baseAddress);
        final int sizeCount = PlatformDependent.UNSAFE.getInt(null, baseAddress + 4);
        final long address = baseAddress;
        return new Iterator&amp;lt;Long&amp;gt;() {
            int offset = 8;

            @Override
            public boolean hasNext() {
                if (offset &amp;lt; sizeCount)
                    return true;
                else {
                    PlatformDependent.UNSAFE.freeMemory(address);
                    return false;
                }
            }

            @Override
            public Long next() {
                offset += 8;
                return PlatformDependent.UNSAFE.getLong(null, address + offset - 8);
            }
        };
    }

    public static   Iterator&amp;lt;Double&amp;gt; doubleIterator( long baseAddress) {
        // int size=PlatformDependent.UNSAFE.getInt(null,baseAddress);
        final int sizeCount = PlatformDependent.UNSAFE.getInt(null, baseAddress + 4);
        final long address = baseAddress;
        return new Iterator&amp;lt;Double&amp;gt;() {
            int offset = 8;

            @Override
            public boolean hasNext() {
                if (offset &amp;lt; sizeCount)
                    return true;
                else {
                    PlatformDependent.UNSAFE.freeMemory(address);
                    return false;
                }
            }

            @Override
            public Double next() {
                offset += 8;
                return PlatformDependent.UNSAFE.getDouble(null, address + offset - 8);
            }
        };
    }


    public static  long createBuff(int size){
        long address=PlatformDependent.UNSAFE.allocateMemory(size);
        PlatformDependent.UNSAFE.putInt(null,address,size);
        PlatformDependent.UNSAFE.putInt(null,address+4,8);
        return address;
    }
}

&lt;/code&gt;&lt;/pre&gt;
</description>
                <link>http://www.turbofei.wang/coding/2016/11/12/java-unsafe%E7%B1%BB%E7%9A%84%E4%BD%BF%E7%94%A8</link>
                <guid>http://www.turbofei.wang/coding/2016/11/12/java-unsafe类的使用</guid>
                <pubDate>2016-11-12T16:24:19-08:00</pubDate>
        </item>

        <item>
                <title>ganglia 安装</title>
                <description>
&lt;p&gt;&lt;strong&gt;Overview&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;最近帮大菠萝安装ganglia，记录下，方便以后安装。&lt;/p&gt;

&lt;h1 id=&quot;cluster-server-and-clients&quot;&gt;Cluster Server and Clients&lt;/h1&gt;

&lt;p&gt;I configured our nodes with the following hostnames using these steps. Our server is:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;3.buhpc.com
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The clients are:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1.buhpc.com
2.buhpc.com
4.buhpc.com
5.buhpc.com
6.buhpc.com
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;!--more--&gt;

&lt;h1 id=&quot;installation&quot;&gt;Installation&lt;/h1&gt;

&lt;p&gt;On the server, inside the shared folder of our cluster, we will first download the latest version of ganglia. For our cluster, /nfs is the folder with our network file system.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd /nfs
wget http://downloads.sourceforge.net/project/ganglia/ganglia%20monitoring%20core/3.7.2/ganglia-3.7.2.tar.gz
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;On the server, we will install dependencies and libconfuse.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;yum install freetype-devel rpm-build php httpd libpng-devel libart_lgpl-devel python-devel pcre-devel autoconf automake libtool expat-devel rrdtool-devel apr-devel gcc-c++ make pkgconfig -y
yum install https://dl.fedoraproject.org/pub/epel/7/x86_64/l/libconfuse-2.7-7.el7.x86_64.rpm -y
yum install https://dl.fedoraproject.org/pub/epel/7/x86_64/l/libconfuse-devel-2.7-7.el7.x86_64.rpm -y

#建立rrd数据库
mkdir -p /var/lib/ganglia/rrds/
chown nobody:nobody -R /var/lib/ganglia/rrds/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now, we will build the rpms from ganglia-3.7.2 on the server.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rpmbuild -tb ganglia-3.7.2.tar.gz
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;After running rpmbuild, /root/rpmbuild/RPMS/x86_64 contains the generated rpms:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd /root/rpmbuild/RPMS/x86_64/
yum install *ganglia*.rpm -y
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;We will remove gmetad because we do not need it on the clients. Send the rest of the rpms to all the clients’ /tmp folder:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd /root/rpmbuild/RPMS/x86_64/
rm -rf ganglia-gmetad*.rpm
scp *.rpm root@1.buhpc.com:/tmp
scp *.rpm root@2.buhpc.com:/tmp
scp *.rpm root@4.buhpc.com:/tmp
scp *.rpm root@5.buhpc.com:/tmp
scp *.rpm root@6.buhpc.com:/tmp
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;SSH onto every client and install the rpms that we will need:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ssh root@#.buhpc.com
yum install https://dl.fedoraproject.org/pub/epel/7/x86_64/l/libconfuse-2.7-7.el7.x86_64.rpm -y
yum install https://dl.fedoraproject.org/pub/epel/7/x86_64/l/libconfuse-devel-2.7-7.el7.x86_64.rpm -y
yum install /tmp/*ganglia*.rpm - y
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Back on the server, we will adjust the gmetad configuration file:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd /etc/ganglia
vim gmetad.conf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;buhpc will be the name of  our cluster. Find the following line and add the name of your cluster and ip address. I am using the subdomain instead of the ip address.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;data_source &quot;buhpc&quot; 1 3.buhpc.com
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Now, we edit the server’s gmond configuration file.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;vim /etc/ganglia/gmond.conf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Make sure that these sections have the following and comment any extra lines you see that are within each section.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cluster {
  name = &quot;buhpc&quot;
  owner = &quot;unspecified&quot;
  latlong = &quot;unspecified&quot;
  url = &quot;unspecified&quot;
}

udp_send_channel {
  host = 1.buhpc.com
  port = 8649
  ttl = 1
}

udp_send_channel {
  host = 2.buhpc.com
  port = 8649
  ttl = 1
}

udp_send_channel {
  host = 3.buhpc.com
  port = 8649
  ttl = 1
}
udp_send_channel {
  host = 4.buhpc.com
  port = 8649
  ttl = 1
}

udp_send_channel {
  host = 5.buhpc.com
  port = 8649
  ttl = 1
}

udp_send_channel {
  host = 6.buhpc.com
  port = 8649
  ttl = 1
}

udp_recv_channel {
  port = 8649
  retry_bind = true
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Now, SSH into each of the clients and do the following individually. On every client:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;vim /etc/ganglia/gmond.conf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;We will change the clients’ gmond.conf in the same way as the server’s.  Make sure that these sections have the following lines and comment any extra lines you see that are within each section.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cluster {
  name = &quot;buhpc&quot;
  owner = &quot;unspecified&quot;
  latlong = &quot;unspecified&quot;
  url = &quot;unspecified&quot;
}

udp_send_channel {
  host = 1.buhpc.com
  port = 8649
  ttl = 1
}

udp_send_channel {
  host = 2.buhpc.com
  port = 8649
  ttl = 1
}

udp_send_channel {
  host = 3.buhpc.com
  port = 8649
  ttl = 1
}
udp_send_channel {
  host = 4.buhpc.com
  port = 8649
  ttl = 1
}

udp_send_channel {
  host = 5.buhpc.com
  port = 8649
  ttl = 1
}

udp_send_channel {
  host = 6.buhpc.com
  port = 8649
  ttl = 1
}

udp_recv_channel {
  port = 8649
  retry_bind = true
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;We will start gmond on the clients for monitoring.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;chkconfig gmond on
systemctl start gmond
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;然后，安装ganglia-web 3.7.1&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;wget http://superb-sea2.dl.sourceforge.net/project/ganglia/ganglia-web/3.7.1/ganglia-web-3.7.1.tar.gz
tar zxvf  ganglia-web-3.7.1.tar.gz
cd  ganglia-web-3.7.1
vim Makefile
      # Location where gweb should be installed to (excluding conf, dwoo dirs).
      GDESTDIR = /var/www/html/ganglia

      # Gweb statedir (where conf dir and Dwoo templates dir are stored)
      GWEB_STATEDIR = /var/lib/ganglia-web

      # Gmetad rootdir (parent location of rrd folder)
      GMETAD_ROOTDIR = /var/lib/ganglia

      # User by which your webserver is running
      APACHE_USER =  apache

 make install
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Next, we will want to disable SELinux. Change SELINUX inside /etc/sysconfig/selinux from enforcing to disabled. Then, restart the server node.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;vim /etc/sysconfig/selinux
SELINUX=disabled
#如果 SELINUX本就是disable，不必reboot
reboot
Now, on the server, we’ll open the correct ports on the firewall.

#如果 firewall 没有打开，systemctl service firewalld
firewall-cmd --permanent --zone=public --add-service=http
firewall-cmd --permanent --zone=public --add-port=8649/udp
firewall-cmd --permanent --zone=public --add-port=8649/tcp
firewall-cmd --permanent --zone=public --add-port=8651/tcp
firewall-cmd --permanent --zone=public --add-port=8652/tcp
firewall-cmd --reload
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;On the server, we will now start httpd, gmetad, and gmond.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;chkconfig httpd
chkconfig gmetad on
chkconfig gmond on
systemctl start httpd
systemctl start gmetad
systemctl start gmond
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Visit http://3.buhpc.com/ganglia to see Ganglia’s monitoring. You should see something like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.slothparadise.com/wp-content/uploads/2016/03/ganglia-home-page.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

</description>
                <link>http://www.turbofei.wang/bigdata/2016/08/16/ganglia-%E5%AE%89%E8%A3%85</link>
                <guid>http://www.turbofei.wang/bigdata/2016/08/16/ganglia-安装</guid>
                <pubDate>2016-08-16T14:15:03-07:00</pubDate>
        </item>

        <item>
                <title>[转载] 详细探究Spark的shuffle实现</title>
                <description>&lt;p&gt;本文转自&lt;a href=&quot;https://github.com/jerryshao/jerryshao.github.com&quot;&gt;Jerryshao Blog&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;

&lt;p&gt;在MapReduce框架中，shuffle是连接Map和Reduce之间的桥梁，Map的输出要用到Reduce中必须经过shuffle这个环节，shuffle的性能高低直接影响了整个程序的性能和吞吐量。Spark作为MapReduce框架的一种实现，自然也实现了shuffle的逻辑，本文就深入研究Spark的shuffle是如何实现的，有什么优缺点，与Hadoop MapReduce的shuffle有什么不同。&lt;/p&gt;

&lt;h2 id=&quot;shuffle&quot;&gt;Shuffle&lt;/h2&gt;

&lt;p&gt;Shuffle是MapReduce框架中的一个特定的phase，介于Map phase和Reduce phase之间，当Map的输出结果要被Reduce使用时，输出结果需要按key哈希，并且分发到每一个Reducer上去，这个过程就是shuffle。由于shuffle涉及到了磁盘的读写和网络的传输，因此shuffle性能的高低直接影响到了整个程序的运行效率。&lt;/p&gt;

&lt;p&gt;下面这幅图清晰地描述了MapReduce算法的整个流程，其中shuffle phase是介于Map phase和Reduce phase之间。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2014-01-04-spark-shuffle/mapreduce-process.jpg&quot; alt=&quot;mapreduce running process&quot; width=&quot;640&quot; /&gt;&lt;/p&gt;

&lt;p&gt;概念上shuffle就是一个沟通数据连接的桥梁，那么实际上shuffle这一部分是如何实现的的呢，下面我们就以Spark为例讲一下shuffle在Spark中的实现。&lt;/p&gt;

&lt;h2 id=&quot;spark-shuffle进化史&quot;&gt;Spark Shuffle进化史&lt;/h2&gt;

&lt;p&gt;先以图为例简单描述一下Spark中shuffle的整一个流程：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2014-01-04-spark-shuffle/spark-shuffle.png&quot; alt=&quot;spark shuffle process&quot; width=&quot;640&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;首先每一个Mapper会根据Reducer的数量创建出相应的bucket，bucket的数量是\(M \times R\)，其中\(M\)是Map的个数，\(R\)是Reduce的个数。&lt;/li&gt;
  &lt;li&gt;其次Mapper产生的结果会根据设置的partition算法填充到每个bucket中去。这里的partition算法是可以自定义的，当然默认的算法是根据key哈希到不同的bucket中去。&lt;/li&gt;
  &lt;li&gt;当Reducer启动时，它会根据自己task的id和所依赖的Mapper的id从远端或是本地的block manager中取得相应的bucket作为Reducer的输入进行处理。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这里的bucket是一个抽象概念，在实现中每个bucket可以对应一个文件，可以对应文件的一部分或是其他等。&lt;/p&gt;

&lt;p&gt;接下来我们分别从&lt;strong&gt;shuffle write&lt;/strong&gt;和&lt;strong&gt;shuffle fetch&lt;/strong&gt;这两块来讲述一下Spark的shuffle进化史。&lt;/p&gt;

&lt;h3 id=&quot;shuffle-write&quot;&gt;Shuffle Write&lt;/h3&gt;

&lt;p&gt;在Spark 0.6和0.7的版本中，对于shuffle数据的存储是以文件的方式存储在block manager中，与&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rdd.persist(StorageLevel.DISk_ONLY)&lt;/code&gt;采取相同的策略，可以参看：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;override def run(attemptId: Long): MapStatus = {
  val numOutputSplits = dep.partitioner.numPartitions

  ...
    // Partition the map output.
    val buckets = Array.fill(numOutputSplits)(new ArrayBuffer[(Any, Any)])
    for (elem &amp;lt;- rdd.iterator(split, taskContext)) {
      val pair = elem.asInstanceOf[(Any, Any)]
      val bucketId = dep.partitioner.getPartition(pair._1)
      buckets(bucketId) += pair
    }

    ...

    val blockManager = SparkEnv.get.blockManager
    for (i &amp;lt;- 0 until numOutputSplits) {
      val blockId = &quot;shuffle_&quot; + dep.shuffleId + &quot;_&quot; + partition + &quot;_&quot; + i
      // Get a Scala iterator from Java map
      val iter: Iterator[(Any, Any)] = buckets(i).iterator
      val size = blockManager.put(blockId, iter, StorageLevel.DISK_ONLY, false)
      totalBytes += size
    }
  ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;我已经将一些干扰代码删去。可以看到Spark在每一个Mapper中为每个Reducer创建一个bucket，并将RDD计算结果放进bucket中。需要注意的是每个bucket是一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ArrayBuffer&lt;/code&gt;，也就是说Map的输出结果是会先存储在内存。&lt;/p&gt;

&lt;p&gt;接着Spark会将ArrayBuffer中的Map输出结果写入block manager所管理的磁盘中，这里文件的命名方式为：
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;shuffle_ + shuffle_id + &quot;_&quot; + map partition id + &quot;_&quot; + shuffle partition id&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;早期的shuffle write有两个比较大的问题：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Map的输出必须先全部存储到内存中，然后写入磁盘。这对内存是一个非常大的开销，当内存不足以存储所有的Map output时就会出现OOM。&lt;/li&gt;
  &lt;li&gt;每一个Mapper都会产生Reducer number个shuffle文件，如果Mapper个数是1k，Reducer个数也是1k，那么就会产生1M个shuffle文件，这对于文件系统是一个非常大的负担。同时在shuffle数据量不大而shuffle文件又非常多的情况下，随机写也会严重降低IO的性能。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;在Spark 0.8版本中，shuffle write采用了与RDD block write不同的方式，同时也为shuffle write单独创建了&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ShuffleBlockManager&lt;/code&gt;，部分解决了0.6和0.7版本中遇到的问题。&lt;/p&gt;

&lt;p&gt;首先我们来看一下Spark 0.8的具体实现：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;override def run(attemptId: Long): MapStatus = {

  ...

  val blockManager = SparkEnv.get.blockManager
  var shuffle: ShuffleBlocks = null
  var buckets: ShuffleWriterGroup = null

  try {
    // Obtain all the block writers for shuffle blocks.
    val ser = SparkEnv.get.serializerManager.get(dep.serializerClass)
    shuffle = blockManager.shuffleBlockManager.forShuffle(dep.shuffleId, numOutputSplits, ser)
    buckets = shuffle.acquireWriters(partition)

    // Write the map output to its associated buckets.
    for (elem &amp;lt;- rdd.iterator(split, taskContext)) {
      val pair = elem.asInstanceOf[Product2[Any, Any]]
      val bucketId = dep.partitioner.getPartition(pair._1)
      buckets.writers(bucketId).write(pair)
    }

    // Commit the writes. Get the size of each bucket block (total block size).
    var totalBytes = 0L
    val compressedSizes: Array[Byte] = buckets.writers.map { writer:   BlockObjectWriter =&amp;gt;
      writer.commit()
      writer.close()
      val size = writer.size()
      totalBytes += size
      MapOutputTracker.compressSize(size)
    }

    ...

  } catch { case e: Exception =&amp;gt;
    // If there is an exception from running the task, revert the partial writes
    // and throw the exception upstream to Spark.
    if (buckets != null) {
      buckets.writers.foreach(_.revertPartialWrites())
    }
    throw e
  } finally {
    // Release the writers back to the shuffle block manager.
    if (shuffle != null &amp;amp;&amp;amp; buckets != null) {
      shuffle.releaseWriters(buckets)
    }
    // Execute the callbacks on task completion.
    taskContext.executeOnCompleteCallbacks()
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在这个版本中为shuffle write添加了一个新的类&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ShuffleBlockManager&lt;/code&gt;，由&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ShuffleBlockManager&lt;/code&gt;来分配和管理bucket。同时&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ShuffleBlockManager&lt;/code&gt;为每一个bucket分配一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DiskObjectWriter&lt;/code&gt;，每个write handler拥有默认100KB的缓存，使用这个write handler将Map output写入文件中。可以看到现在的写入方式变为&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;buckets.writers(bucketId).write(pair)&lt;/code&gt;，也就是说Map output的key-value pair是逐个写入到磁盘而不是预先把所有数据存储在内存中在整体flush到磁盘中去。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ShuffleBlockManager&lt;/code&gt;的代码如下所示：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private[spark]
class ShuffleBlockManager(blockManager: BlockManager) {

  def forShuffle(shuffleId: Int, numBuckets: Int, serializer: Serializer): ShuffleBlocks = {
    new ShuffleBlocks {
      // Get a group of writers for a map task.
      override def acquireWriters(mapId: Int): ShuffleWriterGroup = {
        val bufferSize = System.getProperty(&quot;spark.shuffle.file.buffer.kb&quot;, &quot;100&quot;).toInt * 1024
        val writers = Array.tabulate[BlockObjectWriter](numBuckets) { bucketId =&amp;gt;
          val blockId = ShuffleBlockManager.blockId(shuffleId, bucketId, mapId)
          blockManager.getDiskBlockWriter(blockId, serializer, bufferSize)
        }
        new ShuffleWriterGroup(mapId, writers)
      }

      override def releaseWriters(group: ShuffleWriterGroup) = {
        // Nothing really to release here.
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Spark 0.8显著减少了shuffle的内存压力，现在Map output不需要先全部存储在内存中，再flush到硬盘，而是record-by-record写入到磁盘中。同时对于shuffle文件的管理也独立出新的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ShuffleBlockManager&lt;/code&gt;进行管理，而不是与rdd cache文件在一起了。&lt;/p&gt;

&lt;p&gt;但是这一版Spark 0.8的shuffle write仍然有两个大的问题没有解决：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;首先依旧是shuffle文件过多的问题，shuffle文件过多一是会造成文件系统的压力过大，二是会降低IO的吞吐量。&lt;/li&gt;
  &lt;li&gt;其次虽然Map output数据不再需要预先在内存中evaluate显著减少了内存压力，但是新引入的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DiskObjectWriter&lt;/code&gt;所带来的buffer开销也是一个不容小视的内存开销。假定我们有1k个Mapper和1k个Reducer，那么就会有1M个bucket，于此同时就会有1M个write handler，而每一个write handler默认需要100KB内存，那么总共需要100GB的内存。这样的话仅仅是buffer就需要这么多的内存，内存的开销是惊人的。当然实际情况下这1k个Mapper是分时运行的话，所需的内存就只有&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cores * reducer numbers * 100KB&lt;/code&gt;大小了。但是reducer数量很多的话，这个buffer的内存开销也是蛮厉害的。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;为了解决shuffle文件过多的情况，Spark 0.8.1引入了新的shuffle consolidation，以期显著减少shuffle文件的数量。&lt;/p&gt;

&lt;p&gt;首先我们以图例来介绍一下shuffle consolidation的原理。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2014-01-04-spark-shuffle/spark-shuffle-consolidate.png&quot; alt=&quot;spark shuffle  consolidation process&quot; width=&quot;640&quot; /&gt;&lt;/p&gt;

&lt;p&gt;假定该job有4个Mapper和4个Reducer，有2个core，也就是能并行运行两个task。我们可以算出Spark的shuffle write共需要16个bucket，也就有了16个write handler。在之前的Spark版本中，每一个bucket对应的是一个文件，因此在这里会产生16个shuffle文件。&lt;/p&gt;

&lt;p&gt;而在shuffle consolidation中每一个bucket并非对应一个文件，而是对应文件中的一个segment，同时shuffle consolidation所产生的shuffle文件数量与Spark core的个数也有关系。在上面的图例中，job的4个Mapper分为两批运行，在第一批2个Mapper运行时会申请8个bucket，产生8个shuffle文件；而在第二批Mapper运行时，申请的8个bucket并不会再产生8个新的文件，而是追加写到之前的8个文件后面，这样一共就只有8个shuffle文件，而在文件内部这有16个不同的segment。因此从理论上讲shuffle consolidation所产生的shuffle文件数量为\(C \times R\)，其中\(C\)是Spark集群的core number，\(R\)是Reducer的个数。&lt;/p&gt;

&lt;p&gt;需要注意的是当 \(M=C\)时shuffle consolidation所产生的文件数和之前的实现是一样的。&lt;/p&gt;

&lt;p&gt;Shuffle consolidation显著减少了shuffle文件的数量，解决了之前版本一个比较严重的问题，但是writer handler的buffer开销过大依然没有减少，若要减少writer handler的buffer开销，我们只能减少Reducer的数量，但是这又会引入新的问题，下文将会有详细介绍。&lt;/p&gt;

&lt;p&gt;讲完了shuffle write的进化史，接下来要讲一下shuffle fetch了，同时还要讲一下Spark的aggregator，这一块对于Spark实际应用的性能至关重要。&lt;/p&gt;

&lt;h3 id=&quot;shuffle-fetch-and-aggregator&quot;&gt;Shuffle Fetch and Aggregator&lt;/h3&gt;

&lt;p&gt;Shuffle write写出去的数据要被Reducer使用，就需要shuffle fetcher将所需的数据fetch过来，这里的fetch包括本地和远端，因为shuffle数据有可能一部分是存储在本地的。Spark对shuffle fetcher实现了两套不同的框架：NIO通过socket连接去fetch数据；OIO通过netty server去fetch数据。分别对应的类是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BasicBlockFetcherIterator&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NettyBlockFetcherIterator&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;在Spark 0.7和更早的版本中，只支持&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BasicBlockFetcherIterator&lt;/code&gt;，而&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BasicBlockFetcherIterator&lt;/code&gt;在shuffle数据量比较大的情况下performance始终不是很好，无法充分利用网络带宽，为了解决这个问题，添加了新的shuffle fetcher来试图取得更好的性能。对于早期shuffle性能的评测可以参看&lt;a href=&quot;https://groups.google.com/forum/#!msg/shark-users/IHOb2u5HXSk/huTWyosI1n4J&quot;&gt;Spark usergroup&lt;/a&gt;。当然现在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BasicBlockFetcherIterator&lt;/code&gt;的性能也已经好了很多，使用的时候可以对这两种实现都进行测试比较。&lt;/p&gt;

&lt;p&gt;接下来说一下aggregator。我们都知道在Hadoop MapReduce的shuffle过程中，shuffle fetch过来的数据会进行merge sort，使得相同key下的不同value按序归并到一起供Reducer使用，这个过程可以参看下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2014-01-04-spark-shuffle/mapreduce-shuffle.png&quot; alt=&quot;mapreduce shuffle process&quot; width=&quot;640&quot; /&gt;&lt;/p&gt;

&lt;p&gt;所有的merge sort都是在磁盘上进行的，有效地控制了内存的使用，但是代价是更多的磁盘IO。&lt;/p&gt;

&lt;p&gt;那么Spark是否也有merge sort呢，还是以别的方式实现，下面我们就细细说明。&lt;/p&gt;

&lt;p&gt;首先虽然Spark属于MapReduce体系，但是对传统的MapReduce算法进行了一定的改变。Spark假定在大多数用户的case中，shuffle数据的sort不是必须的，比如word count，强制地进行排序只会使性能变差，因此Spark并不在Reducer端做merge sort。既然没有merge sort那Spark是如何进行reduce的呢？这就要说到aggregator了。&lt;/p&gt;

&lt;p&gt;aggregator本质上是一个hashmap，它是以map output的key为key，以任意所要combine的类型为value的hashmap。当我们在做word count reduce计算count值的时候，它会将shuffle fetch到的每一个key-value pair更新或是插入到hashmap中(若在hashmap中没有查找到，则插入其中；若查找到则更新value值)。这样就不需要预先把所有的key-value进行merge sort，而是来一个处理一个，省下了外部排序这一步骤。但同时需要注意的是reducer的内存必须足以存放这个partition的所有key和count值，因此对内存有一定的要求。&lt;/p&gt;

&lt;p&gt;在上面word count的例子中，因为value会不断地更新，而不需要将其全部记录在内存中，因此内存的使用还是比较少的。考虑一下如果是group by key这样的操作，Reducer需要得到key对应的所有value。在Hadoop MapReduce中，由于有了merge sort，因此给予Reducer的数据已经是group by key了，而Spark没有这一步，因此需要将key和对应的value全部存放在hashmap中，并将value合并成一个array。可以想象为了能够存放所有数据，用户必须确保每一个partition足够小到内存能够容纳，这对于内存是一个非常严峻的考验。因此Spark文档中建议用户涉及到这类操作的时候尽量增加partition，也就是增加Mapper和Reducer的数量。&lt;/p&gt;

&lt;p&gt;增加Mapper和Reducer的数量固然可以减小partition的大小，使得内存可以容纳这个partition。但是我们在shuffle write中提到，bucket和对应于bucket的write handler是由Mapper和Reducer的数量决定的，task越多，bucket就会增加的更多，由此带来write handler所需的buffer也会更多。在一方面我们为了减少内存的使用采取了增加task数量的策略，另一方面task数量增多又会带来buffer开销更大的问题，因此陷入了内存使用的两难境地。&lt;/p&gt;

&lt;p&gt;为了减少内存的使用，只能将aggregator的操作从内存移到磁盘上进行，Spark社区也意识到了Spark在处理数据规模远远大于内存大小时所带来的问题。因此&lt;a href=&quot;https://github.com/apache/incubator-spark/pull/303&quot;&gt;PR303&lt;/a&gt;提供了外部排序的实现方案，相信在Spark 0.9 release的时候，这个patch应该能merge进去，到时候内存的使用量可以显著地减少。&lt;/p&gt;

&lt;h2 id=&quot;end&quot;&gt;End&lt;/h2&gt;

&lt;p&gt;本文详细地介绍了Spark的shuffle实现是如何进化的，以及遇到问题解决问题的过程。shuffle作为Spark程序中很重要的一个环节，直接影响了Spark程序的性能，现如今的Spark版本虽然shuffle实现还存在着种种问题，但是相比于早期版本，已经有了很大的进步。开源代码就是如此不停地迭代推进，随着Spark的普及程度越来越高，贡献的人越来越多，相信后续的版本会有更大的提升。&lt;/p&gt;
</description>
                <link>http://www.turbofei.wang/jerryshao/2014/01/04/spark-shuffle-detail-investigation</link>
                <guid>http://www.turbofei.wang/jerryshao/2014/01/04/spark-shuffle-detail-investigation</guid>
                <pubDate>2014-01-04T00:00:00-08:00</pubDate>
        </item>

        <item>
                <title>[转载] Spark源码分析之-Storage模块</title>
                <description>&lt;p&gt;本文转自&lt;a href=&quot;https://github.com/jerryshao/jerryshao.github.com&quot;&gt;Jerryshao Blog&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;

&lt;p&gt;前段时间琐事颇多，一直没有时间整理自己的博客，Spark源码分析写到一半也搁置了。之前介绍了&lt;a href=&quot;http://jerryshao.me/architecture/2013/04/21/Spark%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B-scheduler%E6%A8%A1%E5%9D%97/&quot;&gt;&lt;strong&gt;deploy&lt;/strong&gt;&lt;/a&gt;和&lt;a href=&quot;http://jerryshao.me/architecture/2013/04/21/Spark%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B-scheduler%E6%A8%A1%E5%9D%97/&quot;&gt;&lt;strong&gt;scheduler&lt;/strong&gt;&lt;/a&gt;两大模块，这次介绍Spark中的另一大模块 - storage模块。&lt;/p&gt;

&lt;p&gt;在写Spark程序的时候我们常常和&lt;strong&gt;RDD&lt;/strong&gt; ( &lt;em&gt;Resilient Distributed Dataset&lt;/em&gt; ) 打交道，通过RDD为我们提供的各种transformation和action接口实现我们的应用，RDD的引入提高了抽象层次，在接口和实现上进行有效地隔离，使用户无需关心底层的实现。但是RDD提供给我们的仅仅是一个“&lt;strong&gt;形&lt;/strong&gt;”, 我们所操作的数据究竟放在哪里，如何存取？它的“&lt;strong&gt;体&lt;/strong&gt;”是怎么样的？这是由storage模块来实现和管理的，接下来我们就要剖析一下storage模块。&lt;/p&gt;

&lt;h2 id=&quot;storage模块整体架构&quot;&gt;Storage模块整体架构&lt;/h2&gt;

&lt;p&gt;Storage模块主要分为两层：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;通信层：storage模块采用的是master-slave结构来实现通信层，master和slave之间传输控制信息、状态信息，这些都是通过通信层来实现的。&lt;/li&gt;
  &lt;li&gt;存储层：storage模块需要把数据存储到disk或是memory上面，有可能还需replicate到远端，这都是由存储层来实现和提供相应接口。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;而其他模块若要和storage模块进行交互，storage模块提供了统一的操作类&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManager&lt;/code&gt;，外部类与storage模块打交道都需要通过调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManager&lt;/code&gt;相应接口来实现。&lt;/p&gt;

&lt;h2 id=&quot;storage模块通信层&quot;&gt;Storage模块通信层&lt;/h2&gt;

&lt;p&gt;首先来看一下通信层的UML类图:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2013-10-08-storage/communication_layer.png&quot; alt=&quot;communication layer class chart&quot; width=&quot;640&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其次我们来看看各个类在master和slave上所扮演的不同角色：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2013-10-08-storage/communication_character.png&quot; alt=&quot;communication character class chart&quot; width=&quot;640&quot; /&gt;&lt;/p&gt;

&lt;p&gt;对于master和slave，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManager&lt;/code&gt;的创建有所不同：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Master (client driver)&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManagerMaster&lt;/code&gt;拥有&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManagerMasterActor&lt;/code&gt;的&lt;em&gt;actor&lt;/em&gt;和所有&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManagerSlaveActor&lt;/code&gt;的&lt;em&gt;ref&lt;/em&gt;。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Slave (executor)&lt;/p&gt;

    &lt;p&gt;对于slave，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManagerMaster&lt;/code&gt;则拥有&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManagerMasterActor&lt;/code&gt;的&lt;em&gt;ref&lt;/em&gt;和自身&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManagerSlaveActor&lt;/code&gt;的&lt;em&gt;actor&lt;/em&gt;。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManagerMasterActor&lt;/code&gt;在&lt;em&gt;ref&lt;/em&gt;和&lt;em&gt;actor&lt;/em&gt;之间进行通信；&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManagerSlaveActor&lt;/code&gt;在&lt;em&gt;ref&lt;/em&gt;和&lt;em&gt;actor&lt;/em&gt;之间通信。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;actor&lt;/em&gt;和&lt;em&gt;ref&lt;/em&gt;:&lt;/p&gt;

  &lt;p&gt;&lt;em&gt;actor&lt;/em&gt;和&lt;em&gt;ref&lt;/em&gt;是&lt;a href=&quot;http://akka.io/&quot;&gt;&lt;strong&gt;Akka&lt;/strong&gt;&lt;/a&gt;中的两个不同的actor reference，分别由&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;actorOf&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;actorFor&lt;/code&gt;所创建。&lt;em&gt;actor&lt;/em&gt;类似于网络服务中的server端，它保存所有的状态信息，接收client端的请求执行并返回给客户端；&lt;em&gt;ref&lt;/em&gt;类似于网络服务中的client端，通过向server端发起请求获取结果。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManager&lt;/code&gt; wrap了&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManagerMaster&lt;/code&gt;，通过&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManagerMaster&lt;/code&gt;进行通信。Spark会在client driver和executor端创建各自的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManager&lt;/code&gt;，通过&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManager&lt;/code&gt;对storage模块进行操作。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManager&lt;/code&gt;对象在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SparkEnv&lt;/code&gt;中被创建，创建的过程如下所示：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def registerOrLookup(name: String, newActor: =&amp;gt; Actor): ActorRef = {
  if (isDriver) {
    logInfo(&quot;Registering &quot; + name)
    actorSystem.actorOf(Props(newActor), name = name)
  } else {
    val driverHost: String = System.getProperty(&quot;spark.driver.host&quot;, &quot;localhost&quot;)
    val driverPort: Int = System.getProperty(&quot;spark.driver.port&quot;, &quot;7077&quot;).toInt
    Utils.checkHost(driverHost, &quot;Expected hostname&quot;)
    val url = &quot;akka://spark@%s:%s/user/%s&quot;.format(driverHost, driverPort, name)
    logInfo(&quot;Connecting to &quot; + name + &quot;: &quot; + url)
    actorSystem.actorFor(url)
  }
}

val blockManagerMaster = new BlockManagerMaster(registerOrLookup(
  &quot;BlockManagerMaster&quot;,
  new BlockManagerMasterActor(isLocal)))
val blockManager = new BlockManager(executorId, actorSystem, blockManagerMaster, serializer)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;可以看到对于client driver和executor，Spark分别创建了&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManagerMasterActor&lt;/code&gt; &lt;em&gt;actor&lt;/em&gt;和&lt;em&gt;ref&lt;/em&gt;，并被wrap到&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManager&lt;/code&gt;中。&lt;/p&gt;

&lt;h3 id=&quot;通信层传递的消息&quot;&gt;通信层传递的消息&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;BlockManagerMasterActor&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;executor&lt;/strong&gt;  to &lt;strong&gt;client driver&lt;/strong&gt;&lt;/p&gt;

        &lt;p&gt;RegisterBlockManager (executor创建BlockManager以后向client driver发送请求注册自身)
  HeartBeat
  UpdateBlockInfo (更新block信息)
  GetPeers (请求获得其他BlockManager的id)
  GetLocations (获取block所在的BlockManager的id)
  GetLocationsMultipleBlockIds (获取一组block所在的BlockManager id)&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;client driver&lt;/strong&gt;  to &lt;strong&gt;client driver&lt;/strong&gt;&lt;/p&gt;

        &lt;p&gt;GetLocations (获取block所在的BlockManager的id)
  GetLocationsMultipleBlockIds (获取一组block所在的BlockManager id)
  RemoveExecutor (删除所保存的已经死亡的executor上的BlockManager)
  StopBlockManagerMaster (停止client driver上的BlockManagerMasterActor)&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;有些消息例如&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GetLocations&lt;/code&gt;在executor端和client driver端都会向&lt;em&gt;actor&lt;/em&gt;请求，而其他的消息比如&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RegisterBlockManager&lt;/code&gt;只会由executor端的&lt;em&gt;ref&lt;/em&gt;向client driver端的&lt;em&gt;actor&lt;/em&gt;发送，于此同时例如&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RemoveExecutor&lt;/code&gt;则只会由client driver端的&lt;em&gt;ref&lt;/em&gt;向client driver端的&lt;em&gt;actor&lt;/em&gt;发送。&lt;/p&gt;

  &lt;p&gt;具体消息是从哪里发送，哪里接收和处理请看代码细节，在这里就不再赘述了。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;BlockManagerSlaveActor&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;client driver&lt;/strong&gt; to &lt;strong&gt;executor&lt;/strong&gt;&lt;/p&gt;

        &lt;p&gt;RemoveBlock (删除block)
  RemoveRdd (删除RDD)&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;通信层中涉及许多控制消息和状态消息的传递以及处理，这些细节可以直接查看源码，这里就不在一一罗列。下面就只简单介绍一下exeuctor端的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManager&lt;/code&gt;是如何启动以及向client driver发送注册请求完成注册。&lt;/p&gt;

&lt;h3 id=&quot;register-blockmanager&quot;&gt;Register BlockManager&lt;/h3&gt;

&lt;p&gt;前面已经介绍了&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManager&lt;/code&gt;对象是如何被创建出来的，当&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManager&lt;/code&gt;被创建出来以后需要向client driver注册自己，下面我们来看一下这个流程：&lt;/p&gt;

&lt;p&gt;首先&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManager&lt;/code&gt;会调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;initialize()&lt;/code&gt;初始化自己&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def initialize() {
  master.registerBlockManager(blockManagerId, maxMemory, slaveActor)
  ...
  if (!BlockManager.getDisableHeartBeatsForTesting) {
    heartBeatTask = actorSystem.scheduler.schedule(0.seconds, heartBeatFrequency.milliseconds) {
      heartBeat()
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;initialized()&lt;/code&gt;函数中首先调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManagerMaster&lt;/code&gt;向client driver注册自己，同时设置heartbeat定时器，定时发送heartbeat报文。可以看到在注册自身的时候向client driver传递了自身的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;slaveActor&lt;/code&gt;，client driver收到&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;slaveActor&lt;/code&gt;以后会将其与之对应的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManagerInfo&lt;/code&gt;存储到hash map中，以便后续通过&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;slaveActor&lt;/code&gt;向executor发送命令。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManagerMaster&lt;/code&gt;会将注册请求包装成&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RegisterBlockManager&lt;/code&gt;报文发送给client driver的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManagerMasterActor&lt;/code&gt;，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManagerMasterActor&lt;/code&gt;调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;register()&lt;/code&gt;函数注册&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManager&lt;/code&gt;：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def register(id: BlockManagerId, maxMemSize: Long, slaveActor: ActorRef) {
  if (id.executorId == &quot;&amp;lt;driver&amp;gt;&quot; &amp;amp;&amp;amp; !isLocal) {
    // Got a register message from the master node; don&apos;t register it
  } else if (!blockManagerInfo.contains(id)) {
    blockManagerIdByExecutor.get(id.executorId) match {
      case Some(manager) =&amp;gt;
        // A block manager of the same executor already exists.
        // This should never happen. Let&apos;s just quit.
        logError(&quot;Got two different block manager registrations on &quot; + id.executorId)
        System.exit(1)
      case None =&amp;gt;
        blockManagerIdByExecutor(id.executorId) = id
    }
    blockManagerInfo(id) = new BlockManagerMasterActor.BlockManagerInfo(
      id, System.currentTimeMillis(), maxMemSize, slaveActor)
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;需要注意的是在client driver端也会执行上述过程，只是在最后注册的时候如果判断是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;&amp;lt;driver&amp;gt;&quot;&lt;/code&gt;就不进行任何操作。可以看到对应的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManagerInfo&lt;/code&gt;对象被创建并保存在hash map中。&lt;/p&gt;

&lt;h2 id=&quot;storage模块存储层&quot;&gt;Storage模块存储层&lt;/h2&gt;

&lt;p&gt;在RDD层面上我们了解到RDD是由不同的partition组成的，我们所进行的transformation和action是在partition上面进行的；而在storage模块内部，RDD又被视为由不同的block组成，对于RDD的存取是以block为单位进行的，本质上partition和block是等价的，只是看待的角度不同。在Spark storage模块中中存取数据的最小单位是block，所有的操作都是以block为单位进行的。&lt;/p&gt;

&lt;p&gt;首先我们来看一下存储层的UML类图:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2013-10-08-storage/storage_layer.png&quot; alt=&quot;storage layer class chart&quot; width=&quot;640&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManager&lt;/code&gt;对象被创建的时候会创建出&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MemoryStore&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DiskStore&lt;/code&gt;对象用以存取block，同时在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;initialize()&lt;/code&gt;函数中创建&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManagerWorker&lt;/code&gt;对象用以监听远程的block存取请求来进行相应处理。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private[storage] val memoryStore: BlockStore = new MemoryStore(this, maxMemory)
private[storage] val diskStore: DiskStore =
  new DiskStore(this, System.getProperty(&quot;spark.local.dir&quot;, System.getProperty(&quot;java.io.tmpdir&quot;)))

private def initialize() {
  ...
  BlockManagerWorker.startBlockManagerWorker(this)
  ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;下面就具体介绍一下对于&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DiskStore&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MemoryStore&lt;/code&gt;，block的存取操作是怎样进行的。&lt;/p&gt;

&lt;h3 id=&quot;diskstore如何存取block&quot;&gt;DiskStore如何存取block&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DiskStore&lt;/code&gt;可以配置多个folder，Spark会在不同的folder下面创建Spark文件夹，文件夹的命名方式为(spark-local-yyyyMMddHHmmss-xxxx, xxxx是一个随机数)，所有的block都会存储在所创建的folder里面。&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DiskStore&lt;/code&gt;会在对象被创建时调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;createLocalDirs()&lt;/code&gt;来创建文件夹：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def createLocalDirs(): Array[File] = {
  logDebug(&quot;Creating local directories at root dirs &apos;&quot; + rootDirs + &quot;&apos;&quot;)
  val dateFormat = new SimpleDateFormat(&quot;yyyyMMddHHmmss&quot;)
  rootDirs.split(&quot;,&quot;).map { rootDir =&amp;gt;
    var foundLocalDir = false
    var localDir: File = null
    var localDirId: String = null
    var tries = 0
    val rand = new Random()
    while (!foundLocalDir &amp;amp;&amp;amp; tries &amp;lt; MAX_DIR_CREATION_ATTEMPTS) {
      tries += 1
      try {
        localDirId = &quot;%s-%04x&quot;.format(dateFormat.format(new Date), rand.nextInt(65536))
        localDir = new File(rootDir, &quot;spark-local-&quot; + localDirId)
        if (!localDir.exists) {
          foundLocalDir = localDir.mkdirs()
        }
      } catch {
        case e: Exception =&amp;gt;
          logWarning(&quot;Attempt &quot; + tries + &quot; to create local dir &quot; + localDir + &quot; failed&quot;, e)
      }
    }
    if (!foundLocalDir) {
      logError(&quot;Failed &quot; + MAX_DIR_CREATION_ATTEMPTS +
        &quot; attempts to create local dir in &quot; + rootDir)
      System.exit(ExecutorExitCode.DISK_STORE_FAILED_TO_CREATE_DIR)
    }
    logInfo(&quot;Created local directory at &quot; + localDir)
    localDir
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DiskStore&lt;/code&gt;里面，每一个block都被存储为一个file，通过计算block id的hash值将block映射到文件中，block id与文件路径的映射关系如下所示：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def getFile(blockId: String): File = {
  logDebug(&quot;Getting file for block &quot; + blockId)

  // Figure out which local directory it hashes to, and which subdirectory in that
  val hash = Utils.nonNegativeHash(blockId)
  val dirId = hash % localDirs.length
  val subDirId = (hash / localDirs.length) % subDirsPerLocalDir

  // Create the subdirectory if it doesn&apos;t already exist
  var subDir = subDirs(dirId)(subDirId)
  if (subDir == null) {
    subDir = subDirs(dirId).synchronized {
      val old = subDirs(dirId)(subDirId)
      if (old != null) {
        old
      } else {
        val newDir = new File(localDirs(dirId), &quot;%02x&quot;.format(subDirId))
        newDir.mkdir()
        subDirs(dirId)(subDirId) = newDir
        newDir
      }
    }
  }

  new File(subDir, blockId)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;根据block id计算出hash值，将hash取模获得&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dirId&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;subDirId&lt;/code&gt;，在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;subDirs&lt;/code&gt;中找出相应的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;subDir&lt;/code&gt;，若没有则新建一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;subDir&lt;/code&gt;，最后以&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;subDir&lt;/code&gt;为路径、block id为文件名创建file handler，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DiskStore&lt;/code&gt;使用此file handler将block写入文件内，代码如下所示：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;override def putBytes(blockId: String, _bytes: ByteBuffer, level: StorageLevel) {
  // So that we do not modify the input offsets !
  // duplicate does not copy buffer, so inexpensive
  val bytes = _bytes.duplicate()
  logDebug(&quot;Attempting to put block &quot; + blockId)
  val startTime = System.currentTimeMillis
  val file = createFile(blockId)
  val channel = new RandomAccessFile(file, &quot;rw&quot;).getChannel()
  while (bytes.remaining &amp;gt; 0) {
    channel.write(bytes)
  }
  channel.close()
  val finishTime = System.currentTimeMillis
  logDebug(&quot;Block %s stored as %s file on disk in %d ms&quot;.format(
    blockId, Utils.bytesToString(bytes.limit), (finishTime - startTime)))
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;而获取block则非常简单，找到相应的文件并读取出来即可：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;override def getBytes(blockId: String): Option[ByteBuffer] = {
  val file = getFile(blockId)
  val bytes = getFileBytes(file)
  Some(bytes)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;因此在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DiskStore&lt;/code&gt;中存取block首先是要将block id映射成相应的文件路径，接着存取文件就可以了。&lt;/p&gt;

&lt;h3 id=&quot;memorystore如何存取block&quot;&gt;MemoryStore如何存取block&lt;/h3&gt;

&lt;p&gt;相对于&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DiskStore&lt;/code&gt;需要根据block id hash计算出文件路径并将block存放到对应的文件里面，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MemoryStore&lt;/code&gt;管理block就显得非常简单：&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MemoryStore&lt;/code&gt;内部维护了一个hash map来管理所有的block，以block id为key将block存放到hash map中。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;case class Entry(value: Any, size: Long, deserialized: Boolean)

private val entries = new LinkedHashMap[String, Entry](32, 0.75f, true)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MemoryStore&lt;/code&gt;中存放block必须确保内存足够容纳下该block，若内存不足则会将block写到文件中，具体的代码如下所示：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;override def putBytes(blockId: String, _bytes: ByteBuffer, level: StorageLevel) {
  // Work on a duplicate - since the original input might be used elsewhere.
  val bytes = _bytes.duplicate()
  bytes.rewind()
  if (level.deserialized) {
    val values = blockManager.dataDeserialize(blockId, bytes)
    val elements = new ArrayBuffer[Any]
    elements ++= values
    val sizeEstimate = SizeEstimator.estimate(elements.asInstanceOf[AnyRef])
    tryToPut(blockId, elements, sizeEstimate, true)
  } else {
    tryToPut(blockId, bytes, bytes.limit, false)
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tryToPut()&lt;/code&gt;中，首先调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ensureFreeSpace()&lt;/code&gt;确保空闲内存是否足以容纳block，若可以则将该block放入hash map中进行管理；若不足以容纳则通过调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dropFromMemory()&lt;/code&gt;将block写入文件。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def tryToPut(blockId: String, value: Any, size: Long, deserialized: Boolean): Boolean = {
  // TODO: Its possible to optimize the locking by locking entries only when selecting blocks
  // to be dropped. Once the to-be-dropped blocks have been selected, and lock on entries has been
  // released, it must be ensured that those to-be-dropped blocks are not double counted for
  // freeing up more space for another block that needs to be put. Only then the actually dropping
  // of blocks (and writing to disk if necessary) can proceed in parallel.
  putLock.synchronized {
    if (ensureFreeSpace(blockId, size)) {
      val entry = new Entry(value, size, deserialized)
      entries.synchronized {
        entries.put(blockId, entry)
        currentMemory += size
      }
      if (deserialized) {
        logInfo(&quot;Block %s stored as values to memory (estimated size %s, free %s)&quot;.format(
          blockId, Utils.bytesToString(size), Utils.bytesToString(freeMemory)))
      } else {
        logInfo(&quot;Block %s stored as bytes to memory (size %s, free %s)&quot;.format(
          blockId, Utils.bytesToString(size), Utils.bytesToString(freeMemory)))
      }
      true
    } else {
      // Tell the block manager that we couldn&apos;t put it in memory so that it can drop it to
      // disk if the block allows disk storage.
      val data = if (deserialized) {
        Left(value.asInstanceOf[ArrayBuffer[Any]])
      } else {
        Right(value.asInstanceOf[ByteBuffer].duplicate())
      }
      blockManager.dropFromMemory(blockId, data)
      false
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;而从&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MemoryStore&lt;/code&gt;中取得block则非常简单，只需从hash map中取出block id对应的value即可。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;override def getValues(blockId: String): Option[Iterator[Any]] = {
  val entry = entries.synchronized {
    entries.get(blockId)
  }
  if (entry == null) {
    None
  } else if (entry.deserialized) {
    Some(entry.value.asInstanceOf[ArrayBuffer[Any]].iterator)
  } else {
    val buffer = entry.value.asInstanceOf[ByteBuffer].duplicate() // Doesn&apos;t actually copy data
    Some(blockManager.dataDeserialize(blockId, buffer))
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;put-or-get-block-through-blockmanager&quot;&gt;Put or Get block through BlockManager&lt;/h3&gt;

&lt;p&gt;上面介绍了&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DiskStore&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MemoryStore&lt;/code&gt;对于block的存取操作，那么我们是要直接与它们交互存取数据吗，还是封装了更抽象的接口使我们无需关心底层？&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManager&lt;/code&gt;为我们提供了&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;put()&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;get()&lt;/code&gt;函数，用户可以使用这两个函数对block进行存取而无需关心底层实现。&lt;/p&gt;

&lt;p&gt;首先我们来看一下&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;put()&lt;/code&gt;函数的实现：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def put(blockId: String, values: ArrayBuffer[Any], level: StorageLevel,
  tellMaster: Boolean = true) : Long = {

  ...

  // Remember the block&apos;s storage level so that we can correctly drop it to disk if it needs
  // to be dropped right after it got put into memory. Note, however, that other threads will
  // not be able to get() this block until we call markReady on its BlockInfo.
  val myInfo = {
    val tinfo = new BlockInfo(level, tellMaster)
    // Do atomically !
    val oldBlockOpt = blockInfo.putIfAbsent(blockId, tinfo)

    if (oldBlockOpt.isDefined) {
      if (oldBlockOpt.get.waitForReady()) {
        logWarning(&quot;Block &quot; + blockId + &quot; already exists on this machine; not re-adding it&quot;)
        return oldBlockOpt.get.size
      }

      // TODO: So the block info exists - but previous attempt to load it (?) failed. What do we do now ? Retry on it ?
      oldBlockOpt.get
    } else {
      tinfo
    }
  }

  val startTimeMs = System.currentTimeMillis

  // If we need to replicate the data, we&apos;ll want access to the values, but because our
  // put will read the whole iterator, there will be no values left. For the case where
  // the put serializes data, we&apos;ll remember the bytes, above; but for the case where it
  // doesn&apos;t, such as deserialized storage, let&apos;s rely on the put returning an Iterator.
  var valuesAfterPut: Iterator[Any] = null

  // Ditto for the bytes after the put
  var bytesAfterPut: ByteBuffer = null

  // Size of the block in bytes (to return to caller)
  var size = 0L

  myInfo.synchronized {
    logTrace(&quot;Put for block &quot; + blockId + &quot; took &quot; + Utils.getUsedTimeMs(startTimeMs)
      + &quot; to get into synchronized block&quot;)

    var marked = false
    try {
      if (level.useMemory) {
        // Save it just to memory first, even if it also has useDisk set to true; we will later
        // drop it to disk if the memory store can&apos;t hold it.
        val res = memoryStore.putValues(blockId, values, level, true)
        size = res.size
        res.data match {
          case Right(newBytes) =&amp;gt; bytesAfterPut = newBytes
          case Left(newIterator) =&amp;gt; valuesAfterPut = newIterator
        }
      } else {
        // Save directly to disk.
        // Don&apos;t get back the bytes unless we replicate them.
        val askForBytes = level.replication &amp;gt; 1
        val res = diskStore.putValues(blockId, values, level, askForBytes)
        size = res.size
        res.data match {
          case Right(newBytes) =&amp;gt; bytesAfterPut = newBytes
          case _ =&amp;gt;
        }
      }

      // Now that the block is in either the memory or disk store, let other threads read it,
      // and tell the master about it.
      marked = true
      myInfo.markReady(size)
      if (tellMaster) {
        reportBlockStatus(blockId, myInfo)
      }
    } finally {
      // If we failed at putting the block to memory/disk, notify other possible readers
      // that it has failed, and then remove it from the block info map.
      if (! marked) {
        // Note that the remove must happen before markFailure otherwise another thread
        // could&apos;ve inserted a new BlockInfo before we remove it.
        blockInfo.remove(blockId)
        myInfo.markFailure()
        logWarning(&quot;Putting block &quot; + blockId + &quot; failed&quot;)
      }
    }
  }
  logDebug(&quot;Put block &quot; + blockId + &quot; locally took &quot; + Utils.getUsedTimeMs(startTimeMs))

  // Replicate block if required
  if (level.replication &amp;gt; 1) {
    val remoteStartTime = System.currentTimeMillis
    // Serialize the block if not already done
    if (bytesAfterPut == null) {
      if (valuesAfterPut == null) {
        throw new SparkException(
          &quot;Underlying put returned neither an Iterator nor bytes! This shouldn&apos;t happen.&quot;)
      }
      bytesAfterPut = dataSerialize(blockId, valuesAfterPut)
    }
    replicate(blockId, bytesAfterPut, level)
    logDebug(&quot;Put block &quot; + blockId + &quot; remotely took &quot; + Utils.getUsedTimeMs(remoteStartTime))
  }
  BlockManager.dispose(bytesAfterPut)

  return size
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;对于&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;put()&lt;/code&gt;操作，主要分为以下3个步骤：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;为block创建&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockInfo&lt;/code&gt;结构体存储block相关信息，同时将其加锁使其不能被访问。&lt;/li&gt;
  &lt;li&gt;根据block的storage level将block存储到memory或是disk上，同时解锁标识该block已经ready，可被访问。&lt;/li&gt;
  &lt;li&gt;根据block的replication数决定是否将该block replicate到远端。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;接着我们来看一下&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;get()&lt;/code&gt;函数的实现：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def get(blockId: String): Option[Iterator[Any]] = {
  val local = getLocal(blockId)
  if (local.isDefined) {
    logInfo(&quot;Found block %s locally&quot;.format(blockId))
    return local
  }
  val remote = getRemote(blockId)
  if (remote.isDefined) {
    logInfo(&quot;Found block %s remotely&quot;.format(blockId))
    return remote
  }
  None
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;get()&lt;/code&gt;首先会从local的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManager&lt;/code&gt;中查找block，如果找到则返回相应的block，若local没有找到该block，则发起请求从其他的executor上的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManager&lt;/code&gt;中查找block。在通常情况下Spark任务的分配是根据block的分布决定的，任务往往会被分配到拥有block的节点上，因此&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;getLocal()&lt;/code&gt;就能找到所需的block；但是在资源有限的情况下，Spark会将任务调度到与block不同的节点上，这样就必须通过&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;getRemote()&lt;/code&gt;来获得block。&lt;/p&gt;

&lt;p&gt;我们先来看一下&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;getLocal()&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def getLocal(blockId: String): Option[Iterator[Any]] = {
  logDebug(&quot;Getting local block &quot; + blockId)
  val info = blockInfo.get(blockId).orNull
  if (info != null) {
    info.synchronized {

      // In the another thread is writing the block, wait for it to become ready.
      if (!info.waitForReady()) {
        // If we get here, the block write failed.
        logWarning(&quot;Block &quot; + blockId + &quot; was marked as failure.&quot;)
        return None
      }

      val level = info.level
      logDebug(&quot;Level for block &quot; + blockId + &quot; is &quot; + level)

      // Look for the block in memory
      if (level.useMemory) {
        logDebug(&quot;Getting block &quot; + blockId + &quot; from memory&quot;)
        memoryStore.getValues(blockId) match {
          case Some(iterator) =&amp;gt;
            return Some(iterator)
          case None =&amp;gt;
            logDebug(&quot;Block &quot; + blockId + &quot; not found in memory&quot;)
        }
      }

      // Look for block on disk, potentially loading it back into memory if required
      if (level.useDisk) {
        logDebug(&quot;Getting block &quot; + blockId + &quot; from disk&quot;)
        if (level.useMemory &amp;amp;&amp;amp; level.deserialized) {
          diskStore.getValues(blockId) match {
            case Some(iterator) =&amp;gt;
              // Put the block back in memory before returning it
              // TODO: Consider creating a putValues that also takes in a iterator ?
              val elements = new ArrayBuffer[Any]
              elements ++= iterator
              memoryStore.putValues(blockId, elements, level, true).data match {
                case Left(iterator2) =&amp;gt;
                  return Some(iterator2)
                case _ =&amp;gt;
                  throw new Exception(&quot;Memory store did not return back an iterator&quot;)
              }
            case None =&amp;gt;
              throw new Exception(&quot;Block &quot; + blockId + &quot; not found on disk, though it should be&quot;)
          }
        } else if (level.useMemory &amp;amp;&amp;amp; !level.deserialized) {
          // Read it as a byte buffer into memory first, then return it
          diskStore.getBytes(blockId) match {
            case Some(bytes) =&amp;gt;
              // Put a copy of the block back in memory before returning it. Note that we can&apos;t
              // put the ByteBuffer returned by the disk store as that&apos;s a memory-mapped file.
              // The use of rewind assumes this.
              assert (0 == bytes.position())
              val copyForMemory = ByteBuffer.allocate(bytes.limit)
              copyForMemory.put(bytes)
              memoryStore.putBytes(blockId, copyForMemory, level)
              bytes.rewind()
              return Some(dataDeserialize(blockId, bytes))
            case None =&amp;gt;
              throw new Exception(&quot;Block &quot; + blockId + &quot; not found on disk, though it should be&quot;)
          }
        } else {
          diskStore.getValues(blockId) match {
            case Some(iterator) =&amp;gt;
              return Some(iterator)
            case None =&amp;gt;
              throw new Exception(&quot;Block &quot; + blockId + &quot; not found on disk, though it should be&quot;)
          }
        }
      }
    }
  } else {
    logDebug(&quot;Block &quot; + blockId + &quot; not registered locally&quot;)
  }
  return None
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;getLocal()&lt;/code&gt;首先会根据block id获得相应的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockInfo&lt;/code&gt;并从中取出该block的storage level，根据storage level的不同&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;getLocal()&lt;/code&gt;又进入以下不同分支：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;level.useMemory == true：从memory中取出block并返回，若没有取到则进入分支2。&lt;/li&gt;
  &lt;li&gt;level.useDisk == true:
    &lt;ul&gt;
      &lt;li&gt;level.useMemory == true: 将block从disk中读出并写入内存以便下次使用时直接从内存中获得，同时返回该block。&lt;/li&gt;
      &lt;li&gt;level.useMemory == false: 将block从disk中读出并返回&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;level.useDisk == false: 没有在本地找到block，返回None。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;接下来我们来看一下&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;getRemote()&lt;/code&gt;：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def getRemote(blockId: String): Option[Iterator[Any]] = {
  if (blockId == null) {
    throw new IllegalArgumentException(&quot;Block Id is null&quot;)
  }
  logDebug(&quot;Getting remote block &quot; + blockId)
  // Get locations of block
  val locations = master.getLocations(blockId)

  // Get block from remote locations
  for (loc &amp;lt;- locations) {
    logDebug(&quot;Getting remote block &quot; + blockId + &quot; from &quot; + loc)
    val data = BlockManagerWorker.syncGetBlock(
      GetBlock(blockId), ConnectionManagerId(loc.host, loc.port))
    if (data != null) {
      return Some(dataDeserialize(blockId, data))
    }
    logDebug(&quot;The value of block &quot; + blockId + &quot; is null&quot;)
  }
  logDebug(&quot;Block &quot; + blockId + &quot; not found&quot;)
  return None
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;getRemote()&lt;/code&gt;首先取得该block的所有location信息，然后根据location向远端发送请求获取block，只要有一个远端返回block该函数就返回而不继续发送请求。&lt;/p&gt;

&lt;p&gt;至此我们简单介绍了&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManager&lt;/code&gt;类中的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;get()&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;put()&lt;/code&gt;函数，使用这两个函数外部类可以轻易地存取block数据。&lt;/p&gt;

&lt;h3 id=&quot;partition如何转化为block&quot;&gt;Partition如何转化为Block&lt;/h3&gt;

&lt;p&gt;在storage模块里面所有的操作都是和block相关的，但是在RDD里面所有的运算都是基于partition的，那么partition是如何与block对应上的呢？&lt;/p&gt;

&lt;p&gt;RDD计算的核心函数是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;iterator()&lt;/code&gt;函数：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;final def iterator(split: Partition, context: TaskContext): Iterator[T] = {
  if (storageLevel != StorageLevel.NONE) {
    SparkEnv.get.cacheManager.getOrCompute(this, split, context, storageLevel)
  } else {
    computeOrReadCheckpoint(split, context)
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;如果当前RDD的storage level不是NONE的话，表示该RDD在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManager&lt;/code&gt;中有存储，那么调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CacheManager&lt;/code&gt;中的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;getOrCompute()&lt;/code&gt;函数计算RDD，在这个函数中partition和block发生了关系：&lt;/p&gt;

&lt;p&gt;首先根据RDD id和partition index构造出block id (rdd_xx_xx)，接着从&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManager&lt;/code&gt;中取出相应的block。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果该block存在，表示此RDD在之前已经被计算过和存储在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManager&lt;/code&gt;中，因此取出即可，无需再重新计算。&lt;/li&gt;
  &lt;li&gt;如果该block不存在则需要调用RDD的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;computeOrReadCheckpoint()&lt;/code&gt;函数计算出新的block，并将其存储到&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManager&lt;/code&gt;中。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;需要注意的是block的计算和存储是阻塞的，若另一线程也需要用到此block则需等到该线程block的loading结束。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def getOrCompute[T](rdd: RDD[T], split: Partition, context: TaskContext, storageLevel: StorageLevel)
    : Iterator[T] = {
  val key = &quot;rdd_%d_%d&quot;.format(rdd.id, split.index)
  logDebug(&quot;Looking for partition &quot; + key)
  blockManager.get(key) match {
    case Some(values) =&amp;gt;
      // Partition is already materialized, so just return its values
      return values.asInstanceOf[Iterator[T]]

    case None =&amp;gt;
      // Mark the split as loading (unless someone else marks it first)
      loading.synchronized {
        if (loading.contains(key)) {
          logInfo(&quot;Another thread is loading %s, waiting for it to finish...&quot;.format (key))
          while (loading.contains(key)) {
            try {loading.wait()} catch {case _ : Throwable =&amp;gt;}
          }
          logInfo(&quot;Finished waiting for %s&quot;.format(key))
          // See whether someone else has successfully loaded it. The main way this would fail
          // is for the RDD-level cache eviction policy if someone else has loaded the same RDD
          // partition but we didn&apos;t want to make space for it. However, that case is unlikely
          // because it&apos;s unlikely that two threads would work on the same RDD partition. One
          // downside of the current code is that threads wait serially if this does happen.
          blockManager.get(key) match {
            case Some(values) =&amp;gt;
              return values.asInstanceOf[Iterator[T]]
            case None =&amp;gt;
              logInfo(&quot;Whoever was loading %s failed; we&apos;ll try it ourselves&quot;.format  (key))
              loading.add(key)
          }
        } else {
          loading.add(key)
        }
      }
      try {
        // If we got here, we have to load the split
        logInfo(&quot;Partition %s not found, computing it&quot;.format(key))
        val computedValues = rdd.computeOrReadCheckpoint(split, context)
        // Persist the result, so long as the task is not running locally
        if (context.runningLocally) { return computedValues }
        val elements = new ArrayBuffer[Any]
        elements ++= computedValues
        blockManager.put(key, elements, storageLevel, true)
        return elements.iterator.asInstanceOf[Iterator[T]]
      } finally {
        loading.synchronized {
          loading.remove(key)
          loading.notifyAll()
        }
      }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这样RDD的transformation、action就和block数据建立了联系，虽然抽象上我们的操作是在partition层面上进行的，但是partition最终还是被映射成为block，因此实际上我们的所有操作都是对block的处理和存取。&lt;/p&gt;

&lt;h2 id=&quot;end&quot;&gt;End&lt;/h2&gt;

&lt;p&gt;本文就storage模块的两个层面进行了介绍-通信层和存储层。通信层中简单介绍了类结构和组成以及类在通信层中所扮演的不同角色，还有不同角色之间通信的报文，同时简单介绍了通信层的启动和注册细节。存储层中分别介绍了&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DiskStore&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MemoryStore&lt;/code&gt;中对于block的存和取的实现代码，同时分析了&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManager&lt;/code&gt;中&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;put()&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;get()&lt;/code&gt;接口，最后简单介绍了Spark RDD中的partition与&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BlockManager&lt;/code&gt;中的block之间的关系，以及如何交互存取block的。&lt;/p&gt;

&lt;p&gt;本文从整体上分析了storage模块的实现，并未就具体实现做非常细节的分析，相信在看完本文对storage模块有一个整体的印象以后再去分析细节的实现会有事半功倍的效果。&lt;/p&gt;
</description>
                <link>http://www.turbofei.wang/jerryshao/2013/10/08/spark-storage-module-analysis</link>
                <guid>http://www.turbofei.wang/jerryshao/2013/10/08/spark-storage-module-analysis</guid>
                <pubDate>2013-10-08T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>[转载] 序列的函数式抽象-Spark API设计</title>
                <description>&lt;p&gt;本文转自&lt;a href=&quot;https://github.com/jerryshao/jerryshao.github.com&quot;&gt;Jerryshao Blog&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;

&lt;p&gt;最近钻研于SICP (&lt;em&gt;Structure and Interpretation of Computer Programs&lt;/em&gt;)，深为lisp所抽象出的公共模式所吸引，联系一直以来所使用的Spark，想到两者对于公共模式提炼的相同之处，有感而发，记下自己的所想。&lt;/p&gt;

&lt;h2 id=&quot;公共模式的提炼&quot;&gt;公共模式的提炼&lt;/h2&gt;

&lt;p&gt;思考程序设计中如下几种场景:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;将一个表里的所有元素按给定因子做一次缩放&lt;/li&gt;
  &lt;li&gt;将一个表里的所有元素进行平方&lt;/li&gt;
  &lt;li&gt;将一个表里的所有元素加上一个给定值&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;可以看到以上三种场景可以抽象为将表内的所有元素进行某种运算得到一个新的表，本质上都是表的映射，我们可以将这种公共模式表述为一个高阶过程&lt;strong&gt;map&lt;/strong&gt;，它的参数一个运算过程参数和一个表参数，返回值是将这个运算过程作用于表中每一个元素后形成的新表。可以参看场景1的例子：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(define (scale-list items factor)
  (if (null? items)
    nil
    (cons (* (car items) factor)
          (scale-list (cdr items) factor))))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;对于它的抽象如下：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(define (map proc items)
  (if (null? items))
    nil
    (cons (proc (car items))
          (map proc (cdr items)))))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;因此&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scale-list&lt;/code&gt;可以简化为如下:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(define (scale-list items factor)
  (map (lambda (x) (* x factor))
        items))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;map&lt;/strong&gt;不仅定义了一种公共模式，同时也设置了抽象屏障，将表变换过程的实现，与如何提取表中元素及组合结果的细节隔离开来，提升了抽象层次。&lt;/p&gt;

&lt;p&gt;函数式语言提供了许多诸如&lt;strong&gt;map&lt;/strong&gt;的公共模式，如&lt;strong&gt;reduce&lt;/strong&gt;，&lt;strong&gt;foreach&lt;/strong&gt;，&lt;strong&gt;filter&lt;/strong&gt;，&lt;strong&gt;accumulate&lt;/strong&gt;，利用这些公共模式，我们可以摆脱底层细节的纠缠，专注于算法的实现。&lt;/p&gt;

&lt;h2 id=&quot;过程的公共模式拆解&quot;&gt;过程的公共模式拆解&lt;/h2&gt;

&lt;p&gt;同样思考以下两种场景:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;计算出树中所有叶子节点值为奇数的平方和&lt;/li&gt;
  &lt;li&gt;构造出所有偶数的斐波那契数Fib(k)的一个表，其中k小于给定整数n&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;乍看之下上面描述的两个场景毫无共同点，无法进行抽象，实际对于复合过程的拆解会发现它们有极大的相似性，对于过程的分解可以参考下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2013-08-30-functional-programming-spark-api/algo-signal-chart.png&quot; alt=&quot;algorithm signal chart&quot; width=&quot;640&quot; /&gt;&lt;/p&gt;

&lt;p&gt;类似于信号流图，通过一些级联的步骤对过程进行子过程分解和抽象，上述两个场景都可以用一些公共模式的串联来解决。我们来看一下场景1是如何利用公共模式构造和串联的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;map&lt;/strong&gt;模式在之前已经构造出来了，接下来我们首先是要构造&lt;strong&gt;filter&lt;/strong&gt;模式:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(define (filter predicate sequence)
  (cond ((null? sequence) nil)
         ((predicate (car sequence))
           (cons (car sequence)
                 (filter predicate (cdr sequence))))
         (else (filter predicate (cdr sequence)))))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;同样我们还需要&lt;strong&gt;accumulate&lt;/strong&gt;累加器对序列进行累加:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(define (accumulate op initial sequence)
  (if (null? sequence)
     initial
     (op (car sequence)
         (accumulate op initial (cdr sequence)))))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;最后我们需要有一个输入序列:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(define (enumerate-tree tree)
  (cond ((null? tree) nil)
        ((not (pair? tree)) (list tree))
        (else (append (enumerate-tree (car tree))
                      (enumerate-tree (cdr tree))))))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;将上面这些子过程串联起来我们就可以得出场景1的复合过程:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(define (sum-odd-square tree)
  (accumulate +
              0
              (map square
                   (filter odd?
                           (enumerate-tree tree)))))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;由此我们可以看到，如果语言或者库为我们提供了抽象的公共模式，我们可以利用公共模式将我们的复杂算法分解为基本的公共模式并进行串联，这样可以使算法描述更为清晰、模块化。&lt;/p&gt;

&lt;h2 id=&quot;spark-api设计&quot;&gt;Spark API设计&lt;/h2&gt;

&lt;p&gt;我们知道Spark将数据集合抽象为RDD (&lt;em&gt;Resilient Distributed Dataset&lt;/em&gt;)，所有的操作过程都是基于RDD的，而RDD本质上就是一个序列，因此Spark也提供了诸如&lt;strong&gt;map&lt;/strong&gt;，&lt;strong&gt;reduce&lt;/strong&gt;，&lt;strong&gt;filter&lt;/strong&gt;等公共模式。&lt;/p&gt;

&lt;p&gt;Spark提供了两大类公共模式: Transformations和Actions。Transformations是将一个RDD转换为另一个RDD，是一种映射。而Actions则提供了RDD计算结果的聚合和获得。我们以word count为例简单地表述一下如何利用公共模式的复合来表述算法。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2013-08-30-functional-programming-spark-api/wordcount-signal-chart.png&quot; alt=&quot;word count signal chart&quot; width=&quot;640&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看到复杂的算法被分解为信号流图的表述方式，并且将不同的公共模式应用于各阶段，清晰明白地描述出了算法的构成，而程序语言的构成如下所示：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rdd.flatMap(_.split(&quot; &quot;)).map(r =&amp;gt; (r, 1)).reduceByKey(_ + _).foreach(println)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Spark屏蔽了RDD的转换和实现细节，设置了抽象屏障，使我们只需关注RDD如何转换并提供行为函数，并且Spark以统一且公认的函数式公共模式提供了API，使得熟悉函数式语言的用户可以轻松地了解这些公共模式的作用。同时由于提供了众多的公共模式，因此可以将算法清晰地分解为不同模式的组合，表述更为清晰和简洁。同样是基于map-reduce的算法框架，相比于Hadoop Spark提供了更精炼的API和更高的抽象模式，使得用户可以更清晰简单地描述其算法。&lt;/p&gt;
</description>
                <link>http://www.turbofei.wang/jerryshao/2013/08/30/Functional-Abstraction-of-Sequence-Spark-API-Design</link>
                <guid>http://www.turbofei.wang/jerryshao/2013/08/30/Functional-Abstraction-of-Sequence-Spark-API-Design</guid>
                <pubDate>2013-08-30T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>[REPRINT] Spark Streaming Job Troubleshooting of Dependency Chain</title>
                <description>&lt;p&gt;本文转自&lt;a href=&quot;https://github.com/jerryshao/jerryshao.github.com&quot;&gt;Jerryshao Blog&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;

&lt;p&gt;Spark Streaming has many commons compared with Spark, it abstracts DStream which based on RDD, its transformations and outputs are similar to Spark. But due to its periodically running property, some problems which may not be serious in Spark will become a big deal in Spark Streaming. This article introduce a dependency chain problem which will delay streaming job gradually and make the job crash.&lt;/p&gt;

&lt;h2 id=&quot;why-streaming-job-runs-gradually-slower&quot;&gt;Why Streaming job runs gradually slower&lt;/h2&gt;

&lt;h3 id=&quot;problem-statement&quot;&gt;Problem statement&lt;/h3&gt;

&lt;p&gt;Spark Streaming job’s running time gradually slows while input data size is almost the same. You can see the job’s running time chart as below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2013-05-22-streaming-troubleshooting/job_delay.png&quot; alt=&quot;job_delay&quot; width=&quot;480&quot; /&gt;&lt;/p&gt;

&lt;p&gt;my job is like this:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;newGenRdd = input.filer(...).map(...).join(...).countByValue()
oldRdd.zipPartition(..., newGenRdd)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;newGenRdd&lt;/code&gt; will be calculated in each batch duration, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;oldRdd&lt;/code&gt; is cached in Shark’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;memoryMetadataManager&lt;/code&gt;. Then &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;oldRdd&lt;/code&gt; will be zipped with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;newGenRdd&lt;/code&gt; to get a zipped RDD, this zipped RDD will be next round’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;oldRdd&lt;/code&gt;. So in each batch duration, job runs as above code shows.&lt;/p&gt;

&lt;p&gt;In my &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;zipPartition&lt;/code&gt;, I will filter out some records which are older than a specific time, to make sure that the total record numbers in the RDD will be stable.&lt;/p&gt;

&lt;p&gt;So in a common sense, while the input data size is almost the same, the job’s running time of each batch duration should be stable as expected. But as above chart shows, running time gradually increase as time passes by.&lt;/p&gt;

&lt;h3 id=&quot;phenomenon&quot;&gt;Phenomenon&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;ClientDriver host’s network output grows gradually, and StandaloneExecutorBackend hosts’ network input grows gradually. You can see the below network graph of the whole cluster, in which sr412 is ClientDriver and others are StandaloneExecutorBackend&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/img/2013-05-22-streaming-troubleshooting/network.png&quot; alt=&quot;network_report&quot; width=&quot;640&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;This graph shows that only ClientDriver’s network output and StandaloneExecutorBackends’ network input increases, which indicates that in each batch duration ClientDriver transmit data to all slaves, there might exists several possibilities:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;data structure created in ClientDriver transmit to slaves for closure to use.&lt;/li&gt;
      &lt;li&gt;some dependent static data structures transmit to slaves when static functions are called on slaves’ closure.&lt;/li&gt;
      &lt;li&gt;some control diagram transmit to slaves in Akka.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;Also the growth of network traffic should be noticed, some data structures that transmited to slaves might be cumulative.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Serialized task size grows gradually. According to network traffic phenomenon, furtherly I dig out all the serialized task size in each job’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;zipPartition&lt;/code&gt; stage, as the blow chart shows, task size gradually grows while the input data size of each batch duration is almost the same.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/img/2013-05-22-streaming-troubleshooting/task_size.png&quot; alt=&quot;network_report&quot; width=&quot;480&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;Also this &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;zipPartition&lt;/code&gt; stage running time is increased, as blow chart shows:&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/img/2013-05-22-streaming-troubleshooting/stage_delay.png&quot; alt=&quot;network_report&quot; width=&quot;480&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;After carefully examing my implementation in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;zipPartition&lt;/code&gt;, in which data structure is invariant in each batch duration job, so I think it might be the Spark framework introduced problem.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;I dig out all the dependencies of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;oldRdd&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;newGenRdd&lt;/code&gt; recursively, I found that as job runs periodically, dependencies of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;oldRdd&lt;/code&gt; increase rapidly, while dependencies of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;newGenRdd&lt;/code&gt; maintains the same, as below chart shows.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/img/2013-05-22-streaming-troubleshooting/dependency_number.png&quot; alt=&quot;network_report&quot; width=&quot;480&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;reason&quot;&gt;Reason&lt;/h3&gt;

&lt;p&gt;According to the above phenomena, it is obviously that the growth of dependency chain makes job being gradually slower, by investigating Spark’s code, in each batch duration, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;oldRdd&lt;/code&gt; will add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;newGenRdd&lt;/code&gt;’s dependency chain to itself, after several rounds, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;oldRdd&lt;/code&gt;’s dependency chain becomes huge, serialization and deserialization which previously is trivial now becomes a time-consuming work. Taking below code as a example:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;var rdd = ...
for (i &amp;lt;- 0 to 100)
  rdd = rdd.map(x =&amp;gt; x)

rdd = rdd.cache
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here as you iteratively use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;oldRdd&lt;/code&gt; to do transformation, each iteration’s dependency chain will be added to recently used rdd, lastly this &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rdd&lt;/code&gt; will have a long dependency chain including all the iterative’s dependency. Also thls transformation will run gradually slower.&lt;/p&gt;

&lt;p&gt;So as included, the growth of dependencies makes serialization and deserialization of each task be a main burden when job runs. Also this reason can explain why task deserialization will meet stack overflow exception even job is not so complicated.&lt;/p&gt;

&lt;p&gt;I also tested without &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;oldRdd&lt;/code&gt; combined, each time &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;newGenRdd&lt;/code&gt; will be put in Shark’s memoryMetadataManager but without zip with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;oldRdd&lt;/code&gt;, now the job running time becomes stable.&lt;/p&gt;

&lt;p&gt;So I think for all the iterative job which will use previously calculated RDD will meet this problem. This problem will sometimes be hidden as GC problem or shuffle problem. For small iteratives this is not a big deal, but if you want to do some machine learning works that will iterate jobs for many times, this should be a problem.&lt;/p&gt;

&lt;p&gt;This issue is also stated in Spark User Group:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://groups.google.com/forum/?fromgroups#!searchin/spark-users/dependency/spark-users/-Cyfe3G6VwY/PFFnslzWn6AJ&quot;&gt;Is there some way to break down the RDD dependency
chain?&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://groups.google.com/forum/?fromgroups#!searchin/spark-users/dependency/spark-users/NkxcmmS-DbM/c9qvuShbHEUJ&quot;&gt;Spark Memory
Question&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;One way to break down this RDD dependency chain is to write RDD to file and read it back to memory, this will clean all the dependencies of this RDD. Maybe a way to clean dependencies might also be a solution, but it is hard to implment.&lt;/p&gt;
</description>
                <link>http://www.turbofei.wang/jerryshao/2013/05/22/SparkStreaming-Job-Troubleshooting-of-Dependency-Chain</link>
                <guid>http://www.turbofei.wang/jerryshao/2013/05/22/SparkStreaming-Job-Troubleshooting-of-Dependency-Chain</guid>
                <pubDate>2013-05-22T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>[转载] Spark源码分析之-deploy模块</title>
                <description>&lt;p&gt;本文转自&lt;a href=&quot;https://github.com/jerryshao/jerryshao.github.com&quot;&gt;Jerryshao Blog&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;

&lt;p&gt;在前文&lt;a href=&quot;http://jerryshao.me/Architecture/2013/04/21/Spark%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B-scheduler%E6%A8%A1%E5%9D%97/&quot;&gt;Spark源码分析之-scheduler模块&lt;/a&gt;中提到了Spark在资源管理和调度上采用了Hadoop &lt;a href=&quot;http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html&quot;&gt;&lt;strong&gt;YARN&lt;/strong&gt;&lt;/a&gt;的方式：外层的资源管理器和应用内的任务调度器；并且分析了Spark应用内的任务调度模块。本文就Spark的外层资源管理器-deploy模块进行分析，探究Spark是如何协调应用之间的资源调度和管理的&lt;/p&gt;

&lt;p&gt;Spark最初是交由&lt;a href=&quot;http://incubator.apache.org/mesos/&quot;&gt;&lt;strong&gt;Mesos&lt;/strong&gt;&lt;/a&gt;进行资源管理，为了使得更多的用户，包括没有接触过Mesos的用户使用Spark，Spark的开发者添加了Standalone的部署方式，也就是deploy模块。因此deploy模块只针对不使用Mesos进行资源管理的部署方式。&lt;/p&gt;

&lt;h1 id=&quot;deploy模块整体架构&quot;&gt;Deploy模块整体架构&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;deploy&lt;/strong&gt;模块主要包含3个子模块：&lt;strong&gt;master&lt;/strong&gt;, &lt;strong&gt;worker&lt;/strong&gt;, &lt;strong&gt;client&lt;/strong&gt;。他们继承于&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Actor&lt;/code&gt;，通过actor实现互相之间的通信。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Master&lt;/strong&gt;：master的主要功能是接收worker的注册并管理所有的worker，接收client提交的application，(FIFO)调度等待的application并向worker提交。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Worker&lt;/strong&gt;：worker的主要功能是向master注册自己，根据master发送的application配置进程环境，并启动&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;StandaloneExecutorBackend&lt;/code&gt;。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Client&lt;/strong&gt;：client的主要功能是向master注册并监控application。当用户创建&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SparkContext&lt;/code&gt;时会实例化&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SparkDeploySchedulerBackend&lt;/code&gt;，而实例化&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SparkDeploySchedulerBackend&lt;/code&gt;的同时就会启动client，通过向client传递启动参数和application有关信息，client向master发送请求注册application并且在slave node上启动&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;StandaloneExecutorBackend&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下面来看一下deploy模块的类图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2013-04-30-deploy/deploy_uml.png&quot; alt=&quot;Deploy moduler class chart&quot; width=&quot;640&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;deploy模块通信消息&quot;&gt;Deploy模块通信消息&lt;/h1&gt;

&lt;p&gt;Deploy模块并不复杂，代码也不多，主要集中在各个子模块之间的消息传递和处理上，因此在这里列出了各个模块之间传递的主要消息：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;client&lt;/strong&gt; to &lt;strong&gt;master&lt;/strong&gt;&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RegisterApplication&lt;/code&gt; (向master注册application)&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;master&lt;/strong&gt; to &lt;strong&gt;client&lt;/strong&gt;&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RegisteredApplication&lt;/code&gt; (作为注册application的reply，回复给client)&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ExecutorAdded&lt;/code&gt; (通知client worker已经启动了Executor环境，当向worker发送&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LaunchExecutor&lt;/code&gt;后通知client)&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ExecutorUpdated&lt;/code&gt; (通知client Executor状态已经发生变化了，包括结束、异常退出等，当worker向master发送&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ExecutorStateChanged&lt;/code&gt;后通知client)&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;master&lt;/strong&gt; to &lt;strong&gt;worker&lt;/strong&gt;&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LaunchExecutor&lt;/code&gt; (发送消息启动Executor环境)&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RegisteredWorker&lt;/code&gt; (作为worker向master注册的reply)&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RegisterWorkerFailed&lt;/code&gt; (作为worker向master注册失败的reply)&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;KillExecutor&lt;/code&gt; (发送给worker请求停止executor环境)&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;worker&lt;/strong&gt; to &lt;strong&gt;master&lt;/strong&gt;&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RegisterWorker&lt;/code&gt; (向master注册自己)&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Heartbeat&lt;/code&gt; (定期向master发送心跳信息)&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ExecutorStateChanged&lt;/code&gt; (向master发送Executor状态改变信息)&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;#Deploy模块代码详解#&lt;/p&gt;

&lt;p&gt;Deploy模块相比于scheduler模块简单，因此对于deploy模块的代码并不做十分细节的分析，只针对application的提交和结束过程做一定的分析。&lt;/p&gt;

&lt;h2 id=&quot;client提交application&quot;&gt;Client提交application&lt;/h2&gt;

&lt;p&gt;Client是由&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SparkDeploySchedulerBackend&lt;/code&gt;创建被启动的，因此client是被嵌入在每一个application中，只为这个applicator所服务，在client启动时首先会先master注册application：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def start() {
  // Just launch an actor; it will call back into the listener.
  actor = actorSystem.actorOf(Props(new ClientActor))
}

override def preStart() {
  logInfo(&quot;Connecting to master &quot; + masterUrl)
  try {
    master = context.actorFor(Master.toAkkaUrl(masterUrl))
    masterAddress = master.path.address
    master ! RegisterApplication(appDescription) //向master注册application
    context.system.eventStream.subscribe(self, classOf[RemoteClientLifeCycleEvent])
    context.watch(master)  // Doesn&apos;t work with remote actors, but useful for testing
  } catch {
    case e: Exception =&amp;gt;
      logError(&quot;Failed to connect to master&quot;, e)
      markDisconnected()
      context.stop(self)
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Master在收到&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RegisterApplication&lt;/code&gt;请求后会把application加到等待队列中，等待调度：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;case RegisterApplication(description) =&amp;gt; {
  logInfo(&quot;Registering app &quot; + description.name)
  val app = addApplication(description, sender)
  logInfo(&quot;Registered app &quot; + description.name + &quot; with ID &quot; + app.id)
  waitingApps += app
  context.watch(sender)  // This doesn&apos;t work with remote actors but helps for testing
  sender ! RegisteredApplication(app.id)
  schedule()
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Master会在每次操作后调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;schedule()&lt;/code&gt;函数，以确保等待的application能够被及时调度。&lt;/p&gt;

&lt;p&gt;在前面提到deploy模块是资源管理模块，那么Spark的deploy管理的是什么资源，资源以什么单位进行调度的呢？在当前版本的Spark中，集群的cpu数量是Spark资源管理的一个标准，每个提交的application都会标明自己所需要的资源数(也就是cpu的core数)，Master以FIFO的方式管理所有的application请求，当资源数量满足当前任务执行需求的时候该任务就会被调度，否则就继续等待，当然如果master能给予当前任务部分资源则也会启动该application。&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;schedule()&lt;/code&gt;函数实现的就是此功能。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def schedule() {
  if (spreadOutApps) {
    for (app &amp;lt;- waitingApps if app.coresLeft &amp;gt; 0) {
      val usableWorkers = workers.toArray.filter(_.state == WorkerState.ALIVE)
                                 .filter(canUse(app, _)).sortBy(_.coresFree).reverse
      val numUsable = usableWorkers.length
      val assigned = new Array[Int](numUsable) // Number of cores to give on each node
      var toAssign = math.min(app.coresLeft, usableWorkers.map(_.coresFree).sum)
      var pos = 0
      while (toAssign &amp;gt; 0) {
        if (usableWorkers(pos).coresFree - assigned(pos) &amp;gt; 0) {
          toAssign -= 1
          assigned(pos) += 1
        }
        pos = (pos + 1) % numUsable
      }
      // Now that we&apos;ve decided how many cores to give on each node, let&apos;s actually give them
      for (pos &amp;lt;- 0 until numUsable) {
        if (assigned(pos) &amp;gt; 0) {
          val exec = app.addExecutor(usableWorkers(pos), assigned(pos))
          launchExecutor(usableWorkers(pos), exec, app.desc.sparkHome)
          app.state = ApplicationState.RUNNING
        }
      }
    }
  } else {
    // Pack each app into as few nodes as possible until we&apos;ve assigned all its cores
    for (worker &amp;lt;- workers if worker.coresFree &amp;gt; 0 &amp;amp;&amp;amp; worker.state == WorkerState.ALIVE) {
      for (app &amp;lt;- waitingApps if app.coresLeft &amp;gt; 0) {
        if (canUse(app, worker)) {
          val coresToUse = math.min(worker.coresFree, app.coresLeft)
          if (coresToUse &amp;gt; 0) {
            val exec = app.addExecutor(worker, coresToUse)
            launchExecutor(worker, exec, app.desc.sparkHome)
            app.state = ApplicationState.RUNNING
          }
        }
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;当application得到调度后就会调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;launchExecutor()&lt;/code&gt;向worker发送请求，同时向client汇报状态：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def launchExecutor(worker: WorkerInfo, exec: ExecutorInfo, sparkHome: String) {
  worker.addExecutor(exec)
  worker.actor ! LaunchExecutor(exec.application.id, exec.id, exec.application.desc, exec.cores, exec.memory, sparkHome)
  exec.application.driver ! ExecutorAdded(exec.id, worker.id, worker.host, exec.cores, exec.memory)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;至此client与master的交互已经转向了master与worker的交互，worker需要配置application启动环境&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;case LaunchExecutor(appId, execId, appDesc, cores_, memory_, execSparkHome_) =&amp;gt;
  val manager = new ExecutorRunner(
    appId, execId, appDesc, cores_, memory_, self, workerId, ip, new File(execSparkHome_), workDir)
  executors(appId + &quot;/&quot; + execId) = manager
  manager.start()
  coresUsed += cores_
  memoryUsed += memory_
  master ! ExecutorStateChanged(appId, execId, ExecutorState.RUNNING, None, None)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Worker在接收到&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LaunchExecutor&lt;/code&gt;消息后创建&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ExecutorRunner&lt;/code&gt;实例，同时汇报master executor环境启动。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ExecutorRunner&lt;/code&gt;在启动的过程中会创建线程，配置环境，启动新进程：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def start() {
  workerThread = new Thread(&quot;ExecutorRunner for &quot; + fullId) {
    override def run() { fetchAndRunExecutor() }
  }
  workerThread.start()

  // Shutdown hook that kills actors on shutdown.
  ...
}

def fetchAndRunExecutor() {
  try {
    // Create the executor&apos;s working directory
    val executorDir = new File(workDir, appId + &quot;/&quot; + execId)
    if (!executorDir.mkdirs()) {
      throw new IOException(&quot;Failed to create directory &quot; + executorDir)
    }

    // Launch the process
    val command = buildCommandSeq()
    val builder = new ProcessBuilder(command: _*).directory(executorDir)
    val env = builder.environment()
    for ((key, value) &amp;lt;- appDesc.command.environment) {
      env.put(key, value)
    }
    env.put(&quot;SPARK_MEM&quot;, memory.toString + &quot;m&quot;)
    // In case we are running this from within the Spark Shell, avoid creating a &quot;scala&quot;
    // parent process for the executor command
    env.put(&quot;SPARK_LAUNCH_WITH_SCALA&quot;, &quot;0&quot;)
    process = builder.start()

    // Redirect its stdout and stderr to files
    redirectStream(process.getInputStream, new File(executorDir, &quot;stdout&quot;))
    redirectStream(process.getErrorStream, new File(executorDir, &quot;stderr&quot;))

    // Wait for it to exit; this is actually a bad thing if it happens, because we expect to run
    // long-lived processes only. However, in the future, we might restart the executor a few
    // times on the same machine.
    val exitCode = process.waitFor()
    val message = &quot;Command exited with code &quot; + exitCode
    worker ! ExecutorStateChanged(appId, execId, ExecutorState.FAILED, Some(message),
                                  Some(exitCode))
  } catch {
    case interrupted: InterruptedException =&amp;gt;
      logInfo(&quot;Runner thread for executor &quot; + fullId + &quot; interrupted&quot;)

    case e: Exception =&amp;gt; {
      logError(&quot;Error running executor&quot;, e)
      if (process != null) {
        process.destroy()
      }
      val message = e.getClass + &quot;: &quot; + e.getMessage
      worker ! ExecutorStateChanged(appId, execId, ExecutorState.FAILED, Some(message), None)
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ExecutorRunner&lt;/code&gt;启动后worker向master汇报&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ExecutorStateChanged&lt;/code&gt;，而master则将消息重新pack成为&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ExecutorUpdated&lt;/code&gt;发送给client。&lt;/p&gt;

&lt;p&gt;至此整个application提交过程基本结束，提交的过程并不复杂，主要涉及到的消息的传递。&lt;/p&gt;

&lt;h2 id=&quot;application的结束&quot;&gt;Application的结束&lt;/h2&gt;

&lt;p&gt;由于各种原因(包括正常结束，异常返回等)会造成application的结束，我们现在就来看看applicatoin结束的整个流程。&lt;/p&gt;

&lt;p&gt;application的结束往往会造成client的结束，而client的结束会被master通过&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Actor&lt;/code&gt;检测到，master检测到后会调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;removeApplication()&lt;/code&gt;函数进行操作：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def removeApplication(app: ApplicationInfo) {
  if (apps.contains(app)) {
    logInfo(&quot;Removing app &quot; + app.id)
    apps -= app
    idToApp -= app.id
    actorToApp -= app.driver
    addressToWorker -= app.driver.path.address
    completedApps += app   // Remember it in our history
    waitingApps -= app
    for (exec &amp;lt;- app.executors.values) {
      exec.worker.removeExecutor(exec)
      exec.worker.actor ! KillExecutor(exec.application.id, exec.id)
    }
    app.markFinished(ApplicationState.FINISHED)  // TODO: Mark it as FAILED if it failed
    schedule()
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;removeApplicatoin()&lt;/code&gt;首先会将application从master自身所管理的数据结构中删除，其次它会通知每一个work，请求其&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;KillExecutor&lt;/code&gt;。worker在收到&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;KillExecutor&lt;/code&gt;后调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ExecutorRunner&lt;/code&gt;的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kill()&lt;/code&gt;函数：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;case KillExecutor(appId, execId) =&amp;gt;
  val fullId = appId + &quot;/&quot; + execId
  executors.get(fullId) match {
    case Some(executor) =&amp;gt;
      logInfo(&quot;Asked to kill executor &quot; + fullId)
      executor.kill()
    case None =&amp;gt;
      logInfo(&quot;Asked to kill unknown executor &quot; + fullId)
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ExecutorRunner&lt;/code&gt;内部，它会结束监控线程，同时结束监控线程所启动的进程，并且向worker汇报&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ExecutorStateChanged&lt;/code&gt;：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def kill() {
  if (workerThread != null) {
    workerThread.interrupt()
    workerThread = null
    if (process != null) {
      logInfo(&quot;Killing process!&quot;)
      process.destroy()
      process.waitFor()
    }
    worker ! ExecutorStateChanged(appId, execId, ExecutorState.KILLED, None, None)
    Runtime.getRuntime.removeShutdownHook(shutdownHook)
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Application结束的同时清理了master和worker上的关于该application的所有信息，这样关于application结束的整个流程就介绍完了，当然在这里我们对于许多异常处理分支没有细究，但这并不影响我们对主线的把握。&lt;/p&gt;

&lt;h1 id=&quot;end&quot;&gt;End&lt;/h1&gt;

&lt;p&gt;至此对于deploy模块的分析暂告一个段落。deploy模块相对来说比较简单，也没有特别复杂的逻辑结构，正如前面所说的deploy模块是为了能让更多的没有部署Mesos的集群的用户能够使用Spark而实现的一种方案。&lt;/p&gt;

&lt;p&gt;当然现阶段看来还略微简陋，比如application的调度方式(FIFO)是否会造成小应用长时间等待大应用的结束，是否有更好的调度策略；资源的衡量标准是否可以更多更合理，而不单单是cpu数量，因为现实场景中有的应用是disk intensive，有的是network intensive，这样就算cpu资源有富余，调度新的application也不一定会很有意义。&lt;/p&gt;

&lt;p&gt;总的来说作为Mesos的一种简单替代方式，deploy模块对于推广Spark还是有积极意义的。&lt;/p&gt;
</description>
                <link>http://www.turbofei.wang/jerryshao/2013/04/30/Spark%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B-deploy%E6%A8%A1%E5%9D%97</link>
                <guid>http://www.turbofei.wang/jerryshao/2013/04/30/Spark源码分析之-deploy模块</guid>
                <pubDate>2013-04-30T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>[转载] Spark源码分析之-scheduler模块</title>
                <description>&lt;p&gt;本文转自&lt;a href=&quot;https://github.com/jerryshao/jerryshao.github.com&quot;&gt;Jerryshao Blog&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;

&lt;p&gt;Spark在资源管理和调度方式上采用了类似于Hadoop &lt;a href=&quot;http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html&quot;&gt;&lt;strong&gt;YARN&lt;/strong&gt;&lt;/a&gt;的方式，最上层是资源调度器，它负责分配资源和调度注册到Spark中的所有应用，Spark选用&lt;a href=&quot;http://incubator.apache.org/mesos/&quot;&gt;Mesos&lt;/a&gt;或是YARN等作为其资源调度框架。在每一个应用内部，Spark又实现了任务调度器，负责任务的调度和协调，类似于&lt;a href=&quot;http://hadoop.apache.org/&quot;&gt;MapReduce&lt;/a&gt;。本质上，外层的资源调度和内层的任务调度相互独立，各司其职。本文对于Spark的源码分析主要集中在内层的任务调度器上，分析Spark任务调度器的实现。&lt;/p&gt;

&lt;h1 id=&quot;scheduler模块整体架构&quot;&gt;Scheduler模块整体架构&lt;/h1&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scheduler&lt;/code&gt;模块主要分为两大部分：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TaskSchedulerListener&lt;/code&gt;。&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TaskSchedulerListener&lt;/code&gt;部分的主要功能是监听用户提交的job，将job分解为不同的类型的stage以及相应的task，并向&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TaskScheduler&lt;/code&gt;提交task。&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TaskScheduler&lt;/code&gt;。&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TaskScheduler&lt;/code&gt;接收用户提交的task并执行。而&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TaskScheduler&lt;/code&gt;根据部署的不同又分为三个子模块:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ClusterScheduler&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LocalScheduler&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MesosScheduler&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;taskschedulerlistener&quot;&gt;TaskSchedulerListener&lt;/h2&gt;

&lt;p&gt;Spark抽象了&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TaskSchedulerListener&lt;/code&gt;并在其上实现了&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DAGScheduler&lt;/code&gt;。&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DAGScheduler&lt;/code&gt;的主要功能是接收用户提交的job，将job根据类型划分为不同的stage，并在每一个stage内产生一系列的task，向&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TaskScheduler&lt;/code&gt;提交task。下面我们首先来看一下&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TaskSchedulerListener&lt;/code&gt;部分的类图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2013-04-21-sheduler/dagscheduler.png&quot; alt=&quot;DAGScheduler class chart&quot; width=&quot;640&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;用户所提交的job在得到&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DAGScheduler&lt;/code&gt;的调度后，会被包装成&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ActiveJob&lt;/code&gt;，同时会启动&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;JobWaiter&lt;/code&gt;阻塞监听job的完成状况。&lt;/li&gt;
  &lt;li&gt;于此同时依据job中&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RDD&lt;/code&gt;的dependency和dependency属性(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NarrowDependency&lt;/code&gt;，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ShufflerDependecy&lt;/code&gt;)，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DAGScheduler&lt;/code&gt;会根据依赖关系的先后产生出不同的stage DAG(result stage, shuffle map stage)。&lt;/li&gt;
  &lt;li&gt;在每一个stage内部，根据stage产生出相应的task，包括&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ResultTask&lt;/code&gt;或是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ShuffleMapTask&lt;/code&gt;，这些task会根据&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RDD&lt;/code&gt;中partition的数量和分布，产生出一组相应的task，并将其包装为&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TaskSet&lt;/code&gt;提交到&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TaskScheduler&lt;/code&gt;上去。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;h4 id=&quot;rdd的依赖关系和stage的分类&quot;&gt;RDD的依赖关系和Stage的分类&lt;/h4&gt;
  &lt;p&gt;在Spark中，每一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RDD&lt;/code&gt;是对于数据集在某一状态下的表现形式，而这个状态有可能是从前一状态转换而来的，因此换句话说这一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RDD&lt;/code&gt;有可能与之前的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RDD(s)&lt;/code&gt;有依赖关系。根据依赖关系的不同，可以将&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RDD&lt;/code&gt;分成两种不同的类型：&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Narrow Dependency&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Wide Dependency&lt;/code&gt;。&lt;/p&gt;

  &lt;ul&gt;
    &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Narrow Dependency&lt;/code&gt;指的是 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;child RDD&lt;/code&gt;只依赖于&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parent RDD(s)&lt;/code&gt;固定数量的partition。&lt;/li&gt;
    &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Wide Dependency&lt;/code&gt;指的是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;child RDD&lt;/code&gt;的每一个partition都依赖于&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parent RDD(s)&lt;/code&gt;所有partition。&lt;/li&gt;
  &lt;/ul&gt;

  &lt;p&gt;它们之间的区别可参看下图：&lt;/p&gt;

  &lt;p&gt;&lt;img src=&quot;/img/2013-04-21-sheduler/rdd_dependency.png&quot; alt=&quot;RDD dependecies&quot; width=&quot;480&quot; /&gt;&lt;/p&gt;

  &lt;p&gt;根据&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RDD&lt;/code&gt;依赖关系的不同，Spark也将每一个job分为不同的stage，而stage之间的依赖关系则形成了DAG。对于&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Narrow Dependency&lt;/code&gt;，Spark会尽量多地将&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RDD&lt;/code&gt;转换放在同一个stage中；而对于&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Wide Dependency&lt;/code&gt;，由于&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Wide Dependency&lt;/code&gt;通常意味着shuffle操作，因此Spark会将此stage定义为&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ShuffleMapStage&lt;/code&gt;，以便于向&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MapOutputTracker&lt;/code&gt;注册shuffle操作。对于stage的划分可参看下图，Spark通常将shuffle操作定义为stage的边界。&lt;/p&gt;

  &lt;p&gt;&lt;img src=&quot;/img/2013-04-21-sheduler/stage.png&quot; alt=&quot;different stage boundary&quot; width=&quot;480&quot; /&gt;&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h3 id=&quot;dagscheduler&quot;&gt;DAGScheduler&lt;/h3&gt;

&lt;p&gt;在用户创建&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SparkContext&lt;/code&gt;对象时，Spark会在内部创建&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DAGScheduler&lt;/code&gt;对象，并根据用户的部署情况，绑定不同的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TaskSechduler&lt;/code&gt;，并启动&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DAGcheduler&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private var taskScheduler: TaskScheduler = {
    //...
}
taskScheduler.start()

private var dagScheduler = new DAGScheduler(taskScheduler)
dagScheduler.start()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;而&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DAGScheduler&lt;/code&gt;的启动会在内部创建daemon线程，daemon线程调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;run()&lt;/code&gt;从block queue中取出event进行处理。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def run() {
  SparkEnv.set(env)

  while (true) {
    val event = eventQueue.poll(POLL_TIMEOUT, TimeUnit.MILLISECONDS)
    if (event != null) {
      logDebug(&quot;Got event of type &quot; + event.getClass.getName)
    }

    if (event != null) {
      if (processEvent(event)) {
        return
      }
    }

    val time = System.currentTimeMillis() // TODO: use a pluggable clock for testability
    if (failed.size &amp;gt; 0 &amp;amp;&amp;amp; time &amp;gt; lastFetchFailureTime + RESUBMIT_TIMEOUT) {
      resubmitFailedStages()
    } else {
      submitWaitingStages()
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;而&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;run()&lt;/code&gt;会调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;processEvent&lt;/code&gt;来处理不同的event。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DAGScheduler&lt;/code&gt;处理的event包括：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;JobSubmitted&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CompletionEvent&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ExecutorLost&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TaskFailed&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;StopDAGScheduler&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;根据event的不同调用不同的方法去处理。&lt;/p&gt;

&lt;p&gt;本质上&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DAGScheduler&lt;/code&gt;是一个生产者-消费者模型，用户和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TaskSchduler&lt;/code&gt;产生event将其放入block queue，daemon线程消费event并处理相应事件。&lt;/p&gt;

&lt;h3 id=&quot;job的生与死&quot;&gt;Job的生与死&lt;/h3&gt;

&lt;p&gt;既然用户提交的job最终会交由&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DAGScheduler&lt;/code&gt;去处理，那么我们就来研究一下&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DAGScheduler&lt;/code&gt;处理job的整个流程。在这里我们分析两种不同类型的job的处理流程。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;没有shuffle和reduce的job&lt;/p&gt;

 	val textFile = sc.textFile(“README.md”)
 	textFile.filter(line =&amp;gt; line.contains(“Spark”)).count()
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;有shuffle和reduce的job&lt;/p&gt;

 	val textFile = sc.textFile(“README.md”)
 	textFile.flatMap(line =&amp;gt; line.split(“ “)).map(word =&amp;gt; (word, 1)).reduceByKey((a, b) =&amp;gt; a + b)
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;首先在对&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RDD&lt;/code&gt;的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;count()&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;reduceByKey()&lt;/code&gt;操作都会调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SparkContext&lt;/code&gt;的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;runJob()&lt;/code&gt;来提交job，而&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SparkContext&lt;/code&gt;的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;runJob()&lt;/code&gt;最终会调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DAGScheduler&lt;/code&gt;的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;runJob()&lt;/code&gt;：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def runJob[T, U: ClassManifest](
    finalRdd: RDD[T],
    func: (TaskContext, Iterator[T]) =&amp;gt; U,
    partitions: Seq[Int],
    callSite: String,
    allowLocal: Boolean,
    resultHandler: (Int, U) =&amp;gt; Unit)
{
  if (partitions.size == 0) {
    return
  }
  val (toSubmit, waiter) = prepareJob(
      finalRdd, func, partitions, callSite, allowLocal, resultHandler)
  eventQueue.put(toSubmit)
  waiter.awaitResult() match {
    case JobSucceeded =&amp;gt; {}
    case JobFailed(exception: Exception) =&amp;gt;
      logInfo(&quot;Failed to run &quot; + callSite)
      throw exception
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;runJob()&lt;/code&gt;会调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;prepareJob()&lt;/code&gt;对job进行预处理，封装成&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;JobSubmitted&lt;/code&gt;事件，放入queue中，并阻塞等待job完成。&lt;/p&gt;

&lt;p&gt;当daemon线程的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;processEvent()&lt;/code&gt;从queue中取出&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;JobSubmitted&lt;/code&gt;事件后，会根据job划分出不同的stage，并且提交stage：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;case JobSubmitted(finalRDD, func, partitions, allowLocal, callSite, listener) =&amp;gt;
  val runId = nextRunId.getAndIncrement()
  val finalStage = newStage(finalRDD, None, runId)
  val job = new ActiveJob(runId, finalStage, func, partitions, callSite, listener)
  clearCacheLocs()
  if (allowLocal &amp;amp;&amp;amp; finalStage.parents.size == 0 &amp;amp;&amp;amp; partitions.length == 1) {
    runLocally(job)
  } else {
    activeJobs += job
    resultStageToJob(finalStage) = job
    submitStage(finalStage)
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;首先，对于任何的job都会产生出一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;finalStage&lt;/code&gt;来产生和提交task。其次对于某些简单的job，它没有依赖关系，并且只有一个partition，这样的job会使用local thread处理而并非提交到&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TaskScheduler&lt;/code&gt;上处理。&lt;/p&gt;

&lt;p&gt;接下来产生&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;finalStage&lt;/code&gt;后，需要调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;submitStage()&lt;/code&gt;，它根据stage之间的依赖关系得出stage DAG，并以依赖关系进行处理：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def submitStage(stage: Stage) {
  if (!waiting(stage) &amp;amp;&amp;amp; !running(stage) &amp;amp;&amp;amp; !failed(stage)) {
    val missing = getMissingParentStages(stage).sortBy(_.id)
    if (missing == Nil) {
      submitMissingTasks(stage)
      running += stage
    } else {
      for (parent &amp;lt;- missing) {
        submitStage(parent)
      }
      waiting += stage
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;对于新提交的job，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;finalStage&lt;/code&gt;的parent stage还未获得，因此&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;submitStage&lt;/code&gt;会调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;getMissingParentStages()&lt;/code&gt;来获得依赖关系：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def getMissingParentStages(stage: Stage): List[Stage] = {
  val missing = new HashSet[Stage]
  val visited = new HashSet[RDD[_]]
  def visit(rdd: RDD[_]) {
    if (!visited(rdd)) {
      visited += rdd
      if (getCacheLocs(rdd).contains(Nil)) {
        for (dep &amp;lt;- rdd.dependencies) {
          dep match {
            case shufDep: ShuffleDependency[_,_] =&amp;gt;
              val mapStage = getShuffleMapStage(shufDep, stage.priority)
              if (!mapStage.isAvailable) {
                missing += mapStage
              }
            case narrowDep: NarrowDependency[_] =&amp;gt;
              visit(narrowDep.rdd)
          }
        }
      }
    }
  }
  visit(stage.rdd)
  missing.toList
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里parent stage是通过&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RDD&lt;/code&gt;的依赖关系递归遍历获得。对于&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Wide Dependecy&lt;/code&gt;也就是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Shuffle Dependecy&lt;/code&gt;，Spark会产生新的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mapStage&lt;/code&gt;作为&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;finalStage&lt;/code&gt;的parent，而对于&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Narrow Dependecy&lt;/code&gt; Spark则不会产生新的stage。这里对stage的划分是按照上面提到的作为划分依据的，因此对于本段开头提到的两种job，第一种job只会产生一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;finalStage&lt;/code&gt;，而第二种job会产生&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;finalStage&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mapStage&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;当stage DAG产生以后，针对每个stage需要产生task去执行，故在这会调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;submitMissingTasks()&lt;/code&gt;：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def submitMissingTasks(stage: Stage) {
  val myPending = pendingTasks.getOrElseUpdate(stage, new HashSet)
  myPending.clear()
  var tasks = ArrayBuffer[Task[_]]()
  if (stage.isShuffleMap) {
    for (p &amp;lt;- 0 until stage.numPartitions if stage.outputLocs(p) == Nil) {
      val locs = getPreferredLocs(stage.rdd, p)
      tasks += new ShuffleMapTask(stage.id, stage.rdd, stage.shuffleDep.get, p, locs)
    }
  } else {
    val job = resultStageToJob(stage)
    for (id &amp;lt;- 0 until job.numPartitions if (!job.finished(id))) {
      val partition = job.partitions(id)
      val locs = getPreferredLocs(stage.rdd, partition)
      tasks += new ResultTask(stage.id, stage.rdd, job.func, partition, locs, id)
    }
  }
  if (tasks.size &amp;gt; 0) {
    myPending ++= tasks
    taskSched.submitTasks(
      new TaskSet(tasks.toArray, stage.id, stage.newAttemptId(), stage.priority))
    if (!stage.submissionTime.isDefined) {
      stage.submissionTime = Some(System.currentTimeMillis())
    }
  } else {
    running -= stage
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;首先根据stage所依赖的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RDD&lt;/code&gt;的partition的分布，会产生出与partition数量相等的task，这些task根据partition的locality进行分布；其次对于&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;finalStage&lt;/code&gt;或是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mapStage&lt;/code&gt;会产生不同的task；最后所有的task会封装到&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TaskSet&lt;/code&gt;内提交到&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TaskScheduler&lt;/code&gt;去执行。&lt;/p&gt;

&lt;p&gt;至此job在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DAGScheduler&lt;/code&gt;内的启动过程全部完成，交由&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TaskScheduler&lt;/code&gt;执行task，当task执行完后会将结果返回给&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DAGScheduler&lt;/code&gt;，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DAGScheduler&lt;/code&gt;调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;handleTaskComplete()&lt;/code&gt;处理task返回:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def handleTaskCompletion(event: CompletionEvent) {
  val task = event.task
  val stage = idToStage(task.stageId)

  def markStageAsFinished(stage: Stage) = {
    val serviceTime = stage.submissionTime match {
      case Some(t) =&amp;gt; &quot;%.03f&quot;.format((System.currentTimeMillis() - t) / 1000.0)
      case _ =&amp;gt; &quot;Unkown&quot;
    }
    logInfo(&quot;%s (%s) finished in %s s&quot;.format(stage, stage.origin, serviceTime))
    running -= stage
  }
  event.reason match {
    case Success =&amp;gt;
        ...
      task match {
        case rt: ResultTask[_, _] =&amp;gt;
          ...
        case smt: ShuffleMapTask =&amp;gt;
          ...
      }
    case Resubmitted =&amp;gt;
      ...

    case FetchFailed(bmAddress, shuffleId, mapId, reduceId) =&amp;gt;
      ...
    case other =&amp;gt;
      abortStage(idToStage(task.stageId), task + &quot; failed: &quot; + other)
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;每个执行完成的task都会将结果返回给&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DAGScheduler&lt;/code&gt;，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DAGScheduler&lt;/code&gt;根据返回结果来进行进一步的动作。&lt;/p&gt;

&lt;h3 id=&quot;rdd的计算&quot;&gt;RDD的计算&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RDD&lt;/code&gt;的计算是在task中完成的。我们之前提到task分为&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ResultTask&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ShuffleMapTask&lt;/code&gt;，我们分别来看一下这两种task具体的执行过程。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ResultTask&lt;/code&gt;&lt;/p&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  override def run(attemptId: Long): U = {
    val context = new TaskContext(stageId, partition, attemptId)
    try {
      func(context, rdd.iterator(split, context))
    } finally {
      context.executeOnCompleteCallbacks()
    }
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ShuffleMapTask&lt;/code&gt;&lt;/p&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  override def run(attemptId: Long): MapStatus = {
    val numOutputSplits = dep.partitioner.numPartitions
    
    val taskContext = new TaskContext(stageId, partition, attemptId)
    try {
      val buckets = Array.fill(numOutputSplits)(new ArrayBuffer[(Any, Any)])
      for (elem &amp;lt;- rdd.iterator(split, taskContext)) {
        val pair = elem.asInstanceOf[(Any, Any)]
        val bucketId = dep.partitioner.getPartition(pair._1)
        buckets(bucketId) += pair
      }
    
      val compressedSizes = new Array[Byte](numOutputSplits)
    
      val blockManager = SparkEnv.get.blockManager
      for (i &amp;lt;- 0 until numOutputSplits) {
        val blockId = &quot;shuffle_&quot; + dep.shuffleId + &quot;_&quot; + partition + &quot;_&quot; + i
        val iter: Iterator[(Any, Any)] = buckets(i).iterator
        val size = blockManager.put(blockId, iter, StorageLevel.DISK_ONLY, false)
        compressedSizes(i) = MapOutputTracker.compressSize(size)
      }
    
      return new MapStatus(blockManager.blockManagerId, compressedSizes)
    } finally {
      taskContext.executeOnCompleteCallbacks()
    }
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ResultTask&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ShuffleMapTask&lt;/code&gt;都会调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RDD&lt;/code&gt;的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;iterator()&lt;/code&gt;来计算和转换&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RDD&lt;/code&gt;，不同的是：&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ResultTask&lt;/code&gt;转换完&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RDD&lt;/code&gt;后调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;func()&lt;/code&gt;计算结果；而&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ShufflerMapTask&lt;/code&gt;则将其放入&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;blockManager&lt;/code&gt;中用来shuffle。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RDD&lt;/code&gt;的计算调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;iterator()&lt;/code&gt;，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;iterator()&lt;/code&gt;在内部调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;compute()&lt;/code&gt;从&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RDD&lt;/code&gt;依赖关系的根开始计算：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;final def iterator(split: Partition, context: TaskContext): Iterator[T] = {
  if (storageLevel != StorageLevel.NONE) {
    SparkEnv.get.cacheManager.getOrCompute(this, split, context, storageLevel)
  } else {
    computeOrReadCheckpoint(split, context)
  }
}

private[spark] def computeOrReadCheckpoint(split: Partition, context: TaskContext): Iterator[T] = {
  if (isCheckpointed) {
    firstParent[T].iterator(split, context)
  } else {
    compute(split, context)
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;至此大致分析了&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TaskSchedulerListener&lt;/code&gt;，包括&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DAGScheduler&lt;/code&gt;内部的结构，job生命周期内的活动，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RDD&lt;/code&gt;是何时何地计算的。接下来我们分析一下task在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TaskScheduler&lt;/code&gt;内干了什么。&lt;/p&gt;

&lt;h2 id=&quot;taskscheduler&quot;&gt;TaskScheduler&lt;/h2&gt;

&lt;p&gt;前面也提到了Spark实现了三种不同的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TaskScheduler&lt;/code&gt;，包括&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LocalSheduler&lt;/code&gt;、&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ClusterScheduler&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MesosScheduler&lt;/code&gt;。&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LocalSheduler&lt;/code&gt;是一个在本地执行的线程池，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DAGScheduler&lt;/code&gt;提交的所有task会在线程池中被执行，并将结果返回给&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DAGScheduler&lt;/code&gt;。&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MesosScheduler&lt;/code&gt;依赖于Mesos进行调度，笔者对Mesos了解甚少，因此不做分析。故此章节主要分析&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ClusterScheduler&lt;/code&gt;模块。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ClusterScheduler&lt;/code&gt;模块与deploy模块和executor模块耦合较为紧密，因此在分析&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ClUsterScheduler&lt;/code&gt;时也会顺带介绍deploy和executor模块。&lt;/p&gt;

&lt;p&gt;首先我们来看一下&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ClusterScheduler&lt;/code&gt;的类图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2013-04-21-sheduler/cluster_scheduler.png&quot; alt=&quot;ClusterScheduler&quot; width=&quot;640&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ClusterScheduler&lt;/code&gt;的启动会伴随&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SparkDeploySchedulerBackend&lt;/code&gt;的启动，而backend会将自己分为两个角色：首先是driver，driver是一个local运行的actor，负责与remote的executor进行通行，提交任务，控制executor；其次是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;StandaloneExecutorBackend&lt;/code&gt;，Spark会在每一个slave node上启动一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;StandaloneExecutorBackend&lt;/code&gt;进程，负责执行任务，返回执行结果。&lt;/p&gt;

&lt;h3 id=&quot;clusterscheduler的启动&quot;&gt;ClusterScheduler的启动&lt;/h3&gt;

&lt;p&gt;在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SparkContext&lt;/code&gt;实例化的过程中，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ClusterScheduler&lt;/code&gt;被随之实例化，同时赋予其&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SparkDeploySchedulerBackend&lt;/code&gt;：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  master match {
      ...

    case SPARK_REGEX(sparkUrl) =&amp;gt;
      val scheduler = new ClusterScheduler(this)
      val backend = new SparkDeploySchedulerBackend(scheduler, this, sparkUrl, appName)
      scheduler.initialize(backend)
      scheduler

    case LOCAL_CLUSTER_REGEX(numSlaves, coresPerSlave, memoryPerSlave) =&amp;gt;
      ...
    case _ =&amp;gt;
      ...
  }
}
taskScheduler.start()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ClusterScheduler&lt;/code&gt;的启动会启动&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SparkDeploySchedulerBackend&lt;/code&gt;，同时启动daemon进程来检查speculative task：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;override def start() {
  backend.start()

  if (System.getProperty(&quot;spark.speculation&quot;, &quot;false&quot;) == &quot;true&quot;) {
    new Thread(&quot;ClusterScheduler speculation check&quot;) {
      setDaemon(true)

      override def run() {
        while (true) {
          try {
            Thread.sleep(SPECULATION_INTERVAL)
          } catch {
            case e: InterruptedException =&amp;gt; {}
          }
          checkSpeculatableTasks()
        }
      }
    }.start()
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SparkDeploySchedulerBacked&lt;/code&gt;的启动首先会调用父类的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;start()&lt;/code&gt;，接着它会启动client，并由client连接到master向每一个node的worker发送请求启动&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;StandaloneExecutorBackend&lt;/code&gt;。这里的client、master、worker涉及到了deploy模块，暂时不做具体介绍。而&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;StandaloneExecutorBackend&lt;/code&gt;则涉及到了executor模块，它主要的功能是在每一个node创建task可以运行的环境，并让task在其环境中运行。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;override def start() {
  super.start()

  val driverUrl = &quot;akka://spark@%s:%s/user/%s&quot;.format(
    System.getProperty(&quot;spark.driver.host&quot;), System.getProperty(&quot;spark.driver.port&quot;),
    StandaloneSchedulerBackend.ACTOR_NAME)
  val args = Seq(driverUrl, &quot;&quot;, &quot;&quot;, &quot;&quot;)
  val command = Command(&quot;spark.executor.StandaloneExecutorBackend&quot;, args, sc.executorEnvs)
  val sparkHome = sc.getSparkHome().getOrElse(
    throw new IllegalArgumentException(&quot;must supply spark home for spark standalone&quot;))
  val appDesc = new ApplicationDescription(appName, maxCores, executorMemory, command, sparkHome)

  client = new Client(sc.env.actorSystem, master, appDesc, this)
  client.start()
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;StandaloneSchedulerBackend&lt;/code&gt;中会创建&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DriverActor&lt;/code&gt;，它就是local的driver，以actor的方式与remote的executor进行通信。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;override def start() {
  val properties = new ArrayBuffer[(String, String)]
  val iterator = System.getProperties.entrySet.iterator
  while (iterator.hasNext) {
    val entry = iterator.next
    val (key, value) = (entry.getKey.toString, entry.getValue.toString)
    if (key.startsWith(&quot;spark.&quot;)) {
      properties += ((key, value))
    }
  }
  driverActor = actorSystem.actorOf(
    Props(new DriverActor(properties)), name = StandaloneSchedulerBackend.ACTOR_NAME)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在client实例化之前，会将&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;StandaloneExecutorBackend&lt;/code&gt;的启动环境作为参数传递给client，而client启动时会将此提交给master，由master分发给所有node上的worker，worker会配置环境并创建进程启动&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;StandaloneExecutorBackend&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;至此&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ClusterScheduler&lt;/code&gt;的启动，local driver的创建，remote executor环境的启动所有过程都已结束，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ClusterScheduler&lt;/code&gt;等待&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DAGScheduler&lt;/code&gt;提交任务。&lt;/p&gt;

&lt;h3 id=&quot;clusterscheduler提交任务&quot;&gt;ClusterScheduler提交任务&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DAGScheduler&lt;/code&gt;会调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ClusterScheduler&lt;/code&gt;提交任务，任务会被包装成&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TaskSetManager&lt;/code&gt;并等待调度：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;override def submitTasks(taskSet: TaskSet) {
  val tasks = taskSet.tasks
  logInfo(&quot;Adding task set &quot; + taskSet.id + &quot; with &quot; + tasks.length + &quot; tasks&quot;)
  this.synchronized {
    val manager = new TaskSetManager(this, taskSet)
    activeTaskSets(taskSet.id) = manager
    activeTaskSetsQueue += manager
    taskSetTaskIds(taskSet.id) = new HashSet[Long]()

    if (hasReceivedTask == false) {
      starvationTimer.scheduleAtFixedRate(new TimerTask() {
        override def run() {
          if (!hasLaunchedTask) {
            logWarning(&quot;Initial job has not accepted any resources; &quot; +
              &quot;check your cluster UI to ensure that workers are registered&quot;)
          } else {
            this.cancel()
          }
        }
      }, STARVATION_TIMEOUT, STARVATION_TIMEOUT)
    }
    hasReceivedTask = true;
  }
  backend.reviveOffers()
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在任务提交的同时会启动定时器，如果任务还未被执行，定时器持续发出警告直到任务被执行。同时会调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;StandaloneSchedulerBackend&lt;/code&gt;的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;reviveOffers()&lt;/code&gt;，而它则会通过actor向driver发送&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ReviveOffers&lt;/code&gt;，driver收到&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ReviveOffers&lt;/code&gt;后调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;makeOffers()&lt;/code&gt;：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// Make fake resource offers on just one executor
def makeOffers(executorId: String) {
  launchTasks(scheduler.resourceOffers(
    Seq(new WorkerOffer(executorId, executorHost(executorId), freeCores(executorId)))))
}

// Launch tasks returned by a set of resource offers
def launchTasks(tasks: Seq[Seq[TaskDescription]]) {
  for (task &amp;lt;- tasks.flatten) {
    freeCores(task.executorId) -= 1
    executorActor(task.executorId) ! LaunchTask(task)
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;makeOffers()&lt;/code&gt;会向&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ClusterScheduler&lt;/code&gt;申请资源，并向executor提交&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LauchTask&lt;/code&gt;请求。&lt;/p&gt;

&lt;p&gt;接下来&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LaunchTask&lt;/code&gt;会进入executor模块，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;StandaloneExecutorBackend&lt;/code&gt;在收到&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LaunchTask&lt;/code&gt;请求后会调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Executor&lt;/code&gt;执行task:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;override def receive = {
  case RegisteredExecutor(sparkProperties) =&amp;gt;
    ...  
  case RegisterExecutorFailed(message) =&amp;gt;
    ...
  case LaunchTask(taskDesc) =&amp;gt;
    logInfo(&quot;Got assigned task &quot; + taskDesc.taskId)
    executor.launchTask(this, taskDesc.taskId, taskDesc.serializedTask)

  case Terminated(_) | RemoteClientDisconnected(_, _) | RemoteClientShutdown(_, _) =&amp;gt;
    ...
}

def launchTask(context: ExecutorBackend, taskId: Long, serializedTask: ByteBuffer) {
  threadPool.execute(new TaskRunner(context, taskId, serializedTask))
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Executor&lt;/code&gt;内部是一个线程池，每一个提交的task都会包装为&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TaskRunner&lt;/code&gt;交由threadpool执行：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class TaskRunner(context: ExecutorBackend, taskId: Long, serializedTask: ByteBuffer)
  extends Runnable {

  override def run() {
    SparkEnv.set(env)
    Thread.currentThread.setContextClassLoader(urlClassLoader)
    val ser = SparkEnv.get.closureSerializer.newInstance()
    logInfo(&quot;Running task ID &quot; + taskId)
    context.statusUpdate(taskId, TaskState.RUNNING, EMPTY_BYTE_BUFFER)
    try {
      SparkEnv.set(env)
      Accumulators.clear()
      val (taskFiles, taskJars, taskBytes) = Task.deserializeWithDependencies(serializedTask)
      updateDependencies(taskFiles, taskJars)
      val task = ser.deserialize[Task[Any]](taskBytes, Thread.currentThread.getContextClassLoader)
      logInfo(&quot;Its generation is &quot; + task.generation)
      env.mapOutputTracker.updateGeneration(task.generation)
      val value = task.run(taskId.toInt)
      val accumUpdates = Accumulators.values
      val result = new TaskResult(value, accumUpdates)
      val serializedResult = ser.serialize(result)
      logInfo(&quot;Serialized size of result for &quot; + taskId + &quot; is &quot; + serializedResult.limit)
      context.statusUpdate(taskId, TaskState.FINISHED, serializedResult)
      logInfo(&quot;Finished task ID &quot; + taskId)
    } catch {
      case ffe: FetchFailedException =&amp;gt; {
        val reason = ffe.toTaskEndReason
        context.statusUpdate(taskId, TaskState.FAILED, ser.serialize(reason))
      }

      case t: Throwable =&amp;gt; {
        val reason = ExceptionFailure(t)
        context.statusUpdate(taskId, TaskState.FAILED, ser.serialize(reason))

        // TODO: Should we exit the whole executor here? On the one hand, the failed task may
        // have left some weird state around depending on when the exception was thrown, but on
        // the other hand, maybe we could detect that when future tasks fail and exit then.
        logError(&quot;Exception in task ID &quot; + taskId, t)
        //System.exit(1)
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;其中&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;task.run()&lt;/code&gt;则真正执行了task中的任务，如前&lt;strong&gt;RDD的计算&lt;/strong&gt;章节所述。返回值被包装成&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TaskResult&lt;/code&gt;返回。&lt;/p&gt;

&lt;p&gt;至此task在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ClusterScheduler&lt;/code&gt;内运行的流程有了一个大致的介绍，当然这里略掉了许多异常处理的分支，但这不影响我们对主线的了解。&lt;/p&gt;

&lt;h1 id=&quot;end&quot;&gt;END&lt;/h1&gt;

&lt;p&gt;至此对Spark的Scheduler模块的主线做了一个顺藤摸瓜式的介绍，Scheduler模块作为Spark最核心的模块之一，充分体现了Spark与MapReduce的不同之处，体现了Spark DAG思想的精巧和设计的优雅。&lt;/p&gt;

&lt;p&gt;当然Spark的代码仍然在积极开发之中，当前的源码分析在过不久后可能会变得没有意义，但重要的是体会Spark区别于MapReduce的设计理念，以及DAG思想的应用。DAG作为对MapReduce框架的改进越来越受到大数据界的重视，&lt;a href=&quot;http://hortonworks.com/&quot;&gt;&lt;strong&gt;hortonworks&lt;/strong&gt;&lt;/a&gt;也提出了类似DAG的框架&lt;a href=&quot;http://hortonworks.com/blog/category/tez/&quot;&gt;tez&lt;/a&gt;作为对MapReduce的改进。&lt;/p&gt;
</description>
                <link>http://www.turbofei.wang/jerryshao/2013/04/21/Spark%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B-scheduler%E6%A8%A1%E5%9D%97</link>
                <guid>http://www.turbofei.wang/jerryshao/2013/04/21/Spark源码分析之-scheduler模块</guid>
                <pubDate>2013-04-21T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>[REPRINT] Spark Streaming Introduction</title>
                <description>&lt;p&gt;本文转自&lt;a href=&quot;https://github.com/jerryshao/jerryshao.github.com&quot;&gt;Jerryshao Blog&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;随着big data的发展，人们对大数据的处理要求也越来越高，传统的MapReduce等批处理框架在某些特定领域(如实时用户推荐，用户行为分析)已经无法满足人们对实时性的需求。因此诞生了一批如&lt;a href=&quot;http://incubator.apache.org/s4/&quot;&gt;&lt;strong&gt;S4&lt;/strong&gt;&lt;/a&gt;，&lt;a href=&quot;http://storm-project.net/&quot;&gt;&lt;strong&gt;Storm&lt;/strong&gt;&lt;/a&gt;这样的流式的、实时的计算框架。本文介绍的&lt;a href=&quot;http://spark-project.org/docs/latest/streaming-programming-guide.html&quot;&gt;&lt;strong&gt;Spark Streaming&lt;/strong&gt;&lt;/a&gt;也正是一个这样的流式计算框架。&lt;/p&gt;

&lt;h1 id=&quot;what-is-spark-streaming&quot;&gt;What is Spark Streaming&lt;/h1&gt;

&lt;p&gt;作为UC Berkeley云计算software stack的一部分，Spark Streaming是建立在Spark上的应用框架，利用Spark的底层框架作为其执行基础，并在其上构建了&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DStream&lt;/code&gt;的行为抽象。利用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DStream&lt;/code&gt;所提供的api，用户可以在数据流上实时进行count，join，aggregate等操作。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A Spark Streaming application is very similar to a Spark application; it consists of a driver program that runs the user’s main function and continuous executes various parallel operations on input streams of data. The main abstraction Spark Streaming provides is a discretized stream (DStream), which is a continuous sequence of RDDs (distributed collections of elements) representing a continuous stream of data. DStreams can be created from live incoming data (such as data from a socket, Kafka, etc.) or can be generated by transformong existing DStreams using parallel operators like map, reduce, and window.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;how-to-use-spark-streaming&quot;&gt;How to Use Spark Streaming&lt;/h1&gt;

&lt;p&gt;作为构建于Spark之上的应用框架，Spark Streaming承袭了Spark的编程风格，对于了解Spark的用户来说能够快速地上手。接下来以word count为例来介绍Spark Streaming的使用方式:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import spark.streaming.{Seconds, StreamingContext}
import spark.streaming.StreamingContext._
...

// Create the context and set up a network input stream to receive from a host:port
val ssc = new StreamingContext(args(0), &quot;NetworkWordCount&quot;, Seconds(1))
val lines = ssc.socketTextStream(args(1), args(2).toInt)

// Split the lines into words, count them, and print some of the counts on the master
val words = lines.flatMap(_.split(&quot; &quot;))
val wordCounts = words.map(x =&amp;gt; (x, 1)).reduceByKey(_ + _)
wordCounts.print()

// Start the computation
ssc.start()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;创建&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;StreamingContext&lt;/code&gt;对象&lt;/p&gt;

    &lt;p&gt;同Spark初始需要创建&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SparkContext&lt;/code&gt;对象一样，使用Spark Streaming就需要创建&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;StreamingContext&lt;/code&gt;对象。创建&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;StreamingContext&lt;/code&gt;对象所需的参数与&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SparkContext&lt;/code&gt;基本一致，包括指明&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;master&lt;/code&gt;，设定名称(如&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NetworkWordCount&lt;/code&gt;)。需要注意的是参数&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Seconds(1)&lt;/code&gt;，Spark Streaming需要指定处理数据的时间间隔，如上例所示的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1s&lt;/code&gt;，那么Spark Streaming会以&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1s&lt;/code&gt;为时间窗口进行数据处理。此参数需要根据用户的需求和集群的处理能力进行适当的设置。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;创建&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;InputDStream&lt;/code&gt;&lt;/p&gt;

    &lt;p&gt;如同Storm的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Spout&lt;/code&gt;，Spark Streaming需要指明数据源。如上例所示的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;socketTextStream&lt;/code&gt;，Spark Streaming以socket连接作为数据源读取数据。当然Spark Streaming支持多种不同的数据源，包括&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kafkaStream&lt;/code&gt;，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;flumeStream&lt;/code&gt;，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fileStream&lt;/code&gt;，	&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;networkStream&lt;/code&gt;等。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;操作&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DStream&lt;/code&gt;&lt;/p&gt;

    &lt;p&gt;对于从数据源得到的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DStream&lt;/code&gt;，用户可以在其基础上进行各种操作，如上例所示的操作就是一个典型的word count执行流程：对于当前时间窗口内从数据源得到的数据首先进行分割，然后利用MapReduce算法映射和计算，当然最后还有&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;print()&lt;/code&gt;输出结果。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;启动Spark Streaming&lt;/p&gt;

    &lt;p&gt;之前所作的所有步骤只是创建了执行流程，程序没有真正连接上数据源，也没有对数据进行任何操作，只是设定好了所有的执行计划，当&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ssc.start()&lt;/code&gt;启动后程序才真正进行所有预期的操作。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;至此对于Spark Streaming的如何使用有了一个大概的印象，接下来我们来探究一下Spark Streaming背后的代码。&lt;/p&gt;

&lt;hr /&gt;
&lt;h1 id=&quot;spark-streaming-源码分析&quot;&gt;Spark Streaming 源码分析#&lt;/h1&gt;

&lt;h2 id=&quot;streamingcontext&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;StreamingContext&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;Spark Streaming使用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;StreamingContext&lt;/code&gt;提供对外接口，用户可以使用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;StreamingContext&lt;/code&gt;提供的api来构建自己的Spark Streaming应用程序。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;StreamingContext&lt;/code&gt;内部维护&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SparkContext&lt;/code&gt;实例，通过&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SparkContext&lt;/code&gt;进行&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RDD&lt;/code&gt;的操作。&lt;/li&gt;
  &lt;li&gt;在实例化&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;StreamingContext&lt;/code&gt;时需要指定&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;batchDuration&lt;/code&gt;,用来指示Spark Streaming recurring job的重复时间。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;StreamingContext&lt;/code&gt;提供了多种不同的接口，可以从多种数据源创建&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DStream&lt;/code&gt;。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;StreamingContext&lt;/code&gt;提供了起停streaming job的api。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;dstream&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DStream&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;Spark Streaming是建立在Spark基础上的，它封装了Spark的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RDD&lt;/code&gt;并在其上抽象了流式的数据表现形式&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DStream&lt;/code&gt;：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A Discretized Stream (DStream), the basic abstraction in Spark Streaming, is a continuous sequence of RDDs (of the same type) representing a continuous stream of data. DStreams can either be created from live data (such as, data from HDFS, Kafka or Flume) or it can be generated by transformation existing DStreams using operations such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;map&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;window&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;reduceByKeyAndWindow&lt;/code&gt;. While a Spark Streaming program is running, each DStream periodically generates a RDD, either from live data or by transforming the RDD generated by a parent DStream.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/img/2013-04-02-spark-streaming-introduction/dstream_hierarchy.png&quot; alt=&quot;DStream Class Hierarchy&quot; width=&quot;640&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DStream&lt;/code&gt;内部主要结构如下所示:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;abstract class DStream[T: ClassManifest] (
    @transient protected[streaming] var ssc: StreamingContext
	) extends Serializable with Logging {

  initLogging()

  // =======================================================================
  // Methods that should be implemented by subclasses of DStream
  // =======================================================================

  /** Time interval after which the DStream generates a RDD */
  def slideDuration: Duration

  /** List of parent DStreams on which this DStream depends on */
  def dependencies: List[DStream[_]]

  /** Method that generates a RDD for the given time */
  /** DStream的核心函数，每一个继承于此的子类都需要实现此compute()函数。而根据不同的
      DStream， compute()函数都需要实现其特定功能，而计算的结果则是返回计算好的RDD*/
  def compute (validTime: Time): Option[RDD[T]]

  // =======================================================================
  // Methods and fields available on all DStreams
  // =======================================================================

  // RDDs generated, marked as protected[streaming] so that testsuites can access it
  /** 每一个DStream内部维护的RDD HashMap，DStream本质上封装了一组以Time为key的RDD，而对于
      DStream的各种操作在内部映射为对RDD的操作 */
  @transient
  protected[streaming] var generatedRDDs = new HashMap[Time, RDD[T]] ()

  // Time zero for the DStream
  protected[streaming] var zeroTime: Time = null

  // Duration for which the DStream will remember each RDD created
  protected[streaming] var rememberDuration: Duration = null

  // Storage level of the RDDs in the stream
  protected[streaming] var storageLevel: StorageLevel = StorageLevel.NONE

  // Checkpoint details
  protected[streaming] val mustCheckpoint = false
  protected[streaming] var checkpointDuration: Duration = null
  protected[streaming] val checkpointData = new DStreamCheckpointData(this)

  // Reference to whole DStream graph
  /** 所有的DStream都注册到DStreamGraph中，调用DStreamGraph来执行所有的DStream和所有的dependencies */
  protected[streaming] var graph: DStreamGraph = null

  protected[streaming] def isInitialized = (zeroTime != null)

  // Duration for which the DStream requires its parent DStream to remember each RDD created
  protected[streaming] def parentRememberDuration = rememberDuration

  ...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DStream&lt;/code&gt;在内部维护了一组时间序列的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RDD&lt;/code&gt;，对于&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DStream&lt;/code&gt;的transformation和output在内部都转化为对于&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RDD&lt;/code&gt;的transformation和output。&lt;/p&gt;

&lt;p&gt;下面来看一下对于&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DStream&lt;/code&gt;的计算是如何映射到对于&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RDD&lt;/code&gt;的计算上去的。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;protected[streaming] def getOrCompute(time: Time): Option[RDD[T]] = {
  // If this DStream was not initialized (i.e., zeroTime not set), then do it
  // If RDD was already generated, then retrieve it from HashMap
  generatedRDDs.get(time) match {

    // If an RDD was already generated and is being reused, then
    // probably all RDDs in this DStream will be reused and hence should be cached
    case Some(oldRDD) =&amp;gt; Some(oldRDD)

    // if RDD was not generated, and if the time is valid
    // (based on sliding time of this DStream), then generate the RDD
    case None =&amp;gt; {
      if (isTimeValid(time)) {
        /** 对于每一次的计算，DStream会调用子类所实现的compute()函数来计算产生新的RDD */
        compute(time) match {
          case Some(newRDD) =&amp;gt;
            if (storageLevel != StorageLevel.NONE) {
              newRDD.persist(storageLevel)
              logInfo(&quot;Persisting RDD &quot; + newRDD.id + &quot; for time &quot; + time + &quot; to &quot; + storageLevel + &quot; at time &quot; + time)
            }
            if (checkpointDuration != null &amp;amp;&amp;amp; (time - zeroTime).isMultipleOf (checkpointDuration)) {
              newRDD.checkpoint()
              logInfo(&quot;Marking RDD &quot; + newRDD.id + &quot; for time &quot; + time + &quot; for checkpointing at time &quot; + time)
            }
			/** 新产生的RDD会放入Hash Map中 */
            generatedRDDs.put(time, newRDD)
            Some(newRDD)
          case None =&amp;gt;
            None
        }
      } else {
        None
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;通过每次提交的job，调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;getOrCompute()&lt;/code&gt;来计算:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;protected[streaming] def generateJob(time: Time): Option[Job] = {
 getOrCompute(time) match {
    case Some(rdd) =&amp;gt; {
      val jobFunc = () =&amp;gt; {
        val emptyFunc = { (iterator: Iterator[T]) =&amp;gt; {} }
        context.sparkContext.runJob(rdd, emptyFunc)
      }
      Some(new Job(time, jobFunc))
    }
    case None =&amp;gt; None
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;job--scheduler&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Job&lt;/code&gt; &amp;amp; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Scheduler&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;从&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DStream&lt;/code&gt;可知，在调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;generateJob()&lt;/code&gt;时，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DStream&lt;/code&gt;会通过&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;getOrCompute()&lt;/code&gt;函数来计算或是转换&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DStream&lt;/code&gt;，那么Spark Streaming会在何时调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;generateJob()&lt;/code&gt;呢?&lt;/p&gt;

&lt;p&gt;在实例化&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;StreamingContext&lt;/code&gt;时，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;StreamingContext&lt;/code&gt;会要求用户设置&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;batchDuration&lt;/code&gt;，而&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;batchDuration&lt;/code&gt;则指明了recurring job的重复时间，在每个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;batchDuration&lt;/code&gt;到来时都会产生一个新的job来计算&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DStream&lt;/code&gt;，从&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Scheduler&lt;/code&gt;的代码里可以看到：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;val clockClass = System.getProperty(&quot;spark.streaming.clock&quot;, &quot;spark.streaming.util.SystemClock&quot;)
val clock = Class.forName(clockClass).newInstance().asInstanceOf[Clock]

/** Spark streaming在Scheduler内部创建了recurring timer，recurring timer的超时时间
    则是用户设置的batchDuration，在超时后调用Scheduler的generateJob */
val timer = new RecurringTimer(clock, ssc.graph.batchDuration.milliseconds,
longTime =&amp;gt; generateJobs(new Time(longTime)))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;generateJobs()&lt;/code&gt;的代码如下所示，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Scheduler&lt;/code&gt;的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;generateJobs()&lt;/code&gt;会调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DStreamGraph&lt;/code&gt;的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;generateJobs&lt;/code&gt;，并对于每一个job使用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;JobManager&lt;/code&gt;来run job。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def generateJobs(time: Time) {
  SparkEnv.set(ssc.env)
  logInfo(&quot;\n-----------------------------------------------------\n&quot;)
  graph.generateJobs(time).foreach(jobManager.runJob)
  latestTime = time
  doCheckpoint(time)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DStreamGraph&lt;/code&gt;中，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;generateJobs()&lt;/code&gt;如下所示：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def generateJobs(time: Time): Seq[Job] = {
  this.synchronized {
    logInfo(&quot;Generating jobs for time &quot; + time)
    val jobs = outputStreams.flatMap(outputStream =&amp;gt; outputStream.generateJob(time))
    logInfo(&quot;Generated &quot; + jobs.length + &quot; jobs for time &quot; + time)
    jobs
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;对于每一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;outputStream&lt;/code&gt;调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;generateJob()&lt;/code&gt;来转换或计算&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DStream&lt;/code&gt;，output的计算会依赖于dependecy的计算，因此最后会对所有dependency都进行计算，得出最后的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;outputStream&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;而所有的这些操作，都在调用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;StreamingContext&lt;/code&gt;的启动函数后进行执行。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def start() {
  if (checkpointDir != null &amp;amp;&amp;amp; checkpointDuration == null &amp;amp;&amp;amp; graph != null) {
    checkpointDuration = graph.batchDuration
  }

  validate()

  /** StreamingContext注册和启动所有的input stream */
  val networkInputStreams = graph.getInputStreams().filter(s =&amp;gt; s match {
      case n: NetworkInputDStream[_] =&amp;gt; true
      case _ =&amp;gt; false
    }).map(_.asInstanceOf[NetworkInputDStream[_]]).toArray

  if (networkInputStreams.length &amp;gt; 0) {
    // Start the network input tracker (must start before receivers)
    networkInputTracker = new NetworkInputTracker(this, networkInputStreams)
    networkInputTracker.start()
  }

  Thread.sleep(1000)

  // 启动scheduler进行streaming的操作
  scheduler = new Scheduler(this)
  scheduler.start()
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;至此，对于Spark Streaming的使用和内部结构应该有了一个基本的了解，以一副Spark Streaming启动后的流程图来结束这篇文章。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2013-04-02-spark-streaming-introduction/flowchart.png&quot; alt=&quot;DStream Class Hierarchy&quot; width=&quot;640&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://spark-project.org/docs/latest/streaming-programming-guide.html&quot;&gt;&lt;strong&gt;Spark Streaming Documentation&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
</description>
                <link>http://www.turbofei.wang/jerryshao/2013/04/02/spark-streaming-introduction</link>
                <guid>http://www.turbofei.wang/jerryshao/2013/04/02/spark-streaming-introduction</guid>
                <pubDate>2013-04-02T00:00:00-07:00</pubDate>
        </item>

        <item>
                <title>[REPRINT] Spark Overview</title>
                <description>&lt;p&gt;本文转自&lt;a href=&quot;https://github.com/jerryshao/jerryshao.github.com&quot;&gt;Jerryshao Blog&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Overview&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;本文章主要对Spark,Spark的基本架构和重要模块作基本介绍，文章不会涉及Spark的安装部署以及使用，对此可以参考&lt;a href=&quot;http://spark-project.org/documentation/&quot;&gt;Spark官方文档&lt;/a&gt;。&lt;/p&gt;

&lt;h1 id=&quot;what-is-spark&quot;&gt;What is Spark&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;http://spark-project.org&quot;&gt;&lt;strong&gt;Spark&lt;/strong&gt;&lt;/a&gt;是UC Berkeley AMP lab所开源的类Hadoop MapReduce
框架，都是基于map reduce算法所实现的分布式计算框架，拥有Hadoop MapReduce所具有的
优点；不同于MapReduce的是Job中间输出和结果可以保存在内存中，而不需要读写HDFS，因
此Spark能更好地适用于machine learning等需要迭代的map reduce算法。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Spark is an open source cluster computing system that aims to make data
analytics fast — both fast to run and fast to write.&lt;/p&gt;

  &lt;p&gt;To run programs faster, Spark provides primitives for in-memory cluster
computing: your job can load data into memory and query it repeatedly much
quicker than with disk-based systems like Hadoop MapReduce.&lt;/p&gt;

  &lt;p&gt;To make programming faster, Spark provides clean, concise APIs in Scala, Java
and Python. You can also use Spark interactively from the Scala and Python
shells to rapidly query big datasets.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;spark-architecture&quot;&gt;Spark Architecture&lt;/h1&gt;

&lt;p&gt;援引&lt;a href=&quot;http://weibo.com/jerrylead&quot;&gt;@JerryLead&lt;/a&gt;的系统架构图作为Spark整体结构的一个
birdview：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2013-03-29-spark-overview/architecture-birdview.jpg&quot; alt=&quot;Spark birdview&quot; width=&quot;640&quot; /&gt;&lt;/p&gt;

&lt;p&gt;整体上Spark分为以下几个主要的子模块:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;deploy&lt;/code&gt;: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;deply&lt;/code&gt;模块包括&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Master&lt;/code&gt;，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Work&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Client&lt;/code&gt;，参见architecture图的最上
部分。&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;deploy&lt;/code&gt;主要负责启动和调度用户实现的Spark application并且分配资源给用户
application，类似于Hadoop YARN框架。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scheduler&lt;/code&gt;: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scheduler&lt;/code&gt;主要负责调度用户application内的tasks，根据部署方式的不
同Spark实现了多种不同的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scheduler&lt;/code&gt;，包括&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LocalScheduler&lt;/code&gt;，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ClusterScheduler&lt;/code&gt;等
。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rdd&lt;/code&gt;: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rdd&lt;/code&gt;类似于一个分布式的数据集，用户可以根据&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rdd&lt;/code&gt;所提供的api进行数据集的
操作，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rdd&lt;/code&gt;模块是用户交互的主要模块。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;storage&lt;/code&gt;: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;storage&lt;/code&gt;模块主要负责数据集，也就是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rdd&lt;/code&gt;的存取。根据设定的不同，数
据可以保存在内存、磁盘或是两者。Spark与Hadoop MapReduce最大的不同在于MapReduce
将数据保存在HDFS上，而Spark则由自己的存储系统。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;当然还有一些其他的子模块，可以参考上图。&lt;/p&gt;

&lt;p&gt;Spark采用了Actor的设计方式，整体架构，包括各子模块的设计上都是采用master-slave模
式，master和slave之间通信的主要协议可以参见上图。&lt;/p&gt;

&lt;h1 id=&quot;end&quot;&gt;End&lt;/h1&gt;
&lt;p&gt;以上大致地介绍了Spark的architecture，之后会陆续对各子模块作详细的介绍&lt;/p&gt;
</description>
                <link>http://www.turbofei.wang/jerryshao/2013/03/29/spark-overview</link>
                <guid>http://www.turbofei.wang/jerryshao/2013/03/29/spark-overview</guid>
                <pubDate>2013-03-29T00:00:00-07:00</pubDate>
        </item>


</channel>
</rss>
