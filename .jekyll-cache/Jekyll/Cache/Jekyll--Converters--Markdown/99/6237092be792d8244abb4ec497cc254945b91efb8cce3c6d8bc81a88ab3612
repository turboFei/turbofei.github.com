I"
<p>目录</p>
<ul id="markdown-toc">
  <li><a href="#前言" id="markdown-toc-前言">前言</a></li>
  <li><a href="#背景" id="markdown-toc-背景">背景</a></li>
  <li><a href="#woody的架构" id="markdown-toc-woody的架构">Woody的架构</a></li>
</ul>

<h3 id="前言">前言</h3>

<table>
  <tbody>
    <tr>
      <td>本文讲eBay Spark测试框架-Woody, 其已被发表在公众号eBay技术荟[Hadoop 平台进阶之路</td>
      <td>eBay Spark测试框架–Woody](https://mp.weixin.qq.com/s/PZoGtkPd6RHTEtfwOx2H0w)</td>
    </tr>
  </tbody>
</table>

<p>新版本的Spark拥有更好的性能和稳定性，对于用户来说，如果长期停留在低版本的Spark，不仅会浪费集群资源，还会进一步加大平台管理团队的工作量。如果进行Spark大版本升级，考虑到版本间可能由于计算行为不一致而导致的数据质量问题，用户就要投入大量的精力去对比重要的job在不同版本下的数据质量，加大了版本升级的困难度。</p>

<p>ADI Hadoop team负责管理eBay的Hadoop集群、 Spark的版本升级和bug修复等事务。<strong>为了提升Spark版本升级的效率，本团队开发了Spark测试框架——Woody。</strong>该测试框架会将线上spark-sql job语句转换为和线上job隔离的测试语句，然后调用不同的Spark版本执行测试语句，最终对比版本间数据质量。Woody不仅可以用于Spark版本升级，也可用于job调优以及job pipeline的端到端测试。本文将分享Spark测试框架Woody的架构，实现以及使用场景，希望能对读者有所帮助。</p>

<h3 id="背景">背景</h3>

<p>Hadoop team目前管理两个大Spark分支，Spark-2.1和Spark-2.3，目前的版本开发均基于Spark-2.3，而对于Spark-2.1分支已经不再进行维护，未来会升级到Spark-3.0。</p>

<p>Hadoop team从两年前就着手进行从Spark-2.1 到Spark-2.3的迁移工作，用了将近两年时间完成了迁移。</p>

<p>为什么会用这么长时间呢？</p>

<p>因为大版本之间可能会存在不兼容问题，计算行为可能发生改变，也就是说两个版本间的计算结果可能不一致。</p>

<p>数据质量是至关重要的，特别是对于金融数据，业务团队需要在升级之前进行两个版本间的计算结果对比。</p>

<p>而这需要用户去手动修改线上代码，然后利用两个Spark版本进行双跑，最后再去手动对比两个版本的计算结果。eBay内部的spark-sql任务数不胜数，大版本升级会消耗大量的资源和人力。</p>

<p>Spark-2.1到Spark-2.3 已经耗费了这么长时间，那么将来升级到Spark-3.0想必也是一个浩大的工程。</p>

<p>为了解决这个问题，Hadoop team开发了一个Spark测试框架，命名为Woody。Woody的名字取自一个卡通啄木鸟，希望可以帮助找出不同Spark版本之间或者Spark job中的bug(虫子)。</p>

<p>Woody可以将线上的SQL语句进行转换，然后分别启动两个Spark版本运行转换后的SQL，从而对比两个版本的计算结果，判断两个版本计算结果是否一致，也可以用于比较两个版本的性能。</p>

<p><img src="/public/img/woody/p1.png" alt="" /></p>

<h3 id="woody的架构">Woody的架构</h3>

<p>Woody的架构如图2所示，提供restful api，使用mysql存储数据，支持多个集群。用户可以一次提交一批用于测试的job，Woody用一个workflow封装这批job,由workflow调度器进行调度，每个workflow调度时生成一个对应的jobSetManager,进入job调度器，job调度器会限制同时运行job的数量。</p>

<p><img src="/public/img/woody/p2.png" alt="" /></p>

<p>一个job的生命周期为：</p>

<ol>
  <li>将job语句转换为测试语句</li>
  <li>测试运行前准备工作</li>
  <li>调用Spark版本1运行测试语句</li>
  <li>计算Spark版本1结果的校验信息</li>
  <li>调用Spark版本2运行测试语句</li>
  <li>计算Spark版本2结果的校验信息</li>
  <li>给出数据质量报告</li>
</ol>

:ET