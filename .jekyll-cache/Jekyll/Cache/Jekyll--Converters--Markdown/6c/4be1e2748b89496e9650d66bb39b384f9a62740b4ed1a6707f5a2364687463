I"®Q
<p>ç›®å½•</p>
<ul id="markdown-toc">
  <li><a href="#å‰è¨€" id="markdown-toc-å‰è¨€">å‰è¨€</a></li>
  <li><a href="#å…³äºbucket-table" id="markdown-toc-å…³äºbucket-table">å…³äºBucket Table</a>    <ul>
      <li><a href="#åˆ›å»ºbucket-è¡¨" id="markdown-toc-åˆ›å»ºbucket-è¡¨">åˆ›å»ºbucket è¡¨</a></li>
      <li><a href="#bucketè¡¨å‚æ•°" id="markdown-toc-bucketè¡¨å‚æ•°">Bucketè¡¨å‚æ•°</a></li>
      <li><a href="#insert-into-bucket-table" id="markdown-toc-insert-into-bucket-table">Insert into bucket table</a></li>
    </ul>
  </li>
  <li><a href="#é—®é¢˜åˆ†æ" id="markdown-toc-é—®é¢˜åˆ†æ">é—®é¢˜åˆ†æ</a></li>
  <li><a href="#é™„å½•" id="markdown-toc-é™„å½•">é™„å½•</a>    <ul>
      <li><a href="#éªŒè¯double-å’Œdecimal-ç±»å‹çš„bucket-id-æ˜¯å¦ä¸åŒ" id="markdown-toc-éªŒè¯double-å’Œdecimal-ç±»å‹çš„bucket-id-æ˜¯å¦ä¸åŒ">éªŒè¯double å’ŒDecimal ç±»å‹çš„bucket Id æ˜¯å¦ä¸åŒ</a></li>
    </ul>
  </li>
</ul>
<p>è®°ä¸€æ¬¡ä¸bucket tableç›¸å…³çš„å°æ–‡ä»¶é—®é¢˜</p>

<h3 id="å‰è¨€">å‰è¨€</h3>

<p>æœ€è¿‘é‡åˆ°äº†ä¸€æ¬¡è·ŸSpark bucket tableç›¸å…³çš„å°æ–‡ä»¶é—®é¢˜ã€‚</p>

<p>åœºæ™¯å¦‚ä¸‹:</p>

<p>å­˜åœ¨ä¸€å¼ bucket table, bucket column æ˜¯ c1, bucketæ•°é‡æ˜¯1000ï¼Œç”¨æˆ·åœ¨å¯¹è¿™å¼ bucket è¡¨è¿›è¡Œinsert overwriteçš„æ—¶å€™ï¼Œå·²ç»å°†spark.sql.shuffle.partitions è®¾ç½®æˆäº†1000ï¼Œè€Œä¸”å¯¹bucket columné‚£åˆ—è¿›è¡Œäº†distribute by æ“ä½œï¼Œç†æƒ³æƒ…å†µä¸‹ï¼Œè¿™æ¬¡overwriteæ“ä½œå°†ç”Ÿæˆ1000ä¸ªå°æ–‡ä»¶ï¼Œä½†æ˜¯å‡ºäººæ„æ–™çš„æ˜¯ï¼Œè¿™æ¬¡æ“ä½œç”Ÿæˆäº† 1000*1000=100ä¸‡ä¸ªå°æ–‡ä»¶!!!</p>

<p>è¿™ä¹ˆå¤šå°æ–‡ä»¶å¿…å®šéœ€è¦å¾ˆå¤šæ¬¡create è¯·æ±‚å’Œrenameè¯·æ±‚ï¼Œå› æ­¤è§¦å‘äº†Hadoopé›†ç¾¤æŠ¥è­¦æœºåˆ¶ã€‚è€Œä¸”é•¿æ­¤ä»¥å¾€ä¹Ÿä¼šå¤§å¤§å¢å¤§namenode çš„å‹åŠ›ã€‚</p>

<h3 id="å…³äºbucket-table">å…³äºBucket Table</h3>

<p>Sparkå’ŒHiveä¸­éƒ½æœ‰bucket tableï¼Œä½†æ˜¯å…¶æ ¼å¼ä¸å°½ç›¸åŒã€‚æœ¬æ–‡ä¸å¯¹æ­¤è¿›è¡Œèµ˜è¿°ï¼Œå…³äºå†…å®¹æ˜¯å…³äºSparkçš„bucketè¡¨ã€‚</p>

<p>Bucketè¡¨çš„ä½œç”¨ç›¸å½“äºä¸€ç§æ•°æ®é¢„å¤„ç†ï¼Œå¦‚æœä¸¤ä¸ªbucket è¡¨çš„bucketæ•°é‡ç›¸åŒï¼Œä¸”å¯¹ä¸¤ä¸ªè¡¨çš„bucket keyè¿›è¡Œjoinï¼Œé‚£ä¸ªå¯ä»¥é¿å…shuffle æ“ä½œï¼Œéœ€è¦æ•°æ®ç®¡ç†è€…è¿›è¡Œä¸€å®šçš„è®¾è®¡ã€‚</p>

<h4 id="åˆ›å»ºbucket-è¡¨">åˆ›å»ºbucket è¡¨</h4>

<p>è¯­å¥æ ¼å¼:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="p">[</span><span class="n">IF</span> <span class="k">NOT</span> <span class="k">EXISTS</span><span class="p">]</span> <span class="p">[</span><span class="n">db_name</span><span class="p">.]</span><span class="k">table_name</span>
  <span class="p">[(</span><span class="n">col_name1</span> <span class="n">col_type1</span> <span class="p">[</span><span class="k">COMMENT</span> <span class="n">col_comment1</span><span class="p">],</span> <span class="p">...)]</span>
  <span class="k">USING</span> <span class="n">data_source</span>
  <span class="p">[</span><span class="k">OPTIONS</span> <span class="p">(</span><span class="n">key1</span><span class="o">=</span><span class="n">val1</span><span class="p">,</span> <span class="n">key2</span><span class="o">=</span><span class="n">val2</span><span class="p">,</span> <span class="p">...)]</span>
  <span class="p">[</span><span class="n">PARTITIONED</span> <span class="k">BY</span> <span class="p">(</span><span class="n">col_name1</span><span class="p">,</span> <span class="n">col_name2</span><span class="p">,</span> <span class="p">...)]</span>
  <span class="p">[</span><span class="n">CLUSTERED</span> <span class="k">BY</span> <span class="p">(</span><span class="n">col_name3</span><span class="p">,</span> <span class="n">col_name4</span><span class="p">,</span> <span class="p">...)</span> <span class="n">SORTED</span> <span class="k">BY</span> <span class="p">(</span><span class="n">col_name1</span> <span class="k">ASC</span><span class="p">,</span> <span class="n">col_name2</span> <span class="k">DESC</span><span class="p">)</span> <span class="k">INTO</span> <span class="n">num_buckets</span> <span class="n">BUCKETS</span><span class="p">]</span>
  <span class="p">[</span><span class="k">LOCATION</span> <span class="n">path</span><span class="p">]</span>
  <span class="p">[</span><span class="k">COMMENT</span> <span class="n">table_comment</span><span class="p">]</span>
  <span class="p">[</span><span class="n">TBLPROPERTIES</span> <span class="p">(</span><span class="n">key1</span><span class="o">=</span><span class="n">val1</span><span class="p">,</span> <span class="n">key2</span><span class="o">=</span><span class="n">val2</span><span class="p">,</span> <span class="p">...)]</span>
  <span class="p">[</span><span class="k">AS</span> <span class="n">select_statement</span><span class="p">]</span>
</code></pre></div></div>

<p>PS: åˆ›å»ºbucketè¡¨æ—¶å€™ç”¨åˆ°çš„<code class="highlighter-rouge">clustered by (key)</code> å’Œ <code class="highlighter-rouge">sorted by (key)</code>ï¼Œå’Œåœ¨select æ•°æ®æ—¶å€™ç”¨çš„<code class="highlighter-rouge">cluster by key</code> å’Œ<code class="highlighter-rouge">sort by key</code> å¾ˆç›¸ä¼¼ï¼Œä½†æ˜¯ç”¨æ³•æ˜¯ä¸åŒçš„ã€‚</p>

<p>å¦å¤–åœ¨select æ—¶å€™æœ‰<code class="highlighter-rouge">distribute by</code> å’Œ <code class="highlighter-rouge">cluster by</code>ä¸¤ç§è¯­æ³•ï¼Œ<code class="highlighter-rouge">cluster by key</code> = <code class="highlighter-rouge">distribute by key sort by key</code>. <code class="highlighter-rouge">distribute by key</code> = <code class="highlighter-rouge">hash shuffle by key</code>.</p>

<h4 id="bucketè¡¨å‚æ•°">Bucketè¡¨å‚æ•°</h4>

<p>Sparkä¸­æœ‰ä¸¤ä¸ªbucketè¡¨ç›¸å…³å‚æ•°ï¼š</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>spark.sql.sources.bucketing.enabled  æ˜¯å¦å°†bucektè¡¨çœ‹æˆæ˜¯bucektè¡¨
spark.sql.sources.bucketing.maxBuckets å…è®¸çš„æœ€å¤§bucekt æ•°é‡ï¼Œé»˜è®¤æ˜¯100000
</code></pre></div></div>

<p>å…³äºç¬¬ä¸€ä¸ªå‚æ•°ï¼Œä½œç”¨æ˜¯å¦å°†bucketè¡¨çœ‹æˆæ˜¯bucektè¡¨ã€‚</p>

<p>Sparké’ˆå¯¹bucketè¡¨è¯»å–çš„æ—¶å€™ï¼Œä¼šå¯¹æ¯ä¸€ä¸ªbucketåˆ†é…ä¸€ä¸ªtaskæ¥è¯»å–ï¼Œå› ä¸ºå¦‚æœè¿›è¡Œbucket joinå°±ä¸èƒ½å†å¯¹è¿™ä¸ªbucketçš„æ•°æ®è¿›è¡Œæ‹†åˆ†ã€‚ä½†æ˜¯æœ‰äº›æ—¶å€™ï¼Œæˆ‘ä»¬ä¸æ˜¯è¯»å–è¿™ä¸ªbucketè¡¨è¿›è¡Œjoinï¼Œæ¯”å¦‚æ˜¯ç®€å•çš„ETLï¼Œè€Œæ­¤æ—¶mapé˜¶æ®µä¼šé’ˆå¯¹æ¯ä¸ªbucketåˆ†é…ä¸€ä¸ªmapTaskï¼Œè€Œå¦‚æœè¿™ä¸ªbucketæ•°æ®é‡å¾ˆå¤§ï¼Œå°±ä¼šå¾ˆç¼“æ…¢ã€‚è€Œå¦‚æœæ­¤æ—¶ï¼Œæˆ‘ä»¬æŠŠspark.sql.sources.bucketing.enabled è®¾ä¸ºfalseï¼Œé‚£ä¹ˆå°±ç›¸å½“äºä¸€ä¸ªæ™®é€šè¡¨ï¼Œmapç«¯å¯èƒ½ä¼šé’ˆå¯¹è¿™ä¸ªbucketçš„æ•°æ®è¿›è¡Œsplitï¼Œä»è€Œå¤šåˆ†é…ä¸€äº›taskï¼ŒåŠ å¿«é€Ÿåº¦ã€‚</p>

<h4 id="insert-into-bucket-table">Insert into bucket table</h4>

<p>Insert into bucket tableçš„æ—¶å€™ï¼Œä¼šåŠ ä¸€ä¸ªé’ˆå¯¹bucket columnçš„hashPartitioning å‡½æ•°ã€‚å› æ­¤å¦‚æœä¸€ä¸ªtaskä¸­çš„æ•°æ®åœ¨insert intoè¿™ä¸ªbucket tableçš„æ—¶å€™ï¼Œæ²¡æœ‰æå‰é’ˆå¯¹è¿™ä¸ªbucket column è¿›è¡Œè¿‡åŸºäºbucket number  çš„hash(å¯ä»¥å°†spark.sql.shuffle.partitions è®¾ç½®ä¸ºbucket numberï¼Œç„¶åè¿›è¡Œdistribute/cluster by),é‚£ä¹ˆæ¯ä¸ªtask å°†ä¼šç”Ÿæˆ bucket numberä¸ªæ–‡ä»¶ã€‚</p>

<h3 id="é—®é¢˜åˆ†æ">é—®é¢˜åˆ†æ</h3>

<p>å‡ºç°é—®é¢˜çš„sqlè¯­å¥çš„æ‰§è¡Œè®¡åˆ’æ ¸å¿ƒéƒ¨åˆ†å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚</p>

<p>å¯ä»¥çœ‹åˆ°è¿™æ˜¯å¯¹ä¸¤ä¸ªå­æŸ¥è¯¢è¿›è¡Œunionï¼Œç„¶åæˆ‘ä»¬åšäº†åŸºäºbucket columnå’Œnumberçš„hash(distribute and sort by), ä¹‹åinsert overwrite ä¸€ä¸ªbucektè¡¨ã€‚</p>

<p>ç”¨æˆ·æœŸæœ›çš„ç»“æœæ˜¯ä¼šæœ€ç»ˆäº§ç”Ÿ1000ä¸ªæ–‡ä»¶ï¼Œä½†æ˜¯å‡ºä¹æ„æ–™çš„ç”Ÿæˆäº†100ä¸‡ä¸ªå°æ–‡ä»¶ã€‚</p>

<p><img src="/imgs/spark-bucket-small-files/plan.png" alt="" /></p>

<p>é€šè¿‡å¯¹è¯­å¥è¿›è¡Œç²¾ç®€ï¼Œæˆ‘æ‹¿åˆ°ä¸€ä¸ªå¯å¤ç°é—®é¢˜çš„ç®€å•æµ‹è¯•ã€‚</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">sql</span><span class="o">(</span><span class="n">s</span><span class="s">"create table ta (c1 decimal(38, 18), c2 int, p1 int) using parquet partitioned"</span> <span class="o">+</span>
  <span class="s">" by (p1) clustered by (c1) sorted by (c1) into 10 buckets"</span><span class="err">ï¼‰</span>

<span class="nf">sql</span><span class="o">(</span><span class="s">"set spark.sql.shuffle.partitions=10"</span><span class="o">)</span>    

<span class="nv">spark</span><span class="o">.</span><span class="py">sparkContext</span><span class="o">.</span><span class="py">parallelize</span><span class="o">(</span><span class="nv">Seq</span><span class="o">.</span><span class="py">range</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">1000</span><span class="o">),</span> <span class="mi">1000</span><span class="o">)</span>
  <span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="n">v</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="nc">Decimal</span><span class="o">(</span><span class="n">v</span><span class="o">),</span> <span class="n">v</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"c1"</span><span class="o">,</span> <span class="s">"c2"</span><span class="o">).</span><span class="py">write</span><span class="o">.</span><span class="py">mode</span><span class="o">(</span><span class="s">"overwrite"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">saveAsTable</span><span class="o">(</span><span class="s">"tb"</span><span class="o">)</span>

<span class="nv">spark</span><span class="o">.</span><span class="py">sparkContext</span><span class="o">.</span><span class="py">parallelize</span><span class="o">(</span><span class="nv">Seq</span><span class="o">.</span><span class="py">range</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">1000</span><span class="o">),</span> <span class="mi">1000</span><span class="o">)</span>
  <span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="n">v</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="nv">v</span><span class="o">.</span><span class="py">toDouble</span><span class="o">,</span> <span class="n">v</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"c1"</span><span class="o">,</span> <span class="s">"c2"</span><span class="o">).</span><span class="py">write</span><span class="o">.</span><span class="py">mode</span><span class="o">(</span><span class="s">"overwrite"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">saveAsTable</span><span class="o">(</span><span class="s">"tc"</span><span class="o">)</span>

<span class="nf">sql</span><span class="o">(</span><span class="s">"insert overwrite table ta partition(p1=1) select c1, c2 from tb union all "</span> <span class="o">+</span>
  <span class="s">"select c1, c2 from tc distribute by c1"</span><span class="o">)</span>
</code></pre></div></div>

<p>åœ¨è¿™ä¸ªæµ‹è¯•ä¸­æœ‰ä¸‰å¼ è¡¨ï¼Œtaæ˜¯ä¸€å¼ bucketè¡¨ï¼Œæœ‰ä¸‰åˆ—, c1, c2, p1, è€Œp1æ˜¯åˆ†åŒºåˆ—ï¼Œc1æ˜¯bucketåˆ—ï¼Œ bucket æ•°ç›®æ˜¯10. æˆ‘ä»¬å·²ç»å°†spark.sql.shuffle.partitions è®¾ç½®ä¸º10.</p>

<p>ç„¶åtb å’Œtcéƒ½æœ‰ä¸¤åˆ— c1, c2, æˆ‘ä»¬å°†select ä¸¤å¼ è¡¨çš„æ•°æ®ï¼Œè¿›è¡Œunionï¼Œä¹‹åå¯¹c1 è¿›è¡Œdistribute byï¼Œä¹‹åoverwrite åˆ° ta ä¸­p1=1çš„åˆ†åŒºã€‚</p>

<p>æ‰§è¡Œä¹‹åï¼ŒæŸ¥çœ‹taä¸‹é¢p1=1ç›®å½•ï¼Œå‘ç°æœ‰200ä¸ªå°æ–‡ä»¶(å·²ç»å¾ˆå¤šäº†)ã€‚</p>

<p>æŸ¥çœ‹insert overwriteè¯­å¥ç‰©ç†æ‰§è¡Œè®¡åˆ’ã€‚</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">==</span> Physical Plan <span class="o">==</span>
Execute InsertIntoHadoopFsRelationCommand file:/private/var/folders/lw/8qtm67pn1gdb86hj4jcrk_ww39cyt7/T/spark-40631839-0276-414f-aa2f-0721eaab3e26, Map<span class="o">(</span>p1 -&gt; 1<span class="o">)</span>, <span class="nb">false</span>, <span class="o">[</span>p1#255], 10 buckets, bucket columns: <span class="o">[</span>c1], <span class="nb">sort </span>columns: <span class="o">[</span>c1], Parquet, Map<span class="o">(</span>path -&gt; file:/private/var/folders/lw/8qtm67pn1gdb86hj4jcrk_ww39cyt7/T/spark-40631839-0276-414f-aa2f-0721eaab3e26<span class="o">)</span>, Overwrite, CatalogTable<span class="o">(</span>
Database: default
Table: ta
Created Time: Sat Mar 28 10:19:48 PDT 2020
Last Access: UNKNOWN
Created By: Spark 3.1.0-SNAPSHOT
Type: EXTERNAL
Provider: parquet
Num Buckets: 10
Bucket Columns: <span class="o">[</span><span class="sb">`</span>c1<span class="sb">`</span><span class="o">]</span>
Sort Columns: <span class="o">[</span><span class="sb">`</span>c1<span class="sb">`</span><span class="o">]</span>
Location: file:///private/var/folders/lw/8qtm67pn1gdb86hj4jcrk_ww39cyt7/T/spark-40631839-0276-414f-aa2f-0721eaab3e26
Partition Provider: Catalog
Partition Columns: <span class="o">[</span><span class="sb">`</span>p1<span class="sb">`</span><span class="o">]</span>
Schema: root
 |-- c1: decimal<span class="o">(</span>38,18<span class="o">)</span> <span class="o">(</span>nullable <span class="o">=</span> <span class="nb">true</span><span class="o">)</span>
 |-- c2: integer <span class="o">(</span>nullable <span class="o">=</span> <span class="nb">true</span><span class="o">)</span>
 |-- p1: integer <span class="o">(</span>nullable <span class="o">=</span> <span class="nb">true</span><span class="o">)</span>
<span class="o">)</span>, org.apache.spark.sql.execution.datasources.CatalogFileIndex@3faae831, <span class="o">[</span>c1, c2, p1]
+- <span class="k">*</span><span class="o">(</span>3<span class="o">)</span> Project <span class="o">[</span>ansi_cast<span class="o">(</span>c1#250 as decimal<span class="o">(</span>38,18<span class="o">))</span> AS c1#254, c2#247, 1 AS p1#255]
   +- Exchange hashpartitioning<span class="o">(</span>c1#250, 10<span class="o">)</span>, <span class="nb">false</span>, <span class="o">[</span><span class="nb">id</span><span class="o">=</span><span class="c">#155]</span>
      +- Union
         :- <span class="k">*</span><span class="o">(</span>1<span class="o">)</span> Project <span class="o">[</span>cast<span class="o">(</span>c1#246 as double<span class="o">)</span> AS c1#250, c2#247]
         :  +- <span class="k">*</span><span class="o">(</span>1<span class="o">)</span> ColumnarToRow
         :     +- FileScan parquet default.tb[c1#246,c2#247] Batched: <span class="nb">true</span>, DataFilters: <span class="o">[]</span>, Format: Parquet, Location: InMemoryFileIndex[file:/Users/fwang12/todo/apache-spark/sql/core/spark-warehouse/org.apache.spark..., PartitionFilters: <span class="o">[]</span>, PushedFilters: <span class="o">[]</span>, ReadSchema: struct&lt;c1:decimal<span class="o">(</span>38,18<span class="o">)</span>,c2:int&gt;
         +- <span class="k">*</span><span class="o">(</span>2<span class="o">)</span> ColumnarToRow
            +- FileScan parquet default.tc[c1#248,c2#249] Batched: <span class="nb">true</span>, DataFilters: <span class="o">[]</span>, Format: Parquet, Location: InMemoryFileIndex[file:/Users/fwang12/todo/apache-spark/sql/core/spark-warehouse/org.apache.spark..., PartitionFilters: <span class="o">[]</span>, PushedFilters: <span class="o">[]</span>, ReadSchema: struct&lt;c1:double,c2:int&gt;

</code></pre></div></div>

<p>åŸæ¥è™½ç„¶è¡¨tb å’Œtcä¸­éƒ½æœ‰åä¸ºc1çš„åˆ—ï¼Œä½†æ˜¯ä¸€ä¸ªæ˜¯Decimalç±»å‹ï¼Œä¸€ä¸ªæ˜¯doubleç±»å‹ã€‚åœ¨åšunionçš„æ—¶å€™ï¼Œå– double å’ŒDecimalçš„å…¬å…±ç±»å‹doubleï¼Œå› æ­¤å¯¹è¡¨tbä¸­çš„c1 è¿›è¡Œäº†cast(c1 as double)ï¼Œä½†æ˜¯åœ¨insert overwrite bucket tableçš„æ—¶å€™ï¼Œç”±äºbucket column c1çš„ç±»å‹æ˜¯Decimalï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥çœ‹åˆ°åœ¨è¿›è¡Œ<code class="highlighter-rouge">Exchange hashpartitioning</code> ä¹‹åè¿›è¡Œäº†<code class="highlighter-rouge">Project [ansi_cast(c1#250 as decimal(38,18)) AS c1#254, c2#247, 1 AS p1#255]</code>  æ“ä½œï¼ŒåˆæŠŠdoubleè½¬æˆäº†Decimal.</p>

<p>å› æ­¤ï¼Œæˆ‘ä»¬å‰é¢hash åçš„æ•°æ®æ˜¯åŸºäºdoubleç±»å‹çš„hashï¼Œè€Œbucket columnç±»å‹æ˜¯Decimalç±»å‹ã€‚</p>

<p>æŸ¥çœ‹FileFormatWriterä¸­çš„writeæ–¹æ³•ï¼Œå…¶é€»è¾‘ä¸ºï¼Œå¦‚æœcurrentPartitionValueæˆ–è€…currentBucketIdä¸next ä¸åŒã€‚</p>

<p>é‚£ä¹ˆä¼šåˆ›å»ºä¸€ä¸ªæ–°çš„æ–‡ä»¶ã€‚</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="nf">if</span> <span class="o">(</span><span class="n">currentPartionValues</span> <span class="o">!=</span> <span class="n">nextPartitionValues</span> <span class="o">||</span> <span class="n">currentBucketId</span> <span class="o">!=</span> <span class="n">nextBucketId</span><span class="o">)</span> <span class="o">{</span>
      <span class="c1">// See a new partition or bucket - write to a new partition dir (or a new bucket file).</span>
      <span class="nf">if</span> <span class="o">(</span><span class="n">isPartitioned</span> <span class="o">&amp;&amp;</span> <span class="n">currentPartionValues</span> <span class="o">!=</span> <span class="n">nextPartitionValues</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">currentPartionValues</span> <span class="k">=</span> <span class="nc">Some</span><span class="o">(</span><span class="nv">nextPartitionValues</span><span class="o">.</span><span class="py">get</span><span class="o">.</span><span class="py">copy</span><span class="o">())</span>
        <span class="nv">statsTrackers</span><span class="o">.</span><span class="py">foreach</span><span class="o">(</span><span class="nv">_</span><span class="o">.</span><span class="py">newPartition</span><span class="o">(</span><span class="nv">currentPartionValues</span><span class="o">.</span><span class="py">get</span><span class="o">))</span>
      <span class="o">}</span>
      <span class="nf">if</span> <span class="o">(</span><span class="n">isBucketed</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">currentBucketId</span> <span class="k">=</span> <span class="n">nextBucketId</span>
        <span class="nv">statsTrackers</span><span class="o">.</span><span class="py">foreach</span><span class="o">(</span><span class="nv">_</span><span class="o">.</span><span class="py">newBucket</span><span class="o">(</span><span class="nv">currentBucketId</span><span class="o">.</span><span class="py">get</span><span class="o">))</span>
      <span class="o">}</span>

      <span class="n">fileCounter</span> <span class="k">=</span> <span class="mi">0</span>
      <span class="nf">newOutputWriter</span><span class="o">(</span><span class="n">currentPartionValues</span><span class="o">,</span> <span class="n">currentBucketId</span><span class="o">)</span>
    <span class="o">}</span>
</code></pre></div></div>

<p>è€Œdoubleç±»å‹å’ŒDecimalç±»å‹getBucketIdçš„ç®—æ³•æ˜¯ä¸åŒçš„ï¼Œé™„å½•ä¸­æä¾›äº†éªŒè¯æ–¹æ³•ã€‚</p>

<p>å› æ­¤ï¼Œhashåçš„doubleç±»å‹æ•°æ®ï¼Œåœ¨è½¬ä¸ºDecimalä¹‹åï¼Œè™½ç„¶å…¶partitionValueè·å–æ˜¯ä¸€è‡´çš„ï¼Œä½†æ˜¯bucketIdè·å–æ–¹æ³•å­˜åœ¨å·®å¼‚ï¼Œå› æ­¤ä¸€ä¸ªtaskä¾ç„¶ç”Ÿæˆäº†åä¸ªbucketæ–‡ä»¶ï¼Œé€ æˆäº†å°æ–‡ä»¶çš„çˆ†ç‚¸ã€‚</p>

<h3 id="é™„å½•">é™„å½•</h3>

<h4 id="éªŒè¯double-å’Œdecimal-ç±»å‹çš„bucket-id-æ˜¯å¦ä¸åŒ">éªŒè¯double å’ŒDecimal ç±»å‹çš„bucket Id æ˜¯å¦ä¸åŒ</h4>

<p>æ­¤å¤„ä½¿ç”¨jsonæ ¼å¼æ˜¯å› ä¸ºå…¶å¯ä»¥ç›´æ¥æŸ¥çœ‹æ•°æ®ã€‚</p>

<p>åœ¨è·‘å®Œä¹‹åå»æŸ¥çœ‹è¡¨ä¸‹é¢çš„æ–‡ä»¶ï¼Œæ–‡ä»¶åæ ¼å¼:</p>

<p>part-{partitionId}-bdc018dc-38ad-4233-91ff-16f777ad812e_{bucketId}.c000.json</p>

<p>æˆ‘ä»¬åªéœ€å¯¹æ¯”ä¸¤å¼ è¡¨åŒæ ·bucketId æ–‡ä»¶ä¸‹é¢çš„å†…å®¹ä¸åŒå³å¯å¾—å‡ºç»“è®ºã€‚</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">sql</span><span class="o">(</span><span class="s">"create table ta(c1 double, c2 int) using json clustered by(c1) into 10 buckets"</span><span class="o">)</span>
<span class="nf">sql</span><span class="o">(</span><span class="s">"create table tb(c1 decimal(38, 18), c2 int) using json clustered by (c1) into 10 buckets"</span><span class="o">)</span>
<span class="nf">sql</span><span class="o">(</span><span class="s">"create table tc(c1 double, c2 int) using json"</span><span class="o">)</span>
<span class="nf">sql</span><span class="o">(</span><span class="s">"create table td(c1 decimal(38, 18), c2 int) using json"</span><span class="o">)</span>
<span class="nf">sql</span><span class="o">(</span><span class="s">"insert into tc select * from values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9), (10, 10)"</span><span class="o">)</span>
<span class="nf">sql</span><span class="o">(</span><span class="s">"insert into td select * from values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9),(10,10)"</span><span class="o">)</span>
<span class="nf">sql</span><span class="o">(</span><span class="s">"insert overwrite table ta select * from tc"</span><span class="o">)</span>
<span class="nf">sql</span><span class="o">(</span><span class="s">"insert overwrite table tb select * from td"</span><span class="o">)</span>
</code></pre></div></div>

:ET