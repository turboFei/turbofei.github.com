I"U–<h3 id="background">Background</h3>

<p>Sparkåœ¨èµ„æºç®¡ç†å’Œè°ƒåº¦æ–¹å¼ä¸Šé‡‡ç”¨äº†ç±»ä¼¼äºHadoop <a href="http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html"><strong>YARN</strong></a>çš„æ–¹å¼ï¼Œæœ€ä¸Šå±‚æ˜¯èµ„æºè°ƒåº¦å™¨ï¼Œå®ƒè´Ÿè´£åˆ†é…èµ„æºå’Œè°ƒåº¦æ³¨å†Œåˆ°Sparkä¸­çš„æ‰€æœ‰åº”ç”¨ï¼ŒSparké€‰ç”¨<a href="http://incubator.apache.org/mesos/">Mesos</a>æˆ–æ˜¯YARNç­‰ä½œä¸ºå…¶èµ„æºè°ƒåº¦æ¡†æ¶ã€‚åœ¨æ¯ä¸€ä¸ªåº”ç”¨å†…éƒ¨ï¼ŒSparkåˆå®ç°äº†ä»»åŠ¡è°ƒåº¦å™¨ï¼Œè´Ÿè´£ä»»åŠ¡çš„è°ƒåº¦å’Œåè°ƒï¼Œç±»ä¼¼äº<a href="http://hadoop.apache.org/">MapReduce</a>ã€‚æœ¬è´¨ä¸Šï¼Œå¤–å±‚çš„èµ„æºè°ƒåº¦å’Œå†…å±‚çš„ä»»åŠ¡è°ƒåº¦ç›¸äº’ç‹¬ç«‹ï¼Œå„å¸å…¶èŒã€‚æœ¬æ–‡å¯¹äºSparkçš„æºç åˆ†æä¸»è¦é›†ä¸­åœ¨å†…å±‚çš„ä»»åŠ¡è°ƒåº¦å™¨ä¸Šï¼Œåˆ†æSparkä»»åŠ¡è°ƒåº¦å™¨çš„å®ç°ã€‚</p>

<h1 id="scheduleræ¨¡å—æ•´ä½“æ¶æ„">Scheduleræ¨¡å—æ•´ä½“æ¶æ„</h1>

<p><code class="language-plaintext highlighter-rouge">scheduler</code>æ¨¡å—ä¸»è¦åˆ†ä¸ºä¸¤å¤§éƒ¨åˆ†ï¼š</p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">TaskSchedulerListener</code>ã€‚<code class="language-plaintext highlighter-rouge">TaskSchedulerListener</code>éƒ¨åˆ†çš„ä¸»è¦åŠŸèƒ½æ˜¯ç›‘å¬ç”¨æˆ·æäº¤çš„jobï¼Œå°†jobåˆ†è§£ä¸ºä¸åŒçš„ç±»å‹çš„stageä»¥åŠç›¸åº”çš„taskï¼Œå¹¶å‘<code class="language-plaintext highlighter-rouge">TaskScheduler</code>æäº¤taskã€‚</li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">TaskScheduler</code>ã€‚<code class="language-plaintext highlighter-rouge">TaskScheduler</code>æ¥æ”¶ç”¨æˆ·æäº¤çš„taskå¹¶æ‰§è¡Œã€‚è€Œ<code class="language-plaintext highlighter-rouge">TaskScheduler</code>æ ¹æ®éƒ¨ç½²çš„ä¸åŒåˆåˆ†ä¸ºä¸‰ä¸ªå­æ¨¡å—:</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">ClusterScheduler</code></li>
      <li><code class="language-plaintext highlighter-rouge">LocalScheduler</code></li>
      <li><code class="language-plaintext highlighter-rouge">MesosScheduler</code></li>
    </ul>
  </li>
</ol>

<h2 id="taskschedulerlistener">TaskSchedulerListener</h2>

<p>SparkæŠ½è±¡äº†<code class="language-plaintext highlighter-rouge">TaskSchedulerListener</code>å¹¶åœ¨å…¶ä¸Šå®ç°äº†<code class="language-plaintext highlighter-rouge">DAGScheduler</code>ã€‚<code class="language-plaintext highlighter-rouge">DAGScheduler</code>çš„ä¸»è¦åŠŸèƒ½æ˜¯æ¥æ”¶ç”¨æˆ·æäº¤çš„jobï¼Œå°†jobæ ¹æ®ç±»å‹åˆ’åˆ†ä¸ºä¸åŒçš„stageï¼Œå¹¶åœ¨æ¯ä¸€ä¸ªstageå†…äº§ç”Ÿä¸€ç³»åˆ—çš„taskï¼Œå‘<code class="language-plaintext highlighter-rouge">TaskScheduler</code>æäº¤taskã€‚ä¸‹é¢æˆ‘ä»¬é¦–å…ˆæ¥çœ‹ä¸€ä¸‹<code class="language-plaintext highlighter-rouge">TaskSchedulerListener</code>éƒ¨åˆ†çš„ç±»å›¾ï¼š</p>

<p><img src="/img/2013-04-21-sheduler/dagscheduler.png" alt="DAGScheduler class chart" width="640" /></p>

<ul>
  <li>ç”¨æˆ·æ‰€æäº¤çš„jobåœ¨å¾—åˆ°<code class="language-plaintext highlighter-rouge">DAGScheduler</code>çš„è°ƒåº¦åï¼Œä¼šè¢«åŒ…è£…æˆ<code class="language-plaintext highlighter-rouge">ActiveJob</code>ï¼ŒåŒæ—¶ä¼šå¯åŠ¨<code class="language-plaintext highlighter-rouge">JobWaiter</code>é˜»å¡ç›‘å¬jobçš„å®ŒæˆçŠ¶å†µã€‚</li>
  <li>äºæ­¤åŒæ—¶ä¾æ®jobä¸­<code class="language-plaintext highlighter-rouge">RDD</code>çš„dependencyå’Œdependencyå±æ€§(<code class="language-plaintext highlighter-rouge">NarrowDependency</code>ï¼Œ<code class="language-plaintext highlighter-rouge">ShufflerDependecy</code>)ï¼Œ<code class="language-plaintext highlighter-rouge">DAGScheduler</code>ä¼šæ ¹æ®ä¾èµ–å…³ç³»çš„å…ˆåäº§ç”Ÿå‡ºä¸åŒçš„stage DAG(result stage, shuffle map stage)ã€‚</li>
  <li>åœ¨æ¯ä¸€ä¸ªstageå†…éƒ¨ï¼Œæ ¹æ®stageäº§ç”Ÿå‡ºç›¸åº”çš„taskï¼ŒåŒ…æ‹¬<code class="language-plaintext highlighter-rouge">ResultTask</code>æˆ–æ˜¯<code class="language-plaintext highlighter-rouge">ShuffleMapTask</code>ï¼Œè¿™äº›taskä¼šæ ¹æ®<code class="language-plaintext highlighter-rouge">RDD</code>ä¸­partitionçš„æ•°é‡å’Œåˆ†å¸ƒï¼Œäº§ç”Ÿå‡ºä¸€ç»„ç›¸åº”çš„taskï¼Œå¹¶å°†å…¶åŒ…è£…ä¸º<code class="language-plaintext highlighter-rouge">TaskSet</code>æäº¤åˆ°<code class="language-plaintext highlighter-rouge">TaskScheduler</code>ä¸Šå»ã€‚</li>
</ul>

<blockquote>
  <h4 id="rddçš„ä¾èµ–å…³ç³»å’Œstageçš„åˆ†ç±»">RDDçš„ä¾èµ–å…³ç³»å’ŒStageçš„åˆ†ç±»</h4>
  <p>åœ¨Sparkä¸­ï¼Œæ¯ä¸€ä¸ª<code class="language-plaintext highlighter-rouge">RDD</code>æ˜¯å¯¹äºæ•°æ®é›†åœ¨æŸä¸€çŠ¶æ€ä¸‹çš„è¡¨ç°å½¢å¼ï¼Œè€Œè¿™ä¸ªçŠ¶æ€æœ‰å¯èƒ½æ˜¯ä»å‰ä¸€çŠ¶æ€è½¬æ¢è€Œæ¥çš„ï¼Œå› æ­¤æ¢å¥è¯è¯´è¿™ä¸€ä¸ª<code class="language-plaintext highlighter-rouge">RDD</code>æœ‰å¯èƒ½ä¸ä¹‹å‰çš„<code class="language-plaintext highlighter-rouge">RDD(s)</code>æœ‰ä¾èµ–å…³ç³»ã€‚æ ¹æ®ä¾èµ–å…³ç³»çš„ä¸åŒï¼Œå¯ä»¥å°†<code class="language-plaintext highlighter-rouge">RDD</code>åˆ†æˆä¸¤ç§ä¸åŒçš„ç±»å‹ï¼š<code class="language-plaintext highlighter-rouge">Narrow Dependency</code>å’Œ<code class="language-plaintext highlighter-rouge">Wide Dependency</code>ã€‚</p>

  <ul>
    <li><code class="language-plaintext highlighter-rouge">Narrow Dependency</code>æŒ‡çš„æ˜¯ <code class="language-plaintext highlighter-rouge">child RDD</code>åªä¾èµ–äº<code class="language-plaintext highlighter-rouge">parent RDD(s)</code>å›ºå®šæ•°é‡çš„partitionã€‚</li>
    <li><code class="language-plaintext highlighter-rouge">Wide Dependency</code>æŒ‡çš„æ˜¯<code class="language-plaintext highlighter-rouge">child RDD</code>çš„æ¯ä¸€ä¸ªpartitionéƒ½ä¾èµ–äº<code class="language-plaintext highlighter-rouge">parent RDD(s)</code>æ‰€æœ‰partitionã€‚</li>
  </ul>

  <p>å®ƒä»¬ä¹‹é—´çš„åŒºåˆ«å¯å‚çœ‹ä¸‹å›¾ï¼š</p>

  <p><img src="/img/2013-04-21-sheduler/rdd_dependency.png" alt="RDD dependecies" width="480" /></p>

  <p>æ ¹æ®<code class="language-plaintext highlighter-rouge">RDD</code>ä¾èµ–å…³ç³»çš„ä¸åŒï¼ŒSparkä¹Ÿå°†æ¯ä¸€ä¸ªjobåˆ†ä¸ºä¸åŒçš„stageï¼Œè€Œstageä¹‹é—´çš„ä¾èµ–å…³ç³»åˆ™å½¢æˆäº†DAGã€‚å¯¹äº<code class="language-plaintext highlighter-rouge">Narrow Dependency</code>ï¼ŒSparkä¼šå°½é‡å¤šåœ°å°†<code class="language-plaintext highlighter-rouge">RDD</code>è½¬æ¢æ”¾åœ¨åŒä¸€ä¸ªstageä¸­ï¼›è€Œå¯¹äº<code class="language-plaintext highlighter-rouge">Wide Dependency</code>ï¼Œç”±äº<code class="language-plaintext highlighter-rouge">Wide Dependency</code>é€šå¸¸æ„å‘³ç€shuffleæ“ä½œï¼Œå› æ­¤Sparkä¼šå°†æ­¤stageå®šä¹‰ä¸º<code class="language-plaintext highlighter-rouge">ShuffleMapStage</code>ï¼Œä»¥ä¾¿äºå‘<code class="language-plaintext highlighter-rouge">MapOutputTracker</code>æ³¨å†Œshuffleæ“ä½œã€‚å¯¹äºstageçš„åˆ’åˆ†å¯å‚çœ‹ä¸‹å›¾ï¼ŒSparké€šå¸¸å°†shuffleæ“ä½œå®šä¹‰ä¸ºstageçš„è¾¹ç•Œã€‚</p>

  <p><img src="/img/2013-04-21-sheduler/stage.png" alt="different stage boundary" width="480" /></p>

</blockquote>

<h3 id="dagscheduler">DAGScheduler</h3>

<p>åœ¨ç”¨æˆ·åˆ›å»º<code class="language-plaintext highlighter-rouge">SparkContext</code>å¯¹è±¡æ—¶ï¼ŒSparkä¼šåœ¨å†…éƒ¨åˆ›å»º<code class="language-plaintext highlighter-rouge">DAGScheduler</code>å¯¹è±¡ï¼Œå¹¶æ ¹æ®ç”¨æˆ·çš„éƒ¨ç½²æƒ…å†µï¼Œç»‘å®šä¸åŒçš„<code class="language-plaintext highlighter-rouge">TaskSechduler</code>ï¼Œå¹¶å¯åŠ¨<code class="language-plaintext highlighter-rouge">DAGcheduler</code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>private var taskScheduler: TaskScheduler = {
    //...
}
taskScheduler.start()

private var dagScheduler = new DAGScheduler(taskScheduler)
dagScheduler.start()
</code></pre></div></div>

<p>è€Œ<code class="language-plaintext highlighter-rouge">DAGScheduler</code>çš„å¯åŠ¨ä¼šåœ¨å†…éƒ¨åˆ›å»ºdaemonçº¿ç¨‹ï¼Œdaemonçº¿ç¨‹è°ƒç”¨<code class="language-plaintext highlighter-rouge">run()</code>ä»block queueä¸­å–å‡ºeventè¿›è¡Œå¤„ç†ã€‚</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>private def run() {
  SparkEnv.set(env)

  while (true) {
    val event = eventQueue.poll(POLL_TIMEOUT, TimeUnit.MILLISECONDS)
    if (event != null) {
      logDebug("Got event of type " + event.getClass.getName)
    }

    if (event != null) {
      if (processEvent(event)) {
        return
      }
    }

    val time = System.currentTimeMillis() // TODO: use a pluggable clock for testability
    if (failed.size &gt; 0 &amp;&amp; time &gt; lastFetchFailureTime + RESUBMIT_TIMEOUT) {
      resubmitFailedStages()
    } else {
      submitWaitingStages()
    }
  }
}
</code></pre></div></div>

<p>è€Œ<code class="language-plaintext highlighter-rouge">run()</code>ä¼šè°ƒç”¨<code class="language-plaintext highlighter-rouge">processEvent</code>æ¥å¤„ç†ä¸åŒçš„eventã€‚</p>

<p><code class="language-plaintext highlighter-rouge">DAGScheduler</code>å¤„ç†çš„eventåŒ…æ‹¬ï¼š</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">JobSubmitted</code></li>
  <li><code class="language-plaintext highlighter-rouge">CompletionEvent</code></li>
  <li><code class="language-plaintext highlighter-rouge">ExecutorLost</code></li>
  <li><code class="language-plaintext highlighter-rouge">TaskFailed</code></li>
  <li><code class="language-plaintext highlighter-rouge">StopDAGScheduler</code></li>
</ul>

<p>æ ¹æ®eventçš„ä¸åŒè°ƒç”¨ä¸åŒçš„æ–¹æ³•å»å¤„ç†ã€‚</p>

<p>æœ¬è´¨ä¸Š<code class="language-plaintext highlighter-rouge">DAGScheduler</code>æ˜¯ä¸€ä¸ªç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å‹ï¼Œç”¨æˆ·å’Œ<code class="language-plaintext highlighter-rouge">TaskSchduler</code>äº§ç”Ÿeventå°†å…¶æ”¾å…¥block queueï¼Œdaemonçº¿ç¨‹æ¶ˆè´¹eventå¹¶å¤„ç†ç›¸åº”äº‹ä»¶ã€‚</p>

<h3 id="jobçš„ç”Ÿä¸æ­»">Jobçš„ç”Ÿä¸æ­»</h3>

<p>æ—¢ç„¶ç”¨æˆ·æäº¤çš„jobæœ€ç»ˆä¼šäº¤ç”±<code class="language-plaintext highlighter-rouge">DAGScheduler</code>å»å¤„ç†ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±æ¥ç ”ç©¶ä¸€ä¸‹<code class="language-plaintext highlighter-rouge">DAGScheduler</code>å¤„ç†jobçš„æ•´ä¸ªæµç¨‹ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬åˆ†æä¸¤ç§ä¸åŒç±»å‹çš„jobçš„å¤„ç†æµç¨‹ã€‚</p>

<ol>
  <li>
    <p>æ²¡æœ‰shuffleå’Œreduceçš„job</p>

 	val textFile = sc.textFile(â€œREADME.mdâ€)
 	textFile.filter(line =&gt; line.contains(â€œSparkâ€)).count()
  </li>
  <li>
    <p>æœ‰shuffleå’Œreduceçš„job</p>

 	val textFile = sc.textFile(â€œREADME.mdâ€)
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> textFile.flatMap(line =&gt; line.split(" ")).map(word =&gt; (word, 1)).reduceByKey((a, b) =&gt; a + b)
</code></pre></div>    </div>
  </li>
</ol>

<p>é¦–å…ˆåœ¨å¯¹<code class="language-plaintext highlighter-rouge">RDD</code>çš„<code class="language-plaintext highlighter-rouge">count()</code>å’Œ<code class="language-plaintext highlighter-rouge">reduceByKey()</code>æ“ä½œéƒ½ä¼šè°ƒç”¨<code class="language-plaintext highlighter-rouge">SparkContext</code>çš„<code class="language-plaintext highlighter-rouge">runJob()</code>æ¥æäº¤jobï¼Œè€Œ<code class="language-plaintext highlighter-rouge">SparkContext</code>çš„<code class="language-plaintext highlighter-rouge">runJob()</code>æœ€ç»ˆä¼šè°ƒç”¨<code class="language-plaintext highlighter-rouge">DAGScheduler</code>çš„<code class="language-plaintext highlighter-rouge">runJob()</code>ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def runJob[T, U: ClassManifest](
    finalRdd: RDD[T],
    func: (TaskContext, Iterator[T]) =&gt; U,
    partitions: Seq[Int],
    callSite: String,
    allowLocal: Boolean,
    resultHandler: (Int, U) =&gt; Unit)
{
  if (partitions.size == 0) {
    return
  }
  val (toSubmit, waiter) = prepareJob(
      finalRdd, func, partitions, callSite, allowLocal, resultHandler)
  eventQueue.put(toSubmit)
  waiter.awaitResult() match {
    case JobSucceeded =&gt; {}
    case JobFailed(exception: Exception) =&gt;
      logInfo("Failed to run " + callSite)
      throw exception
  }
}
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">runJob()</code>ä¼šè°ƒç”¨<code class="language-plaintext highlighter-rouge">prepareJob()</code>å¯¹jobè¿›è¡Œé¢„å¤„ç†ï¼Œå°è£…æˆ<code class="language-plaintext highlighter-rouge">JobSubmitted</code>äº‹ä»¶ï¼Œæ”¾å…¥queueä¸­ï¼Œå¹¶é˜»å¡ç­‰å¾…jobå®Œæˆã€‚</p>

<p>å½“daemonçº¿ç¨‹çš„<code class="language-plaintext highlighter-rouge">processEvent()</code>ä»queueä¸­å–å‡º<code class="language-plaintext highlighter-rouge">JobSubmitted</code>äº‹ä»¶åï¼Œä¼šæ ¹æ®jobåˆ’åˆ†å‡ºä¸åŒçš„stageï¼Œå¹¶ä¸”æäº¤stageï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>case JobSubmitted(finalRDD, func, partitions, allowLocal, callSite, listener) =&gt;
  val runId = nextRunId.getAndIncrement()
  val finalStage = newStage(finalRDD, None, runId)
  val job = new ActiveJob(runId, finalStage, func, partitions, callSite, listener)
  clearCacheLocs()
  if (allowLocal &amp;&amp; finalStage.parents.size == 0 &amp;&amp; partitions.length == 1) {
    runLocally(job)
  } else {
    activeJobs += job
    resultStageToJob(finalStage) = job
    submitStage(finalStage)
  }
</code></pre></div></div>

<p>é¦–å…ˆï¼Œå¯¹äºä»»ä½•çš„jobéƒ½ä¼šäº§ç”Ÿå‡ºä¸€ä¸ª<code class="language-plaintext highlighter-rouge">finalStage</code>æ¥äº§ç”Ÿå’Œæäº¤taskã€‚å…¶æ¬¡å¯¹äºæŸäº›ç®€å•çš„jobï¼Œå®ƒæ²¡æœ‰ä¾èµ–å…³ç³»ï¼Œå¹¶ä¸”åªæœ‰ä¸€ä¸ªpartitionï¼Œè¿™æ ·çš„jobä¼šä½¿ç”¨local threadå¤„ç†è€Œå¹¶éæäº¤åˆ°<code class="language-plaintext highlighter-rouge">TaskScheduler</code>ä¸Šå¤„ç†ã€‚</p>

<p>æ¥ä¸‹æ¥äº§ç”Ÿ<code class="language-plaintext highlighter-rouge">finalStage</code>åï¼Œéœ€è¦è°ƒç”¨<code class="language-plaintext highlighter-rouge">submitStage()</code>ï¼Œå®ƒæ ¹æ®stageä¹‹é—´çš„ä¾èµ–å…³ç³»å¾—å‡ºstage DAGï¼Œå¹¶ä»¥ä¾èµ–å…³ç³»è¿›è¡Œå¤„ç†ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>private def submitStage(stage: Stage) {
  if (!waiting(stage) &amp;&amp; !running(stage) &amp;&amp; !failed(stage)) {
    val missing = getMissingParentStages(stage).sortBy(_.id)
    if (missing == Nil) {
      submitMissingTasks(stage)
      running += stage
    } else {
      for (parent &lt;- missing) {
        submitStage(parent)
      }
      waiting += stage
    }
  }
}
</code></pre></div></div>

<p>å¯¹äºæ–°æäº¤çš„jobï¼Œ<code class="language-plaintext highlighter-rouge">finalStage</code>çš„parent stageè¿˜æœªè·å¾—ï¼Œå› æ­¤<code class="language-plaintext highlighter-rouge">submitStage</code>ä¼šè°ƒç”¨<code class="language-plaintext highlighter-rouge">getMissingParentStages()</code>æ¥è·å¾—ä¾èµ–å…³ç³»ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>private def getMissingParentStages(stage: Stage): List[Stage] = {
  val missing = new HashSet[Stage]
  val visited = new HashSet[RDD[_]]
  def visit(rdd: RDD[_]) {
    if (!visited(rdd)) {
      visited += rdd
      if (getCacheLocs(rdd).contains(Nil)) {
        for (dep &lt;- rdd.dependencies) {
          dep match {
            case shufDep: ShuffleDependency[_,_] =&gt;
              val mapStage = getShuffleMapStage(shufDep, stage.priority)
              if (!mapStage.isAvailable) {
                missing += mapStage
              }
            case narrowDep: NarrowDependency[_] =&gt;
              visit(narrowDep.rdd)
          }
        }
      }
    }
  }
  visit(stage.rdd)
  missing.toList
}
</code></pre></div></div>

<p>è¿™é‡Œparent stageæ˜¯é€šè¿‡<code class="language-plaintext highlighter-rouge">RDD</code>çš„ä¾èµ–å…³ç³»é€’å½’éå†è·å¾—ã€‚å¯¹äº<code class="language-plaintext highlighter-rouge">Wide Dependecy</code>ä¹Ÿå°±æ˜¯<code class="language-plaintext highlighter-rouge">Shuffle Dependecy</code>ï¼ŒSparkä¼šäº§ç”Ÿæ–°çš„<code class="language-plaintext highlighter-rouge">mapStage</code>ä½œä¸º<code class="language-plaintext highlighter-rouge">finalStage</code>çš„parentï¼Œè€Œå¯¹äº<code class="language-plaintext highlighter-rouge">Narrow Dependecy</code> Sparkåˆ™ä¸ä¼šäº§ç”Ÿæ–°çš„stageã€‚è¿™é‡Œå¯¹stageçš„åˆ’åˆ†æ˜¯æŒ‰ç…§ä¸Šé¢æåˆ°çš„ä½œä¸ºåˆ’åˆ†ä¾æ®çš„ï¼Œå› æ­¤å¯¹äºæœ¬æ®µå¼€å¤´æåˆ°çš„ä¸¤ç§jobï¼Œç¬¬ä¸€ç§jobåªä¼šäº§ç”Ÿä¸€ä¸ª<code class="language-plaintext highlighter-rouge">finalStage</code>ï¼Œè€Œç¬¬äºŒç§jobä¼šäº§ç”Ÿ<code class="language-plaintext highlighter-rouge">finalStage</code>å’Œ<code class="language-plaintext highlighter-rouge">mapStage</code>ã€‚</p>

<p>å½“stage DAGäº§ç”Ÿä»¥åï¼Œé’ˆå¯¹æ¯ä¸ªstageéœ€è¦äº§ç”Ÿtaskå»æ‰§è¡Œï¼Œæ•…åœ¨è¿™ä¼šè°ƒç”¨<code class="language-plaintext highlighter-rouge">submitMissingTasks()</code>ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>private def submitMissingTasks(stage: Stage) {
  val myPending = pendingTasks.getOrElseUpdate(stage, new HashSet)
  myPending.clear()
  var tasks = ArrayBuffer[Task[_]]()
  if (stage.isShuffleMap) {
    for (p &lt;- 0 until stage.numPartitions if stage.outputLocs(p) == Nil) {
      val locs = getPreferredLocs(stage.rdd, p)
      tasks += new ShuffleMapTask(stage.id, stage.rdd, stage.shuffleDep.get, p, locs)
    }
  } else {
    val job = resultStageToJob(stage)
    for (id &lt;- 0 until job.numPartitions if (!job.finished(id))) {
      val partition = job.partitions(id)
      val locs = getPreferredLocs(stage.rdd, partition)
      tasks += new ResultTask(stage.id, stage.rdd, job.func, partition, locs, id)
    }
  }
  if (tasks.size &gt; 0) {
    myPending ++= tasks
    taskSched.submitTasks(
      new TaskSet(tasks.toArray, stage.id, stage.newAttemptId(), stage.priority))
    if (!stage.submissionTime.isDefined) {
      stage.submissionTime = Some(System.currentTimeMillis())
    }
  } else {
    running -= stage
  }
}
</code></pre></div></div>

<p>é¦–å…ˆæ ¹æ®stageæ‰€ä¾èµ–çš„<code class="language-plaintext highlighter-rouge">RDD</code>çš„partitionçš„åˆ†å¸ƒï¼Œä¼šäº§ç”Ÿå‡ºä¸partitionæ•°é‡ç›¸ç­‰çš„taskï¼Œè¿™äº›taskæ ¹æ®partitionçš„localityè¿›è¡Œåˆ†å¸ƒï¼›å…¶æ¬¡å¯¹äº<code class="language-plaintext highlighter-rouge">finalStage</code>æˆ–æ˜¯<code class="language-plaintext highlighter-rouge">mapStage</code>ä¼šäº§ç”Ÿä¸åŒçš„taskï¼›æœ€åæ‰€æœ‰çš„taskä¼šå°è£…åˆ°<code class="language-plaintext highlighter-rouge">TaskSet</code>å†…æäº¤åˆ°<code class="language-plaintext highlighter-rouge">TaskScheduler</code>å»æ‰§è¡Œã€‚</p>

<p>è‡³æ­¤jobåœ¨<code class="language-plaintext highlighter-rouge">DAGScheduler</code>å†…çš„å¯åŠ¨è¿‡ç¨‹å…¨éƒ¨å®Œæˆï¼Œäº¤ç”±<code class="language-plaintext highlighter-rouge">TaskScheduler</code>æ‰§è¡Œtaskï¼Œå½“taskæ‰§è¡Œå®Œåä¼šå°†ç»“æœè¿”å›ç»™<code class="language-plaintext highlighter-rouge">DAGScheduler</code>ï¼Œ<code class="language-plaintext highlighter-rouge">DAGScheduler</code>è°ƒç”¨<code class="language-plaintext highlighter-rouge">handleTaskComplete()</code>å¤„ç†taskè¿”å›:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>private def handleTaskCompletion(event: CompletionEvent) {
  val task = event.task
  val stage = idToStage(task.stageId)

  def markStageAsFinished(stage: Stage) = {
    val serviceTime = stage.submissionTime match {
      case Some(t) =&gt; "%.03f".format((System.currentTimeMillis() - t) / 1000.0)
      case _ =&gt; "Unkown"
    }
    logInfo("%s (%s) finished in %s s".format(stage, stage.origin, serviceTime))
    running -= stage
  }
  event.reason match {
    case Success =&gt;
        ...
      task match {
        case rt: ResultTask[_, _] =&gt;
          ...
        case smt: ShuffleMapTask =&gt;
          ...
      }
    case Resubmitted =&gt;
      ...

    case FetchFailed(bmAddress, shuffleId, mapId, reduceId) =&gt;
      ...
    case other =&gt;
      abortStage(idToStage(task.stageId), task + " failed: " + other)
  }
}
</code></pre></div></div>

<p>æ¯ä¸ªæ‰§è¡Œå®Œæˆçš„taskéƒ½ä¼šå°†ç»“æœè¿”å›ç»™<code class="language-plaintext highlighter-rouge">DAGScheduler</code>ï¼Œ<code class="language-plaintext highlighter-rouge">DAGScheduler</code>æ ¹æ®è¿”å›ç»“æœæ¥è¿›è¡Œè¿›ä¸€æ­¥çš„åŠ¨ä½œã€‚</p>

<h3 id="rddçš„è®¡ç®—">RDDçš„è®¡ç®—</h3>

<p><code class="language-plaintext highlighter-rouge">RDD</code>çš„è®¡ç®—æ˜¯åœ¨taskä¸­å®Œæˆçš„ã€‚æˆ‘ä»¬ä¹‹å‰æåˆ°taskåˆ†ä¸º<code class="language-plaintext highlighter-rouge">ResultTask</code>å’Œ<code class="language-plaintext highlighter-rouge">ShuffleMapTask</code>ï¼Œæˆ‘ä»¬åˆ†åˆ«æ¥çœ‹ä¸€ä¸‹è¿™ä¸¤ç§taskå…·ä½“çš„æ‰§è¡Œè¿‡ç¨‹ã€‚</p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">ResultTask</code></p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  override def run(attemptId: Long): U = {
    val context = new TaskContext(stageId, partition, attemptId)
    try {
      func(context, rdd.iterator(split, context))
    } finally {
      context.executeOnCompleteCallbacks()
    }
  }
</code></pre></div>    </div>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">ShuffleMapTask</code></p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  override def run(attemptId: Long): MapStatus = {
    val numOutputSplits = dep.partitioner.numPartitions

    val taskContext = new TaskContext(stageId, partition, attemptId)
    try {
      val buckets = Array.fill(numOutputSplits)(new ArrayBuffer[(Any, Any)])
      for (elem &lt;- rdd.iterator(split, taskContext)) {
        val pair = elem.asInstanceOf[(Any, Any)]
        val bucketId = dep.partitioner.getPartition(pair._1)
        buckets(bucketId) += pair
      }

      val compressedSizes = new Array[Byte](numOutputSplits)

      val blockManager = SparkEnv.get.blockManager
      for (i &lt;- 0 until numOutputSplits) {
        val blockId = "shuffle_" + dep.shuffleId + "_" + partition + "_" + i
        val iter: Iterator[(Any, Any)] = buckets(i).iterator
        val size = blockManager.put(blockId, iter, StorageLevel.DISK_ONLY, false)
        compressedSizes(i) = MapOutputTracker.compressSize(size)
      }

      return new MapStatus(blockManager.blockManagerId, compressedSizes)
    } finally {
      taskContext.executeOnCompleteCallbacks()
    }
  }
</code></pre></div>    </div>
  </li>
</ul>

<p><code class="language-plaintext highlighter-rouge">ResultTask</code>å’Œ<code class="language-plaintext highlighter-rouge">ShuffleMapTask</code>éƒ½ä¼šè°ƒç”¨<code class="language-plaintext highlighter-rouge">RDD</code>çš„<code class="language-plaintext highlighter-rouge">iterator()</code>æ¥è®¡ç®—å’Œè½¬æ¢<code class="language-plaintext highlighter-rouge">RDD</code>ï¼Œä¸åŒçš„æ˜¯ï¼š<code class="language-plaintext highlighter-rouge">ResultTask</code>è½¬æ¢å®Œ<code class="language-plaintext highlighter-rouge">RDD</code>åè°ƒç”¨<code class="language-plaintext highlighter-rouge">func()</code>è®¡ç®—ç»“æœï¼›è€Œ<code class="language-plaintext highlighter-rouge">ShufflerMapTask</code>åˆ™å°†å…¶æ”¾å…¥<code class="language-plaintext highlighter-rouge">blockManager</code>ä¸­ç”¨æ¥shuffleã€‚</p>

<p><code class="language-plaintext highlighter-rouge">RDD</code>çš„è®¡ç®—è°ƒç”¨<code class="language-plaintext highlighter-rouge">iterator()</code>ï¼Œ<code class="language-plaintext highlighter-rouge">iterator()</code>åœ¨å†…éƒ¨è°ƒç”¨<code class="language-plaintext highlighter-rouge">compute()</code>ä»<code class="language-plaintext highlighter-rouge">RDD</code>ä¾èµ–å…³ç³»çš„æ ¹å¼€å§‹è®¡ç®—ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>final def iterator(split: Partition, context: TaskContext): Iterator[T] = {
  if (storageLevel != StorageLevel.NONE) {
    SparkEnv.get.cacheManager.getOrCompute(this, split, context, storageLevel)
  } else {
    computeOrReadCheckpoint(split, context)
  }
}

private[spark] def computeOrReadCheckpoint(split: Partition, context: TaskContext): Iterator[T] = {
  if (isCheckpointed) {
    firstParent[T].iterator(split, context)
  } else {
    compute(split, context)
  }
}
</code></pre></div></div>

<p>è‡³æ­¤å¤§è‡´åˆ†æäº†<code class="language-plaintext highlighter-rouge">TaskSchedulerListener</code>ï¼ŒåŒ…æ‹¬<code class="language-plaintext highlighter-rouge">DAGScheduler</code>å†…éƒ¨çš„ç»“æ„ï¼Œjobç”Ÿå‘½å‘¨æœŸå†…çš„æ´»åŠ¨ï¼Œ<code class="language-plaintext highlighter-rouge">RDD</code>æ˜¯ä½•æ—¶ä½•åœ°è®¡ç®—çš„ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬åˆ†æä¸€ä¸‹taskåœ¨<code class="language-plaintext highlighter-rouge">TaskScheduler</code>å†…å¹²äº†ä»€ä¹ˆã€‚</p>

<h2 id="taskscheduler">TaskScheduler</h2>

<p>å‰é¢ä¹Ÿæåˆ°äº†Sparkå®ç°äº†ä¸‰ç§ä¸åŒçš„<code class="language-plaintext highlighter-rouge">TaskScheduler</code>ï¼ŒåŒ…æ‹¬<code class="language-plaintext highlighter-rouge">LocalSheduler</code>ã€<code class="language-plaintext highlighter-rouge">ClusterScheduler</code>å’Œ<code class="language-plaintext highlighter-rouge">MesosScheduler</code>ã€‚<code class="language-plaintext highlighter-rouge">LocalSheduler</code>æ˜¯ä¸€ä¸ªåœ¨æœ¬åœ°æ‰§è¡Œçš„çº¿ç¨‹æ± ï¼Œ<code class="language-plaintext highlighter-rouge">DAGScheduler</code>æäº¤çš„æ‰€æœ‰taskä¼šåœ¨çº¿ç¨‹æ± ä¸­è¢«æ‰§è¡Œï¼Œå¹¶å°†ç»“æœè¿”å›ç»™<code class="language-plaintext highlighter-rouge">DAGScheduler</code>ã€‚<code class="language-plaintext highlighter-rouge">MesosScheduler</code>ä¾èµ–äºMesosè¿›è¡Œè°ƒåº¦ï¼Œç¬”è€…å¯¹Mesosäº†è§£ç”šå°‘ï¼Œå› æ­¤ä¸åšåˆ†æã€‚æ•…æ­¤ç« èŠ‚ä¸»è¦åˆ†æ<code class="language-plaintext highlighter-rouge">ClusterScheduler</code>æ¨¡å—ã€‚</p>

<p><code class="language-plaintext highlighter-rouge">ClusterScheduler</code>æ¨¡å—ä¸deployæ¨¡å—å’Œexecutoræ¨¡å—è€¦åˆè¾ƒä¸ºç´§å¯†ï¼Œå› æ­¤åœ¨åˆ†æ<code class="language-plaintext highlighter-rouge">ClUsterScheduler</code>æ—¶ä¹Ÿä¼šé¡ºå¸¦ä»‹ç»deployå’Œexecutoræ¨¡å—ã€‚</p>

<p>é¦–å…ˆæˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹<code class="language-plaintext highlighter-rouge">ClusterScheduler</code>çš„ç±»å›¾ï¼š</p>

<p><img src="/img/2013-04-21-sheduler/cluster_scheduler.png" alt="ClusterScheduler" width="640" /></p>

<p><code class="language-plaintext highlighter-rouge">ClusterScheduler</code>çš„å¯åŠ¨ä¼šä¼´éš<code class="language-plaintext highlighter-rouge">SparkDeploySchedulerBackend</code>çš„å¯åŠ¨ï¼Œè€Œbackendä¼šå°†è‡ªå·±åˆ†ä¸ºä¸¤ä¸ªè§’è‰²ï¼šé¦–å…ˆæ˜¯driverï¼Œdriveræ˜¯ä¸€ä¸ªlocalè¿è¡Œçš„actorï¼Œè´Ÿè´£ä¸remoteçš„executorè¿›è¡Œé€šè¡Œï¼Œæäº¤ä»»åŠ¡ï¼Œæ§åˆ¶executorï¼›å…¶æ¬¡æ˜¯<code class="language-plaintext highlighter-rouge">StandaloneExecutorBackend</code>ï¼ŒSparkä¼šåœ¨æ¯ä¸€ä¸ªslave nodeä¸Šå¯åŠ¨ä¸€ä¸ª<code class="language-plaintext highlighter-rouge">StandaloneExecutorBackend</code>è¿›ç¨‹ï¼Œè´Ÿè´£æ‰§è¡Œä»»åŠ¡ï¼Œè¿”å›æ‰§è¡Œç»“æœã€‚</p>

<h3 id="clusterschedulerçš„å¯åŠ¨">ClusterSchedulerçš„å¯åŠ¨</h3>

<p>åœ¨<code class="language-plaintext highlighter-rouge">SparkContext</code>å®ä¾‹åŒ–çš„è¿‡ç¨‹ä¸­ï¼Œ<code class="language-plaintext highlighter-rouge">ClusterScheduler</code>è¢«éšä¹‹å®ä¾‹åŒ–ï¼ŒåŒæ—¶èµ‹äºˆå…¶<code class="language-plaintext highlighter-rouge">SparkDeploySchedulerBackend</code>ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  master match {
      ...

    case SPARK_REGEX(sparkUrl) =&gt;
      val scheduler = new ClusterScheduler(this)
      val backend = new SparkDeploySchedulerBackend(scheduler, this, sparkUrl, appName)
      scheduler.initialize(backend)
      scheduler

    case LOCAL_CLUSTER_REGEX(numSlaves, coresPerSlave, memoryPerSlave) =&gt;
      ...
    case _ =&gt;
      ...
  }
}
taskScheduler.start()
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">ClusterScheduler</code>çš„å¯åŠ¨ä¼šå¯åŠ¨<code class="language-plaintext highlighter-rouge">SparkDeploySchedulerBackend</code>ï¼ŒåŒæ—¶å¯åŠ¨daemonè¿›ç¨‹æ¥æ£€æŸ¥speculative taskï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>override def start() {
  backend.start()

  if (System.getProperty("spark.speculation", "false") == "true") {
    new Thread("ClusterScheduler speculation check") {
      setDaemon(true)

      override def run() {
        while (true) {
          try {
            Thread.sleep(SPECULATION_INTERVAL)
          } catch {
            case e: InterruptedException =&gt; {}
          }
          checkSpeculatableTasks()
        }
      }
    }.start()
  }
}
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">SparkDeploySchedulerBacked</code>çš„å¯åŠ¨é¦–å…ˆä¼šè°ƒç”¨çˆ¶ç±»çš„<code class="language-plaintext highlighter-rouge">start()</code>ï¼Œæ¥ç€å®ƒä¼šå¯åŠ¨clientï¼Œå¹¶ç”±clientè¿æ¥åˆ°masterå‘æ¯ä¸€ä¸ªnodeçš„workerå‘é€è¯·æ±‚å¯åŠ¨<code class="language-plaintext highlighter-rouge">StandaloneExecutorBackend</code>ã€‚è¿™é‡Œçš„clientã€masterã€workeræ¶‰åŠåˆ°äº†deployæ¨¡å—ï¼Œæš‚æ—¶ä¸åšå…·ä½“ä»‹ç»ã€‚è€Œ<code class="language-plaintext highlighter-rouge">StandaloneExecutorBackend</code>åˆ™æ¶‰åŠåˆ°äº†executoræ¨¡å—ï¼Œå®ƒä¸»è¦çš„åŠŸèƒ½æ˜¯åœ¨æ¯ä¸€ä¸ªnodeåˆ›å»ºtaskå¯ä»¥è¿è¡Œçš„ç¯å¢ƒï¼Œå¹¶è®©taskåœ¨å…¶ç¯å¢ƒä¸­è¿è¡Œã€‚</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>override def start() {
  super.start()

  val driverUrl = "akka://spark@%s:%s/user/%s".format(
    System.getProperty("spark.driver.host"), System.getProperty("spark.driver.port"),
    StandaloneSchedulerBackend.ACTOR_NAME)
  val args = Seq(driverUrl, "", "", "")
  val command = Command("spark.executor.StandaloneExecutorBackend", args, sc.executorEnvs)
  val sparkHome = sc.getSparkHome().getOrElse(
    throw new IllegalArgumentException("must supply spark home for spark standalone"))
  val appDesc = new ApplicationDescription(appName, maxCores, executorMemory, command, sparkHome)

  client = new Client(sc.env.actorSystem, master, appDesc, this)
  client.start()
}
</code></pre></div></div>

<p>åœ¨<code class="language-plaintext highlighter-rouge">StandaloneSchedulerBackend</code>ä¸­ä¼šåˆ›å»º<code class="language-plaintext highlighter-rouge">DriverActor</code>ï¼Œå®ƒå°±æ˜¯localçš„driverï¼Œä»¥actorçš„æ–¹å¼ä¸remoteçš„executorè¿›è¡Œé€šä¿¡ã€‚</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>override def start() {
  val properties = new ArrayBuffer[(String, String)]
  val iterator = System.getProperties.entrySet.iterator
  while (iterator.hasNext) {
    val entry = iterator.next
    val (key, value) = (entry.getKey.toString, entry.getValue.toString)
    if (key.startsWith("spark.")) {
      properties += ((key, value))
    }
  }
  driverActor = actorSystem.actorOf(
    Props(new DriverActor(properties)), name = StandaloneSchedulerBackend.ACTOR_NAME)
}
</code></pre></div></div>

<p>åœ¨clientå®ä¾‹åŒ–ä¹‹å‰ï¼Œä¼šå°†<code class="language-plaintext highlighter-rouge">StandaloneExecutorBackend</code>çš„å¯åŠ¨ç¯å¢ƒä½œä¸ºå‚æ•°ä¼ é€’ç»™clientï¼Œè€Œclientå¯åŠ¨æ—¶ä¼šå°†æ­¤æäº¤ç»™masterï¼Œç”±masteråˆ†å‘ç»™æ‰€æœ‰nodeä¸Šçš„workerï¼Œworkerä¼šé…ç½®ç¯å¢ƒå¹¶åˆ›å»ºè¿›ç¨‹å¯åŠ¨<code class="language-plaintext highlighter-rouge">StandaloneExecutorBackend</code>ã€‚</p>

<p>è‡³æ­¤<code class="language-plaintext highlighter-rouge">ClusterScheduler</code>çš„å¯åŠ¨ï¼Œlocal driverçš„åˆ›å»ºï¼Œremote executorç¯å¢ƒçš„å¯åŠ¨æ‰€æœ‰è¿‡ç¨‹éƒ½å·²ç»“æŸï¼Œ<code class="language-plaintext highlighter-rouge">ClusterScheduler</code>ç­‰å¾…<code class="language-plaintext highlighter-rouge">DAGScheduler</code>æäº¤ä»»åŠ¡ã€‚</p>

<h3 id="clusterscheduleræäº¤ä»»åŠ¡">ClusterScheduleræäº¤ä»»åŠ¡</h3>

<p><code class="language-plaintext highlighter-rouge">DAGScheduler</code>ä¼šè°ƒç”¨<code class="language-plaintext highlighter-rouge">ClusterScheduler</code>æäº¤ä»»åŠ¡ï¼Œä»»åŠ¡ä¼šè¢«åŒ…è£…æˆ<code class="language-plaintext highlighter-rouge">TaskSetManager</code>å¹¶ç­‰å¾…è°ƒåº¦ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>override def submitTasks(taskSet: TaskSet) {
  val tasks = taskSet.tasks
  logInfo("Adding task set " + taskSet.id + " with " + tasks.length + " tasks")
  this.synchronized {
    val manager = new TaskSetManager(this, taskSet)
    activeTaskSets(taskSet.id) = manager
    activeTaskSetsQueue += manager
    taskSetTaskIds(taskSet.id) = new HashSet[Long]()

    if (hasReceivedTask == false) {
      starvationTimer.scheduleAtFixedRate(new TimerTask() {
        override def run() {
          if (!hasLaunchedTask) {
            logWarning("Initial job has not accepted any resources; " +
              "check your cluster UI to ensure that workers are registered")
          } else {
            this.cancel()
          }
        }
      }, STARVATION_TIMEOUT, STARVATION_TIMEOUT)
    }
    hasReceivedTask = true;
  }
  backend.reviveOffers()
}
</code></pre></div></div>

<p>åœ¨ä»»åŠ¡æäº¤çš„åŒæ—¶ä¼šå¯åŠ¨å®šæ—¶å™¨ï¼Œå¦‚æœä»»åŠ¡è¿˜æœªè¢«æ‰§è¡Œï¼Œå®šæ—¶å™¨æŒç»­å‘å‡ºè­¦å‘Šç›´åˆ°ä»»åŠ¡è¢«æ‰§è¡Œã€‚åŒæ—¶ä¼šè°ƒç”¨<code class="language-plaintext highlighter-rouge">StandaloneSchedulerBackend</code>çš„<code class="language-plaintext highlighter-rouge">reviveOffers()</code>ï¼Œè€Œå®ƒåˆ™ä¼šé€šè¿‡actorå‘driverå‘é€<code class="language-plaintext highlighter-rouge">ReviveOffers</code>ï¼Œdriveræ”¶åˆ°<code class="language-plaintext highlighter-rouge">ReviveOffers</code>åè°ƒç”¨<code class="language-plaintext highlighter-rouge">makeOffers()</code>ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>// Make fake resource offers on just one executor
def makeOffers(executorId: String) {
  launchTasks(scheduler.resourceOffers(
    Seq(new WorkerOffer(executorId, executorHost(executorId), freeCores(executorId)))))
}

// Launch tasks returned by a set of resource offers
def launchTasks(tasks: Seq[Seq[TaskDescription]]) {
  for (task &lt;- tasks.flatten) {
    freeCores(task.executorId) -= 1
    executorActor(task.executorId) ! LaunchTask(task)
  }
}
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">makeOffers()</code>ä¼šå‘<code class="language-plaintext highlighter-rouge">ClusterScheduler</code>ç”³è¯·èµ„æºï¼Œå¹¶å‘executoræäº¤<code class="language-plaintext highlighter-rouge">LauchTask</code>è¯·æ±‚ã€‚</p>

<p>æ¥ä¸‹æ¥<code class="language-plaintext highlighter-rouge">LaunchTask</code>ä¼šè¿›å…¥executoræ¨¡å—ï¼Œ<code class="language-plaintext highlighter-rouge">StandaloneExecutorBackend</code>åœ¨æ”¶åˆ°<code class="language-plaintext highlighter-rouge">LaunchTask</code>è¯·æ±‚åä¼šè°ƒç”¨<code class="language-plaintext highlighter-rouge">Executor</code>æ‰§è¡Œtask:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>override def receive = {
  case RegisteredExecutor(sparkProperties) =&gt;
    ...  
  case RegisterExecutorFailed(message) =&gt;
    ...
  case LaunchTask(taskDesc) =&gt;
    logInfo("Got assigned task " + taskDesc.taskId)
    executor.launchTask(this, taskDesc.taskId, taskDesc.serializedTask)

  case Terminated(_) | RemoteClientDisconnected(_, _) | RemoteClientShutdown(_, _) =&gt;
    ...
}

def launchTask(context: ExecutorBackend, taskId: Long, serializedTask: ByteBuffer) {
  threadPool.execute(new TaskRunner(context, taskId, serializedTask))
}
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Executor</code>å†…éƒ¨æ˜¯ä¸€ä¸ªçº¿ç¨‹æ± ï¼Œæ¯ä¸€ä¸ªæäº¤çš„taskéƒ½ä¼šåŒ…è£…ä¸º<code class="language-plaintext highlighter-rouge">TaskRunner</code>äº¤ç”±threadpoolæ‰§è¡Œï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>class TaskRunner(context: ExecutorBackend, taskId: Long, serializedTask: ByteBuffer)
  extends Runnable {

  override def run() {
    SparkEnv.set(env)
    Thread.currentThread.setContextClassLoader(urlClassLoader)
    val ser = SparkEnv.get.closureSerializer.newInstance()
    logInfo("Running task ID " + taskId)
    context.statusUpdate(taskId, TaskState.RUNNING, EMPTY_BYTE_BUFFER)
    try {
      SparkEnv.set(env)
      Accumulators.clear()
      val (taskFiles, taskJars, taskBytes) = Task.deserializeWithDependencies(serializedTask)
      updateDependencies(taskFiles, taskJars)
      val task = ser.deserialize[Task[Any]](taskBytes, Thread.currentThread.getContextClassLoader)
      logInfo("Its generation is " + task.generation)
      env.mapOutputTracker.updateGeneration(task.generation)
      val value = task.run(taskId.toInt)
      val accumUpdates = Accumulators.values
      val result = new TaskResult(value, accumUpdates)
      val serializedResult = ser.serialize(result)
      logInfo("Serialized size of result for " + taskId + " is " + serializedResult.limit)
      context.statusUpdate(taskId, TaskState.FINISHED, serializedResult)
      logInfo("Finished task ID " + taskId)
    } catch {
      case ffe: FetchFailedException =&gt; {
        val reason = ffe.toTaskEndReason
        context.statusUpdate(taskId, TaskState.FAILED, ser.serialize(reason))
      }

      case t: Throwable =&gt; {
        val reason = ExceptionFailure(t)
        context.statusUpdate(taskId, TaskState.FAILED, ser.serialize(reason))

        // TODO: Should we exit the whole executor here? On the one hand, the failed task may
        // have left some weird state around depending on when the exception was thrown, but on
        // the other hand, maybe we could detect that when future tasks fail and exit then.
        logError("Exception in task ID " + taskId, t)
        //System.exit(1)
      }
    }
  }
}
</code></pre></div></div>

<p>å…¶ä¸­<code class="language-plaintext highlighter-rouge">task.run()</code>åˆ™çœŸæ­£æ‰§è¡Œäº†taskä¸­çš„ä»»åŠ¡ï¼Œå¦‚å‰<strong>RDDçš„è®¡ç®—</strong>ç« èŠ‚æ‰€è¿°ã€‚è¿”å›å€¼è¢«åŒ…è£…æˆ<code class="language-plaintext highlighter-rouge">TaskResult</code>è¿”å›ã€‚</p>

<p>è‡³æ­¤taskåœ¨<code class="language-plaintext highlighter-rouge">ClusterScheduler</code>å†…è¿è¡Œçš„æµç¨‹æœ‰äº†ä¸€ä¸ªå¤§è‡´çš„ä»‹ç»ï¼Œå½“ç„¶è¿™é‡Œç•¥æ‰äº†è®¸å¤šå¼‚å¸¸å¤„ç†çš„åˆ†æ”¯ï¼Œä½†è¿™ä¸å½±å“æˆ‘ä»¬å¯¹ä¸»çº¿çš„äº†è§£ã€‚</p>

<h1 id="end">END</h1>

<p>è‡³æ­¤å¯¹Sparkçš„Scheduleræ¨¡å—çš„ä¸»çº¿åšäº†ä¸€ä¸ªé¡ºè—¤æ‘¸ç“œå¼çš„ä»‹ç»ï¼ŒScheduleræ¨¡å—ä½œä¸ºSparkæœ€æ ¸å¿ƒçš„æ¨¡å—ä¹‹ä¸€ï¼Œå……åˆ†ä½“ç°äº†Sparkä¸MapReduceçš„ä¸åŒä¹‹å¤„ï¼Œä½“ç°äº†Spark DAGæ€æƒ³çš„ç²¾å·§å’Œè®¾è®¡çš„ä¼˜é›…ã€‚</p>

<p>å½“ç„¶Sparkçš„ä»£ç ä»ç„¶åœ¨ç§¯æå¼€å‘ä¹‹ä¸­ï¼Œå½“å‰çš„æºç åˆ†æåœ¨è¿‡ä¸ä¹…åå¯èƒ½ä¼šå˜å¾—æ²¡æœ‰æ„ä¹‰ï¼Œä½†é‡è¦çš„æ˜¯ä½“ä¼šSparkåŒºåˆ«äºMapReduceçš„è®¾è®¡ç†å¿µï¼Œä»¥åŠDAGæ€æƒ³çš„åº”ç”¨ã€‚DAGä½œä¸ºå¯¹MapReduceæ¡†æ¶çš„æ”¹è¿›è¶Šæ¥è¶Šå—åˆ°å¤§æ•°æ®ç•Œçš„é‡è§†ï¼Œ<a href="http://hortonworks.com/"><strong>hortonworks</strong></a>ä¹Ÿæå‡ºäº†ç±»ä¼¼DAGçš„æ¡†æ¶<a href="http://hortonworks.com/blog/category/tez/">tez</a>ä½œä¸ºå¯¹MapReduceçš„æ”¹è¿›ã€‚</p>
:ET