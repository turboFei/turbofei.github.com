I"áA
<p>ç›®å½•</p>

<ul id="markdown-toc">
  <li><a href="#background" id="markdown-toc-background">Background</a></li>
  <li><a href="#spark-sqlæ¦‚è¿°" id="markdown-toc-spark-sqlæ¦‚è¿°">Spark Sqlæ¦‚è¿°##</a></li>
  <li><a href="#æºç è·Ÿè¸ª" id="markdown-toc-æºç è·Ÿè¸ª">æºç è·Ÿè¸ª</a>    <ul>
      <li><a href="#sql-è¯­å¥--unresolved-logicalplan" id="markdown-toc-sql-è¯­å¥--unresolved-logicalplan">sql è¯­å¥-&gt; Unresolved LogicalPlan###</a></li>
      <li><a href="#resolved-logicalplan" id="markdown-toc-resolved-logicalplan">Resolved LogicalPlan###</a></li>
      <li><a href="#optimizedlogicalplan" id="markdown-toc-optimizedlogicalplan">OptimizedLogicalPlan###</a></li>
      <li><a href="#physicalplan" id="markdown-toc-physicalplan">PhysicalPlan###</a></li>
      <li><a href="#å¯æ‰§è¡Œçš„ç‰©ç†è®¡åˆ’" id="markdown-toc-å¯æ‰§è¡Œçš„ç‰©ç†è®¡åˆ’">å¯æ‰§è¡Œçš„ç‰©ç†è®¡åˆ’###</a></li>
      <li><a href="#æ‰§è¡Œ" id="markdown-toc-æ‰§è¡Œ">æ‰§è¡Œ</a></li>
    </ul>
  </li>
</ul>
<h2 id="background">Background</h2>

<p>ä»æºç å±‚é¢è§£é‡Šä¸€ä¸ªsparkSqlè¯­å¥æ˜¯å¦‚ä½•æ‰§è¡Œçš„ï¼Œä»sqlåˆ°ä¸åº•å±‚RDDå¦‚ä½•å¯¹æ¥</p>

<h2 id="spark-sqlæ¦‚è¿°">Spark Sqlæ¦‚è¿°##</h2>

<p>spark sqlæ˜¯ apache sparkçš„å…¶ä¸­ä¸€ä¸ªæ¨¡å—ï¼Œä¸»è¦ç”¨äºè¿›è¡Œç»“æ„åŒ–æ•°æ®çš„å¤„ç†ã€‚spark sqlçš„åº•å±‚æ‰§è¡Œè¿˜æ˜¯è°ƒç”¨rddï¼Œåœ¨ä¹‹å‰çš„æ–‡ç« ä¸­æè¿‡rddçš„æ‰§è¡Œæµç¨‹ï¼Œå› æ­¤æœ¬æ–‡ä¸»è¦è®²è§£ä¸€ä¸‹ä»sqlåˆ°åº•å±‚rddçš„å¯¹æ¥ã€‚é€šè¿‡è§‚å¯Ÿspark sql æ¨¡å—çš„æºç ï¼Œæºç åˆ†ä¸ºå››ä¸ªéƒ¨åˆ†ï¼Œå¦‚ä¸‹å›¾ã€‚</p>

<div align="center">
<img src="/public/img/spark-sql/sql-model.png" title="sql-model" width="60%" />
</div>

<p>åœ¨å®˜æ–¹githubçš„sqlæ¨¡å—readmeæ–‡ä»¶æœ‰å¦‚ä¸‹æè¿°ã€‚</p>

<ul>
  <li>
    <p>Catalyst (sql/catalyst) - An implementation-agnostic framework for manipulating trees of relational operators and expressions.</p>
  </li>
  <li>
    <p>Execution (sql/core) - A query planner / execution engine for translating Catalystâ€™s logical query plans into Spark RDDs. This component also includes a new public interface, SQLContext, that allows users to execute SQL or LINQ statements against existing RDDs and Parquet files.</p>
  </li>
  <li>
    <p>Hive Support (sql/hive) - Includes an extension of SQLContext called HiveContext that allows users to write queries using a subset of HiveQL and access data from a Hive Metastore using Hive SerDes. There are also wrappers that allow users to run queries that include Hive UDFs, UDAFs, and UDTFs.</p>
  </li>
  <li>
    <p>HiveServer and CLI support (sql/hive-thriftserver) - Includes support for the SQL CLI (bin/spark-sql) and a HiveServer2 (for JDBC/ODBC) compatible server.</p>
  </li>
</ul>

<p>æœ¬æ–‡ä¸»è¦è®²è§£coreå’Œcatalystæ¨¡å—ã€‚é¦–å…ˆç»™ä¸€ä¸ªspark sqlè¯­å¥æ‰§è¡Œæµç¨‹ï¼Œæ¥æ–¹ä¾¿å¯¹åç»­å†…å®¹è¿›è¡Œæ•´ä½“æŠŠæ¡ã€‚</p>

<ol>
  <li>SQL è¯­å¥ç»è¿‡ SqlParser è§£ææˆ Unresolved LogicalPlan;</li>
  <li>ä½¿ç”¨ analyzer ç»“åˆæ•°æ®æ•°æ®å­—å…¸ (catalog) è¿›è¡Œç»‘å®š, ç”Ÿæˆ resolved LogicalPlan;</li>
  <li>ä½¿ç”¨ optimizer å¯¹ resolved LogicalPlan è¿›è¡Œä¼˜åŒ–, ç”Ÿæˆ optimized LogicalPlan;</li>
  <li>ä½¿ç”¨ SparkPlan å°† LogicalPlan è½¬æ¢æˆ PhysicalPlan;</li>
  <li>ä½¿ç”¨ prepareForExecution() å°† PhysicalPlan è½¬æ¢æˆå¯æ‰§è¡Œç‰©ç†è®¡åˆ’;</li>
  <li>ä½¿ç”¨ execute() æ‰§è¡Œå¯æ‰§è¡Œç‰©ç†è®¡åˆ’;</li>
  <li>ç”Ÿæˆ RDDã€‚</li>
</ol>

<h2 id="æºç è·Ÿè¸ª">æºç è·Ÿè¸ª</h2>

<p>é¦–å…ˆæ˜¯è¦åˆ›å»ºsparkSessionç„¶åå¯¼å…¥æ•°æ®ï¼Œæ­¤å¤„ä¸èµ˜è¿°ã€‚æˆ‘ä»¬ä»æ‰§è¡Œsqlè¯­å¥å¼€å§‹è·Ÿè¸ªã€‚</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val teenagersDF = spark.sql("SELECT SUM(v) FROM (SELECT score.id, 100+80+ score.math_score +score.english_score AS v FROM people JOIN score WHERE  people.id=score.id AND people.age &gt;100) tmp")
</code></pre></div></div>

<h3 id="sql-è¯­å¥--unresolved-logicalplan">sql è¯­å¥-&gt; Unresolved LogicalPlan###</h3>

<p>æ­¤éƒ¨åˆ†ä¸»è¦æ˜¯å¯¹sqlè¯­å¥è¿›è¡Œè§£æã€‚åˆ¤æ–­ä¸€æ¡sqlè¯­å¥æ˜¯å¦ç¬¦åˆè¦æ±‚ï¼Œå¹¶ä¸”è¿›è¡Œå„éƒ¨åˆ†çš„åˆ’åˆ†ï¼Œæ¯”å¦‚å“ªäº›æ˜¯æ“ä½œï¼Œå“ªäº›æ˜¯å¾—åˆ°çš„ç»“æœç­‰ç­‰ã€‚</p>

<p><img src="/public/img/spark-sql/parser.png" alt="" /></p>

<p>è¿™æ ·ä¸€å¥sql è°ƒç”¨ï¼Œè·Ÿè¿›å»ã€‚</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def sql(sqlText: String): DataFrame = {
  Dataset.ofRows(self, sessionState.sqlParser.parsePlan(sqlText))
}
</code></pre></div></div>

<p>æˆ‘ä»¬å¯ä»¥çœ‹åˆ°sqlè¯­å¥ä¼šè¿”å›ä¸€ä¸ª<code class="highlighter-rouge">dataFrame</code>ã€‚è€Œåœ¨sparkä¸­DataFrameçš„å®šä¹‰å°±æ˜¯<code class="highlighter-rouge">Dataset[Row]</code> .å€¼å¾—ä¸€æçš„æ˜¯ï¼Œåœ¨sparkæºç ä¸­ç”¨åˆ°äº†è®¸å¤š<code class="highlighter-rouge">lazy</code>å˜é‡ï¼Œè¿™äº›å˜é‡è™½ç„¶æ˜¯å£°æ˜åœ¨ç±»ä¸­ï¼Œä½†æ˜¯å¹¶ä¸æ˜¯åœ¨åˆ›å»ºå¯¹è±¡çš„æ—¶å€™å°±åˆå§‹åŒ–è¿™äº›å˜é‡ï¼Œè€Œæ˜¯åœ¨ç¬¬ä¸€æ¬¡è°ƒç”¨æ˜¯æ‰è¿›è¡Œåˆå§‹åŒ–ï¼Œå› æ­¤åœ¨è·Ÿè¸ªæºç æ—¶ä¸€å®šè¦æ³¨æ„è¿™äº›lazyå˜é‡çš„è°ƒç”¨ï¼Œå› ä¸ºå¾ˆå¤šlazyå˜é‡çš„åˆå§‹åŒ–éƒ½æ¶‰åŠåˆ°ä¸€ç³»åˆ—å‡½æ•°çš„è°ƒç”¨ã€‚å¦‚æœä¸æ³¨æ„ï¼Œä¼šå¤±å»å¯¹å¾ˆå¤šå‡½æ•°çš„è·Ÿè¸ªã€‚å…·ä½“lazyå˜é‡çš„ä»‹ç»ï¼Œ<a href="https://stackoverflow.com/questions/7484928/what-does-a-lazy-val-do">å¯ä»¥å‚è€ƒ</a>.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>lazy val sqlParser: ParserInterface = new SparkSqlParser(conf)
</code></pre></div></div>

<p>å¯ä»¥çœ‹åˆ°sqlParserå°±æ˜¯ä¸€ä¸ªlazyå˜é‡ï¼Œå®ƒä¼šåˆ›å»ºä¸€ä¸ªè§£æå™¨ã€‚ä¸Šè¿°çš„sqlå‡½æ•°åœ¨åˆ›å»ºè§£æå™¨ä¹‹åè°ƒç”¨parsePlanå‡½æ•°ï¼Œå¦‚ä¸‹ã€‚</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/** Creates LogicalPlan for a given SQL string. */
override def parsePlan(sqlText: String): LogicalPlan = parse(sqlText) { parser =&gt;
  astBuilder.visitSingleStatement(parser.singleStatement()) match {
    case plan: LogicalPlan =&gt; plan
    case _ =&gt;
      val position = Origin(None, None)
      throw new ParseException(Option(sqlText), "Unsupported SQL statement", position, position)
  }
}
</code></pre></div></div>

<p>è¿™ä¸ªå‡½æ•°æ˜¯ä½¿ç”¨äº†ScalaæŸ¯é‡ŒåŒ–ç‰¹æ€§ã€‚å…¶å®æ˜¯è°ƒç”¨çš„parseå‡½æ•°ã€‚</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  protected def parse[T](command: String)(toResult: SqlBaseParser =&gt; T): T = {
    logInfo(s"Parsing command: $command")
    val lexer = new SqlBaseLexer(new ANTLRNoCaseStringStream(command))
    lexer.removeErrorListeners()
    lexer.addErrorListener(ParseErrorListener)
    val tokenStream = new CommonTokenStream(lexer)
    val parser = new SqlBaseParser(tokenStream)
    parser.addParseListener(PostProcessor)
    parser.removeErrorListeners()
    parser.addErrorListener(ParseErrorListener)

    try {
      try {
        // first, try parsing with potentially faster SLL mode
        parser.getInterpreter.setPredictionMode(PredictionMode.SLL)
        toResult(parser)
      }
      catch {
     ...
      }
    }
    catch {
      ...
    }
  }
}
</code></pre></div></div>

<p>è€Œæ­¤å¤„çš„parseå‡½æ•°æ˜¯ä½¿ç”¨çš„Antlr(ä¸€ä¸ªå¼€æºè¯­æ³•åˆ†æå™¨)æ¥å¯¹sqlè¯­å¥è¿›è¡Œè§£æï¼Œlexeræ˜¯å…¶è¯æ³•åˆ†æå™¨ï¼Œç„¶åsparkä½¿ç”¨è‡ªèº«çš„sqlBaseParserå¯¹sqlè¯­å¥è¿›è¡Œè¯­æ³•åˆ†æï¼Œç»“åˆparseå’ŒparsePlanå‡½æ•°ï¼Œå¾—åˆ°äº†sqlè¯­å¥çš„<code class="highlighter-rouge">UnresolvedLogicalPlan</code>.</p>

<h3 id="resolved-logicalplan">Resolved LogicalPlan###</h3>

<p>æ­¤éƒ¨åˆ†æ˜¯å¯¹ä¹‹å‰å¾—åˆ°çš„é€»è¾‘è®¡åˆ’è¿›è¡Œåˆ†æï¼Œæ¯”å¦‚è¿™ä¸ªå­—æ®µåˆ°åº•åº”è¯¥æ˜¯ä»€ä¹ˆç±»å‹ï¼Œç­‰ç­‰ï¼Œä¸æ˜¯å¾ˆç†Ÿæ‚‰ç¼–è¯‘ã€‚</p>

<p><img src="/public/img/spark-sql/analysis.png" alt="" /></p>

<p>è¿›å…¥åˆ°Datasetç±»çš„ofRowså‡½æ•°ã€‚</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def ofRows(sparkSession: SparkSession, logicalPlan: LogicalPlan): DataFrame = {
  val qe = sparkSession.sessionState.executePlan(logicalPlan)
  qe.assertAnalyzed()
  new Dataset[Row](sparkSession, qe, RowEncoder(qe.analyzed.schema))
}
</code></pre></div></div>

<p>è¿™ä¸ªå‡½æ•°å¾ˆçŸ­ï¼Œè·Ÿè¸ªexecutePlanå‡½æ•°ï¼Œå¯ä»¥çœ‹åˆ°å®ƒæ˜¯åˆ›å»ºäº†ä¸€ä¸ªqueryExecutionå¯¹è±¡ã€‚</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def executePlan(plan: LogicalPlan): QueryExecution = new QueryExecution(sparkSession, plan)
</code></pre></div></div>

<p>è¿™ä¸ªå¯¹è±¡æ˜¯å¾ˆé‡è¦çš„ä¸€ä¸ªå¯¹è±¡,æ¶‰åŠåˆ°å‰é¢çš„<code class="highlighter-rouge">UnresolvedLogicalPlan</code>çš„åˆ†æã€ä¼˜åŒ–ã€è½¬ç‰©ç†è®¡åˆ’ä»¥åŠToRDDæ‰€æœ‰æ“ä½œã€‚</p>

<p>ofRowså‡½æ•°ç¬¬äºŒè¡Œæ˜¯å¯¹é€»è¾‘è®¡åˆ’è¿›è¡Œç¡®è®¤åˆ†æï¼Œé‡Œé¢æ¶‰åŠåˆ°åˆ†ææ“ä½œï¼Œåˆ†ææ˜¯å¯¹ä¹‹å‰é€»è¾‘è®¡åˆ’é‡Œé¢çš„å±æ€§è¿›è¡Œåˆ†æã€‚åˆ†æçš„æºç æˆ‘å°±ä¸è´´äº†ï¼Œåˆ†ææ˜¯ä½¿ç”¨ä¸€å¥—æ—¢å®šçš„è§„åˆ™ï¼Œç„¶åè¿›è¡Œå¤šæ¬¡è¿­ä»£ï¼ŒçŸ¥é“åˆ†æç»“æœè¾¾åˆ°ä¸€ä¸ªå›ºå®šç‚¹æˆ–è€…åˆ°è¾¾æœ€é«˜è¿­ä»£æ¬¡æ•°åœæ­¢ã€‚å¾—åˆ°<code class="highlighter-rouge">resolvedLogicalPlan</code>.</p>

<h3 id="optimizedlogicalplan">OptimizedLogicalPlan###</h3>

<p>æ­¤éƒ¨åˆ†ä¸»è¦æ˜¯å¯¹é€»è¾‘è®¡åˆ’è¿›è¡Œä¼˜åŒ–ï¼Œ ä¾‹å¦‚è°“è¯ä¸‹æ¨ç­‰ç­‰ã€‚</p>

<p><img src="/public/img/spark-sql/optimizer.png" alt="" /></p>

<p>ç„¶åç¬¬ä¸‰è¡Œï¼Œå°±æ˜¯ç”Ÿæˆä¸€ä¸ªDataset[Row]ï¼Œå‰é¢æåˆ°è¿‡ï¼Œå…¶å®è¿™å°±æ˜¯dataFrameã€‚</p>

<p>è·Ÿè¸ªè¿›å…¥Datasetçš„thiså‡½æ•°ã€‚é‡Œé¢æœ‰ä¸€ä¸ªå˜é‡ä¼šåœ¨åˆ›å»ºå¯¹è±¡æ—¶æ‰§è¡Œ</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@transient private[sql] val logicalPlan: LogicalPlan = {
  def hasSideEffects(plan: LogicalPlan): Boolean = plan match {
    case _: Command |
         _: InsertIntoTable =&gt; true
    case _ =&gt; false
  }

  queryExecution.analyzed match {
    // For various commands (like DDL) and queries with side effects, we force query execution
    // to happen right away to let these side effects take place eagerly.
    case p if hasSideEffects(p) =&gt;
      LogicalRDD(queryExecution.analyzed.output, queryExecution.toRdd)(sparkSession)
    case Union(children) if children.forall(hasSideEffects) =&gt;
      LogicalRDD(queryExecution.analyzed.output, queryExecution.toRdd)(sparkSession)
    case _ =&gt;
      queryExecution.analyzed
  }
}
</code></pre></div></div>

<p>çœ‹åˆ°é‡Œé¢æœ‰ä¸€è¡Œè°ƒç”¨äº†LogicalRDDå‡½æ•°ï¼Œç¬¬ä¸€ä¸ªå‚æ•°æ˜¯è¾“å‡ºä½ç½®ï¼Œç¬¬ä¸€ä¸ªå‚æ•°ï¼ŒqueryExecution.toRdd. ä¸€ç³»åˆ—çš„lazyå˜é‡ã€‚</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>lazy val toRdd: RDD[InternalRow] = executedPlan.execute()
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>lazy val executedPlan: SparkPlan = prepareForExecution(sparkPlan)
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>lazy val sparkPlan: SparkPlan = {
  SparkSession.setActiveSession(sparkSession)
  // TODO: We use next(), i.e. take the first plan returned by the planner, here for now,
  //       but we will implement to choose the best plan.
  planner.plan(ReturnAnswer(optimizedPlan)).next()
}
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>lazy val optimizedPlan: LogicalPlan = sparkSession.sessionState.optimizer.execute(withCachedData)
</code></pre></div></div>

<p>è¿™é‡Œè°ƒç”¨äº†ä¸€äº›åˆ—ï¼Œè°ƒç”¨åˆ°optimizedPlanï¼Œå…¶å®ä¹Ÿæ˜¯è¿›è¡Œè§„åˆ™ä¼˜åŒ–ï¼ŒåŸºäºä¸€ç³»åˆ—è§„åˆ™ï¼Œåˆ°ä¸åŠ¨ç‚¹æˆ–è€…æœ€å¤§è¿­ä»£æ¬¡æ•°é€€å‡ºä¼˜åŒ–ã€‚è¿™å°±å¾—åˆ°äº†<code class="highlighter-rouge">optimizedLogicalPlan</code>.</p>

<h3 id="physicalplan">PhysicalPlan###</h3>

<p>å›åˆ°å‰é¢çš„sparkPlanæ‡’å˜é‡ï¼Œæœ€åä¸€å¥ï¼Œplanner.planå¯¹ä¹‹å‰çš„ <code class="highlighter-rouge">optimizedLogicalPlan</code>è¿›è¡Œè½¬åŒ–ç”ŸæˆphsicalPlanã€‚æ­¤å¤„çš„nextæ˜¯æ“ä½œæ˜¯è·å¾—è¿”å›çš„physicalPlanè¿­ä»£å™¨ä¸­çš„ç¬¬ä¸€ä¸ªphysicalPlanã€‚</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>lazy val sparkPlan: SparkPlan = {
  SparkSession.setActiveSession(sparkSession)
  // TODO: We use next(), i.e. take the first plan returned by the planner, here for now,
  //       but we will implement to choose the best plan.
  planner.plan(ReturnAnswer(optimizedPlan)).next()
}
</code></pre></div></div>

<p>è¿™é‡Œçš„plannerä¸ºSparkPlannerï¼Œç±»ä¸­æœ‰ä¸€ç³»åˆ—çš„ç­–ç•¥ï¼Œè¿˜å¯ä»¥ä»å¤–éƒ¨åŠ ç­–ç•¥ã€‚</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def strategies: Seq[Strategy] =
    extraStrategies ++ (
    FileSourceStrategy ::
    DataSourceStrategy ::
    DDLStrategy ::
    SpecialLimits ::
    Aggregation ::
    JoinSelection ::
    InMemoryScans ::
    BasicOperators :: Nil)
</code></pre></div></div>
<p>ç„¶åè¿›è¡Œè½¬åŒ–çš„å‡½æ•°å¦‚ä¸‹ã€‚</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def plan(plan: LogicalPlan): Iterator[PhysicalPlan] = {
  // Obviously a lot to do here still...

  // Collect physical plan candidates.
  val candidates = strategies.iterator.flatMap(_(plan))

  // The candidates may contain placeholders marked as [[planLater]],
  // so try to replace them by their child plans.
  val plans = candidates.flatMap { candidate =&gt;
    val placeholders = collectPlaceholders(candidate)

    if (placeholders.isEmpty) {
      // Take the candidate as is because it does not contain placeholders.
      Iterator(candidate)
    } else {
      // Plan the logical plan marked as [[planLater]] and replace the placeholders.
      placeholders.iterator.foldLeft(Iterator(candidate)) {
        case (candidatesWithPlaceholders, (placeholder, logicalPlan)) =&gt;
          // Plan the logical plan for the placeholder.
          val childPlans = this.plan(logicalPlan)

          candidatesWithPlaceholders.flatMap { candidateWithPlaceholders =&gt;
            childPlans.map { childPlan =&gt;
              // Replace the placeholder by the child plan
              candidateWithPlaceholders.transformUp {
                case p if p == placeholder =&gt; childPlan
              }
            }
          }
      }
    }
  }

  val pruned = prunePlans(plans)
  assert(pruned.hasNext, s"No plan for $plan")
  pruned
}
</code></pre></div></div>

<p>æ²¡çœ‹æ˜ç™½ï¼ŒçŸ¥è¯†æ¬ ç¼ºã€‚å¤§æ¦‚å°±æ˜¯å¾—åˆ°ä¸€ç³»åˆ—physicalPlanï¼Œç„¶åè¿›è¡Œå‰ªæï¼Œç­›é™¤æ‰æ€§èƒ½ä¸å¥½çš„ï¼Œè¿™å°±å¾—åˆ°äº†<code class="highlighter-rouge">physicalPlan</code>è¿­ä»£å™¨ï¼Œç„¶åé€šè¿‡å‰é¢è¯´çš„nextå‡½æ•°ï¼Œå¾—åˆ°è¿­ä»£å™¨å¤´éƒ¨çš„<code class="highlighter-rouge">physicalPlan</code>ï¼Œåº”è¯¥æ˜¯æœ€å¥½çš„é‚£ä¸ªã€‚</p>

<h3 id="å¯æ‰§è¡Œçš„ç‰©ç†è®¡åˆ’">å¯æ‰§è¡Œçš„ç‰©ç†è®¡åˆ’###</h3>

<p>åœ¨å¾—åˆ°ç‰©ç†è®¡åˆ’sparkPlanä¹‹åä¼šæ‰§è¡Œä¸‹é¢çš„å‡½æ•°ï¼ŒprepareForExecution(sparkPlan)ï¼Œå¾—åˆ°å¯æ‰§è¡Œçš„ç‰©ç†è®¡åˆ’ã€‚</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>lazy val executedPlan: SparkPlan = prepareForExecution(sparkPlan)
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/**
 * Prepares a planned [[SparkPlan]] for execution by inserting shuffle operations and internal
 * row format conversions as needed.
 */
protected def prepareForExecution(plan: SparkPlan): SparkPlan = {
  preparations.foldLeft(plan) { case (sp, rule) =&gt; rule.apply(sp) }
}

/** A sequence of rules that will be applied in order to the physical plan before execution. */
protected def preparations: Seq[Rule[SparkPlan]] = Seq(
  python.ExtractPythonUDFs,
  PlanSubqueries(sparkSession),
  EnsureRequirements(sparkSession.sessionState.conf),
  CollapseCodegenStages(sparkSession.sessionState.conf),
  ReuseExchange(sparkSession.sessionState.conf),
  ReuseSubquery(sparkSession.sessionState.conf))
</code></pre></div></div>

<p>çœ‹æ³¨é‡Šä»¥åŠæºç ï¼Œç†è§£ï¼Œå°±æ˜¯åˆæ˜¯ä¸€äº›è§„åˆ™ï¼Œç„¶åå¯¹é€»è¾‘è®¡åˆ’ä¸æ–­ä½¿ç”¨è¿™äº›è§„åˆ™è¿›è¡Œå®Œå–„ï¼Œå°±æ˜¯æŠŠè§„åˆ™æŒ‰é¡ºåºè¿ç”¨ä¸€éï¼Œ<a href="https://blog.csdn.net/oopsoom/article/details/23447317">scalaçš„ foldleftç”¨æ³•å‚è€ƒè¿™é‡Œ</a>,ä¸å¾—ä¸è¯´scalaè¯­æ³•çœŸå¤šã€‚</p>

<h3 id="æ‰§è¡Œ">æ‰§è¡Œ</h3>

<p>å¯ä»¥çœ‹åˆ°åœ¨è·å¾—è·å¾—å¯æ‰§è¡Œè®¡åˆ’ä¹‹åå°±æ˜¯æ‰§è¡Œï¼Œ</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>lazy val toRdd: RDD[InternalRow] = executedPlan.execute()
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>final def execute(): RDD[InternalRow] = executeQuery {
  doExecute()
}
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>//class sparkPlan
protected def doExecute(): RDD[InternalRow]
</code></pre></div></div>

<p>è¿™ä¸ªå‡½æ•°å¯¹åº”å¾ˆå¤šå­ç±»ï¼Œæ¯ä¸ªå­ç±»çš„ç¬¬ä¸€å¥åŸºæœ¬éƒ½æ˜¯<code class="highlighter-rouge">child.execute()</code>,å¯è§è¿™æ˜¯åœ¨æ„å»ºlineageã€‚ä¹Ÿå°±æ˜¯ä¸€æ¡é“¾ï¼ŒæŠŠæ‰€æœ‰å¯æ‰§è¡Œè®¡åˆ’ä¸²è”èµ·æ¥ã€‚</p>

<p>è¿™é‡Œçš„doExecuteè¿”å›çš„æ˜¯ä¸€ä¸ªä¸­é—´ç±»å‹çš„RDDã€‚</p>

:ET