I"è
<h3 id="background">Background</h3>
<p>sparkç»Ÿä¸€å†…å­˜ç®¡ç†æ˜¯spark1.6.0çš„æ–°ç‰¹æ€§ï¼Œæ˜¯å¯¹shuffle memory å’Œ storage memory è¿›è¡Œç»Ÿä¸€çš„ç®¡ç†ï¼Œæ‰“ç ´äº†ä»¥å¾€çš„å‚æ•°é™åˆ¶ã€‚</p>

<h2 id="éç»Ÿä¸€å†…å­˜ç®¡ç†">éç»Ÿä¸€å†…å­˜ç®¡ç†</h2>

<p>sparkåœ¨1.6 ä¹‹å‰éƒ½æ˜¯éç»Ÿä¸€å†…å­˜ç®¡ç†ï¼Œé€šè¿‡è®¾ç½®<code class="language-plaintext highlighter-rouge">spark.shuffle.memoryFraction</code> å’Œ <code class="language-plaintext highlighter-rouge">spark.storage.memoryFraction</code>æ¥è®¾ç½®shuffle å’Œstorageçš„memory å¤§å°ã€‚çœ‹ä¸‹<code class="language-plaintext highlighter-rouge">StaticMemoryManager</code>çš„è·å¾—æœ€å¤§shuffleå’Œstorage memoryçš„å‡½æ•°ã€‚</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>private def getMaxStorageMemory(conf: SparkConf): Long = {
  val systemMaxMemory = conf.getLong("spark.testing.memory", Runtime.getRuntime.maxMemory)
  val memoryFraction = conf.getDouble("spark.storage.memoryFraction", 0.6)
  val safetyFraction = conf.getDouble("spark.storage.safetyFraction", 0.9)
  (systemMaxMemory * memoryFraction * safetyFraction).toLong
}

/**
 * Return the total amount of memory available for the execution region, in bytes.
 */
private def getMaxExecutionMemory(conf: SparkConf): Long = {
  val systemMaxMemory = conf.getLong("spark.testing.memory", Runtime.getRuntime.maxMemory)
...
  val memoryFraction = conf.getDouble("spark.shuffle.memoryFraction", 0.2)
  val safetyFraction = conf.getDouble("spark.shuffle.safetyFraction", 0.8)
  (systemMaxMemory * memoryFraction * safetyFraction).toLong
}
</code></pre></div></div>
<p>å¯ä»¥çœ‹å‡ºï¼Œ<code class="language-plaintext highlighter-rouge">systemMaxMemory</code>æ˜¯é€šè¿‡å‚æ•°<code class="language-plaintext highlighter-rouge">spark.testing.memory</code>æ¥è·å¾—ï¼Œå¦‚æœè¿™ä¸ªå‚æ•°æ²¡æœ‰è®¾ç½®ï¼Œå°±å–è™šæ‹Ÿæœºå†…å­˜ï¼Œç„¶åshuffle å’Œ storageéƒ½æœ‰å®‰å…¨ç³»æ•°ï¼Œæœ€åå¯ç”¨çš„æœ€å¤§å†…å­˜éƒ½æ˜¯ï¼šç³»ç»Ÿæœ€å¤§å†…å­˜*æ¯”ä¾‹ç³»æ•°*å®‰å…¨ç³»æ•°ã€‚</p>

<h2 id="ç»Ÿä¸€å†…å­˜ç®¡ç†">ç»Ÿä¸€å†…å­˜ç®¡ç†</h2>

<p>spark 1.6.0 å‡ºç°äº†ç»Ÿä¸€å†…å­˜ç®¡ç†ï¼Œæ˜¯æ‰“ç ´äº†shuffle å†…å­˜å’Œstorageå†…å­˜çš„é™æ€é™åˆ¶ã€‚é€šä¿—çš„æè¿°ï¼Œå°±æ˜¯å¦‚æœstorageå†…å­˜ä¸å¤Ÿï¼Œè€Œshuffleå†…å­˜å‰©ä½™å°±èƒ½å€Ÿå†…å­˜ï¼Œå¦‚æœshuffleå†…å­˜ä¸è¶³ï¼Œæ­¤æ—¶å¦‚æœstorageå·²ç»è¶…å‡ºäº†<code class="language-plaintext highlighter-rouge">storageRegionSize</code>ï¼Œé‚£ä¹ˆå°±é©±é€å½“å‰ä½¿ç”¨storageå†…å­˜-<code class="language-plaintext highlighter-rouge">storageRegionSize</code>ï¼Œå¦‚æœstorage ä½¿ç”¨æ²¡æœ‰è¶…è¿‡<code class="language-plaintext highlighter-rouge">storageRegionSize</code>ï¼Œé‚£ä¹ˆåˆ™æŠŠå®ƒå‰©ä½™çš„éƒ½å¯ä»¥å€Ÿç»™shuffleä½¿ç”¨ã€‚</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  private def getMaxMemory(conf: SparkConf): Long = {
    val systemMemory = conf.getLong("spark.testing.memory", Runtime.getRuntime.maxMemory)
    val reservedMemory = conf.getLong("spark.testing.reservedMemory",
      if (conf.contains("spark.testing")) 0 else RESERVED_SYSTEM_MEMORY_BYTES)
    val minSystemMemory = (reservedMemory * 1.5).ceil.toLong
    if (systemMemory &lt; minSystemMemory) {
      throw new IllegalArgumentException(s"System memory $systemMemory must " +
        s"be at least $minSystemMemory. Please increase heap size using the --driver-memory " +
        s"option or spark.driver.memory in Spark configuration.")
    }
    // SPARK-12759 Check executor memory to fail fast if memory is insufficient
    if (conf.contains("spark.executor.memory")) {
      val executorMemory = conf.getSizeAsBytes("spark.executor.memory")
      if (executorMemory &lt; minSystemMemory) {
        throw new IllegalArgumentException(s"Executor memory $executorMemory must be at least " +
          s"$minSystemMemory. Please increase executor memory using the " +
          s"--executor-memory option or spark.executor.memory in Spark configuration.")
      }
    }
    val usableMemory = systemMemory - reservedMemory
    val memoryFraction = conf.getDouble("spark.memory.fraction", 0.6)
    (usableMemory * memoryFraction).toLong
  }
</code></pre></div></div>
<p>è¿™ä¸ªæ˜¯ç»Ÿä¸€å†…å­˜ç®¡ç†çš„è·å¾—æœ€å¤§å†…å­˜çš„å‡½æ•°ï¼Œå› ä¸ºshuffleå’Œstorageæ˜¯ç»Ÿä¸€ç®¡ç†çš„ï¼Œæ‰€ä»¥åªæœ‰ä¸€ä¸ªè·å¾—ç»Ÿä¸€æœ€å¤§å†…å­˜çš„å‡½æ•°ã€‚<code class="language-plaintext highlighter-rouge">usableMemory = systemMemory - reservedMemory</code>.</p>

<p>æœ€å¤§å†…å­˜=<code class="language-plaintext highlighter-rouge">usableMemory * memoryFraction</code>.</p>

<h2 id="ç»Ÿä¸€å†…å­˜ç®¡ç†çš„ä½¿ç”¨">ç»Ÿä¸€å†…å­˜ç®¡ç†çš„ä½¿ç”¨##</h2>

<p><code class="language-plaintext highlighter-rouge">UnifiedMemoryManager</code>æ˜¯åœ¨ä¸€ä¸ªé™æ€ç±»é‡Œé¢çš„<code class="language-plaintext highlighter-rouge">apply</code>æ–¹æ³•è°ƒç”¨çš„ã€‚</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def apply(conf: SparkConf, numCores: Int): UnifiedMemoryManager = {
  val maxMemory = getMaxMemory(conf)
  new UnifiedMemoryManager(
    conf,
    maxHeapMemory = maxMemory,
    onHeapStorageRegionSize =
      (maxMemory * conf.getDouble("spark.memory.storageFraction", 0.5)).toLong,
    numCores = numCores)
}
</code></pre></div></div>

<p>ç„¶åé€šè¿‡ find Uages æ‰¾åˆ°æ˜¯åœ¨ <code class="language-plaintext highlighter-rouge">sparkEnv</code>é‡Œé¢è°ƒç”¨ã€‚</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val memoryManager: MemoryManager =
  if (useLegacyMemoryManager) {
    new StaticMemoryManager(conf, numUsableCores)
  } else {
    UnifiedMemoryManager(conf, numUsableCores)
  }
</code></pre></div></div>

<p>æ˜¯é€šè¿‡åˆ¤æ–­å‚æ•°ï¼Œåˆ¤æ–­æ˜¯ä½¿ç”¨ç»Ÿä¸€å†…å­˜ç®¡ç†è¿˜æ˜¯éå†…å­˜ç®¡ç†ã€‚</p>

<p>ç„¶åé€šè¿‡æŸ¥çœ‹usages å‘ç°æ˜¯åœ¨ <code class="language-plaintext highlighter-rouge">CoarseGrainedExecutorBackEnd</code> å’Œ <code class="language-plaintext highlighter-rouge">MesosExecutorBackEnd</code>é‡Œé¢è°ƒç”¨çš„ï¼Œæ‰€ä»¥æ˜¯æ¯ä¸ªexecutoréƒ½æœ‰ä¸€ä¸ªç»Ÿä¸€å†…å­˜ç®¡ç†çš„å®ä¾‹(â€¦å¾ˆæ˜¾ç„¶ï¼Œé€»è¾‘ä¹Ÿæ˜¯è¿™æ ·)ã€‚</p>
:ET