I"ç<p>æœ¬æ–‡è½¬è‡ªjerryshao blog(https://github.com/jerryshao/jerryshao.github.com)</p>

<p><strong>Overview</strong></p>

<p>æœ¬æ–‡ç« ä¸»è¦å¯¹Spark,Sparkçš„åŸºæœ¬æ¶æ„å’Œé‡è¦æ¨¡å—ä½œåŸºæœ¬ä»‹ç»ï¼Œæ–‡ç« ä¸ä¼šæ¶‰åŠSparkçš„å®‰è£…éƒ¨ç½²ä»¥åŠä½¿ç”¨ï¼Œå¯¹æ­¤å¯ä»¥å‚è€ƒ<a href="http://spark-project.org/documentation/">Sparkå®˜æ–¹æ–‡æ¡£</a>ã€‚</p>

<h1 id="what-is-spark">What is Spark</h1>

<p><a href="http://spark-project.org"><strong>Spark</strong></a>æ˜¯UC Berkeley AMP labæ‰€å¼€æºçš„ç±»Hadoop MapReduce
æ¡†æ¶ï¼Œéƒ½æ˜¯åŸºäºmap reduceç®—æ³•æ‰€å®ç°çš„åˆ†å¸ƒå¼è®¡ç®—æ¡†æ¶ï¼Œæ‹¥æœ‰Hadoop MapReduceæ‰€å…·æœ‰çš„
ä¼˜ç‚¹ï¼›ä¸åŒäºMapReduceçš„æ˜¯Jobä¸­é—´è¾“å‡ºå’Œç»“æœå¯ä»¥ä¿å­˜åœ¨å†…å­˜ä¸­ï¼Œè€Œä¸éœ€è¦è¯»å†™HDFSï¼Œå› 
æ­¤Sparkèƒ½æ›´å¥½åœ°é€‚ç”¨äºmachine learningç­‰éœ€è¦è¿­ä»£çš„map reduceç®—æ³•ã€‚</p>

<blockquote>
  <p>Spark is an open source cluster computing system that aims to make data
analytics fast â€” both fast to run and fast to write.</p>

  <p>To run programs faster, Spark provides primitives for in-memory cluster
computing: your job can load data into memory and query it repeatedly much
quicker than with disk-based systems like Hadoop MapReduce.</p>

  <p>To make programming faster, Spark provides clean, concise APIs in Scala, Java
and Python. You can also use Spark interactively from the Scala and Python
shells to rapidly query big datasets.</p>
</blockquote>

<h1 id="spark-architecture">Spark Architecture</h1>

<p>æ´å¼•<a href="http://weibo.com/jerrylead">@JerryLead</a>çš„ç³»ç»Ÿæ¶æ„å›¾ä½œä¸ºSparkæ•´ä½“ç»“æ„çš„ä¸€ä¸ª
birdviewï¼š</p>

<p><img src="/img/2013-03-29-spark-overview/architecture-birdview.jpg" alt="Spark birdview" width="640" /></p>

<p>æ•´ä½“ä¸ŠSparkåˆ†ä¸ºä»¥ä¸‹å‡ ä¸ªä¸»è¦çš„å­æ¨¡å—:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">deploy</code>: <code class="language-plaintext highlighter-rouge">deply</code>æ¨¡å—åŒ…æ‹¬<code class="language-plaintext highlighter-rouge">Master</code>ï¼Œ<code class="language-plaintext highlighter-rouge">Work</code>å’Œ<code class="language-plaintext highlighter-rouge">Client</code>ï¼Œå‚è§architectureå›¾çš„æœ€ä¸Š
éƒ¨åˆ†ã€‚<code class="language-plaintext highlighter-rouge">deploy</code>ä¸»è¦è´Ÿè´£å¯åŠ¨å’Œè°ƒåº¦ç”¨æˆ·å®ç°çš„Spark applicationå¹¶ä¸”åˆ†é…èµ„æºç»™ç”¨æˆ·
applicationï¼Œç±»ä¼¼äºHadoop YARNæ¡†æ¶ã€‚</li>
  <li><code class="language-plaintext highlighter-rouge">scheduler</code>: <code class="language-plaintext highlighter-rouge">scheduler</code>ä¸»è¦è´Ÿè´£è°ƒåº¦ç”¨æˆ·applicationå†…çš„tasksï¼Œæ ¹æ®éƒ¨ç½²æ–¹å¼çš„ä¸
åŒSparkå®ç°äº†å¤šç§ä¸åŒçš„<code class="language-plaintext highlighter-rouge">scheduler</code>ï¼ŒåŒ…æ‹¬<code class="language-plaintext highlighter-rouge">LocalScheduler</code>ï¼Œ<code class="language-plaintext highlighter-rouge">ClusterScheduler</code>ç­‰
ã€‚</li>
  <li><code class="language-plaintext highlighter-rouge">rdd</code>: <code class="language-plaintext highlighter-rouge">rdd</code>ç±»ä¼¼äºä¸€ä¸ªåˆ†å¸ƒå¼çš„æ•°æ®é›†ï¼Œç”¨æˆ·å¯ä»¥æ ¹æ®<code class="language-plaintext highlighter-rouge">rdd</code>æ‰€æä¾›çš„apiè¿›è¡Œæ•°æ®é›†çš„
æ“ä½œï¼Œ<code class="language-plaintext highlighter-rouge">rdd</code>æ¨¡å—æ˜¯ç”¨æˆ·äº¤äº’çš„ä¸»è¦æ¨¡å—ã€‚</li>
  <li><code class="language-plaintext highlighter-rouge">storage</code>: <code class="language-plaintext highlighter-rouge">storage</code>æ¨¡å—ä¸»è¦è´Ÿè´£æ•°æ®é›†ï¼Œä¹Ÿå°±æ˜¯<code class="language-plaintext highlighter-rouge">rdd</code>çš„å­˜å–ã€‚æ ¹æ®è®¾å®šçš„ä¸åŒï¼Œæ•°
æ®å¯ä»¥ä¿å­˜åœ¨å†…å­˜ã€ç£ç›˜æˆ–æ˜¯ä¸¤è€…ã€‚Sparkä¸Hadoop MapReduceæœ€å¤§çš„ä¸åŒåœ¨äºMapReduce
å°†æ•°æ®ä¿å­˜åœ¨HDFSä¸Šï¼Œè€ŒSparkåˆ™ç”±è‡ªå·±çš„å­˜å‚¨ç³»ç»Ÿã€‚</li>
</ul>

<p>å½“ç„¶è¿˜æœ‰ä¸€äº›å…¶ä»–çš„å­æ¨¡å—ï¼Œå¯ä»¥å‚è€ƒä¸Šå›¾ã€‚</p>

<p>Sparké‡‡ç”¨äº†Actorçš„è®¾è®¡æ–¹å¼ï¼Œæ•´ä½“æ¶æ„ï¼ŒåŒ…æ‹¬å„å­æ¨¡å—çš„è®¾è®¡ä¸Šéƒ½æ˜¯é‡‡ç”¨master-slaveæ¨¡
å¼ï¼Œmasterå’Œslaveä¹‹é—´é€šä¿¡çš„ä¸»è¦åè®®å¯ä»¥å‚è§ä¸Šå›¾ã€‚</p>

<h1 id="end">End</h1>
<p>ä»¥ä¸Šå¤§è‡´åœ°ä»‹ç»äº†Sparkçš„architectureï¼Œä¹‹åä¼šé™†ç»­å¯¹å„å­æ¨¡å—ä½œè¯¦ç»†çš„ä»‹ç»</p>
:ET