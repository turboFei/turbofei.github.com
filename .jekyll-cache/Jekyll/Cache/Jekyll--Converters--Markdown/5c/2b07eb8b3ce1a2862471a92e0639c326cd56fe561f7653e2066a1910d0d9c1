I"¿F<p>æœ¬æ–‡è½¬è‡ª<a href="https://github.com/jerryshao/jerryshao.github.com">Jerryshao Blog</a></p>

<h3 id="background">Background</h3>

<p>åœ¨å‰æ–‡<a href="http://jerryshao.me/Architecture/2013/04/21/Spark%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B-scheduler%E6%A8%A1%E5%9D%97/">Sparkæºç åˆ†æä¹‹-scheduleræ¨¡å—</a>ä¸­æåˆ°äº†Sparkåœ¨èµ„æºç®¡ç†å’Œè°ƒåº¦ä¸Šé‡‡ç”¨äº†Hadoop <a href="http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html"><strong>YARN</strong></a>çš„æ–¹å¼ï¼šå¤–å±‚çš„èµ„æºç®¡ç†å™¨å’Œåº”ç”¨å†…çš„ä»»åŠ¡è°ƒåº¦å™¨ï¼›å¹¶ä¸”åˆ†æäº†Sparkåº”ç”¨å†…çš„ä»»åŠ¡è°ƒåº¦æ¨¡å—ã€‚æœ¬æ–‡å°±Sparkçš„å¤–å±‚èµ„æºç®¡ç†å™¨-deployæ¨¡å—è¿›è¡Œåˆ†æï¼Œæ¢ç©¶Sparkæ˜¯å¦‚ä½•åè°ƒåº”ç”¨ä¹‹é—´çš„èµ„æºè°ƒåº¦å’Œç®¡ç†çš„</p>

<p>Sparkæœ€åˆæ˜¯äº¤ç”±<a href="http://incubator.apache.org/mesos/"><strong>Mesos</strong></a>è¿›è¡Œèµ„æºç®¡ç†ï¼Œä¸ºäº†ä½¿å¾—æ›´å¤šçš„ç”¨æˆ·ï¼ŒåŒ…æ‹¬æ²¡æœ‰æ¥è§¦è¿‡Mesosçš„ç”¨æˆ·ä½¿ç”¨Sparkï¼ŒSparkçš„å¼€å‘è€…æ·»åŠ äº†Standaloneçš„éƒ¨ç½²æ–¹å¼ï¼Œä¹Ÿå°±æ˜¯deployæ¨¡å—ã€‚å› æ­¤deployæ¨¡å—åªé’ˆå¯¹ä¸ä½¿ç”¨Mesosè¿›è¡Œèµ„æºç®¡ç†çš„éƒ¨ç½²æ–¹å¼ã€‚</p>

<h1 id="deployæ¨¡å—æ•´ä½“æ¶æ„">Deployæ¨¡å—æ•´ä½“æ¶æ„</h1>

<p><strong>deploy</strong>æ¨¡å—ä¸»è¦åŒ…å«3ä¸ªå­æ¨¡å—ï¼š<strong>master</strong>, <strong>worker</strong>, <strong>client</strong>ã€‚ä»–ä»¬ç»§æ‰¿äº<code class="language-plaintext highlighter-rouge">Actor</code>ï¼Œé€šè¿‡actorå®ç°äº’ç›¸ä¹‹é—´çš„é€šä¿¡ã€‚</p>

<ul>
  <li><strong>Master</strong>ï¼šmasterçš„ä¸»è¦åŠŸèƒ½æ˜¯æ¥æ”¶workerçš„æ³¨å†Œå¹¶ç®¡ç†æ‰€æœ‰çš„workerï¼Œæ¥æ”¶clientæäº¤çš„applicationï¼Œ(FIFO)è°ƒåº¦ç­‰å¾…çš„applicationå¹¶å‘workeræäº¤ã€‚</li>
  <li><strong>Worker</strong>ï¼šworkerçš„ä¸»è¦åŠŸèƒ½æ˜¯å‘masteræ³¨å†Œè‡ªå·±ï¼Œæ ¹æ®masterå‘é€çš„applicationé…ç½®è¿›ç¨‹ç¯å¢ƒï¼Œå¹¶å¯åŠ¨<code class="language-plaintext highlighter-rouge">StandaloneExecutorBackend</code>ã€‚</li>
  <li><strong>Client</strong>ï¼šclientçš„ä¸»è¦åŠŸèƒ½æ˜¯å‘masteræ³¨å†Œå¹¶ç›‘æ§applicationã€‚å½“ç”¨æˆ·åˆ›å»º<code class="language-plaintext highlighter-rouge">SparkContext</code>æ—¶ä¼šå®ä¾‹åŒ–<code class="language-plaintext highlighter-rouge">SparkDeploySchedulerBackend</code>ï¼Œè€Œå®ä¾‹åŒ–<code class="language-plaintext highlighter-rouge">SparkDeploySchedulerBackend</code>çš„åŒæ—¶å°±ä¼šå¯åŠ¨clientï¼Œé€šè¿‡å‘clientä¼ é€’å¯åŠ¨å‚æ•°å’Œapplicationæœ‰å…³ä¿¡æ¯ï¼Œclientå‘masterå‘é€è¯·æ±‚æ³¨å†Œapplicationå¹¶ä¸”åœ¨slave nodeä¸Šå¯åŠ¨<code class="language-plaintext highlighter-rouge">StandaloneExecutorBackend</code>ã€‚</li>
</ul>

<p>ä¸‹é¢æ¥çœ‹ä¸€ä¸‹deployæ¨¡å—çš„ç±»å›¾ï¼š</p>

<p><img src="/img/2013-04-30-deploy/deploy_uml.png" alt="Deploy moduler class chart" width="640" /></p>

<h1 id="deployæ¨¡å—é€šä¿¡æ¶ˆæ¯">Deployæ¨¡å—é€šä¿¡æ¶ˆæ¯</h1>

<p>Deployæ¨¡å—å¹¶ä¸å¤æ‚ï¼Œä»£ç ä¹Ÿä¸å¤šï¼Œä¸»è¦é›†ä¸­åœ¨å„ä¸ªå­æ¨¡å—ä¹‹é—´çš„æ¶ˆæ¯ä¼ é€’å’Œå¤„ç†ä¸Šï¼Œå› æ­¤åœ¨è¿™é‡Œåˆ—å‡ºäº†å„ä¸ªæ¨¡å—ä¹‹é—´ä¼ é€’çš„ä¸»è¦æ¶ˆæ¯ï¼š</p>

<ul>
  <li>
    <p><strong>client</strong> to <strong>master</strong></p>

    <ol>
      <li><code class="language-plaintext highlighter-rouge">RegisterApplication</code> (å‘masteræ³¨å†Œapplication)</li>
    </ol>
  </li>
  <li>
    <p><strong>master</strong> to <strong>client</strong></p>

    <ol>
      <li><code class="language-plaintext highlighter-rouge">RegisteredApplication</code> (ä½œä¸ºæ³¨å†Œapplicationçš„replyï¼Œå›å¤ç»™client)</li>
      <li><code class="language-plaintext highlighter-rouge">ExecutorAdded</code> (é€šçŸ¥client workerå·²ç»å¯åŠ¨äº†Executorç¯å¢ƒï¼Œå½“å‘workerå‘é€<code class="language-plaintext highlighter-rouge">LaunchExecutor</code>åé€šçŸ¥client)</li>
      <li><code class="language-plaintext highlighter-rouge">ExecutorUpdated</code> (é€šçŸ¥client ExecutorçŠ¶æ€å·²ç»å‘ç”Ÿå˜åŒ–äº†ï¼ŒåŒ…æ‹¬ç»“æŸã€å¼‚å¸¸é€€å‡ºç­‰ï¼Œå½“workerå‘masterå‘é€<code class="language-plaintext highlighter-rouge">ExecutorStateChanged</code>åé€šçŸ¥client)</li>
    </ol>
  </li>
  <li>
    <p><strong>master</strong> to <strong>worker</strong></p>

    <ol>
      <li><code class="language-plaintext highlighter-rouge">LaunchExecutor</code> (å‘é€æ¶ˆæ¯å¯åŠ¨Executorç¯å¢ƒ)</li>
      <li><code class="language-plaintext highlighter-rouge">RegisteredWorker</code> (ä½œä¸ºworkerå‘masteræ³¨å†Œçš„reply)</li>
      <li><code class="language-plaintext highlighter-rouge">RegisterWorkerFailed</code> (ä½œä¸ºworkerå‘masteræ³¨å†Œå¤±è´¥çš„reply)</li>
      <li><code class="language-plaintext highlighter-rouge">KillExecutor</code> (å‘é€ç»™workerè¯·æ±‚åœæ­¢executorç¯å¢ƒ)</li>
    </ol>
  </li>
  <li>
    <p><strong>worker</strong> to <strong>master</strong></p>

    <ol>
      <li><code class="language-plaintext highlighter-rouge">RegisterWorker</code> (å‘masteræ³¨å†Œè‡ªå·±)</li>
      <li><code class="language-plaintext highlighter-rouge">Heartbeat</code> (å®šæœŸå‘masterå‘é€å¿ƒè·³ä¿¡æ¯)</li>
      <li><code class="language-plaintext highlighter-rouge">ExecutorStateChanged</code> (å‘masterå‘é€ExecutorçŠ¶æ€æ”¹å˜ä¿¡æ¯)</li>
    </ol>
  </li>
</ul>

<p>#Deployæ¨¡å—ä»£ç è¯¦è§£#</p>

<p>Deployæ¨¡å—ç›¸æ¯”äºscheduleræ¨¡å—ç®€å•ï¼Œå› æ­¤å¯¹äºdeployæ¨¡å—çš„ä»£ç å¹¶ä¸åšååˆ†ç»†èŠ‚çš„åˆ†æï¼Œåªé’ˆå¯¹applicationçš„æäº¤å’Œç»“æŸè¿‡ç¨‹åšä¸€å®šçš„åˆ†æã€‚</p>

<h2 id="clientæäº¤application">Clientæäº¤application</h2>

<p>Clientæ˜¯ç”±<code class="language-plaintext highlighter-rouge">SparkDeploySchedulerBackend</code>åˆ›å»ºè¢«å¯åŠ¨çš„ï¼Œå› æ­¤clientæ˜¯è¢«åµŒå…¥åœ¨æ¯ä¸€ä¸ªapplicationä¸­ï¼Œåªä¸ºè¿™ä¸ªapplicatoræ‰€æœåŠ¡ï¼Œåœ¨clientå¯åŠ¨æ—¶é¦–å…ˆä¼šå…ˆmasteræ³¨å†Œapplicationï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def start() {
  // Just launch an actor; it will call back into the listener.
  actor = actorSystem.actorOf(Props(new ClientActor))
}

override def preStart() {
  logInfo("Connecting to master " + masterUrl)
  try {
    master = context.actorFor(Master.toAkkaUrl(masterUrl))
    masterAddress = master.path.address
    master ! RegisterApplication(appDescription) //å‘masteræ³¨å†Œapplication
    context.system.eventStream.subscribe(self, classOf[RemoteClientLifeCycleEvent])
    context.watch(master)  // Doesn't work with remote actors, but useful for testing
  } catch {
    case e: Exception =&gt;
      logError("Failed to connect to master", e)
      markDisconnected()
      context.stop(self)
  }
}
</code></pre></div></div>

<p>Masteråœ¨æ”¶åˆ°<code class="language-plaintext highlighter-rouge">RegisterApplication</code>è¯·æ±‚åä¼šæŠŠapplicationåŠ åˆ°ç­‰å¾…é˜Ÿåˆ—ä¸­ï¼Œç­‰å¾…è°ƒåº¦ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>case RegisterApplication(description) =&gt; {
  logInfo("Registering app " + description.name)
  val app = addApplication(description, sender)
  logInfo("Registered app " + description.name + " with ID " + app.id)
  waitingApps += app
  context.watch(sender)  // This doesn't work with remote actors but helps for testing
  sender ! RegisteredApplication(app.id)
  schedule()
}
</code></pre></div></div>

<p>Masterä¼šåœ¨æ¯æ¬¡æ“ä½œåè°ƒç”¨<code class="language-plaintext highlighter-rouge">schedule()</code>å‡½æ•°ï¼Œä»¥ç¡®ä¿ç­‰å¾…çš„applicationèƒ½å¤Ÿè¢«åŠæ—¶è°ƒåº¦ã€‚</p>

<p>åœ¨å‰é¢æåˆ°deployæ¨¡å—æ˜¯èµ„æºç®¡ç†æ¨¡å—ï¼Œé‚£ä¹ˆSparkçš„deployç®¡ç†çš„æ˜¯ä»€ä¹ˆèµ„æºï¼Œèµ„æºä»¥ä»€ä¹ˆå•ä½è¿›è¡Œè°ƒåº¦çš„å‘¢ï¼Ÿåœ¨å½“å‰ç‰ˆæœ¬çš„Sparkä¸­ï¼Œé›†ç¾¤çš„cpuæ•°é‡æ˜¯Sparkèµ„æºç®¡ç†çš„ä¸€ä¸ªæ ‡å‡†ï¼Œæ¯ä¸ªæäº¤çš„applicationéƒ½ä¼šæ ‡æ˜è‡ªå·±æ‰€éœ€è¦çš„èµ„æºæ•°(ä¹Ÿå°±æ˜¯cpuçš„coreæ•°)ï¼ŒMasterä»¥FIFOçš„æ–¹å¼ç®¡ç†æ‰€æœ‰çš„applicationè¯·æ±‚ï¼Œå½“èµ„æºæ•°é‡æ»¡è¶³å½“å‰ä»»åŠ¡æ‰§è¡Œéœ€æ±‚çš„æ—¶å€™è¯¥ä»»åŠ¡å°±ä¼šè¢«è°ƒåº¦ï¼Œå¦åˆ™å°±ç»§ç»­ç­‰å¾…ï¼Œå½“ç„¶å¦‚æœmasterèƒ½ç»™äºˆå½“å‰ä»»åŠ¡éƒ¨åˆ†èµ„æºåˆ™ä¹Ÿä¼šå¯åŠ¨è¯¥applicationã€‚<code class="language-plaintext highlighter-rouge">schedule()</code>å‡½æ•°å®ç°çš„å°±æ˜¯æ­¤åŠŸèƒ½ã€‚</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def schedule() {
  if (spreadOutApps) {
    for (app &lt;- waitingApps if app.coresLeft &gt; 0) {
      val usableWorkers = workers.toArray.filter(_.state == WorkerState.ALIVE)
                                 .filter(canUse(app, _)).sortBy(_.coresFree).reverse
      val numUsable = usableWorkers.length
      val assigned = new Array[Int](numUsable) // Number of cores to give on each node
      var toAssign = math.min(app.coresLeft, usableWorkers.map(_.coresFree).sum)
      var pos = 0
      while (toAssign &gt; 0) {
        if (usableWorkers(pos).coresFree - assigned(pos) &gt; 0) {
          toAssign -= 1
          assigned(pos) += 1
        }
        pos = (pos + 1) % numUsable
      }
      // Now that we've decided how many cores to give on each node, let's actually give them
      for (pos &lt;- 0 until numUsable) {
        if (assigned(pos) &gt; 0) {
          val exec = app.addExecutor(usableWorkers(pos), assigned(pos))
          launchExecutor(usableWorkers(pos), exec, app.desc.sparkHome)
          app.state = ApplicationState.RUNNING
        }
      }
    }
  } else {
    // Pack each app into as few nodes as possible until we've assigned all its cores
    for (worker &lt;- workers if worker.coresFree &gt; 0 &amp;&amp; worker.state == WorkerState.ALIVE) {
      for (app &lt;- waitingApps if app.coresLeft &gt; 0) {
        if (canUse(app, worker)) {
          val coresToUse = math.min(worker.coresFree, app.coresLeft)
          if (coresToUse &gt; 0) {
            val exec = app.addExecutor(worker, coresToUse)
            launchExecutor(worker, exec, app.desc.sparkHome)
            app.state = ApplicationState.RUNNING
          }
        }
      }
    }
  }
}
</code></pre></div></div>

<p>å½“applicationå¾—åˆ°è°ƒåº¦åå°±ä¼šè°ƒç”¨<code class="language-plaintext highlighter-rouge">launchExecutor()</code>å‘workerå‘é€è¯·æ±‚ï¼ŒåŒæ—¶å‘clientæ±‡æŠ¥çŠ¶æ€ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def launchExecutor(worker: WorkerInfo, exec: ExecutorInfo, sparkHome: String) {
  worker.addExecutor(exec)
  worker.actor ! LaunchExecutor(exec.application.id, exec.id, exec.application.desc, exec.cores, exec.memory, sparkHome)
  exec.application.driver ! ExecutorAdded(exec.id, worker.id, worker.host, exec.cores, exec.memory)
}
</code></pre></div></div>

<p>è‡³æ­¤clientä¸masterçš„äº¤äº’å·²ç»è½¬å‘äº†masterä¸workerçš„äº¤äº’ï¼Œworkeréœ€è¦é…ç½®applicationå¯åŠ¨ç¯å¢ƒ</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>case LaunchExecutor(appId, execId, appDesc, cores_, memory_, execSparkHome_) =&gt;
  val manager = new ExecutorRunner(
    appId, execId, appDesc, cores_, memory_, self, workerId, ip, new File(execSparkHome_), workDir)
  executors(appId + "/" + execId) = manager
  manager.start()
  coresUsed += cores_
  memoryUsed += memory_
  master ! ExecutorStateChanged(appId, execId, ExecutorState.RUNNING, None, None)
</code></pre></div></div>

<p>Workeråœ¨æ¥æ”¶åˆ°<code class="language-plaintext highlighter-rouge">LaunchExecutor</code>æ¶ˆæ¯ååˆ›å»º<code class="language-plaintext highlighter-rouge">ExecutorRunner</code>å®ä¾‹ï¼ŒåŒæ—¶æ±‡æŠ¥master executorç¯å¢ƒå¯åŠ¨ã€‚</p>

<p><code class="language-plaintext highlighter-rouge">ExecutorRunner</code>åœ¨å¯åŠ¨çš„è¿‡ç¨‹ä¸­ä¼šåˆ›å»ºçº¿ç¨‹ï¼Œé…ç½®ç¯å¢ƒï¼Œå¯åŠ¨æ–°è¿›ç¨‹ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def start() {
  workerThread = new Thread("ExecutorRunner for " + fullId) {
    override def run() { fetchAndRunExecutor() }
  }
  workerThread.start()

  // Shutdown hook that kills actors on shutdown.
  ...
}

def fetchAndRunExecutor() {
  try {
    // Create the executor's working directory
    val executorDir = new File(workDir, appId + "/" + execId)
    if (!executorDir.mkdirs()) {
      throw new IOException("Failed to create directory " + executorDir)
    }

    // Launch the process
    val command = buildCommandSeq()
    val builder = new ProcessBuilder(command: _*).directory(executorDir)
    val env = builder.environment()
    for ((key, value) &lt;- appDesc.command.environment) {
      env.put(key, value)
    }
    env.put("SPARK_MEM", memory.toString + "m")
    // In case we are running this from within the Spark Shell, avoid creating a "scala"
    // parent process for the executor command
    env.put("SPARK_LAUNCH_WITH_SCALA", "0")
    process = builder.start()

    // Redirect its stdout and stderr to files
    redirectStream(process.getInputStream, new File(executorDir, "stdout"))
    redirectStream(process.getErrorStream, new File(executorDir, "stderr"))

    // Wait for it to exit; this is actually a bad thing if it happens, because we expect to run
    // long-lived processes only. However, in the future, we might restart the executor a few
    // times on the same machine.
    val exitCode = process.waitFor()
    val message = "Command exited with code " + exitCode
    worker ! ExecutorStateChanged(appId, execId, ExecutorState.FAILED, Some(message),
                                  Some(exitCode))
  } catch {
    case interrupted: InterruptedException =&gt;
      logInfo("Runner thread for executor " + fullId + " interrupted")

    case e: Exception =&gt; {
      logError("Error running executor", e)
      if (process != null) {
        process.destroy()
      }
      val message = e.getClass + ": " + e.getMessage
      worker ! ExecutorStateChanged(appId, execId, ExecutorState.FAILED, Some(message), None)
    }
  }
}
</code></pre></div></div>

<p>åœ¨<code class="language-plaintext highlighter-rouge">ExecutorRunner</code>å¯åŠ¨åworkerå‘masteræ±‡æŠ¥<code class="language-plaintext highlighter-rouge">ExecutorStateChanged</code>ï¼Œè€Œmasteråˆ™å°†æ¶ˆæ¯é‡æ–°packæˆä¸º<code class="language-plaintext highlighter-rouge">ExecutorUpdated</code>å‘é€ç»™clientã€‚</p>

<p>è‡³æ­¤æ•´ä¸ªapplicationæäº¤è¿‡ç¨‹åŸºæœ¬ç»“æŸï¼Œæäº¤çš„è¿‡ç¨‹å¹¶ä¸å¤æ‚ï¼Œä¸»è¦æ¶‰åŠåˆ°çš„æ¶ˆæ¯çš„ä¼ é€’ã€‚</p>

<h2 id="applicationçš„ç»“æŸ">Applicationçš„ç»“æŸ</h2>

<p>ç”±äºå„ç§åŸå› (åŒ…æ‹¬æ­£å¸¸ç»“æŸï¼Œå¼‚å¸¸è¿”å›ç­‰)ä¼šé€ æˆapplicationçš„ç»“æŸï¼Œæˆ‘ä»¬ç°åœ¨å°±æ¥çœ‹çœ‹applicatoinç»“æŸçš„æ•´ä¸ªæµç¨‹ã€‚</p>

<p>applicationçš„ç»“æŸå¾€å¾€ä¼šé€ æˆclientçš„ç»“æŸï¼Œè€Œclientçš„ç»“æŸä¼šè¢«masteré€šè¿‡<code class="language-plaintext highlighter-rouge">Actor</code>æ£€æµ‹åˆ°ï¼Œmasteræ£€æµ‹åˆ°åä¼šè°ƒç”¨<code class="language-plaintext highlighter-rouge">removeApplication()</code>å‡½æ•°è¿›è¡Œæ“ä½œï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def removeApplication(app: ApplicationInfo) {
  if (apps.contains(app)) {
    logInfo("Removing app " + app.id)
    apps -= app
    idToApp -= app.id
    actorToApp -= app.driver
    addressToWorker -= app.driver.path.address
    completedApps += app   // Remember it in our history
    waitingApps -= app
    for (exec &lt;- app.executors.values) {
      exec.worker.removeExecutor(exec)
      exec.worker.actor ! KillExecutor(exec.application.id, exec.id)
    }
    app.markFinished(ApplicationState.FINISHED)  // TODO: Mark it as FAILED if it failed
    schedule()
  }
}
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">removeApplicatoin()</code>é¦–å…ˆä¼šå°†applicationä»masterè‡ªèº«æ‰€ç®¡ç†çš„æ•°æ®ç»“æ„ä¸­åˆ é™¤ï¼Œå…¶æ¬¡å®ƒä¼šé€šçŸ¥æ¯ä¸€ä¸ªworkï¼Œè¯·æ±‚å…¶<code class="language-plaintext highlighter-rouge">KillExecutor</code>ã€‚workeråœ¨æ”¶åˆ°<code class="language-plaintext highlighter-rouge">KillExecutor</code>åè°ƒç”¨<code class="language-plaintext highlighter-rouge">ExecutorRunner</code>çš„<code class="language-plaintext highlighter-rouge">kill()</code>å‡½æ•°ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>case KillExecutor(appId, execId) =&gt;
  val fullId = appId + "/" + execId
  executors.get(fullId) match {
    case Some(executor) =&gt;
      logInfo("Asked to kill executor " + fullId)
      executor.kill()
    case None =&gt;
      logInfo("Asked to kill unknown executor " + fullId)
  }
</code></pre></div></div>

<p>åœ¨<code class="language-plaintext highlighter-rouge">ExecutorRunner</code>å†…éƒ¨ï¼Œå®ƒä¼šç»“æŸç›‘æ§çº¿ç¨‹ï¼ŒåŒæ—¶ç»“æŸç›‘æ§çº¿ç¨‹æ‰€å¯åŠ¨çš„è¿›ç¨‹ï¼Œå¹¶ä¸”å‘workeræ±‡æŠ¥<code class="language-plaintext highlighter-rouge">ExecutorStateChanged</code>ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def kill() {
  if (workerThread != null) {
    workerThread.interrupt()
    workerThread = null
    if (process != null) {
      logInfo("Killing process!")
      process.destroy()
      process.waitFor()
    }
    worker ! ExecutorStateChanged(appId, execId, ExecutorState.KILLED, None, None)
    Runtime.getRuntime.removeShutdownHook(shutdownHook)
  }
}
</code></pre></div></div>

<p>Applicationç»“æŸçš„åŒæ—¶æ¸…ç†äº†masterå’Œworkerä¸Šçš„å…³äºè¯¥applicationçš„æ‰€æœ‰ä¿¡æ¯ï¼Œè¿™æ ·å…³äºapplicationç»“æŸçš„æ•´ä¸ªæµç¨‹å°±ä»‹ç»å®Œäº†ï¼Œå½“ç„¶åœ¨è¿™é‡Œæˆ‘ä»¬å¯¹äºè®¸å¤šå¼‚å¸¸å¤„ç†åˆ†æ”¯æ²¡æœ‰ç»†ç©¶ï¼Œä½†è¿™å¹¶ä¸å½±å“æˆ‘ä»¬å¯¹ä¸»çº¿çš„æŠŠæ¡ã€‚</p>

<h1 id="end">End</h1>

<p>è‡³æ­¤å¯¹äºdeployæ¨¡å—çš„åˆ†ææš‚å‘Šä¸€ä¸ªæ®µè½ã€‚deployæ¨¡å—ç›¸å¯¹æ¥è¯´æ¯”è¾ƒç®€å•ï¼Œä¹Ÿæ²¡æœ‰ç‰¹åˆ«å¤æ‚çš„é€»è¾‘ç»“æ„ï¼Œæ­£å¦‚å‰é¢æ‰€è¯´çš„deployæ¨¡å—æ˜¯ä¸ºäº†èƒ½è®©æ›´å¤šçš„æ²¡æœ‰éƒ¨ç½²Mesosçš„é›†ç¾¤çš„ç”¨æˆ·èƒ½å¤Ÿä½¿ç”¨Sparkè€Œå®ç°çš„ä¸€ç§æ–¹æ¡ˆã€‚</p>

<p>å½“ç„¶ç°é˜¶æ®µçœ‹æ¥è¿˜ç•¥å¾®ç®€é™‹ï¼Œæ¯”å¦‚applicationçš„è°ƒåº¦æ–¹å¼(FIFO)æ˜¯å¦ä¼šé€ æˆå°åº”ç”¨é•¿æ—¶é—´ç­‰å¾…å¤§åº”ç”¨çš„ç»“æŸï¼Œæ˜¯å¦æœ‰æ›´å¥½çš„è°ƒåº¦ç­–ç•¥ï¼›èµ„æºçš„è¡¡é‡æ ‡å‡†æ˜¯å¦å¯ä»¥æ›´å¤šæ›´åˆç†ï¼Œè€Œä¸å•å•æ˜¯cpuæ•°é‡ï¼Œå› ä¸ºç°å®åœºæ™¯ä¸­æœ‰çš„åº”ç”¨æ˜¯disk intensiveï¼Œæœ‰çš„æ˜¯network intensiveï¼Œè¿™æ ·å°±ç®—cpuèµ„æºæœ‰å¯Œä½™ï¼Œè°ƒåº¦æ–°çš„applicationä¹Ÿä¸ä¸€å®šä¼šå¾ˆæœ‰æ„ä¹‰ã€‚</p>

<p>æ€»çš„æ¥è¯´ä½œä¸ºMesosçš„ä¸€ç§ç®€å•æ›¿ä»£æ–¹å¼ï¼Œdeployæ¨¡å—å¯¹äºæ¨å¹¿Sparkè¿˜æ˜¯æœ‰ç§¯ææ„ä¹‰çš„ã€‚</p>
:ET